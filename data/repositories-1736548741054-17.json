{
  "metadata": {
    "timestamp": 1736548741054,
    "page": 17,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE3MA=="
  },
  "repositories": [
    {
      "nameWithOwner": "leonardomso/33-js-concepts",
      "stars": 64360,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".DS_Store",
          "type": "blob",
          "size": 6,
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.93,
          "content": "# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\n\n# nyc test coverage\n.nyc_output\n\n# Grunt intermediate storage (http://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# Bower dependency directory (https://bower.io/)\nbower_components\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (https://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/\n\n# TypeScript v1 declaration files\ntypings/\n\n# Optional npm cache directory\n.npm\n\n# Optional eslint cache\n.eslintcache\n\n# Optional REPL history\n.node_repl_history\n\n# Output of 'npm pack'\n*.tgz\n\n# Yarn Integrity file\n.yarn-integrity\n\n# dotenv environment variables file\n.env\n\n# next.js build output\n.next\n\n# webstore IDE created directory\n.idea\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.09,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to participate in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity includes:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct that could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public areas.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nleonardomso11@gmail.com.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.1,
          "content": "# Contribution\nThis project would not be possible without your help and support, and we appreciate your willingness to contribute!\n\n### Creating a New Translation\n\nTo create a new translation, please follow these steps:\n\n* Fork the [main repository](https://github.com/leonardomso/33-js-concepts).\n* Add yourself to the watch list of the main repository to stay updated with any changes.\n* Translate the repository on your forked copy.\n* Go to the [main repository](https://github.com/leonardomso/33-js-concepts) and edit the README.md file to include a link to your translated repository.\n* Inside the **Community** section, add a new line with the link to your translated repository in the following format:\n  * [Your language in native form (English name)](link to your repository here) — Your Name\n  * For example, `[日本語 (Japanese)](https://github.com/oimo23/33-js-concepts) — oimo23`\n* Create a new Pull Request with the name \"Add *your language here* translation.\"\n* Now, just wait for the merge!\n\n## License\nBy contributing, you agree that your contributions will be licensed under the [MIT license](./LICENSE).\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.05,
          "content": "MIT License\n\nCopyright (c) 2018 Leonardo Maldonado\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 112.52,
          "content": "<h1 align=\"center\">\n<br>\n  <a href=\"https://github.com/leonardomso/33\"><img src=\"https://i.imgur.com/dsHmk6H.jpg\" alt=\"33 Concepts Every JS Developer Should Know\" width=200\" /></a>\n  <br>\n    <br>\n  33 Concepts Every JavaScript Developer Should Know\n  <br><br>\n</h1>\n\n## Introduction \n\nThis repository was created with the intention of helping developers master their concepts in JavaScript. It is not a requirement, but a guide for future studies. It is based on an article written by Stephen Curtis and you can read it [here](https://medium.com/@stephenthecurt/33-fundamentals-every-javascript-developer-should-know-13dd720a90d1).\n\n**🚀 Considered by GitHub as one of the [top open source projects of 2018!](https://blog.github.com/2018-12-13-new-open-source-projects/)**\n\n## Community\n\nFeel free to submit a PR by adding a link to your own recaps or reviews. If you want to translate the repo into your native language, please feel free to do so.\n\nAll the translations for this repo will be listed below:\n\n- [اَلْعَرَبِيَّةُ‎ (Arabic)](https://github.com/amrsekilly/33-js-concepts) — Amr Elsekilly\n- [Български (Bulgarian)](https://github.com/thewebmasterp/33-js-concepts) - thewebmasterp\n- [汉语 (Chinese)](https://github.com/stephentian/33-js-concepts) — Re Tian\n- [Português do Brasil (Brazilian Portuguese)](https://github.com/tiagoboeing/33-js-concepts) — Tiago Boeing\n- [한국어 (Korean)](https://github.com/yjs03057/33-js-concepts.git) — Suin Lee\n- [Español (Spanish)](https://github.com/adonismendozaperez/33-js-conceptos) — Adonis Mendoza\n- [Türkçe (Turkish)](https://github.com/ilker0/33-js-concepts) — İlker Demir\n- [русский язык (Russian)](https://github.com/gumennii/33-js-concepts) — Mihail Gumennii\n- [Tiếng Việt (Vietnamese)](https://github.com/nguyentranchung/33-js-concepts) — Nguyễn Trần Chung\n- [Polski (Polish)](https://github.com/lip3k/33-js-concepts) — Dawid Lipinski\n- [فارسی (Persian)](https://github.com/majidalavizadeh/33-js-concepts) — Majid Alavizadeh\n- [Bahasa Indonesia (Indonesian)](https://github.com/rijdz/33-js-concepts) — Rijdzuan Sampoerna\n- [Français (French)](https://github.com/robinmetral/33-concepts-js) — Robin Métral\n- [हिन्दी (Hindi)](https://github.com/vikaschauhan/33-js-concepts) — Vikas Chauhan\n- [Ελληνικά (Greek)](https://github.com/DimitrisZx/33-js-concepts) — Dimitris Zarachanis\n- [日本語 (Japanese)](https://github.com/oimo23/33-js-concepts) — oimo23\n- [Deutsch (German)](https://github.com/burhannn/33-js-concepts) — burhannn\n- [украї́нська мо́ва (Ukrainian)](https://github.com/AndrewSavetchuk/33-js-concepts-ukrainian-translation) — Andrew Savetchuk\n- [සිංහල (Sinhala)](https://github.com/ududsha/33-js-concepts) — Udaya Shamendra\n- [Italiano (Italian)](https://github.com/Donearm/33-js-concepts) — Gianluca Fiore\n- [Latviešu (Latvian)](https://github.com/ANormalStick/33-js-concepts) - Jānis Īvāns\n- [Afaan Oromoo (Oromo)](https://github.com/Amandagne/33-js-concepts) - Amanuel Dagnachew\n- [ภาษาไทย (Thai)](https://github.com/ninearif/33-js-concepts) — Arif Waram\n- [Català (Catalan)](https://github.com/marioestradaf/33-js-concepts) — Mario Estrada\n- [Svenska (Swedish)](https://github.com/FenixHongell/33-js-concepts/) — Fenix Hongell\n- [ខ្មែរ (Khmer)](https://github.com/Chhunneng/33-js-concepts) — Chrea Chanchhunneng\n- [አማርኛ (Ethiopian)](https://github.com/hmhard/33-js-concepts) - Miniyahil Kebede(ምንያህል ከበደ)\n- [Беларуская мова (Belarussian)](https://github.com/Yafimau/33-js-concepts) — Dzianis Yafimau\n- [O'zbekcha (Uzbek)](https://github.com/smnv-shokh/33-js-concepts) — Shokhrukh Usmonov\n- [Urdu (اردو)](https://github.com/sudoyasir/33-js-concepts) — Yasir Nawaz\n- [Marathi (मराठी)](https://github.com/dhruvchandak30/33-js-concepts) - Dhruv Chandak\n- [हिन्दी (Hindi)](https://github.com/milostivyy/33-js-concepts) — Mahima Chauhan\n- [বাংলা (Bengali)](https://github.com/Jisan-mia/33-js-concepts) — Jisan Mia\n- [ગુજરાતી (Gujarati)](https://github.com/VatsalBhuva11/33-js-concepts) — Vatsal Bhuva\n- [سنڌي (Sindhi)](https://github.com/Sunny-unik/33-js-concepts) — Sunny Gandhwani\n- [भोजपुरी (Bhojpuri)](https://github.com/debnath003/33-js-concepts) — Pronay Debnath\n- [ਪੰਜਾਬੀ (Punjabi)](https://github.com/Harshdev098/33-js-concepts) — Harsh Dev Pathak\n- [தமிழ் (Tamil)](https://github.com/Jaimin25/33-js-concepts) - Jaimin Chovatia\n- [Latin (Latin)](https://github.com/Harshdev098/33-js-concepts) — Harsh Dev Pathak\n- [മലയാളം (Malayalam)](https://github.com/Stark-Akshay/33-js-concepts) — Akshay Manoj\n- [Yorùbá (Yoruba)](https://github.com/ayobaj/33-js-concepts) - Ayomide Bajulaye\n- [עברית‎ (Hebrew)](https://github.com/rafyzg/33-js-concepts) — Refael Yzgea\n\n---\n## <img  align= center width=50px height=50px src=\"https://media4.giphy.com/media/3hoLIVAJYkz6T0Ichp/giphy.gif?cid=6c09b952m4j3poopinf91rquev6qy4e8avu0bflq1e0vh4gp&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=s\"> <a id=\"table-of-contents\">Table of Contents</a>\n\n1. **[Call Stack](#1-call-stack)**\n2. **[Primitive Types](#2-primitive-types)**\n3. **[Value Types and Reference Types](#3-value-types-and-reference-types)**\n4. **[Implicit, Explicit, Nominal, Structuring and Duck Typing](#4-implicit-explicit-nominal-structuring-and-duck-typing)**\n5. **[== vs === vs typeof](#5--vs--vs-typeof)**\n6. **[Function Scope, Block Scope and Lexical Scope](#6-function-scope-block-scope-and-lexical-scope)**\n7. **[Expression vs Statement](#7-expression-vs-statement)**\n8. **[IIFE, Modules and Namespaces](#8-iife-modules-and-namespaces)**\n9. **[Message Queue and Event Loop](#9-message-queue-and-event-loop)**\n10. **[setTimeout, setInterval and requestAnimationFrame](#10-settimeout-setinterval-and-requestanimationframe)**\n11. **[JavaScript Engines](#11-javascript-engines)**\n12. **[Bitwise Operators, Type Arrays and Array Buffers](#12-bitwise-operators-type-arrays-and-array-buffers)**\n13. **[DOM and Layout Trees](#13-dom-and-layout-trees)**\n14. **[Factories and Classes](#14-factories-and-classes)**\n15. **[this, call, apply and bind](#15-this-call-apply-and-bind)**\n16. **[new, Constructor, instanceof and Instances](#16-new-constructor-instanceof-and-instances)**\n17. **[Prototype Inheritance and Prototype Chain](#17-prototype-inheritance-and-prototype-chain)**\n18. **[Object.create and Object.assign](#18-objectcreate-and-objectassign)**\n19. **[map, reduce, filter](#19-map-reduce-filter)**\n20. **[Pure Functions, Side Effects, State Mutation and Event Propagation](#20-pure-functions-side-effects-state-mutation-and-event-propagation)**\n21. **[Closures](#21-closures)**\n22. **[High Order Functions](#22-high-order-functions)**\n23. **[Recursion](#23-recursion)**\n24. **[Collections and Generators](#24-collections-and-generators)**\n25. **[Promises](#25-promises)**\n26. **[async/await](#26-asyncawait)**\n27. **[Data Structures](#27-data-structures)**\n28. **[Expensive Operation and Big O Notation](#28-expensive-operation-and-big-o-notation)**\n29. **[Algorithms](#29-algorithms)**\n30. **[Inheritance, Polymorphism and Code Reuse](#30-inheritance-polymorphism-and-code-reuse)**\n31. **[Design Patterns](#31-design-patterns)**\n32. **[Partial Applications, Currying, Compose and Pipe](#32-partial-applications-currying-compose-and-pipe)**\n33. **[Clean Code](#33-clean-code)**\n\n---\n\n## 1. Call Stack\n\nThe call stack is a mechanism that the JavaScript interpreter uses to keep track of function execution within a program. In JavaScript, functions are executed in the order they are called. The call stack follows the Last In, First Out (LIFO) principle, meaning that the last function pushed onto the stack is the first one to be executed.\n\nAccording to the ECMAScript specification, the call stack is defined as part of the execution context. Whenever a function is called, a new execution context is created and placed at the top of the stack. Once the function completes, its execution context is removed from the stack, and control returns to the previous context. This helps manage synchronous code execution, as each function call must complete before the next one can begin.\n\n### Reference\n\n-  [Call Stack — MDN](https://developer.mozilla.org/en-US/docs/Glossary/Call_stack)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n- [Understanding Javascript Call Stack, Event Loops — Gaurav Pandvia](https://medium.com/@gaurav.pandvia/understanding-javascript-function-executions-tasks-event-loop-call-stack-more-part-1-5683dea1f5ec)\n- [Understanding the JavaScript Call Stack — Charles Freeborn](https://medium.freecodecamp.org/understanding-the-javascript-call-stack-861e41ae61d4)\n-  [Javascript: What Is The Execution Context? What Is The Call Stack? — Valentino Gagliardi](https://medium.com/@valentinog/javascript-what-is-the-execution-context-what-is-the-call-stack-bd23c78f10d1)\n-  [What is the JS Event Loop and Call Stack? — Jess Telford](https://gist.github.com/jesstelford/9a35d20a2aa044df8bf241e00d7bc2d0)\n-  [Understanding Execution Context and Execution Stack in Javascript — Sukhjinder Arora](https://blog.bitsrc.io/understanding-execution-context-and-execution-stack-in-javascript-1c9ea8642dd0)\n-  [How JavaScript Works Under The Hood: An Overview of JavaScript Engine, Heap and, Call Stack — Bipin Rajbhar](https://dev.to/bipinrajbhar/how-javascript-works-under-the-hood-an-overview-of-javascript-engine-heap-and-call-stack-1j5o)\n-  [The JS Call stack Explained in 9 minutes](https://www.youtube.com/watch?v=W8AeMrVtFLY) - Colt Steel (YouTube)\n-  [Call Stack in JavaScript - Syed Rafsan Raiyan](https://srafsan.hashnode.dev/call-stack-in-javascript)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Javascript: the Call Stack explained — Coding Blocks India](https://www.youtube.com/watch?v=w6QGEiQceOM)\n- [The JS Call Stack Explained In 9 Minutes — Colt Steele](https://www.youtube.com/watch?v=W8AeMrVtFLY)\n- [What is the Call Stack? — Eric Traub](https://www.youtube.com/watch?v=w7QWQlkLY_s)\n- [The Call Stack — Kevin Drumm](https://www.youtube.com/watch?v=Q2sFmqvpBe0)\n- [Understanding JavaScript Execution — Codesmith](https://www.youtube.com/watch?v=Z6a1cLyq7Ac&list=PLWrQZnG8l0E4kd1T_nyuVoxQUaYEWFgcD)\n- [What the heck is the event loop anyway? — Philip Roberts](https://www.youtube.com/watch?v=8aGhZQkoFbQ)\n- [How JavaScript Code is executed? ❤️& Call Stack — Akshay Saini](https://www.youtube.com/watch?v=iLWTnMzWtj4&list=PLlasXeu85E9cQ32gLCvAvr9vNaUccPVNP)\n- [Call Stacks - CS50](https://www.youtube.com/watch?v=aCPkszeKRa4)\n- [Learn the JavaScript Call Stack - codecupdev](https://www.youtube.com/watch?v=HXqXPGS96rw)\n- [JavaScript Functions and the Call Stack | How does the Call stack work - Chidre'sTechTutorials](https://www.youtube.com/watch?v=P6H-T4cUDR4)\n    \n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 2. Primitive Types\nAccording to the ECMAScript specification, JavaScript has six primitive data types: string, number, bigint, boolean, undefined, and symbol. These types are immutable, meaning their values cannot be altered. There is also a special primitive type called null, which represents the intentional absence of any object value.\n\nPrimitive values are directly assigned to a variable, and when you manipulate a primitive type, you're working directly on the value. Unlike objects, primitives do not have properties or methods, but JavaScript automatically wraps primitive values with object counterparts when necessary (e.g., when calling methods on strings).\n\n### Reference\n\n-  [JavaScript data types and data structures — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Primitive_values)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Primitive and Non-primitive data-types in JavaScript - GeeksforGeeks](https://www.geeksforgeeks.org/primitive-and-non-primitive-data-types-in-javascript)\n-  [Javascript variables (Beginner thinking)](https://robiul.dev/javascript-variables-beginner-thinking)\n-  [How numbers are encoded in JavaScript — Dr. Axel Rauschmayer](http://2ality.com/2012/04/number-encoding.html)\n-  [What You Need to Know About JavaScript Number Type — Max Wizard K](https://indepth.dev/posts/1139/here-is-what-you-need-to-know-about-javascripts-number-type)\n-  [What Every JavaScript Developer Should Know About Floating Point Numbers — Chewxy](https://blog.chewxy.com/2014/02/24/what-every-javascript-developer-should-know-about-floating-point-numbers/)\n-  [The Secret Life of JavaScript Primitives — Angus Croll](https://javascriptweblog.wordpress.com/2010/09/27/the-secret-life-of-javascript-primitives/)\n-  [Primitive Types — Flow](https://flow.org/en/docs/types/primitives/)\n-  [(Not) Everything in JavaScript is an Object — Daniel Li](https://dev.to/d4nyll/not-everything-in-javascript-is-an-object)\n-  [JavaScript data types and data structures — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Primitive_values)\n-  [Diving Deeper in JavaScripts Objects — Arfat Salman](https://blog.bitsrc.io/diving-deeper-in-javascripts-objects-318b1e13dc12)\n-  [The differences between Object.freeze() vs Const in JavaScript — Bolaji Ayodeji](https://medium.com/@bolajiayodeji/the-differences-between-object-freeze-vs-const-in-javascript-4eacea534d7c)\n-  [Object to primitive conversion — JavaScript.info](https://javascript.info/object-toprimitive)\n- [Methods of primitives - Javascript.info](https://javascript.info/primitives-methods)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript Reference vs Primitive Types — Academind](https://www.youtube.com/watch?v=9ooYYRLdg_g)\n- [JavaScript Primitive Types — Simon Sez IT](https://www.youtube.com/watch?v=HsbWQsSCE5Y)\n- [Value Types and Reference Types in JavaScript — Programming with Mosh](https://www.youtube.com/watch?v=e-_mDyqm2oU)\n- [JavaScript Primitive Data Types — Avelx](https://www.youtube.com/watch?v=qw3j0A3DIzQ)\n- [Everything you never wanted to know about JavaScript numbers — Bartek Szopka](https://www.youtube.com/watch?v=MqHDDtVYJRI)\n- [What are variables in Javascript? — JS For Everyone](https://www.youtube.com/watch?v=B4Bbmei_thw)\n- [TIPOS DE DATOS PRIMITIVOS en JAVASCRIPT - La Cocina del Código](https://www.youtube.com/watch?v=cC65D2q5f8I)\n- [Data Type in JavaScript - ScholarHat](https://www.youtube.com/watch?v=aFDvBjVjCh8)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 3. Value Types and Reference Types\nAccording to the ECMAScript specification, value types are stored directly in the location that the variable accesses. These include types like number, string, boolean, undefined, bigint, symbol, and null. When you assign a value type to a variable, the value itself is stored.\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Explaining Value vs. Reference in Javascript — Arnav Aggarwal](https://codeburst.io/explaining-value-vs-reference-in-javascript-647a975e12a0)\n-  [Primitive Types & Reference Types in JavaScript — Bran van der Meer](https://gist.github.com/branneman/7fb06d8a74d7e6d4cbcf75c50fec599c)\n-  [Value Types, Reference Types and Scope in JavaScript — Ben Aston](https://medium.com/@benastontweet/lesson-1b-javascript-fundamentals-380f601ba851)\n-  [Back to roots: JavaScript Value vs Reference — Miro Koczka](https://medium.com/dailyjs/back-to-roots-javascript-value-vs-reference-8fb69d587a18)\n-  [Grasp “By Value” and “By Reference” in JavaScript — Léna Faure](https://hackernoon.com/grasp-by-value-and-by-reference-in-javascript-7ed75efa1293)\n-  [JavaScript Reference and Copy Variables — Vítor Capretz](https://hackernoon.com/javascript-reference-and-copy-variables-b0103074fdf0)\n-  [JavaScript Primitive vs Reference Values](http://www.javascripttutorial.net/javascript-primitive-vs-reference-values/)\n-  [JavaScript by Reference vs. by Value — nrabinowitz](https://stackoverflow.com/questions/6605640/javascript-by-reference-vs-by-value)\n-  [JavaScript Interview Prep: Primitive vs. Reference Types — Mike Cronin](https://dev.to/mostlyfocusedmike/javascript-interview-prep-primitive-vs-reference-types-3o4f)\n-  [forEach method in JavaScript - A Comprehensive Guide](https://robiul.dev/foreach-method-in-javascript-a-comprehensive-guide)\n-  [JavaScript map vs. forEach: When to Use Each One - Sajal Soni](https://code.tutsplus.com/tutorials/javascript-map-vs-foreach-when-to-use-each-one--cms-38365)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Javascript Pass by Value vs Pass by Reference — techsith](https://www.youtube.com/watch?v=E-dAnFdq8k8)\n- [JavaScript Value vs Reference Types — Programming with Mosh](https://www.youtube.com/watch?v=fD0t_DKREbE)\n- [VALORES vs REFERENCIAS en JAVASCRIPT - La Cocina del Código](https://www.youtube.com/watch?v=AvkyOrWkuQc)\n- [JavaScript - Reference vs Primitive Values/ Types - Academind](https://www.youtube.com/watch?v=9ooYYRLdg_g)\n- [Value Types and Reference Types in JavaScript - Programming with Mosh](https://www.youtube.com/watch?v=e-_mDyqm2oU)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 4. Implicit, Explicit, Nominal, Structuring and Duck Typing\nThe ECMAScript specification defines JavaScript as a dynamically typed language, meaning that types are associated with values rather than variables, and type checking occurs at runtime. There are various ways JavaScript manages types:\n\nImplicit Typing (or Type Coercion): This occurs when JavaScript automatically converts one data type to another when required. For instance, JavaScript might convert a string to a number during an arithmetic operation. While this can simplify some code, it can also lead to unexpected results if not handled carefully.\n\nExplicit Typing: Unlike implicit typing, explicit typing involves manually converting a value from one type to another using functions like Number(), String(), or Boolean().\n\nNominal Typing: JavaScript doesn't natively support nominal typing, where types are explicitly declared and checked. However, TypeScript, a superset of JavaScript, brings this feature to help catch type errors during development.\n\nStructuring Typing: In this type system, types are based on the structure or properties of the data. JavaScript is a structurally typed language where objects are compatible if they share the same structure (i.e., the same set of properties and methods).\n\nDuck Typing: This is a concept where an object's suitability is determined by the presence of certain properties and methods, rather than by the actual type of the object. JavaScript relies heavily on duck typing, where behavior is inferred from an object's properties rather than its declared type.\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [What you need to know about Javascript's Implicit Coercion — Promise Tochi](https://dev.to/promhize/what-you-need-to-know-about-javascripts-implicit-coercion-e23)\n-  [JavaScript Type Coercion Explained — Alexey Samoshkin](https://medium.freecodecamp.org/js-type-coercion-explained-27ba3d9a2839)\n-  [Javascript Coercion Explained — Ben Garrison](https://hackernoon.com/javascript-coercion-explained-545c895213d3)\n-  [What exactly is Type Coercion in Javascript? - Stack Overflow](https://stackoverflow.com/questions/19915688/what-exactly-is-type-coercion-in-javascript)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [== ? === ??? ...#@^% - Shirmung Bielefeld](https://www.youtube.com/watch?v=qGyqzN0bjhc&t)\n- [Coercion in Javascript - Hitesh Choudhary](https://www.youtube.com/watch?v=b04Q_vyqEG8)\n- [JavaScript Questions: What is Coercion? - Steven Hancock](https://www.youtube.com/watch?v=z4-8wMSPJyI)\n- [Typing: Static vs Dynamic, Weak vs. Strong - Codexpanse](https://www.youtube.com/watch?v=C5fr0LZLMAs)\n- [EL SISTEMA de TIPOS DE JAVASCRIPT - La Cocina del Código](https://www.youtube.com/watch?v=0ei4nb49GKo)\n- [Duck Typing in Javascript - Techmaker Studio](https://www.youtube.com/watch?v=oEpgyoMEkrM)\n- [Duck Typing in Javascript - Programming with Kartik](https://youtu.be/e4X1KAuk6Bs?si=krZKbsM2i3tmIl2G)\n\n### Books\n\n- [You Don't Know JS, 1st Edition: Types & Grammar — Kyle Simpson](https://github.com/getify/You-Dont-Know-JS/tree/1st-ed)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 5. == vs === vs typeof\n According to the ECMAScript specification, JavaScript includes both strict (===) and loose (==) equality operators, which behave differently when comparing values. Here's a breakdown:\n\n== (Loose Equality): This operator performs type coercion before comparing two values. If the values are of different types, JavaScript will attempt to convert one or both values to a common type before comparison, which can lead to unexpected results.\n\n=== (Strict Equality): This operator compares both the value and the type without any type coercion. If the two values are not of the same type, the comparison will return false.\n\ntypeof Operator: The typeof operator is used to check the data type of a variable. While it's generally reliable, there are certain quirks, like how typeof null returns \"object\" instead of \"null\", due to a long-standing behavior in JavaScript's implementation.\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript Double Equals vs. Triple Equals — Brandon Morelli](https://codeburst.io/javascript-double-equals-vs-triple-equals-61d4ce5a121a)\n-  [Should I use === or == equality comparison operator in JavaScript? — Panu Pitkamaki](https://bytearcher.com/articles/equality-comparison-operator-javascript/)\n-  [Why Use the Triple-Equals Operator in JavaScript? — Louis Lazaris](https://www.impressivewebs.com/why-use-triple-equals-javascipt/)\n-  [What is the difference between == and === in JavaScript? — Craig Buckler](https://www.oreilly.com/learning/what-is-the-difference-between-and-in-javascript)\n-  [Why javascript's typeof always return \"object\"? — Stack Overflow](https://stackoverflow.com/questions/3787901/why-javascripts-typeof-always-return-object)\n-  [Checking Types in Javascript — Toby Ho](http://tobyho.com/2011/01/28/checking-types-in-javascript/)\n-  [How to better check data types in JavaScript — Webbjocke](https://webbjocke.com/javascript-check-data-types/)\n-  [Checking for the Absence of a Value in JavaScript — Tomer Aberbach](https://tomeraberba.ch/html/post/checking-for-the-absence-of-a-value-in-javascript.html)\n-  [Difference Between == and === in Javascript](https://www.scaler.com/topics/javascript/difference-between-double-equals-and-triple-equals-in-javascript/)    \n-  [Difference between == and === in JavaScript — GeeksforGeeks](https://www.geeksforgeeks.org/difference-between-double-equal-vs-triple-equal-javascript/)\n-  [=== vs == Comparision in JavaScript — FreeCodeCamp](https://www.freecodecamp.org/news/javascript-triple-equals-sign-vs-double-equals-sign-comparison-operators-explained-with-examples/)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript - The typeof operator — Java Brains](https://www.youtube.com/watch?v=ol_su88I3kw)\n- [Javascript typeof operator — DevDelight](https://www.youtube.com/watch?v=qPYhTPt_SbQ)\n- [JavaScript \"==\" VS \"===\" — Web Dev Simplified](https://www.youtube.com/watch?v=C5ZVC4HHgIg)\n- [=== vs == in javascript - Hitesh Choudhary](https://www.youtube.com/watch?v=a0S1iG3TgP0)\n- [The typeof operator in JS - CodeVault](https://www.youtube.com/watch?v=NSS5WRcv7yM)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 6. Function Scope, Block Scope and Lexical Scope\n The ECMAScript specification outlines three key types of scope:\n\nFunction Scope: Variables declared within a function using var are only accessible within that function. This scope isolates variables from being accessed outside of the function where they are declared.\n\nBlock Scope: Introduced with ES6, variables declared with let and const are block-scoped. This means they are only accessible within the specific block {} in which they are defined, such as inside loops or conditionals.\n\nLexical Scope: Refers to how variable access is determined based on the physical location of the variables in the code. Functions are lexically scoped, meaning that they can access variables from their parent scope.\n\n### Books\n\n- [You Don't Know JS Yet, 2nd Edition: Scope & Closures — Kyle Simpson](https://github.com/getify/You-Dont-Know-JS/tree/2nd-ed/scope-closures)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript Functions — Understanding The Basics — Brandon Morelli](https://codeburst.io/javascript-functions-understanding-the-basics-207dbf42ed99)\n-  [Var, Let, and Const – What's the Difference?](https://www.freecodecamp.org/news/var-let-and-const-whats-the-difference/)\n-  [Functions in JavaScript - Deepa Pandey](https://www.scaler.com/topics/javascript/javascript-functions/)\n-  [Emulating Block Scope in JavaScript — Josh Clanton](http://adripofjavascript.com/blog/drips/emulating-block-scope-in-javascript.html)\n-  [The Difference Between Function and Block Scope in JavaScript — Joseph Cardillo](https://medium.com/@josephcardillo/the-difference-between-function-and-block-scope-in-javascript-4296b2322abe)\n-  [Function Scopes and Block Scopes in JavaScript — Samer Buna](https://edgecoders.com/function-scopes-and-block-scopes-in-javascript-25bbd7f293d7)\n-  [Understanding Scope and Context in JavaScript — Ryan Morr](http://ryanmorr.com/understanding-scope-and-context-in-javascript/)\n-  [JavaScript Scope and Closures — Zell Liew](https://css-tricks.com/javascript-scope-closures/)\n-  [Understanding Scope in JavaScript — Wissam Abirached](https://developer.telerik.com/topics/web-development/understanding-scope-in-javascript/)\n-  [Understanding Scope in JavaScript ― Hammad Ahmed](https://scotch.io/tutorials/understanding-scope-in-javascript)\n-  [When to use a function declaration vs. a function expression ― Amber Wilkie](https://medium.freecodecamp.org/when-to-use-a-function-declarations-vs-a-function-expression-70f15152a0a0)\n-  [A JavaScript Fundamentals Cheat Sheet: Scope, Context, and “this” ― Alexandra Fren](https://dev.to/alexandrafren/a-javascript-fundamentals-cheat-sheet-scope-context-and-this-28ai)\n-  [Functions / Function scope ― MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Functions#function_scope)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [What Makes Javascript Weird ... and Awesome pt. 4 — LearnCode.academy](https://www.youtube.com/watch?v=SBwoFkRjZvE)\n- [Variable Scope in JavaScript — Kirupa Chinnathambi](https://www.youtube.com/watch?v=dhp57T3p760)\n- [JavaScript Block Scope and Function Scope — mmtuts](https://www.youtube.com/watch?v=aK_nuUAdr8E)\n- [What the Heck is Lexical Scope? — NWCalvank](https://www.youtube.com/watch?v=GhNA0r10MmA)\n- [Variable Scope — Steve Griffith](https://www.youtube.com/watch?v=FyWdrCZZavQ)\n- [Javascript Tutorials for Beginners — Mosh Hemadani](https://www.youtube.com/watch?v=W6NZfCO5SIk)\n- [JavaScript Block scope vs Function scope - nivek](https://www.youtube.com/watch?v=IaTztAtoNEY)\n- [Lexical scoping in javascript - Hitesh Choudhary](https://www.youtube.com/watch?v=qT5S7GgIioE)\n- [Modern Scope Handling in JavaScript (ES6 and Beyond) -Prashant Dewangan ](https://www.youtube.com/watch?v=zMseUdOR7z8)\n\n \n\n\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 7. Expression vs Statement\nAccording to the ECMAScript specification, expressions produce a value, and statements are instructions to perform an action, such as variable assignment or control flow. Function declarations are hoisted and can be called before they are defined in the code, while function expressions are not hoisted and must be defined before being invoked.\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [All you need to know about Javascript's Expressions, Statements and Expression Statements — Promise Tochi](https://dev.to/promhize/javascript-in-depth-all-you-need-to-know-about-expressions-statements-and-expression-statements-5k2)\n-  [Function Expressions vs Function Declarations — Paul Wilkins](https://www.sitepoint.com/function-expressions-vs-declarations/)\n-  [JavaScript Function — Declaration vs Expression — Ravi Roshan](https://medium.com/@raviroshan.talk/javascript-function-declaration-vs-expression-f5873b8c7b38)\n-  [Function Declarations vs. Function Expressions — Mandeep Singh](https://medium.com/@mandeep1012/function-declarations-vs-function-expressions-b43646042052)\n-  [Function Declarations vs. Function Expressions — Anguls Croll](https://javascriptweblog.wordpress.com/2010/07/06/function-declarations-vs-function-expressions/)\n- [Expression statement — MDN web docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/Expression_statement)\n\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Expressions vs. Statements in JavaScript — Hexlet](https://www.youtube.com/watch?v=WVyCrI1cHi8)\n- [JavaScript - Expression vs. Statement — WebTunings](https://www.youtube.com/watch?v=3jDpNGJkupA)\n- [Javascript Function Expression Vs Declaration For Beginners — Dev Material](https://www.youtube.com/watch?v=qz7Nq1tV7Io)\n- [The difference between an expression and a statement in JavaScript](https://youtu.be/eWTuFoBYiwg)\n- [Expression in javascript | Statement in javascript - Sathelli Srikanth](https://www.youtube.com/watch?v=cVDs3TZ-kXs)\n\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 8. IIFE, Modules and Namespaces\nWith the introduction of ES6 modules, the role of IIFEs in scope isolation has diminished but they still remain relevant.\n### Reference\n\n-  [IIFE — MDN](https://developer.mozilla.org/en-US/docs/Glossary/IIFE)\n-  [Modularity — MDN](https://developer.mozilla.org/en-US/docs/Glossary/modularity)\n-  [Namespace — MDN](https://developer.mozilla.org/en-US/docs/Glossary/Namespace)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Mastering Immediately-Invoked Function Expressions ― Chandra Gundamaraju](https://medium.com/@vvkchandra/essential-javascript-mastering-immediately-invoked-function-expressions-67791338ddc6)\n-  [JavaScript Immediately Invoked Function Expression — javascripttutorial.net](https://www.javascripttutorial.net/javascript-immediately-invoked-function-expression-iife/)\n-  [Do ES6 Modules make the case of IIFEs obsolete?](https://hashnode.com/post/do-es6-modules-make-the-case-of-iifes-obsolete-civ96wet80scqgc538un20es0)\n-  [A 10 minute primer to JavaScript modules, module formats, module loaders and module bundlers ― Jurgen Van de Moere](https://www.jvandemo.com/a-10-minute-primer-to-javascript-modules-module-formats-module-loaders-and-module-bundlers/)\n-  [Modules ― Exploring JS](http://exploringjs.com/es6/ch_modules.html)\n-  [ES modules: A cartoon deep-dive — Lin Clark](https://hacks.mozilla.org/2018/03/es-modules-a-cartoon-deep-dive/)\n-  [Understanding ES6 Modules — Craig Buckler](https://www.sitepoint.com/understanding-es6-modules/)\n-  [An overview of ES6 Modules in JavaScript — Brent Graham](https://blog.cloud66.com/an-overview-of-es6-modules-in-javascript/)\n-  [ES6 Modules in Depth — Nicolás Bevacqua](https://ponyfoo.com/articles/es6-modules-in-depth)\n-  [ES6 modules, Node.js and the Michael Jackson Solution — Alberto Gimeno](https://medium.com/dailyjs/es6-modules-node-js-and-the-michael-jackson-solution-828dc244b8b)\n-  [JavaScript Modules: A Beginner’s Guide — Preethi Kasireddy](https://medium.freecodecamp.org/javascript-modules-a-beginner-s-guide-783f7d7a5fcc)\n-  [Using JavaScript modules on the web — Addy Osmani & Mathias Bynens](https://developers.google.com/web/fundamentals/primers/modules)\n-  [IIFE: Immediately Invoked Function Expressions — Parwinder](https://dev.to/bhagatparwinder/iife-immediately-invoked-function-expressions-49c5)\n-  [Javascript Module Bundlers — Vanshu Hassija](https://sassy-butter-197.notion.site/Javascript-bundlers-016932b17b0744e983c2cc0db31e6f02)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Immediately Invoked Function Expression - Beau teaches JavaScript — freeCodeCamp](https://www.youtube.com/watch?v=3cbiZV4H22c)\n- [Understanding JavaScript IIFE — Sheo Narayan](https://www.youtube.com/watch?v=I5EntfMeIIQ)\n- [JavaScript Modules: ES6 Import and Export — Kyle Robinson](https://www.youtube.com/watch?v=_3oSWwapPKQ)\n- [ES6 - Modules — Ryan Christiani](https://www.youtube.com/watch?v=aQr2bV1BPyE)\n- [ES6 Modules in the Real World — Sam Thorogood](https://www.youtube.com/watch?v=fIP4pjAqCtQ)\n- [ES6 Modules — TempleCoding](https://www.youtube.com/watch?v=5P04OK6KlXA)\n- [JavaScript IIFE (Immediately Invoked Function Expressions) — Steve Griffith](https://www.youtube.com/watch?v=Xd7zgPFwVX8&)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 9. Message Queue and Event Loop\nThe Event Loop is a critical part of JavaScript’s concurrency model, ensuring non-blocking behavior by processing tasks in an asynchronous manner. Understanding how it interacts with the Message Queue and Microtasks is key to mastering JavaScript behavior.\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript Event Loop Explained — Anoop Raveendran](https://medium.com/front-end-hacking/javascript-event-loop-explained-4cd26af121d4)\n-  [The JavaScript Event Loop: Explained — Erin Sweson-Healey](https://blog.carbonfive.com/2013/10/27/the-javascript-event-loop-explained/)\n-  [Understanding JS: The Event Loop — Alexander Kondov](https://hackernoon.com/understanding-js-the-event-loop-959beae3ac40)\n-  [The JavaScript Event Loop — Flavio Copes](https://flaviocopes.com/javascript-event-loop/)\n-  [Tasks, microtasks, queues and schedules — Jake Archibald](https://jakearchibald.com/2015/tasks-microtasks-queues-and-schedules/)\n-  [Visualising the JavaScript Event Loop with a Pizza Restaurant analogy — Priyansh Jain](https://dev.to/presto412/visualising-the-javascript-event-loop-with-a-pizza-restaurant-analogy-47a8)\n-  [JavaScript Visualized: Event Loop — Lydia Hallie](https://dev.to/lydiahallie/javascript-visualized-event-loop-3dif)\n-  [setTimeout vs setImmediate in JavaScript — Navneet Singh](https://medium.com/@navneetskahlon/settimeout-vs-setimmediate-in-javascript-a2eaab973490)\n- [Understanding and Optimizing JavaScript’s Event Loop — Xiuer Old](https://medium.com/javascript-zone/understanding-and-optimizing-javascripts-event-loop-717ae0095038#:~:text=The%20event%20loop%20is%20the,%2Dblocking%20I%2FO%20operations.)\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [What the heck is the event loop anyway? | JSConf EU — Philip Roberts](https://www.youtube.com/watch?v=8aGhZQkoFbQ)\n- [JavaScript Event Loop — ComScience Simplified](https://www.youtube.com/watch?v=XzXIMZMN9k4)\n- [I'm stuck in an Event Loop — Philip Roberts](https://www.youtube.com/watch?v=6MXRNXXgP_0)\n- [In The Loop - Jake Archibald | JSConf.Asia 2018](https://www.youtube.com/watch?v=cCOL7MC4Pl0)\n- [Desmitificando el Event Loop (Spanish)](https://www.youtube.com/watch?v=Eqq2Rb7LzYE)\n- [Callbacks, Sincrono, Assíncrono e Event Loop (PT-BR)](https://www.youtube.com/watch?v=6lbBaM18X3g)\n- [JavaScript Event Loop: How it Works and Why it Matters in 5 Minutes - James Q Quick](https://www.youtube.com/watch?v=6lbBaM18X3g)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 10. setTimeout, setInterval and requestAnimationFrame\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Javascript setTimeout - All you need to know](https://robiul.dev/javascript-settimeout-all-you-need-to-know)\n-  [setTimeout and setInterval — JavaScript.Info](https://javascript.info/settimeout-setinterval)\n-  [Why not to use setInterval — Akanksha Sharma](https://dev.to/akanksha_9560/why-not-to-use-setinterval--2na9)\n-  [setTimeout VS setInterval — Develoger](https://develoger.com/settimeout-vs-setinterval-cff85142555b)\n-  [Using requestAnimationFrame — Chris Coyier](https://css-tricks.com/using-requestanimationframe/)\n-  [Understanding JavaScript's requestAnimationFrame() — JavaScript Kit](http://www.javascriptkit.com/javatutors/requestanimationframe.shtml)\n-  [Handling time intervals in JavaScript - Amit Merchant](https://www.amitmerchant.com/Handling-Time-Intervals-In-Javascript/)\n-  [Debounce – How to Delay a Function in JavaScript - Ondrej Polesny](https://www.freecodecamp.org/news/javascript-debounce-example/)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Javascript: How setTimeout and setInterval works — Coding Blocks India](https://www.youtube.com/watch?v=6bPKyl8WYWI)\n- [TRUST ISSUES with setTimeout() — Akshay Saini ](https://youtu.be/nqsPmuicJJc?si=4FXKlZfqiJUqO2Y4)                  \n- [setTimeout and setInterval in JavaScript — techsith](https://www.youtube.com/watch?v=TbCgGWe8LN8)\n- [JavaScript Timers — Steve Griffith](https://www.youtube.com/watch?v=0VVJSvlUgtg)\n- [JavaScript setTimeOut and setInterval Explained — Theodore Anderson](https://www.youtube.com/watch?v=mVKfrWCOB60)   \n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 11. JavaScript Engines\n\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Is javascript compiled or interpreted language?](https://robiul.dev/is-javascript-compiled-or-interpreted-language)\n-  [JavaScript Engines — Jen Looper](http://www.softwaremag.com/javascript-engines/)\n-  [Understanding How the Chrome V8 Engine Translates JavaScript into Machine Code — DroidHead](https://medium.freecodecamp.org/understanding-the-core-of-nodejs-the-powerful-chrome-v8-engine-79e7eb8af964)\n-  [Understanding V8’s Bytecode — Franziska Hinkelmann](https://medium.com/dailyjs/understanding-v8s-bytecode-317d46c94775)\n-  [A Brief History of Google’s V8 Javascript Engine — Clair Smith](https://www.mediacurrent.com/blog/brief-history-googles-v8-javascript-engine/)\n-  [JavaScript essentials: why you should know how the engine works - Rainer Hahnekamp](https://www.freecodecamp.org/news/javascript-essentials-why-you-should-know-how-the-engine-works-c2cc0d321553)\n-  [JavaScript engine fundamentals: Shapes and Inline Caches](https://mathiasbynens.be/notes/shapes-ics)\n-  [JavaScript engine fundamentals: optimizing prototypes](https://mathiasbynens.be/notes/prototypes)\n-  [How V8 optimizes array operations](https://v8.dev/blog/elements-kinds)\n-  [JavaScript Internals: JavaScript engine, Run-time environment & setTimeout Web API — Rupesh Mishra](https://blog.bitsrc.io/javascript-internals-javascript-engine-run-time-environment-settimeout-web-api-eeed263b1617)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript Engines: The Good Parts™ — Mathias Bynens & Benedikt Meurer](https://www.youtube.com/watch?v=5nmpokoRaZI)\n- [JS Engine EXPOSED 🔥 Google's V8 Architecture 🚀 | Namaste JavaScript Ep. 16 - Akshay Saini](https://www.youtube.com/watch?v=2WJL19wDH68)\n- [How JavaScript Code is executed? How Javascript works behind the scenes](https://youtu.be/iLWTnMzWtj4)   \n- [Understanding the V8 JavaScript Engine - freeCodeCamp Talks](https://www.youtube.com/watch?v=xckH5s3UuX4)\n- [JavaScript Under The Hood - JavaScript Engine Overview - Traversy Media](https://www.youtube.com/watch?v=oc6faXVc54E)\n- [Arindam Paul - JavaScript VM internals, EventLoop, Async and ScopeChains](https://www.youtube.com/watch?v=QyUFheng6J0)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 12. Bitwise Operators, Type Arrays and Array Buffers\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Programming with JS: Bitwise Operations — Alexander Kondov](https://hackernoon.com/programming-with-js-bitwise-operations-393eb0745dc4)\n-  [Using JavaScript’s Bitwise Operators in Real Life — ian m](https://codeburst.io/using-javascript-bitwise-operators-in-real-life-f551a731ff5)\n-  [JavaScript Bitwise Operators — w3resource](https://www.w3resource.com/javascript/operators/bitwise-operator.php)\n-  [Bitwise Operators in Javascript — Joe Cha](https://medium.com/bother7-blog/bitwise-operators-in-javascript-65c4c69be0d3)\n-  [A Comprehensive Primer on Binary Computation and Bitwise Operators in Javascript — Paul Brown](https://medium.com/techtrument/a-comprehensive-primer-on-binary-computation-and-bitwise-operators-in-javascript-81acf8341f04)\n-  [How can I understand Bitwise operation in JavaScript?](https://www.quora.com/How-can-I-understand-Bitwise-operation-in-JavaScript)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript Bitwise Operators — Programming with Mosh](https://www.youtube.com/watch?v=mesu75PTDC8)\n- [Bitwise Operators and WHY we use them — Alex Hyett](https://www.youtube.com/watch?v=igIjGxF2J-w)\n- [JS Bitwise Operators and Binary Numbers — Steve Griffith - Prof3ssorSt3v3](https://www.youtube.com/watch?v=RRyxCmLX_ag)\n- [Deep Dive into Blobs, Files, and ArrayBuffers — Steve Griffith - Prof3ssorSt3v3](https://www.youtube.com/watch?v=ScZZoHj7mqY)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 13. DOM and Layout Trees\n\n### Reference\n\n- [Document Object Model (DOM) — MDN](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model)\n\n### Books\n\n-  [Eloquent JavaScript, 3rd Edition: Ch. 14 - The Document Object Model](https://eloquentjavascript.net/14_dom.html)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [How To Understand and Modify the DOM in JavaScript — Tania Rascia](https://www.digitalocean.com/community/tutorials/introduction-to-the-dom)\n-  [What’s the Document Object Model, and why you should know how to use it — Leonardo Maldonado](https://medium.freecodecamp.org/whats-the-document-object-model-and-why-you-should-know-how-to-use-it-1a2d0bc5429d)\n-  [JavaScript DOM Tutorial with Example — Guru99](https://www.guru99.com/how-to-use-dom-and-events-in-javascript.html)\n-  [What is the DOM? — Chris Coyier](https://css-tricks.com/dom/)\n-  [Traversing the DOM with JavaScript — Zell Liew](https://zellwk.com/blog/dom-traversals/)\n-  [DOM Tree](https://javascript.info/dom-nodes)\n-  [How to traverse the DOM in Javascript — Vojislav Grujić](https://medium.com/javascript-in-plain-english/how-to-traverse-the-dom-in-javascript-d6555c335b4e)\n-  [Render Tree Construction — Ilya Grigorik](https://developers.google.com/web/fundamentals/performance/critical-rendering-path/render-tree-construction)\n-  [What exactly is the DOM?](https://bitsofco.de/what-exactly-is-the-dom/)\n-  [JavaScript DOM](https://www.javascripttutorial.net/javascript-dom/)\n-  [Traversing the Dom with Javascript](https://www.youtube.com/watch?v=Pr4LLrmDLLo) - Steve Griffith (YouTube)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript DOM — The Net Ninja](https://www.youtube.com/watch?v=FIORjGvT0kk)\n- [JavaScript DOM Crash Course — Traversy Media](https://www.youtube.com/watch?v=0ik6X4DJKCc)\n- [JavaScript DOM Manipulation Methods — Web Dev Simplified](https://www.youtube.com/watch?v=y17RuWkWdn8)\n- [JavaScript DOM Traversal Methods — Web Dev Simplified](https://www.youtube.com/watch?v=v7rSSy8CaYE)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 14. Factories and Classes\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [How To Use Classes in JavaScript — Tania Rascia](https://www.digitalocean.com/community/tutorials/understanding-classes-in-javascript)\n-  [Javascript Classes — Under The Hood — Majid](https://medium.com/tech-tajawal/javascript-classes-under-the-hood-6b26d2667677)\n-  [Better JavaScript with ES6, Pt. II: A Deep Dive into Classes ― Peleke Sengstacke](https://scotch.io/tutorials/better-javascript-with-es6-pt-ii-a-deep-dive-into-classes)\n-  [Understand the Factory Design Pattern in Plain JavaScript — Aditya Agarwal](https://medium.com/front-end-hacking/understand-the-factory-design-pattern-in-plain-javascript-20b348c832bd)\n-  [Factory Functions in JavaScript — Josh Miller](https://atendesigngroup.com/blog/factory-functions-javascript)\n-  [The Factory Pattern in JS ES6 — SnstsDev](https://medium.com/@SntsDev/the-factory-pattern-in-js-es6-78f0afad17e9)\n-  [Class vs Factory function: exploring the way forward — Cristi Salcescu](https://medium.freecodecamp.org/class-vs-factory-function-exploring-the-way-forward-73258b6a8d15)\n-  [How ES6 classes really work and how to build your own — Robert Grosse](https://medium.com/@robertgrosse/how-es6-classes-really-work-and-how-to-build-your-own-fd6085eb326a)\n-  [Understanding `super` in JavaScript](https://jordankasper.com/understanding-super-in-javascript)\n-  [An Easy Guide To Understanding Classes In JavaScript](https://dev.to/lawrence_eagles/an-easy-guide-to-understanding-classes-in-javascript-3bcm)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript Factory Functions — Programming with Mosh](https://www.youtube.com/watch?v=jpegXpQpb3o)\n- [Factory Functions in JavaScript — Fun Fun Function](https://www.youtube.com/watch?v=ImwrezYhw4w)\n- [Javascript Tutorial Function Factories — Crypto Chan](https://www.youtube.com/watch?v=R7-IwpH80UE)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 15. this, call, apply and bind\n\n### Reference\n\n-  [call() — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/call)\n-  [bind() — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_objects/Function/bind)\n-  [apply() — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/apply)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Grokking call(), apply() and bind() methods in JavaScript — Aniket Kudale](https://levelup.gitconnected.com/grokking-call-apply-and-bind-methods-in-javascript-392351a4be8b)\n-  [JavaScript’s Apply, Call, and Bind Methods are Essential for JavaScript Professionals — Richard Bovell](http://javascriptissexy.com/javascript-apply-call-and-bind-methods-are-essential-for-javascript-professionals/)\n-  [Javascript: call(), apply() and bind() — Omer Goldberg](https://medium.com/@omergoldberg/javascript-call-apply-and-bind-e5c27301f7bb)\n-  [The difference between call / apply / bind — Ivan Sifrim](https://medium.com/@ivansifrim/the-differences-between-call-apply-bind-276724bb825b)\n-  [What the hack is call, apply, bind in JavaScript — Ritik](https://dev.to/ritik_dev_js/what-the-hack-is-call-apply-bind-in-javascript-11ce)\n-  [Mastering 'this' in JavaScript: Callbacks and bind(), apply(), call() — Michelle Gienow](https://thenewstack.io/mastering-javascript-callbacks-bind-apply-call/)\n-  [JavaScript’s apply, call, and bind explained by hosting a cookout — Kevin Kononenko](https://dev.to/kbk0125/javascripts-apply-call-and-bind-explained-by-hosting-a-cookout-32jo)\n-  [How AND When to use bind, call, and apply in Javascript — Eigen X](https://www.eigenx.com/blog/https/mediumcom/eigen-x/how-and-when-to-use-bind-call-and-apply-in-javascript-77b6f42898fb)\n-  [Let me explain to you what is `this`. (Javascript) — Jason Yu](https://dev.to/ycmjason/let-me-explain-to-you-what-is-this-javascript-44ja)\n-  [Understanding the “this” Keyword in JavaScript — Pavan](https://medium.com/quick-code/understanding-the-this-keyword-in-javascript-cb76d4c7c5e8)\n-  [How to understand the keyword this and context in JavaScript — Lukas Gisder-Dubé](https://medium.freecodecamp.org/how-to-understand-the-keyword-this-and-context-in-javascript-cd624c6b74b8)\n-  [What the heck is this in Javascript? — Hridayesh Sharma](https://dev.to/_hridaysharma/what-the-heck-is-this-in-javascript-37n1)\n-  [This and Bind In Javascript — Brian Barbour](https://dev.to/steelvoltage/this-and-bind-in-javascript-2pam)\n-  [3 Techniques for Maintaining Your Sanity Using \"This\" in JavaScript — Carl](https://dev.to/canderson93/3-techniques-for-maintaining-your-sanity-using-this-in-javascript-3idf)\n-  [Mastering the JavaScript \"this\" Keyword — Aakash Srivastav](https://dev.to/aakashsr/mastering-the-javascript-this-keyword-4pfa)\n-  [This binding in JavaScript – 4. New binding — Spyros Argalias](https://dev.to/sargalias/this-binding-in-javascript-4-new-binding-2p1n)\n-  [A quick intro to 'this' in JavaScript — Natalie Smith](https://dev.to/thatgalnatalie/a-quick-intro-to-this-in-javascript-2mhp)\n-  [A conversation with the 'this' keyword in Javascript — Karen Efereyan](https://dev.to/developerkaren/a-conversation-with-the-this-keyword-in-javascript-3j6g)\n-  [What are call(), apply() and bind() in JavaScript — Amitav Mishra](https://jscurious.com/what-are-call-apply-and-bind-in-javascript/)\n-  [Understanding 'this' binding in JavaScript — Yasemin Cidem](https://yasemincidem.medium.com/understanding-this-binding-in-javascript-86687397c76d)\n-  [Top 7 tricky questions of 'this' keyword](https://dmitripavlutin.com/javascript-this-interview-questions/)\n    \n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript call, apply and bind — techsith](https://www.youtube.com/watch?v=c0mLRpw-9rI)\n- [JavaScript Practical Applications of Call, Apply and Bind functions— techsith](https://www.youtube.com/watch?v=AYVYxezrMWA)\n- [JavaScript (call, bind, apply) — curious aatma](https://www.youtube.com/watch?v=Uy0NOXLBraE)\n- [Understanding Functions and 'this' In The World of ES2017 — Bryan Hughes](https://www.youtube.com/watch?v=AOSYY1_np_4)\n- [bind and this - Object Creation in JavaScript - FunFunFunction](https://www.youtube.com/watch?v=GhbhD1HR5vk)\n- [JS Function Methods call(), apply(), and bind() — Steve Griffith](https://www.youtube.com/watch?v=uBdH0iB1VDM)\n- [call, apply and bind method in JavaScript — Akshay Saini](https://www.youtube.com/watch?v=75W8UPQ5l7k)\n- .[Javascript Interview Questions ( Call, Bind and Apply ) - Polyfills, Output Based, Explicit Binding - Roadside Coder] (https://youtu.be/VkmUOktYDAU?si=SdvLZ8FBmephPxjS)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 16. new, Constructor, instanceof and Instances\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript For Beginners: the ‘new’ operator — Brandon Morelli](https://codeburst.io/javascript-for-beginners-the-new-operator-cee35beb669e)\n-  [Let’s demystify JavaScript’s ‘new’ keyword — Cynthia Lee](https://medium.freecodecamp.org/demystifying-javascripts-new-keyword-874df126184c)\n-  [Constructor, operator \"new\" — JavaScript.Info](https://javascript.info/constructor-new)\n-  [Understanding JavaScript Constructors — Faraz Kelhini](https://css-tricks.com/understanding-javascript-constructors/)\n-  [Use Constructor Functions — Openclassrooms](https://openclassrooms.com/en/courses/3523231-learn-to-code-with-javascript/4379006-use-constructor-functions)\n-  [Beyond `typeof` and `instanceof`: simplifying dynamic type checks — Dr. Axel Rauschmayer](http://2ality.com/2017/08/type-right.html)\n-  [Function and Object, instances of each other — Kiro Risk](https://javascriptrefined.io/function-and-object-instances-of-each-other-1e1095d5faac)\n-  [JavaScript instanceof operator](https://flexiple.com/javascript/instanceof-javascript)\n  \n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 17. Prototype Inheritance and Prototype Chain\n\n### Reference\n\n-  [Inheritance and the prototype chain — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Inheritance_and_the_prototype_chain)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Javascript : Prototype vs Class — Valentin PARSY](https://medium.com/@parsyval/javascript-prototype-vs-class-a7015d5473b)\n-  [JavaScript engine fundamentals: optimizing prototypes — Mathias Bynens](https://mathiasbynens.be/notes/prototypes)\n-  [JavaScript Prototype — NC Patro](https://codeburst.io/javascript-prototype-cb29d82b8809)\n-  [Prototypes in JavaScript — Rupesh Mishra](https://hackernoon.com/prototypes-in-javascript-5bba2990e04b)\n-  [Prototype in JavaScript: it’s quirky, but here’s how it works — Pranav Jindal](https://medium.freecodecamp.org/prototype-in-js-busted-5547ec68872)\n-  [Understanding JavaScript: Prototype and Inheritance — Alexander Kondov](https://hackernoon.com/understanding-javascript-prototype-and-inheritance-d55a9a23bde2)\n-  [Understanding Classes (ES5) and Prototypal Inheritance in JavaScript — Hridayesh Sharma](https://dev.to/_hridaysharma/understanding-classes-es5-and-prototypal-inheritance-in-javascript-n8d)\n-  [prototype, **proto** and Prototypal inheritance in JavaScript — Varun Dey](https://dev.to/varundey/prototype-proto-and-prototypal-inheritance-in-javascript-2inl)\n-  [Prototypal Inheritance — JavaScript.Info](https://javascript.info/prototype-inheritance)\n-  [How To Work with Prototypes and Inheritance in JavaScript — Tania Rascia](https://www.digitalocean.com/community/tutorials/understanding-prototypes-and-inheritance-in-javascript)\n-  [Master JavaScript Prototypes & Inheritance — Arnav Aggarwal](https://codeburst.io/master-javascript-prototypes-inheritance-d0a9a5a75c4e)\n-  [JavaScript’s Prototypal Inheritance Explained Using CSS — Nash Vail](https://medium.freecodecamp.org/understanding-prototypal-inheritance-in-javascript-with-css-93b2fcda75e4)\n-  [Prototypal Inheritance in JavaScript — Jannis Redmann](https://gist.github.com/derhuerst/a585c4916b1c361cc6f0)\n-  [Demystifying ES6 Classes And Prototypal Inheritance ― Neo Ighodaro](https://scotch.io/tutorials/demystifying-es6-classes-and-prototypal-inheritance)\n-  [Intro To Prototypal Inheritance — Dharani Jayakanthan](https://dev.to/danny/intro-to-prototypal-inheritance---js-9di)\n-  [Let’s Build Prototypal Inheritance in JS — var-che](https://dev.to/varche/let-s-build-prototypal-inheritance-in-js-56mm)\n-  [Objects, Prototypes and Classes in JavaScript — Atta](https://dev.to/attacomsian/objects-prototypes-and-classes-in-javascript-3i9b)\n-  [The magical world of JavaScript prototypes — Belén](https://dev.to/ladybenko/the-magical-world-of-javascript-prototypes-1mhg)\n-  [Understanding Prototypal Inheritance In JavaScript — Lawrence Eagles](https://dev.to/lawrence_eagles/understanding-prototypal-inheritance-in-javascript-4f31#chp-4)\n-  [Objects and Prototypes in JavaScript — Irena Popova](https://dev.to/irenejpopova/objects-and-prototypes-in-javascript-2eie)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Javascript Prototype Inheritance — Avelx](https://www.youtube.com/watch?v=sOrtAjyk4lQ)\n- [JavaScript Prototype Inheritance Explained pt. I — techsith](https://www.youtube.com/watch?v=7oNWNlMrkpc)\n- [JavaScript Prototype Inheritance Explained pt. II — techsith](https://www.youtube.com/watch?v=uIlj6_z_wL8)\n- [JavaScript Prototype Inheritance Explained — Kyle Robinson](https://www.youtube.com/watch?v=qMO-LTOrJaE)\n- [Advanced Javascript - Prototypal Inheritance In 1 Minute](https://www.youtube.com/watch?v=G6l5CHl67HQ)\n- [An Overview Of Classical Javascript Classes and Prototypal Inheritance — Pentacode](https://www.youtube.com/watch?v=phwzuiJJPpQ)\n- [Object Oriented JavaScript - Prototype — The Net Ninja](https://www.youtube.com/watch?v=4jb4AYEyhRc)\n- [Prototype in JavaScript — kudvenkat](https://www.youtube.com/watch?v=2rkEbcptR64)\n- [JavaScript Using Prototypes — O'Reilly](https://www.youtube.com/watch?v=oCwCcNvaXAQ)\n- [A Beginner's Guide to Javascript's Prototype — Tyler Mcginnis](https://www.youtube.com/watch?v=XskMWBXNbp0)\n- [Prototypes in Javascript - p5.js Tutorial — The Coding Train](https://www.youtube.com/watch?v=hS_WqkyUah8)\n\n### Books\n\n- [You Don't Know JS, 1st Edition: this & Object Prototypes — Kyle Simpson](https://github.com/getify/You-Dont-Know-JS/tree/1st-ed)\n- [The Principles of Object-Oriented JavaScript - Nicholas C. Zakas](https://www.google.com.pk/books/edition/The_Principles_of_Object_Oriented_JavaSc/rorlAwAAQBAJ?hl=en&gbpv=1&pg=PP1&printsec=frontcover)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 18. Object.create and Object.assign\n\n### Reference\n\n-  [Object.create() — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/create)\n-  [Object.assign() — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Object.create in JavaScript — Rupesh Mishra](https://medium.com/@happymishra66/object-create-in-javascript-fa8674df6ed2)\n-  [Object.create(): the New Way to Create Objects in JavaScript — Rob Gravelle](https://www.htmlgoodies.com/beyond/javascript/object.create-the-new-way-to-create-objects-in-javascript.html)\n-  [Basic Inheritance with Object.create — Joshua Clanton](http://adripofjavascript.com/blog/drips/basic-inheritance-with-object-create.html)\n-  [Object.create() In JavaScript — GeeksforGeeks](https://www.geeksforgeeks.org/object-create-javascript/)\n-  [Understanding the difference between Object.create() and the new operator — Jonathan Voxland](https://medium.com/@jonathanvox01/understanding-the-difference-between-object-create-and-the-new-operator-b2a2f4749358)\n-  [JavaScript Object Creation: Patterns and Best Practices — Jeff Mott](https://www.sitepoint.com/javascript-object-creation-patterns-best-practises/)\n-  [Javascript hasOwnProperty: A Powerful Property Checking tool](https://robiul.dev/javascript-hasownproperty-method)\n-  [Dealing With Objects in JavaScript With Object.assign, Object.keys and hasOwnProperty](https://www.digitalocean.com/community/tutorials/js-dealing-with-objects)\n-  [Copying Objects in JavaScript ― Orinami Olatunji](https://scotch.io/bar-talk/copying-objects-in-javascript)\n-  [JavaScript: Object.assign() — Thiago S. Adriano](https://codeburst.io/javascript-object-assign-bc9696dcbb6e)\n-  [How to deep clone a JavaScript Object — Flavio Copes](https://flaviocopes.com/how-to-clone-javascript-object/)\n-  [Object.create(): When and Why to Use — VZing](https://dev.to/vzing/object-create-when-and-why-to-use-20m9)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Object.assign() explained — Aaron Writes Code](https://www.youtube.com/watch?v=aw7NfYhR5rc)\n- [Object.assign() Method — techsith](https://www.youtube.com/watch?v=9Ky4X6inpi4)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 19. map, reduce, filter\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript Functional Programming — map, filter and reduce — Bojan Gvozderac](https://medium.com/jsguru/javascript-functional-programming-map-filter-and-reduce-846ff9ba492d)\n-  [Learn map, filter and reduce in Javascript — João Miguel Cunha](https://medium.com/@joomiguelcunha/learn-map-filter-and-reduce-in-javascript-ea59009593c4)\n-  [JavaScript’s Map, Reduce, and Filter — Dan Martensen](https://danmartensen.svbtle.com/javascripts-map-reduce-and-filter)\n-  [How to Use Map, Filter, & Reduce in JavaScript — Peleke Sengstacke](https://code.tutsplus.com/tutorials/how-to-use-map-filter-reduce-in-javascript--cms-26209)\n-  [JavaScript — Learn to Chain Map, Filter, and Reduce — Brandon Morelli](https://codeburst.io/javascript-learn-to-chain-map-filter-and-reduce-acd2d0562cd4)\n-  [Javascript data structure with map, reduce, filter and ES6 — Deepak Gupta](https://codeburst.io/write-beautiful-javascript-with-%CE%BB-fp-es6-350cd64ab5bf)\n-  [Understanding map, filter and reduce in Javascript — Luuk Gruijs](https://hackernoon.com/understanding-map-filter-and-reduce-in-javascript-5df1c7eee464)\n-  [Functional Programming in JS: map, filter, reduce (Pt. 5) — Omer Goldberg](https://hackernoon.com/functional-programming-in-js-map-filter-reduce-pt-5-308a205fdd5f)\n-  [JavaScript: Map, Filter, Reduce — William S. Vincent](https://wsvincent.com/functional-javascript-map-filter-reduce/)\n-  [Arrow Functions: Fat and Concise Syntax in JavaScript — Kyle Pennell](https://www.sitepoint.com/es6-arrow-functions-new-fat-concise-syntax-javascript/)\n-  [JavaScript: Arrow Functions for Beginners — Brandon Morelli](https://codeburst.io/javascript-arrow-functions-for-beginners-926947fc0cdc)\n-  [When (and why) you should use ES6 arrow functions — and when you shouldn’t — Cynthia Lee](https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26)\n-  [JavaScript — Learn & Understand Arrow Functions — Brandon Morelli](https://codeburst.io/javascript-learn-understand-arrow-functions-fe2083533946)\n-  [(JavaScript )=> Arrow functions — sigu](https://medium.com/podiihq/javascript-arrow-functions-27d4c3334b83)\n-  [Javascript.reduce() — Paul Anderson](https://medium.com/@panderson.dev/javascript-reduce-79aab078da23)\n-  [Why you should replace forEach with map and filter in JavaScript — Roope Hakulinen](https://gofore.com/en/why-you-should-replace-foreach/)\n-  [Simplify your JavaScript – Use .map(), .reduce(), and .filter() — Etienne Talbot](https://medium.com/poka-techblog/simplify-your-javascript-use-map-reduce-and-filter-bd02c593cc2d)\n-  [JavaScript’s Reduce Method Explained By Going On a Diet — Kevin Kononenko](https://blog.codeanalogies.com/2018/07/24/javascripts-reduce-method-explained-by-going-on-a-diet/)\n-  [Difference between map, filter and reduce in JavaScript — Amirata Khodaparast](https://medium.com/@amiratak88/difference-between-map-filter-and-reduce-in-javascript-822ff79d5160)\n-  [Map⇄Filter⇄Reduce↻ — ashay mandwarya](https://hackernoon.com/map-filter-reduce-ebbed4be4201)\n-  [Finding Your Way With .map() — Brandon Wozniewicz](https://medium.freecodecamp.org/finding-your-way-with-map-aecb8ca038f6)\n-  [How to write your own map, filter and reduce functions in JavaScript — Hemand Nair](https://medium.freecodecamp.org/how-to-write-your-own-map-filter-and-reduce-functions-in-javascript-ab1e35679d26)\n-  [How to Manipulate Arrays in JavaScript — Bolaji Ayodeji](https://www.freecodecamp.org/news/manipulating-arrays-in-javascript/)\n-  [How to simplify your codebase with map(), reduce(), and filter() in JavaScript — Alex Permyakov](https://www.freecodecamp.org/news/15-useful-javascript-examples-of-map-reduce-and-filter-74cbbb5e0a1f)\n-  [.map(), .filter(), and .reduce() — Andy Pickle](https://dev.to/pickleat/map-filter-and-reduce-2efb)\n-  [Map/Filter/Reduce Crash Course — Chris Achard](https://dev.to/chrisachard/map-filter-reduce-crash-course-5gan)\n-  [Map, Filter and Reduce – Animated — JavaScript Teacher](https://medium.com/@js_tut/map-filter-and-reduce-animated-7fe391a35a47)\n-  [Map, Filter, Reduce and others Arrays Iterators You Must Know to Become an Algorithms Wizard — Mauro Bono](https://dev.to/uptheirons78/map-filter-reduce-and-others-arrays-iterators-you-must-know-to-become-an-algorithms-wizard-4209)\n-  [How to Use JavaScript’s .map, .filter, and .reduce — Avery Duffin](https://betterprogramming.pub/how-to-javascripts-map-vs-filter-vs-reduce-80d87a5a0a24)\n-  [Javascript performance test - for vs for each vs (map, reduce, filter, find) — Deepak Gupta](https://towardsdatascience.com/javascript-performance-test-for-vs-for-each-vs-map-reduce-filter-find-32c1113f19d7)\n-  [Using .map(), .filter() and .reduce() properly — Sasanka Kudagoda](https://medium.com/javascript-in-plain-english/using-map-filter-and-reduce-properly-50e07f80c8b2)\n-  [Mastering the JavaScript Reduce method ✂️ — sanderdebr](https://dev.to/sanderdebr/mastering-the-javascript-reduce-method-2foj)\n-  [JavaScript Map – How to Use the JS .map() Function (Array Method) — FreeCodeCamp](https://www.freecodecamp.org/news/javascript-map-how-to-use-the-js-map-function-array-method/)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Map, Filter and Reduce — Lydia Hallie](https://www.youtube.com/watch?v=UXiYii0Y7Nw)\n- [Map, Filter and Reduce - Akshaay Saini](https://youtu.be/zdp0zrpKzIE?si=6QusFzD6tmwn-el4)\n- [Functional JavaScript: Map, forEach, Reduce, Filter — Theodore Anderson](https://www.youtube.com/watch?v=vytzLlY_wmU)\n- [JavaScript Array superpowers: Map, Filter, Reduce (part I) — Michael Rosata](https://www.youtube.com/watch?v=qTeeVd8hOFY)\n- [JavaScript Array superpowers: Map, Filter, Reduce (part 2) — Michael Rosata](https://www.youtube.com/watch?v=gIm9xLYudL0)\n- [JavaScript Higher Order Functions - Filter, Map, Sort & Reduce — Epicop](https://www.youtube.com/watch?v=zYBeEPxNSbw)\n- [[Array Methods 2/3] .filter + .map + .reduce — CodeWithNick](https://www.youtube.com/watch?v=4qWlqD0yYTU)\n- [Arrow functions in JavaScript - What, Why and How — Fun Fun Function](https://www.youtube.com/watch?v=6sQDTgOqh-I)\n- [Learning Functional Programming with JavaScript — Anjana Vakil - JSUnconf](https://www.youtube.com/watch?v=e-5obm1G_FY&t=1521s)\n- [Map - Parte 2 JavaScript - Fun Fun Function](https://www.youtube.com/watch?v=bCqtb-Z5YGQ&t=17s)\n- [Reduce basics - Part 3 of FP in JavaScript - Fun Fun Function](https://www.youtube.com/watch?v=Wl98eZpkp-c)\n- [Reduce Advanced - Part 4 of FP in JavaScript - Fun Fun Function](https://www.youtube.com/watch?v=1DMolJ2FrNY&t=621s)\n- [reduce Array Method | JavaScript Tutorial - Florin Pop](https://www.youtube.com/watch?v=IXp06KekEjM)\n- [map Array Method | JavaScript Tutorial - Florin Pop](https://www.youtube.com/watch?v=P4RAFdZDn3M)\n- [Different array methods in 1 minute | Midudev (Spanish)](https://youtu.be/Ah7-PPjQ5Ls)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 20. Pure Functions, Side Effects, State Mutation and Event Propagation\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Javascript and Functional Programming — Pure Functions — Omer Goldberg](https://hackernoon.com/javascript-and-functional-programming-pt-3-pure-functions-d572bb52e21c)\n-  [Master the JavaScript Interview: What is a Pure Function? — Eric Elliott](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-a-pure-function-d1c076bec976)\n-  [JavaScript: What Are Pure Functions And Why Use Them? — James Jeffery](https://medium.com/@jamesjefferyuk/javascript-what-are-pure-functions-4d4d5392d49c)\n-  [Pure functions in JavaScript — @nicoespeon](http://www.nicoespeon.com/en/2015/01/pure-functions-javascript/)\n-  [Functional Programming: Pure Functions — Arne Brasseur](https://www.sitepoint.com/functional-programming-pure-functions/)\n-  [Making your JavaScript Pure — Jack Franklin](https://alistapart.com/article/making-your-javascript-pure)\n-  [Arrays, Objects and Mutations — Federico Knüssel](https://medium.com/@fknussel/arrays-objects-and-mutations-6b23348b54aa)\n-  [The State of Immutability — Maciej Sikora](https://medium.com/dailyjs/the-state-of-immutability-169d2cd11310)\n-  [Hablemos de Inmutabilidad — Kike Sanchez](https://medium.com/zurvin/hablemos-de-inmutabilidad-3dc65d290783)\n-  [How to deal with dirty side effects in your pure functional JavaScript — James Sinclair](https://jrsinclair.com/articles/2018/how-to-deal-with-dirty-side-effects-in-your-pure-functional-javascript/)\n-  [Preventing Side Effects in JavaScript — David Walsh](https://davidwalsh.name/preventing-sideeffects-javascript)\n-  [JavaScript: Pure Functions — William S. Vincent](https://wsvincent.com/javascript-pure-functions/)\n-  [Functional programming paradigms in modern JavaScript: Pure functions — Alexander Kondov](https://hackernoon.com/functional-programming-paradigms-in-modern-javascript-pure-functions-797d9abbee1)\n-  [Understanding Javascript Mutation and Pure Functions — Chidume Nnamdi](https://blog.bitsrc.io/understanding-javascript-mutation-and-pure-functions-7231cc2180d3)\n-  [Functional-ish JavaScript — Daniel Brain](https://medium.com/@bluepnume/functional-ish-javascript-205c05d0ed08)\n-  [Event Propagation — MDN](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Building_blocks/Events)\n-  [Event Propagation — Bubbling and capturing](https://javascript.info/bubbling-and-capturing)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Pure Functions — Hexlet](https://www.youtube.com/watch?v=dZ41D6LDSBg)\n- [Pure Functions - Functional Programming in JavaScript — Paul McBride](https://www.youtube.com/watch?v=Jh_Uzqzz_wM)\n- [JavaScript Pure Functions — Seth Alexander](https://www.youtube.com/watch?v=frT3H-eBmPc)\n- [JavaScript Pure vs Impure Functions Explained — Theodore Anderson](https://www.youtube.com/watch?v=AHbRVJzpB54)\n- [Pure Functions - Programação Funcional: Parte 1 - Fun Fun Function](https://www.youtube.com/watch?v=BMUiFMZr7vk)\n- [Event Propagation - JavaScript Event Bubbling and Propagation - Steve Griffith](https://www.youtube.com/watch?v=JYc7gr9Ehl0)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 21. Closures\n\n### Reference\n\n-  [Closures — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures)\n-  [Closure — JavaScript.Info](https://javascript.info/closure)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [I never understood JavaScript closures — Olivier De Meulder](https://medium.com/dailyjs/i-never-understood-javascript-closures-9663703368e8)\n-  [Understand JavaScript Closures With Ease — Richard Bovell](http://javascriptissexy.com/understand-javascript-closures-with-ease/)\n-  [Understanding JavaScript Closures — Codesmith](https://codeburst.io/understanding-javascript-closures-da6aab330302)\n-  [Understand Closures in JavaScript — Brandon Morelli](https://codeburst.io/understand-closures-in-javascript-d07852fa51e7)\n-  [A simple guide to help you understand closures in JavaScript — Prashant Ram](https://medium.freecodecamp.org/javascript-closures-simplified-d0d23fa06ba4)\n-  [Understanding JavaScript Closures: A Practical Approach — Paul Upendo](https://scotch.io/tutorials/understanding-javascript-closures-a-practical-approach)\n-  [Understanding JavaScript: Closures — Alexander Kondov](https://hackernoon.com/understanding-javascript-closures-4188edf5ea1b)\n-  [How to use JavaScript closures with confidence — Léna Faure](https://hackernoon.com/how-to-use-javascript-closures-with-confidence-85cd1f841a6b)\n-  [JavaScript closures by example — tyler](https://howchoo.com/g/mge2mji2mtq/javascript-closures-by-example)\n-  [JavaScript — Closures and Scope — Alex Aitken](https://codeburst.io/javascript-closures-and-scope-3784c75b9290)\n-  [Discover the power of closures in JavaScript — Cristi Salcescu](https://medium.freecodecamp.org/discover-the-power-of-closures-in-javascript-5c472a7765d7)\n-  [Getting Closure — RealLifeJS](http://reallifejs.com/the-meat/getting-closure/)\n-  [Closure, Currying and IIFE in JavaScript — Ritik](https://dev.to/ritik_dev_js/what-the-hack-is-closure-currying-and-iife-in-javascript-32m9)\n-  [Understanding Closures in JavaScript — Sukhjinder Arora](https://blog.bitsrc.io/a-beginners-guide-to-closures-in-javascript-97d372284dda)\n-  [A basic guide to Closures in JavaScript — Parathan Thiyagalingam](https://medium.freecodecamp.org/a-basic-guide-to-closures-in-javascript-9fc8b7e3463e)\n-  [Closures: Using Memoization — Brian Barbour](https://dev.to/steelvoltage/closures-using-memoization-3597)\n-  [A Brief Introduction to Closures and Lexical Scoping in JavaScript — Ashutosh K Singh](https://betterprogramming.pub/a-brief-introduction-to-closures-and-lexical-scoping-in-javascript-8a5866496232)\n-  [Demystify Closures — stereobooster](https://dev.to/stereobooster/demystify-closures-5g42)\n-  [Scopes and Closures - JavaScript Concepts — Agney Menon](https://dev.to/boywithsilverwings/scopes-and-closures-javascript-concepts-4dfj)\n-  [Understanding Closures in JavaScript — Matt Popovich](https://dev.to/mattpopovich/understanding-closures-in-javascript-3k0d)\n-  [whatthefuck.is · A Closure - Dan Abramov](https://whatthefuck.is/closure)\n-  [Closures in JavaScript can... - Brandon LeBoeuf](https://dev.to/brandonleboeuf/closure-in-javascript-49n7)\n-  [Do you know Closures - Mohamed Khaled](https://dev.to/this_mkhy/do-you-know-es6-part-3-advanced-3fcl#Closures-2)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript The Hard Parts: Closure, Scope & Execution Context - Codesmith](https://www.youtube.com/watch?v=XTAzsODSCsM)\n- [Namaste Javascript by Akshay Saini](https://youtu.be/qikxEIxsXco?si=fGFgUHuaOW49Wg9p)\n- [Javascript Closure — techsith](https://www.youtube.com/watch?v=71AtaJpJHw0)\n- [Closures — Fun Fun Function](https://www.youtube.com/watch?v=CQqwU2Ixu-U)\n- [Closures in JavaScript — techsith](https://www.youtube.com/watch?v=-xqJo5VRP4A)\n- [JavaScript Closures 101: What is a closure? — JavaScript Tutorials](https://www.youtube.com/watch?v=yiEeiMN2Khs)\n- [Closures — freeCodeCamp](https://www.youtube.com/watch?v=1JsJx1x35c0)\n- [JavaScript Closures — CodeWorkr](https://www.youtube.com/watch?v=-rLrGAXK8WE)\n- [Closures in JS - Akshay Saini](https://www.youtube.com/watch?v=qikxEIxsXco)\n- [CLOSURES en JavaScript: Qué son y cómo funcionan - Carlos Azaustre](https://youtu.be/xa8lhVwQBw4)\n- [Learn Closures In 7 Minutes - Web Dev Simplified](https://www.youtube.com/watch?v=3a0I8ICR1Vg)\n\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 22. High Order Functions\n\n### Books\n\n-  [Eloquent JavaScript, 3rd Edition: Ch. 5 - Higher-order Functions](https://eloquentjavascript.net/05_higher_order.html)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Higher-Order Functions in JavaScript — M. David Green](https://www.sitepoint.com/higher-order-functions-javascript/)\n-  [Higher Order Functions: Using Filter, Map and Reduce for More Maintainable Code — Guido Schmitz](https://medium.freecodecamp.org/higher-order-functions-in-javascript-d9101f9cf528)\n-  [First-class and Higher Order Functions: Effective Functional JavaScript — Hugo Di Francesco](https://hackernoon.com/effective-functional-javascript-first-class-and-higher-order-functions-713fde8df50a)\n-  [Higher Order Functions in JavaScript — John Hannah](https://www.lullabot.com/articles/higher-order-functions-in-javascript)\n-  [Just a reminder on how to use high order functions — Pedro Filho](https://github.com/pedroapfilho/high-order-functions)\n-  [Understanding Higher-Order Functions in JavaScript — Sukhjinder Arora](https://blog.bitsrc.io/understanding-higher-order-functions-in-javascript-75461803bad)\n-  [Higher Order Functions - A pragmatic approach — emmanuel ikwuoma](https://dev.to/nuel_ikwuoma/higher-order-functions-a-pragmatic-approach-51fb)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript Higher Order Functions & Arrays — Traversy Media](https://www.youtube.com/watch?v=rRgD1yVwIvE)\n- [Higher Order Functions — Fun Fun Function](https://www.youtube.com/watch?v=BMUiFMZr7vk)\n- [Higher Order Functions in Javascript — Raja Yogan](https://www.youtube.com/watch?v=dTlpYnmBW9I)\n- [Higher Order Iterators in JavaScript — Fun Fun Function](https://www.youtube.com/watch?v=GYRMNp1SKXA)\n- [Higher Order Functions in JavaScript — The Coding Train](https://www.youtube.com/watch?v=H4awPsyugS0)\n- [Part 1: An Introduction to Callbacks and Higher Order Functions - Codesmith](https://www.youtube.com/watch?v=7E8ctomPQJw)\n- [Part 2: Understanding Why We Need Higher Order Functions - Codesmith](https://www.youtube.com/watch?v=28MXziDZkE4)\n- [Higher-Order Functions ft. Functional Programming - Akshay Saini](https://www.youtube.com/watch?v=HkWxvB1RJq0)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 23. Recursion\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Recursion in JavaScript — Kevin Ennis](https://medium.freecodecamp.org/recursion-in-javascript-1608032c7a1f)\n-  [Understanding Recursion in JavaScript — Zak Frisch](https://medium.com/@zfrisch/understanding-recursion-in-javascript-992e96449e03)\n-  [Learn and Understand Recursion in JavaScript — Brandon Morelli](https://codeburst.io/learn-and-understand-recursion-in-javascript-b588218e87ea)\n-  [Recursion in Functional JavaScript — M. David Green](https://www.sitepoint.com/recursion-functional-javascript/)\n-  [Programming with JS: Recursion — Alexander Kondov](https://hackernoon.com/programming-with-js-recursion-31371e2bf808)\n-  [Anonymous Recursion in JavaScript — simo](https://dev.to/simov/anonymous-recursion-in-javascript)\n-  [Recursion, iteration and tail calls in JS — loverajoel](http://www.jstips.co/en/javascript/recursion-iteration-and-tail-calls-in-js/)\n-  [What is Recursion? A Recursive Function Explained with JavaScript Code Examples — Nathan Sebhastian](https://www.freecodecamp.org/news/what-is-recursion-in-javascript/)\n-  [Intro to Recursion — Brad Newman](https://medium.com/@newmanbradm/intro-to-recursion-984a8bd50f4b)\n-  [Accio Recursion!: Your New Favorite JavaScript Spell — Leanne Cabey](https://medium.datadriveninvestor.com/accio-recursion-your-new-favorite-javascript-spell-7e10d3125fb3)\n-  [Recursion Explained (with Examples) — Christina](https://dev.to/christinamcmahon/recursion-explained-with-examples-4k1m)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Recursion In JavaScript — techsith](https://www.youtube.com/watch?v=VtG0WAUvq2w)\n- [Recursion — Fun Fun Function](https://www.youtube.com/watch?v=k7-N8R0-KY4)\n- [Recursion and Recursive Functions — Hexlet](https://www.youtube.com/watch?v=vLhHyGTkjCs)\n- [Recursion: Recursion() — JS Monthly — Lucas da Costa](https://www.youtube.com/watch?v=kGXVsd8pBLw)\n- [Recursive Function in JavaScript — kudvenkat](https://www.youtube.com/watch?v=uyjsR9eNTIw)\n- [What on Earth is Recursion? — Computerphile](https://www.youtube.com/watch?v=Mv9NEXX1VHc)\n- [Javascript Tutorial 34: Introduction To Recursion — codedamn](https://www.youtube.com/watch?v=9NO5dXSlbv8)\n- [Recursion, Iteration, and JavaScript: A Love Story | JSHeroes 2018 — Anjana Vakil](https://www.youtube.com/watch?v=FmiQr4nfoPQ)\n- [Recursion crash course - Colt Steele](https://www.youtube.com/watch?v=lMBVwYrmFZQ&ab_channel=ColtSteele)\n- [What Is Recursion - In Depth - Web Dev Simplified](https://www.youtube.com/watch?v=6oDQaB2one8)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 24. Collections and Generators\n\n### Reference\n\n-  [Generator — MDN web docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [ES6 In Depth: Collections — Jason Orendorff](https://hacks.mozilla.org/2015/06/es6-in-depth-collections/)\n-  [ES6 Collections: Using Map, Set, WeakMap, WeakSet — Kyle Pennell](https://www.sitepoint.com/es6-collections-map-set-weakmap-weakset/)\n-  [ES6 WeakMaps, Sets, and WeakSets in Depth — Nicolás Bevacqua](https://ponyfoo.com/articles/es6-weakmaps-sets-and-weaksets-in-depth)\n-  [Map, Set, WeakMap and WeakSet — JavaScript.Info](https://javascript.info/map-set-weakmap-weakset)\n-  [Maps in ES6 - A Quick Guide — Ben Mildren](https://dev.to/mildrenben/maps-in-es6---a-quick-guide-35pk)\n-  [ES6 — Set vs Array — What and when? — Maya Shavin](https://medium.com/front-end-hacking/es6-set-vs-array-what-and-when-efc055655e1a)\n-  [ES6 — Map vs Object — What and when? — Maya Shavin](https://medium.com/front-end-hacking/es6-map-vs-object-what-and-when-b80621932373)\n-  [Array vs Set vs Map vs Object — Real-time use cases in Javascript (ES6/ES7) — Rajesh Babu](https://codeburst.io/array-vs-set-vs-map-vs-object-real-time-use-cases-in-javascript-es6-47ee3295329b)\n-  [How to create an array of unique values in JavaScript using Sets — Claire Parker-Jones](https://dev.to/claireparker/how-to-create-an-array-of-unique-values-in-javascript-using-sets-5dg6)\n-  [What You Should Know About ES6 Maps — Just Chris](https://hackernoon.com/what-you-should-know-about-es6-maps-dc66af6b9a1e)\n-  [ES6 Maps in Depth — Nicolás Bevacqua](https://ponyfoo.com/articles/es6-maps-in-depth)\n-  [What are JavaScript Generators and how to use them — Vladislav Stepanov](https://codeburst.io/what-are-javascript-generators-and-how-to-use-them-c6f2713fd12e)\n-  [Understanding JavaScript Generators With Examples — Arfat Salman](https://codeburst.io/understanding-generators-in-es6-javascript-with-examples-6728834016d5)\n-  [The Basics of ES6 Generators — Kyle Simpson](https://davidwalsh.name/es6-generators)\n-  [An Introduction to JavaScript Generators — Alice Kallaugher](https://dev.to/kallaugher/an-introduction-to-javascript-generators-1224)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript ES6 / ES2015 Set, Map, WeakSet and WeakMap — Traversy Media](https://www.youtube.com/watch?v=ycohYSx5h9w)\n- [JavaScript ES6 / ES2015 - \\[11\\] Generators - Traversy Media](https://www.youtube.com/watch?v=dcP039DYzmE)\n- [The Differences between ES6 Maps and Sets — Steve Griffith](https://www.youtube.com/watch?v=m4abICrldQI)\n- [Javascript Generators - THEY CHANGE EVERYTHING - ES6 Generators Harmony Generators — LearnCode.academy](https://www.youtube.com/watch?v=QO07THdLWQo)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 25. Promises\n\n### Reference\n\n-  [Promise — MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript Promises for Dummies ― Jecelyn Yeen](https://scotch.io/tutorials/javascript-promises-for-dummies)\n-  [Understanding promises in JavaScript — Gokul N K](https://hackernoon.com/understanding-promises-in-javascript-13d99df067c1)\n-  [Master the JavaScript Interview: What is a Promise? — Eric Elliott](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-a-promise-27fc71e77261)\n-  [An Overview of JavaScript Promises — Sandeep Panda](https://www.sitepoint.com/overview-javascript-promises/)\n-  [How to use Promises in JavaScript — Prashant Ram](https://medium.freecodecamp.org/promises-in-javascript-explained-277b98850de)\n-  [Implementing Promises In JavaScript — Maciej Cieslar](https://medium.freecodecamp.org/how-to-implement-promises-in-javascript-1ce2680a7f51)\n-  [JavaScript: Promises explained with simple real life analogies — Shruti Kapoor](https://codeburst.io/javascript-promises-explained-with-simple-real-life-analogies-dd6908092138)\n-  [Promises for Asynchronous Programming — Exploring JS](http://exploringjs.com/es6/ch_promises.html)\n-  [JavaScript Promises Explained By Gambling At A Casino — Kevin Kononenko](https://blog.codeanalogies.com/2018/08/26/javascript-promises-explained-by-gambling-at-a-casino/)\n-  [ES6 Promises: Patterns and Anti-Patterns — Bobby Brennan](https://medium.com/datafire-io/es6-promises-patterns-and-anti-patterns-bbb21a5d0918)\n-  [A Simple Guide to ES6 Promises — Brandon Morelli](https://codeburst.io/a-simple-guide-to-es6-promises-d71bacd2e13a)\n-  [The ES6 Promises — Manoj Singh Negi](https://codeburst.io/the-es6-promises-87a979ab27e4)\n-  [ES6 Promises in Depth — Nicolás Bevacqua](https://ponyfoo.com/articles/es6-promises-in-depth)\n-  [Playing with Javascript Promises: A Comprehensive Approach — Rajesh Babu](https://codeburst.io/playing-with-javascript-promises-a-comprehensive-approach-25ab752c78c3)\n-  [How to Write a JavaScript Promise — Brandon Wozniewicz](https://medium.freecodecamp.org/how-to-write-a-javascript-promise-4ed8d44292b8)\n-  [A Coding Writer’s Guide: An Introduction To ES6 Promises — Andrew Ly](https://medium.com/@andrewly07/a-coding-writers-guide-an-introduction-to-es6-promises-9ff9f9e88f6c)\n-  [Understanding Promises in JavaScript — Chris Noring](https://dev.to/itnext/reverse-engineering-understand-promises-1jfc)\n-  [Converting callbacks to promises — Zell Liew](https://dev.to/zellwk/converting-callbacks-to-promises-nhn)\n-  [JavaScript Promises: Zero To Hero Plus Cheat Sheet — Joshua Saunders](https://medium.com/dailyjs/javascript-promises-zero-to-hero-plus-cheat-sheet-64d75051cffa)\n-  [Promises - JavaScript concepts — Agney Menon](https://dev.to/boywithsilverwings/promises-javascript-concepts-293c)\n-  [Javascript `Promise` 101 — Igor Irianto](https://dev.to/iggredible/javascript-promise-101-3idl)\n-  [Simplify JavaScript Promises — Sunny Singh](https://dev.to/sunnysingh/simplify-javascript-promises-4djb)\n-  [The Lowdown on Promises — Aphinya Dechalert](https://medium.matcha.fyi/the-low-down-on-promises-af4a96bbb95f)\n-  [JavaScript Visualized: Promises & Async/Await — Lydia Hallie](https://dev.to/lydiahallie/javascript-visualized-promises-async-await-5gke)\n-  [Promises in JavaScript — Peter Klingelhofer](https://dev.to/peterklingelhofer/promises-in-javascript-3h5k)\n-  [Best Practices for ES6 Promises — Basti Ortiz](https://dev.to/somedood/best-practices-for-es6-promises-36da)\n-  [Lo que debemos saber de EScript 2020 — Kike Sanchez](https://medium.com/zurvin/lo-que-debemos-saber-de-escript-2020-5fc61da5e4cd)\n-  [Promise Basics - javascript.info](https://javascript.info/promise-basics)\n-  [The Complete JavaScript Promise Guide](https://blog.webdevsimplified.com/2021-09/javascript-promises)\n-  [Promise Chaining - javascript.info](https://javascript.info/promise-chaining)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Let's Learn ES6 - Promises — Ryan Christiani](https://www.youtube.com/watch?v=vQ3MoXnKfuQ)\n- [JavaScript ES6 / ES2015 Promises — Traversy Media](https://www.youtube.com/watch?v=XJEHuBZQ5dU)\n- [Promises — Fun Fun Function](https://www.youtube.com/watch?v=2d7s3spWAzo)\n- [Error Handling Promises in JavaScript — Fun Fun Function](https://www.youtube.com/watch?v=f8IgdnYIwOU)\n- [Promises Part 1 - Topics of JavaScript/ES6 — The Coding Train](https://www.youtube.com/watch?v=QO4NXhWo_NM)\n- [JavaScript Promise in 100 Seconds](https://www.youtube.com/watch?v=RvYYCGs45L4)\n- [JavaScript Promise in 9 Minutes](https://youtu.be/3NjdOtHpcBM)\n- [JavaScript Promises In 10 Minutes — Web Dev Simplified ](https://www.youtube.com/watch?v=DHvZLI7Db8E)\n- [Promises | Ep 02 Season 02 - Namaste JavaScript - Akshay Saini ](https://youtu.be/ap-6PPAuK1Y?si=Ri1fopXeYjlrHzpf)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 26. async/await\n\n### Reference\n\n-  [async/await — JavaScript.Info](https://javascript.info/async-await)\n\n### Books\n\n-  [Eloquent JavaScript, 3rd Edition: Ch. 11 - Asynchronous Programming](https://eloquentjavascript.net/11_async.html)\n-  [Exploring JS: Asynchronous Programming](http://exploringjs.com/es6/ch_async.html)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Understanding async/await in Javascript — Gokul N K](https://hackernoon.com/understanding-async-await-in-javascript-1d81bb079b2c)\n-  [Asynchronous Javascript using async/await — Joy Warugu](https://scotch.io/tutorials/asynchronous-javascript-using-async-await)\n-  [Modern Asynchronous JavaScript with async/await — Flavio Copes](https://flaviocopes.com/javascript-async-await/)\n-  [Asynchronous JavaScript: From Callback Hell to Async and Await — Demir Selmanovic](https://www.toptal.com/javascript/asynchronous-javascript-async-await-tutorial)\n-  [Javascript — ES8 Introducing async/await Functions — Ben Garrison](https://medium.com/@_bengarrison/javascript-es8-introducing-async-await-functions-7a471ec7de8a)\n-  [How to escape async/await hell — Aditya Agarwal](https://medium.freecodecamp.org/avoiding-the-async-await-hell-c77a0fb71c4c)\n-  [Understanding JavaScript’s async await — Nicolás Bevacqua](https://ponyfoo.com/articles/understanding-javascript-async-await)\n-  [JavaScript Async/Await: Serial, Parallel and Complex Flow — TechBrij](https://techbrij.com/javascript-async-await-parallel-sequence)\n-  [From JavaScript Promises to Async/Await: why bother? — Chris Nwamba](https://blog.pusher.com/promises-async-await/)\n-  [Flow Control in Modern JS: Callbacks to Promises to Async/Await — Craig Buckler](https://www.sitepoint.com/flow-control-callbacks-promises-async-await/)\n-  [How to improve your asynchronous Javascript code with async and await — Indrek Lasn](https://medium.freecodecamp.org/improve-your-asynchronous-javascript-code-with-async-and-await-c02fc3813eda)\n-  [Making Fetches Easy With Async Await — Mickey Sheridan](https://medium.com/@micksheridan.24/making-fetches-easy-with-async-await-8a1246efa1f6)\n-  [7 Reasons Why JavaScript Async/Await Is Better Than Plain Promises — Mostafa Gaafar](https://dev.to/gafi/7-reasons-to-always-use-async-await-over-plain-promises-tutorial-4ej9)\n-  [Asynchronous Operations in JavaScript — Jscrambler](https://dev.to/jscrambler/asynchronous-operations-in-javascript-2p6b)\n-  [JavaScript: Promises or async-await — Gokul N K](https://medium.com/better-programming/should-i-use-promises-or-async-await-126ab5c98789)\n-  [Async / Await: From Zero to Hero — Zhi Yuan](https://dev.to/zhiyuanamos/async-await-from-zero-to-hero-a22)\n-  [JavaScript Visualized: Promises & Async/Await — Lydia Hallie](https://dev.to/lydiahallie/javascript-visualized-promises-async-await-5gke)\n-  [Making asynchronous programming easier with async and await — MDN](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await)\n-  [JavaScript Async/Await Tutorial – Learn Callbacks, Promises, and Async/Await in JS by Making Ice Cream](https://www.freecodecamp.org/news/javascript-async-await-tutorial-learn-callbacks-promises-async-await-by-making-icecream/)\n-  [Better Than Promises - JavaScript Async/Await](https://blog.webdevsimplified.com/2021-11/async-await/)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Asynchronous JavaScript Crash Course](https://www.youtube.com/watch?v=exBgWAIeIeg)\n- [Async + Await — Wes Bos](https://www.youtube.com/watch?v=9YkUCxvaLEk)\n- [Asynchrony: Under the Hood — Shelley Vohr](https://www.youtube.com/watch?v=SrNQS8J67zc)\n- [async/await in JavaScript - What, Why and How — Fun Fun Function](https://www.youtube.com/watch?v=568g8hxJJp4&index=3&list=PL0zVEGEvSaeHJppaRLrqjeTPnCH6)\n- [async/await Part 1 - Topics of JavaScript/ES8 — The Coding Train](https://www.youtube.com/watch?v=XO77Fib9tSI&index=3&list=PLRqwX-V7Uu6bKLPQvPRNNE65kBL62mVfx)\n- [async/await Part 2 - Topics of JavaScript/ES8 — The Coding Train](https://www.youtube.com/watch?v=chavThlNz3s&index=4&list=PLRqwX-V7Uu6bKLPQvPRNNE65kBL62mVfx)\n- [Complete Guide to JS Async & Await ES2017/ES8 — Colt Steele](https://www.youtube.com/watch?v=krAYA4rvbdA)\n- [Tips for using async/await in JavaScript — James Q Quick](https://www.youtube.com/watch?v=_9vgd9XKlDQ)\n- [JavaScript Async Await — Web Dev Simplified](https://www.youtube.com/watch?v=V_Kr9OSfDeU)\n- [Promise async and await in javascript — Hitesh Choudhary](https://youtu.be/Gjbr21JLfgg?si=SDCVKr9ONw2GsNdT)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 27. Data Structures\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Data Structures in JavaScript — Thon Ly](https://medium.com/siliconwat/data-structures-in-javascript-1b9aed0ea17c)\n-  [Algorithms and Data Structures in JavaScript — Oleksii Trekhleb](https://itnext.io/algorithms-and-data-structures-in-javascript-a71548f902cb)\n-  [Data Structures: Objects and Arrays ― Chris Nwamba](https://scotch.io/courses/10-need-to-know-javascript-concepts/data-structures-objects-and-arrays)\n-  [Data structures in JavaScript — Benoit Vallon](http://blog.benoitvallon.com/data-structures-in-javascript/data-structures-in-javascript/)\n-  [Playing with Data Structures in Javascript — Anish K.](https://blog.cloudboost.io/playing-with-data-structures-in-javascript-stack-a55ebe50f29d)\n-  [The Little Guide of Queue in JavaScript — Germán Cutraro](https://hackernoon.com/the-little-guide-of-queue-in-javascript-4f67e79260d9)\n-  [All algorithms writing with JavaScript in the book 'Algorithms Fourth Edition'](https://github.com/barretlee/algorithms)\n-  [Collection of classic computer science paradigms in JavaScript](https://github.com/nzakas/computer-science-in-javascript)\n-  [All the things you didn't know you wanted to know about data structures](https://github.com/jamiebuilds/itsy-bitsy-data-structures)\n-  [JavaScript Data Structures: 40 Part Series — miku86](https://dev.to/miku86/series/3259)\n-  [Data Structures: Understanding Graphs — Rachel Hawa](https://medium.com/javascript-in-plain-english/data-structures-understanding-graphs-82509d35e6b5)\n-  [Data Structures Two Ways: Linked List (Pt 1) — Freddie Duffield](https://dev.to/freddieduffield/data-structures-two-ways-linked-list-2n61)\n-  [Data Structures Two Ways: Linked List (Pt 2) — Freddie Duffield](https://dev.to/freddieduffield/data-structures-two-ways-linked-list-pt2-2i60)\n-  [Graph Data Structures Explained in JavaScript — Adrian Mejia](https://dev.to/amejiarosario/graph-data-structures-for-beginners-5edn)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Algorithms In Javascript | Ace Your Interview — Eduonix Learning Solutions](https://www.youtube.com/watch?v=H_EBPZgiAas&list=PLDmvslp_VR0zYUSth_8O69p4_cmvZEgLa)\n- [Data Structures and Algorithms in JavaScript — freeCodeCamp](https://www.youtube.com/watch?v=Gj5qBheGOEo&list=PLWKjhJtqVAbkso-IbgiiP48n-O-JQA9PJ)\n- [Learning JavaScript Data Structures and Algorithms: Sorting — Packt Video](https://www.youtube.com/watch?v=Ymh_AurrMbA)\n- [JavaScript Data Structures: Getting Started — Academind](https://www.youtube.com/watch?v=41GSinwoMYA&ab_channel=Academind)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 28. Expensive Operation and Big O Notation\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Big O Notation in Javascript — César Antón Dorantes](https://medium.com/cesars-tech-insights/big-o-notation-javascript-25c79f50b19b)\n-  [Time Complexity/Big O Notation — Tim Roberts](https://medium.com/javascript-scene/time-complexity-big-o-notation-1a4310c3ee4b)\n-  [Big O in JavaScript — Gabriela Medina](https://medium.com/@gmedina229/big-o-in-javascript-36ff67766051)\n-  [Big O Search Algorithms in JavaScript — Bradley Braithwaite](https://www.bradoncode.com/blog/2012/04/big-o-algorithm-examples-in-javascript.html)\n-  [Algorithms in plain English: time complexity and Big-O Notation — Michael Olorunnisola](https://medium.freecodecamp.org/time-is-complex-but-priceless-f0abd015063c)\n-  [An Introduction to Big O Notation — Joseph Trettevik](https://dev.to/lofiandcode/an-introduction-to-big-o-notation-210o)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript: Intro to Big O Notation and Function Runtime — Eric Traub](https://www.youtube.com/watch?v=HgA5VOFan5E)\n- [Essential Big O for JavaScript Developers — Dave Smith](https://www.youtube.com/watch?v=KatlvCFHPRo)\n- [Big O Notation - Time Complexity Analysis — WebTunings](https://www.youtube.com/watch?v=ALl86xJiTD8)\n- [Learn Big O Notation In 12 Minutes - Web Dev Simplified](https://www.youtube.com/watch?v=itn09C2ZB9Y)\n- [JavaScript Algorithms: Big-O Notation - Codevolution](https://www.youtube.com/watch?v=3yUuo7TqMW8)\n- [JavaScript Algorithms Crash Course: Learn Algorithms & \"Big O\" from the Ground Up! - Academind](https://www.youtube.com/watch?v=JgWm6sQwS_I)\n- [Big O Notation - Data Structures and Algorithms in Javascript - RoadSideCoder](https://www.youtube.com/watch?v=LaexPVi1VRE)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 29. Algorithms\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Data Structures and Algorithms using ES6](https://github.com/Crizstian/data-structure-and-algorithms-with-ES6)\n-  [Algorithms and data structures implemented in JavaScript with explanations and links to further readings](https://github.com/trekhleb/javascript-algorithms)\n-  [JS: Interview Algorithm](http://www.thatjsdude.com/interview/js1.html)\n-  [Algorithms in JavaScript — Thon Ly](https://medium.com/siliconwat/algorithms-in-javascript-b0bed68f4038)\n-  [JavaScript Objects, Square Brackets and Algorithms — Dmitri Grabov](https://medium.freecodecamp.org/javascript-objects-square-brackets-and-algorithms-e9a2916dc158)\n-  [Atwood's Law applied to CS101 - Classic algorithms and data structures implemented in JavaScript](https://github.com/felipernb/algorithms.js)\n-  [Data Structures and Algorithms library in JavaScript](https://github.com/yangshun/lago)\n-  [Collection of computer science algorithms and data structures written in JavaScript](https://github.com/idosela/algorithms-in-javascript)\n-  [Algorithms and Data Structures in JavaScript — Oleksii Trekhleb](https://dev.to/trekhleb/algorithms-and-data-structures-in-javascript-49i3)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- 🎥 [JavaScript Algorithms - Codevolution](https://www.youtube.com/playlist?list=PLC3y8-rFHvwiRYB4-HHKHblh3_bQNJTMa)\n- 🎥 [Dynamic Programming - Learn to Solve Algorithmic Problems & Coding Challenges - FreeCodeCamp](https://www.youtube.com/watch?v=oBt53YbR9Kk&t=1021s)\n- 🎥 [Data Structures and Algorithms in Javascript | DSA with JS - RoadsideCoder](https://www.youtube.com/playlist?list=PLKhlp2qtUcSZtJefDThsXcsAbRBCSTgW4)\n- 🎥 [Javascript Algorithms + Data Structures - KodingKevin](https://www.youtube.com/playlist?list=PLn2ipk-jqgZiAHiA70hOxAj8RMUeqYNK3)\n- 🎥 [JavaScript Data Structures: Getting Started - Academind](https://www.youtube.com/watch?v=41GSinwoMYA)\n- 🎥 [Algorithms and Data Structures - The Coding Train (Daniel Shiffman)](https://www.youtube.com/playlist?list=PLRqwX-V7Uu6ZiZxtDDRCi6uhfTH4FilpH)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 30. Inheritance, Polymorphism and Code Reuse\n\n### Reference\n\n-  [Inheritance in JavaScript — MDN](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Objects/Inheritance)\n-  [Class inheritance, super — JavaScript.Info](https://javascript.info/class-inheritance)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Inheritance in JavaScript — Rupesh Mishra](https://hackernoon.com/inheritance-in-javascript-21d2b82ffa6f)\n-  [Simple Inheritance with JavaScript — David Catuhe](https://www.sitepoint.com/simple-inheritance-javascript/)\n-  [JavaScript — Inheritance, delegation patterns and Object linking — NC Patro](https://codeburst.io/javascript-inheritance-25fe61ab9f85)\n-  [Object Oriented JavaScript: Polymorphism with examples — Knoldus Blogs](https://blog.knoldus.com/object-oriented-javascript-polymorphism-with-examples/)\n-  [Program Like Proteus — A beginner’s guide to polymorphism in Javascript — Sam Galson](https://medium.com/yld-blog/program-like-proteus-a-beginners-guide-to-polymorphism-in-javascript-867bea7c8be2)\n-  [Object-oriented JavaScript: A Deep Dive into ES6 Classes — Jeff Mott](https://www.sitepoint.com/object-oriented-javascript-deep-dive-es6-classes/)\n-  [Unlocking the Power of Polymorphism in JavaScript: A Deep Dive](https://prototypr.io/post/unlocking-the-power-of-polymorphism-in-javascript-a-deep-dive)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Inheritance in JavaScript — kudvenkat](https://www.youtube.com/watch?v=yXlFR81tDBM)\n- [JavaScript ES6 Classes and Inheritance — Traversy Media](https://www.youtube.com/watch?v=RBLIm5LMrmc)\n- [Polymorphism in JavaScript — kudvenkat](https://www.youtube.com/watch?v=zdovG9cuEBA)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 31. Design Patterns\n\n### Books\n\n-  [Learning JavaScript Design Patterns — Addy Osmani](https://addyosmani.com/resources/essentialjsdesignpatterns/book/)\n-  [Pro JavaScript Design Patterns — Ross Harmes and Dustin Diaz](https://pepa.holla.cz/wp-content/uploads/2016/08/Pro-JavaScript-Design-Patterns.pdf)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [JavaScript Design Patterns – Explained with Examples — Germán Cocca](https://www.freecodecamp.org/news/javascript-design-patterns-explained/)\n-  [4 JavaScript Design Patterns You Should Know — Devan Patel](https://scotch.io/bar-talk/4-javascript-design-patterns-you-should-know)\n-  [JavaScript Design Patterns – Beginner's Guide to Mobile Web Development — Soumyajit Pathak](https://medium.com/beginners-guide-to-mobile-web-development/javascript-design-patterns-25f0faaaa15)\n-  [JavaScript Design Patterns — Akash Pal](https://medium.com/front-end-hacking/javascript-design-patterns-ed9d4c144c81)\n-  [JavaScript Design Patterns: Understanding Design Patterns in JavaScript - Sukhjinder Arora](https://blog.bitsrc.io/understanding-design-patterns-in-javascript-13345223f2dd)\n-  [All the 23 (GoF) design patterns implemented in Javascript — Felipe Beline](https://github.com/fbeline/Design-Patterns-JS)\n-  [The Power of the Module Pattern in JavaScript — jsmanifest](https://medium.com/better-programming/the-power-of-the-module-pattern-in-javascript-3c73f7cd10e8)\n-  [Design Patterns for Developers using JavaScript pt. I — Oliver Mensah](https://dev.to/omensah/design-patterns-for-developers-using-javascript----part-one--b3e)\n-  [Design Patterns for Developers using JavaScript pt. II — Oliver Mensah](https://dev.to/omensah/design-patterns-for-developers-using-javascript---part-two--3p39)\n-  [Design patterns in modern JavaScript development](https://levelup.gitconnected.com/design-patterns-in-modern-javascript-development-ec84d8be06ca)\n-  [Understanding Design Patterns: Iterator using Dev.to and Medium social networks! — Carlos Caballero](https://dev.to/carlillo/understanding-design-patterns-iterator-using-dev-to-and-medium-social-networks-3bdd)\n-  [JavaScript Design Patterns - Factory Pattern — KristijanFištrek](https://dev.to/kristijanfistrek/javascript-design-patterns-factory-pattern-562p)\n-  [JavaScript Design Pattern — Module Pattern - Factory Pattern — Moon](https://medium.com/javascript-in-plain-english/javascript-design-pattern-module-pattern-555737eccecd)\n-  [Design Patterns: Null Object - Carlos Caballero](https://medium.com/better-programming/design-patterns-null-object-5ee839e37892)\n-  [Strategy Pattern - Francesco Ciulla](https://dev.to/francescoxx/strategy-pattern-5oh)\n-  [Adapter Pattern - Francesco Ciulla](https://dev.to/francescoxx/adapter-pattern-5bjk)\n-  [The Power of Composite Pattern in JavaScript - jsmanifest](https://dev.to/jsmanifest/the-power-of-composite-pattern-in-javascript-2732)\n-  [In Defense of Defensive Programming - Adam Nathaniel Davis](https://dev.to/bytebodger/in-defense-of-defensive-programming-k45)\n-  [JavaScript Patterns Workshop — Lydia Hallie](https://javascriptpatterns.vercel.app/patterns)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [JavaScript Design Patterns — Udacity](https://www.udacity.com/course/javascript-design-patterns--ud989)\n- [JavaScript Patterns for 2017 — Scott Allen](https://www.youtube.com/watch?v=hO7mzO83N1Q)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 32. Partial Applications, Currying, Compose and Pipe\n\n### Books\n\n-  [Functional-Light JavaScript: Ch. 3 - Managing Function Inputs — Kyle Simpson](https://github.com/getify/Functional-Light-JS/blob/master/manuscript/ch3.md)\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Composition and Currying Elegance in JavaScript — Pragyan Das](https://medium.com/@pragyan88/writing-middleware-composition-and-currying-elegance-in-javascript-8b15c98a541b)\n-  [Functional JavaScript: Function Composition For Every Day Use — Joel Thoms](https://hackernoon.com/javascript-functional-composition-for-every-day-use-22421ef65a10)\n-  [Functional Composition: compose() and pipe() — Anton Paras](https://medium.com/@acparas/what-i-learned-today-july-2-2017-ab9a46dbf85f)\n-  [Why The Hipsters Compose Everything: Functional Composing In JavaScript — A. Sharif](http://busypeoples.github.io/post/functional-composing-javascript/)\n-  [A Gentle Introduction to Functional JavaScript pt III: Functions for making functions — James Sinclair](https://jrsinclair.com/articles/2016/gentle-introduction-to-functional-javascript-functions/)\n-  [Curry And Compose (why you should be using something like ramda in your code) — jsanchesleao](https://jsleao.wordpress.com/2015/02/22/curry-and-compose-why-you-should-be-using-something-like-ramda-in-your-code/)\n-  [Function Composition in JavaScript with Pipe — Andy Van Slaars](https://vanslaars.io/post/create-pipe-function/)\n-  [Practical Functional JavaScript with Ramda — Andrew D'Amelio, Yuri Takhteyev](https://developer.telerik.com/featured/practical-functional-javascript-ramda/)\n-  [The beauty in Partial Application, Currying, and Function Composition — Joel Thoms](https://hackernoon.com/the-beauty-in-partial-application-currying-and-function-composition-d885bdf0d574)\n-  [Curry or Partial Application? — Eric Elliott](https://medium.com/javascript-scene/curry-or-partial-application-8150044c78b8)\n-  [Partial Application in JavaScript — Ben Alman](http://benalman.com/news/2012/09/partial-application-in-javascript/)\n-  [Partial Application of Functions — Functional Reactive Ninja](https://hackernoon.com/partial-application-of-functions-dbe7d9b80760)\n-  [Currying vs Partial Application — Deepak Gupta](https://towardsdatascience.com/javascript-currying-vs-partial-application-4db5b2442be8)\n-  [Partial Application in ECMAScript 2015 — Ragan Wald](http://raganwald.com/2015/04/01/partial-application.html)\n-  [So You Want to be a Functional Programmer pt. I — Charles Scalfani](https://medium.com/@cscalfani/so-you-want-to-be-a-functional-programmer-part-1-1f15e387e536)\n-  [So You Want to be a Functional Programmer pt. II — Charles Scalfani](https://medium.com/@cscalfani/so-you-want-to-be-a-functional-programmer-part-2-7005682cec4a)\n-  [So You Want to be a Functional Programmer pt. III — Charles Scalfani](https://medium.com/@cscalfani/so-you-want-to-be-a-functional-programmer-part-3-1b0fd14eb1a7)\n-  [So You Want to be a Functional Programmer pt. IV — Charles Scalfani](https://medium.com/@cscalfani/so-you-want-to-be-a-functional-programmer-part-4-18fbe3ea9e49)\n-  [So You Want to be a Functional Programmer pt. V — Charles Scalfani](https://medium.com/@cscalfani/so-you-want-to-be-a-functional-programmer-part-5-c70adc9cf56a)\n-  [An introduction to the basic principles of Functional Programming — TK](https://medium.freecodecamp.org/an-introduction-to-the-basic-principles-of-functional-programming-a2c2a15c84)\n-  [Concepts of Functional Programming in Javascript — TK](https://medium.com/the-renaissance-developer/concepts-of-functional-programming-in-javascript-6bc84220d2aa)\n-  [An Introduction to Functional Programming Style in JavaScript — JavaScript Teacher](https://medium.freecodecamp.org/an-introduction-to-functional-programming-style-in-javascript-71fcc050f064)\n-  [A practical guide to writing more functional JavaScript — Nadeesha Cabral](https://medium.freecodecamp.org/a-practical-guide-to-writing-more-functional-javascript-db49409f71)\n-  [A simple explanation of functional pipe in JavaScript — Ben Lesh](https://dev.to/benlesh/a-simple-explanation-of-functional-pipe-in-javascript-2hbj)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- [Compose vs Pipe: Functional Programming in JavaScript — Chyld Studios](https://www.youtube.com/watch?v=Wl2ejJOqHUU)\n- [JavaScript Functional Programing: Compose — Theodore Anderson](https://www.youtube.com/watch?v=jigHxo9YR30)\n- [Function Composition - Functional JavaScript — NWCalvank](https://www.youtube.com/watch?v=mth5WpEc4Qs)\n- [JavaScript Function Composition Explained — Theodore Anderson](https://www.youtube.com/watch?v=Uam37AlzPYw)\n- [Let's code with function composition — Fun Fun Function](https://www.youtube.com/watch?v=VGB9HbL1GHk)\n- [Partial Application vs. Currying — NWCalvank](https://www.youtube.com/watch?v=DzLkRsUN2vE)\n- [JavaScript Partial Application — Theodore Anderson](https://www.youtube.com/watch?v=jkebgHEcvac)\n- [call, apply and bind method in JavaScript](https://www.youtube.com/watch?v=75W8UPQ5l7k&t=261s)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n---\n\n## 33. Clean Code\n\n### <img  align= center width=40px height=40px src=\"https://cdn-icons-png.flaticon.com/512/1945/1945940.png\"> Articles\n\n-  [Clean Code Explained – A Practical Introduction to Clean Coding for Beginners — freeCodeCamp](https://www.freecodecamp.org/news/clean-coding-for-beginners/)\n-  [Clean Code concepts adapted for JavaScript — Ryan McDermott](https://github.com/ryanmcdermott/clean-code-javascript)\n-  [Clean Code Practice: How to write clean code — Tirth Bodawala](https://www.atyantik.com/clean-code-practices-javascript/)\n-  [Function parameters in JavaScript Clean Code — Kevin Peters](https://medium.com/@kevin_peters/function-parameters-in-javascript-clean-code-4caac109159b)\n-  [Keeping your code clean — Samuel James](https://codeburst.io/keeping-your-code-clean-d30bcffd1a10)\n-  [Best Practices for Using Modern JavaScript Syntax — M. David Green](https://www.sitepoint.com/modern-javascript-best-practices/)\n-  [best practices for cross node/web development - Jimmy Wärting](https://github.com/cross-js/cross-js)\n-  [Writing Clean Code - Dylan Paulus](https://dev.to/ganderzz/on-writing-clean-code-57cm)\n-  [Writing Clean Code and The Practice of Programming - Nityesh Agarwal](https://dev.to/nityeshaga/writing-clean-code-and-the-practice-of-programming-actionable-advice-for-beginners-5f0k)\n-  [Clean code, dirty code, human code - Daniel Irvine](https://dev.to/d_ir/clean-code-dirty-code-human-code-6nm)\n-  [Practical Ways to Write Better JavaScript - Ryland G](https://dev.to/taillogs/practical-ways-to-write-better-javascript-26d4)\n-  [The Must-Know Clean Code Principles - Kesk on Medium](https://medium.com/swlh/the-must-know-clean-code-principles-1371a14a2e75)\n-  [The Clean Code Book - Robert C Martin](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882/)\n-  [How to use destructuring in JavaScript to write cleaner, more powerful code - freecodecamp](https://www.freecodecamp.org/news/how-to-use-destructuring-in-javascript-to-write-cleaner-more-powerful-code-9d1b38794050/)\n-  [Write Clean Code Using JavaScript Object Destructuring - Asel Siriwardena](https://betterprogramming.pub/write-clean-code-using-javascript-object-destructuring-3551302130e7)\n- [JavaScript Clean Coding Best Practices](https://blog.risingstack.com/javascript-clean-coding-best-practices-node-js-at-scale/)\n\n### <img align=center width=\"40\" height=\"40\" src=\"https://img.icons8.com/dusk/64/video.png\" alt=\"video\"/>  Videos\n\n- 🎥 [JavaScript Pro Tips - Code This, NOT That](https://www.youtube.com/watch?v=Mus_vwhTCq0)\n- 🎥 [Clean Code playlist - Beau teaches](https://www.youtube.com/watch?v=b9c5GmmS7ks&list=PLWKjhJtqVAbkK24EaPurzMq0-kw5U9pJh&index=1)\n- 🎥 [JavaScript Best Practices and Coding Conventions - Write Clean Code](https://youtu.be/RMN_bkZ1KM0?si=Ssg3cNZ_DB7CIwKQ)\n- 🎥 [JavaScript Clean Code](https://youtu.be/vPXzVNmCPg4?si=QR1k4E6Zx5H4mfcs)\n- 🎥 [Tips On Learning How To Code](https://www.youtube.com/watch?v=0wHyoBPc6zs)\n\n**[⬆ Back to Top](#table-of-contents)**\n\n## <img  align= center width=50px height=50px src=\"https://moein.video/wp-content/uploads/2022/05/license-GIF-Certificate-Royalty-Free-Animated-Icon-350px-after-effects-project.gif\"> License <a id = \"License\"></a>\nThis software is licensed under MIT License, See [License](https://github.com/leonardomso/33-js-concepts/blob/master/LICENSE) for more information ©Leonardo Maldonado.\n"
        },
        {
          "name": "index.js",
          "type": "blob",
          "size": 0.33,
          "content": "/* \n    33 JavaScript Concepts is a project created to help JavaScript developers master their skills. It is a compilation of fundamental JavaScript concepts that are important and fundamental. \n\n    This project was inspired by an article written by Stephen Curtis. \n\n    Any kind of contribution is welcome. Feel free to contribute.\n*/\n"
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 0.75,
          "content": "{\n  \"name\": \"33-js-concepts\",\n  \"version\": \"1.0.0\",\n  \"description\": \"33 concepts every JavaScript developer should know.\",\n  \"main\": \"index.js\",\n  \"author\": {\n    \"name\": \"Leonardo Maldonado\",\n    \"url\": \"https://github.com/leonardomso\"\n  },\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/leonardomso/33/issues\"\n  },\n  \"homepage\": \"https://github.com/leonardomso/33#readme\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/leonardomso/33.git\"\n  },\n  \"keywords\": [\n    \"JavaScript\",\n    \"javascript\",\n    \"JS\",\n    \"programming\",\n    \"web\",\n    \"web dev\",\n    \"front end\",\n    \"front-end\",\n    \"nodejs\",\n    \"Node.js\",\n    \"NodeJS\",\n    \"Node\"\n  ]\n}\n"
        }
      ]
    },
    {
      "nameWithOwner": "ventoy/Ventoy",
      "stars": 64012,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "BUSYBOX",
          "type": "tree",
          "content": null
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 34.33,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<https://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<https://www.gnu.org/licenses/why-not-lgpl.html>.\n"
        },
        {
          "name": "DMPATCH",
          "type": "tree",
          "content": null
        },
        {
          "name": "DMSETUP",
          "type": "tree",
          "content": null
        },
        {
          "name": "DOC",
          "type": "tree",
          "content": null
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.78,
          "content": "FROM centos:7\n\nRUN sed -i \\\n    -e 's/^mirrorlist/#mirrorlist/' \\\n    -e 's/^#baseurl/baseurl/' \\\n    -e 's/mirror\\.centos\\.org/vault.centos.org/' \\\n    /etc/yum.repos.d/*.repo && \\\n    yum -y -q install \\\n        libXpm net-tools bzip2 wget vim gcc gcc-c++ samba dos2unix glibc-devel glibc.i686 glibc-devel.i686 \\\n        mpfr.i686 mpfr-devel.i686 rsync autogen autoconf automake libtool gettext* bison binutils \\\n        flex device-mapper-devel SDL libpciaccess libusb freetype freetype-devel gnu-free-* qemu-* virt-* \\\n        libvirt* vte* NetworkManager-bluetooth brlapi fuse-devel dejavu* gnu-efi* pesign shim \\\n        iscsi-initiator-utils grub2-tools zip nasm acpica-tools glibc-static zlib-static xorriso lz4 squashfs-tools\n\nCMD cd /ventoy/INSTALL && ls -la && sh docker_ci_build.sh    \n"
        },
        {
          "name": "EDK2",
          "type": "tree",
          "content": null
        },
        {
          "name": "EfiISO",
          "type": "tree",
          "content": null
        },
        {
          "name": "ExFAT",
          "type": "tree",
          "content": null
        },
        {
          "name": "FUSEISO",
          "type": "tree",
          "content": null
        },
        {
          "name": "GRUB2",
          "type": "tree",
          "content": null
        },
        {
          "name": "ICON",
          "type": "tree",
          "content": null
        },
        {
          "name": "IMG",
          "type": "tree",
          "content": null
        },
        {
          "name": "INSTALL",
          "type": "tree",
          "content": null
        },
        {
          "name": "IPXE",
          "type": "tree",
          "content": null
        },
        {
          "name": "KBD",
          "type": "tree",
          "content": null
        },
        {
          "name": "LANGUAGES",
          "type": "tree",
          "content": null
        },
        {
          "name": "LZIP",
          "type": "tree",
          "content": null
        },
        {
          "name": "License",
          "type": "tree",
          "content": null
        },
        {
          "name": "LinuxGUI",
          "type": "tree",
          "content": null
        },
        {
          "name": "LiveCD",
          "type": "tree",
          "content": null
        },
        {
          "name": "LiveCDGUI",
          "type": "tree",
          "content": null
        },
        {
          "name": "Plugson",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.29,
          "content": "<h1 align=\"center\">\n  <a href=https://www.ventoy.net/>Ventoy</a>\n</h1>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/github/release/ventoy/Ventoy.svg?style=for-the-badge\">\n  <img src=\"https://img.shields.io/github/license/ventoy/Ventoy?style=for-the-badge\">\n  <img src=\"https://img.shields.io/github/stars/ventoy/Ventoy?style=for-the-badge\">\n  <img src=\"https://img.shields.io/github/downloads/ventoy/Ventoy/total.svg?style=for-the-badge\">\n  <img src=\"https://img.shields.io/github/actions/workflow/status/ventoy/Ventoy/ci.yml?label=actions&logo=github&style=for-the-badge\">\n</p>\n\n<h4 align=\"left\">\nVentoy is an open source tool to create bootable USB drive for ISO/WIM/IMG/VHD(x)/EFI files. <br/>\nWith ventoy, you don't need to format the disk over and over, you just need to copy the image files to the USB drive and boot it.   \nYou can copy many image files at a time and ventoy will give you a boot menu to select them. <br/> \nYou can also browse ISO/WIM/IMG/VHD(x)/EFI files in local disk and boot them.<br/>\nx86 Legacy BIOS, IA32 UEFI, x86_64 UEFI, ARM64 UEFI and MIPS64EL UEFI are supported in the same way.<br/>\nBoth MBR and GPT partition style are supported in the same way.<br/>\nMost type of OS supported(Windows/WinPE/Linux/Unix/ChromeOS/Vmware/Xen...) <br/>\n  1200+ ISO files are tested (<a href=\"https://www.ventoy.net/en/isolist.html\">List</a>). 90%+ distros in <a href=\"https://distrowatch.com/\">distrowatch.com</a> supported (<a href=\"https://www.ventoy.net/en/distrowatch.html\">Details</a>). <br/>\n<br/>Official Website: <a href=https://www.ventoy.net>https://www.ventoy.net</a>\n</h4>\n\n# Tested OS\n**Windows**  \nWindows 7, Windows 8, Windows 8.1, Windows 10, Windows 11, Windows Server 2012, Windows Server 2012 R2, Windows Server 2016, Windows Server 2019, Windows Server 2022, WinPE\n\n**Linux**  \nDebian, Ubuntu, CentOS(6/7/8/9), RHEL(6/7/8/9), Deepin, Fedora, Rocky Linux, AlmaLinux, EuroLinux(6/7/8/9), openEuler, OpenAnolis, SLES, openSUSE, MX Linux, Manjaro, Linux Mint, Endless OS, Elementary OS, Solus, Linx, Zorin, antiX, PClinuxOS, Arch, ArcoLinux, ArchLabs, BlackArch, Obarun, Artix Linux, Puppy Linux, Tails, Slax, Kali, Mageia, Slackware, Q4OS, Archman, Gentoo, Pentoo, NixOS, Kylin, openKylin, Ubuntu Kylin, KylinSec, Lubuntu, Xubuntu, Kubuntu, Ubuntu MATE, Ubuntu Budgie, Ubuntu Studio, Bluestar, OpenMandriva, ExTiX, Netrunner, ALT Linux, Nitrux, Peppermint, KDE neon, Linux Lite, Parrot OS, Qubes, Pop OS, ROSA, Void Linux, Star Linux, EndeavourOS, MakuluLinux, Voyager, Feren, ArchBang, LXLE, Knoppix, Calculate Linux, Clear Linux, Pure OS, Oracle Linux, Trident, Septor, Porteus, Devuan, GoboLinux, 4MLinux, Simplicity Linux, Zeroshell, Android-x86, netboot.xyz, Slitaz, SuperGrub2Disk, Proxmox VE, Kaspersky Rescue, SystemRescueCD, MemTest86, MemTest86+, MiniTool Partition Wizard, Parted Magic, veket, Sabayon, Scientific, alpine, ClearOS, CloneZilla, Berry Linux, Trisquel, Ataraxia Linux, Minimal Linux Live, BackBox Linux, Emmabuntüs, ESET SysRescue Live,Nova Linux, AV Linux, RoboLinux, NuTyX, IPFire, SELKS, ZStack, Enso Linux, Security Onion, Network Security Toolkit, Absolute Linux, TinyCore, Springdale Linux, Frost Linux, Shark Linux, LinuxFX, Snail Linux, Astra Linux, Namib Linux, Resilient Linux, Virage Linux, Blackweb Security OS, R-DriveImage, O-O.DiskImage, Macrium, ToOpPy LINUX, GNU Guix, YunoHost, foxclone, siduction, Adelie Linux, Elive, Pardus, CDlinux, AcademiX, Austrumi, Zenwalk, Anarchy, DuZeru, BigLinux, OpenMediaVault, Ubuntu DP, Exe GNU/Linux, 3CX Phone System, KANOTIX, Grml, Karoshi, PrimTux, ArchStrike, CAELinux, Cucumber, Fatdog, ForLEx, Hanthana, Kwort, MiniNo, Redcore, Runtu, Asianux, Clu Linux Live, Uruk, OB2D, BlueOnyx, Finnix, HamoniKR, Parabola, LinHES, LinuxConsole, BEE free, Untangle, Pearl, Thinstation, TurnKey, tuxtrans, Neptune, HefftorLinux, GeckoLinux, Mabox Linux, Zentyal, Maui, Reborn OS, SereneLinux , SkyWave Linux, Kaisen Linux, Regata OS, TROM-Jaro, DRBL Linux, Chalet OS, Chapeau, Desa OS, BlankOn, OpenMamba, Frugalware, Kibojoe Linux, Revenge OS, Tsurugi Linux, Drauger OS, Hash Linux, gNewSense, Ikki Boot, SteamOS, Hyperbola, VyOS, EasyNAS, SuperGamer, Live Raizo, Swift Linux, RebeccaBlackOS, Daphile, CRUX, Univention, Ufficio Zero, Rescuezilla, Phoenix OS, Garuda Linux, Mll, NethServer, OSGeoLive, Easy OS, Volumio, FreedomBox, paldo, UBOS, Recalbox, batocera, Lakka, LibreELEC, Pardus Topluluk, Pinguy, KolibriOS, Elastix, Arya, Omoikane, Omarine, Endian Firewall, Hamara, Rocks Cluster, MorpheusArch, Redo, Slackel, SME Server, APODIO, Smoothwall, Dragora, Linspire, Secure-K OS, Peach OSI, Photon, Plamo, SuperX, Bicom, Ploplinux, HP SPP, LliureX, Freespire, DietPi, BOSS, Webconverger, Lunar, TENS, Source Mage, RancherOS, T2, Vine, Pisi, blackPanther, mAid, Acronis, Active.Boot, AOMEI, Boot.Repair, CAINE, DaRT, EasyUEFI, R-Drive, PrimeOS, Avira Rescue System, bitdefender, Checkra1n Linux, Lenovo Diagnostics, Clover, Bliss-OS, Lenovo BIOS Update, Arcabit Rescue Disk, MiyoLinux, TeLOS, Kerio Control, RED OS, OpenWrt, MocaccinoOS, EasyStartup, Pyabr, Refracta, Eset SysRescue, Linpack Xtreme, Archcraft, NHVBOOT, pearOS, SeaTools, Easy Recovery Essentional, iKuai, StorageCraft SCRE, ZFSBootMenu, TROMjaro, BunsenLabs, Todo en Uno, ChallengerOS, Nobara, Holo, CachyOS, Peux OS, Vanilla OS, ShredOS, paladin, Palen1x, dban, ReviOS, HelenOS, XeroLinux, Tiny 11, chimera linux, CuteFish, DragonOs, Rhino Linux, vanilladpup, crystal, IGELOS, MiniOS, gnoppix, PikaOS, ......\n\n**Unix**  \nDragonFly, FreeBSD, pfSense, GhostBSD, FreeNAS, TrueNAS, XigmaNAS, FuryBSD, OPNsense, HardenedBSD, MidnightBSD, ClonOS, EmergencyBootKit\n\n**ChromeOS**  \nFydeOS, CloudReady, ChromeOS Flex\n\n**Other**  \nVMware ESXi, Citrix XenServer, Xen XCP-ng\n\n\n# Tested Image Report\n[【How to report a successfully tested image file】](https://github.com/ventoy/Ventoy/issues/1195)\n\n# Ventoy Browser\nWith Ventoy, you can also browse ISO/WIM/IMG/VHD(x)/EFI files in local disk and boot them. [Notes](https://www.ventoy.net/en/doc_browser.html)\n  \n# VentoyPlugson\nA GUI Ventoy plugin configurator. [VentoyPlugson](https://www.ventoy.net/en/plugin_plugson.html)\n\n# Features\n* 100% open source\n* Simple to use\n* Fast (limited only by the speed of copying iso file)\n* Can be installed in USB/Local Disk/SSD/NVMe/SD Card\n* Directly boot from ISO/WIM/IMG/VHD(x)/EFI files, no extraction needed\n* Support to browse and boot ISO/WIM/IMG/VHD(x)/EFI files in local disk\n* No need to be continuous in disk for ISO/WIM/IMG/VHD(x)/EFI files\n* MBR and GPT partition style supported (1.0.15+)\n* x86 Legacy BIOS, IA32 UEFI, x86_64 UEFI, ARM64 UEFI, MIPS64EL UEFI supported\n* IA32/x86_64 UEFI Secure Boot supported (1.0.07+)\n* Linux Persistence supported (1.0.11+)\n* Windows auto installation supported (1.0.09+)\n* Linux auto installation supported (1.0.09+)\n* Variables Expansion supported for Windows/Linux auto installation script\n* FAT32/exFAT/NTFS/UDF/XFS/Ext2(3)(4) supported for main partition\n* ISO files larger than 4GB supported\n* Menu alias, Menu tip message supported\n* Password protect supported\n* Native boot menu style for Legacy & UEFI\n* Most types of OS supported, 1200+ iso files tested\n* Linux vDisk boot supported\n* Not only boot but also complete installation process\n* Menu dynamically switchable between List/TreeView mode\n* \"Ventoy Compatible\" concept\n* Plugin Framework and GUI plugin configurator\n* Injection files to runtime environment\n* Boot configuration file dynamically replacement\n* Highly customizable theme and menu\n* USB drive write-protected support\n* USB normal use unaffected\n* Data nondestructive during version upgrade\n* No need to update Ventoy when a new distro is released\n\n![avatar](https://www.ventoy.net/static/img/screen/screen_uefi.png)\n\n\n# Installation Instructions\nSee [https://www.ventoy.net/en/doc_start.html](https://www.ventoy.net/en/doc_start.html) for detailed instructions. \n\n# Compile Instructions\nPlease refer to [BuildVentoyFromSource.txt](DOC/BuildVentoyFromSource.txt)\n\n# Document\nTitle | Link\n-|-\n**Install & Update** | [https://www.ventoy.net/en/doc_start.html](https://www.ventoy.net/en/doc_start.html)\n**Browse/Boot Files In Local Disk** | [https://www.ventoy.net/en/doc_browser.html](https://www.ventoy.net/en/doc_browser.html)\n**Secure Boot** | [https://www.ventoy.net/en/doc_secure.html](https://www.ventoy.net/en/doc_secure.html)\n**Customize Theme** | [https://www.ventoy.net/en/plugin_theme.html](https://www.ventoy.net/en/plugin_theme.html)  \n**Global Control** | [https://www.ventoy.net/en/plugin_control.html](https://www.ventoy.net/en/plugin_control.html)  \n**Image List** | [https://www.ventoy.net/en/plugin_imagelist.html](https://www.ventoy.net/en/plugin_imagelist.html)  \n**Auto Installation** | [https://www.ventoy.net/en/plugin_autoinstall.html](https://www.ventoy.net/en/plugin_autoinstall.html)  \n**Injection Plugin** | [https://www.ventoy.net/en/plugin_injection.html](https://www.ventoy.net/en/plugin_injection.html)  \n**Persistence Support** | [https://www.ventoy.net/en/plugin_persistence.html](https://www.ventoy.net/en/plugin_persistence.html)  \n**Boot WIM file** | [https://www.ventoy.net/en/plugin_wimboot.html](https://www.ventoy.net/en/plugin_wimboot.html)  \n**Windows VHD Boot** | [https://www.ventoy.net/en/plugin_vhdboot.html](https://www.ventoy.net/en/plugin_vhdboot.html)  \n**Linux vDisk Boot** | [https://www.ventoy.net/en/plugin_vtoyboot.html](https://www.ventoy.net/en/plugin_vtoyboot.html)  \n**DUD Plugin** | [https://www.ventoy.net/en/plugin_dud.html](https://www.ventoy.net/en/plugin_dud.html)  \n**Password Plugin** | [https://www.ventoy.net/en/plugin_password.html](https://www.ventoy.net/en/plugin_password.html)  \n**Conf Replace Plugin** | [https://www.ventoy.net/en/plugin_bootconf_replace.html](https://www.ventoy.net/en/plugin_bootconf_replace.html)  \n**Menu Class** | [https://www.ventoy.net/en/plugin_menuclass.html](https://www.ventoy.net/en/plugin_menuclass.html)  \n**Menu Alias** | [https://www.ventoy.net/en/plugin_menualias.html](https://www.ventoy.net/en/plugin_menualias.html)  \n**Menu Extension** | [https://www.ventoy.net/en/plugin_grubmenu.html](https://www.ventoy.net/en/plugin_grubmenu.html)  \n**Memdisk Mode** | [https://www.ventoy.net/en/doc_memdisk.html](https://www.ventoy.net/en/doc_memdisk.html)  \n**TreeView Mode** | [https://www.ventoy.net/en/doc_treeview.html](https://www.ventoy.net/en/doc_treeview.html)  \n**Disk Layout MBR** | [https://www.ventoy.net/en/doc_disk_layout.html](https://www.ventoy.net/en/doc_disk_layout.html)  \n**Disk Layout GPT** | [https://www.ventoy.net/en/doc_disk_layout_gpt.html](https://www.ventoy.net/en/doc_disk_layout_gpt.html)  \n**Search Configuration** | [https://www.ventoy.net/en/doc_search_path.html](https://www.ventoy.net/en/doc_search_path.html)\n\n\n# FAQ\nSee [https://www.ventoy.net/en/faq.html](https://www.ventoy.net/en/faq.html) for detail\n\n\n# Forum\n[https://forums.ventoy.net](https://forums.ventoy.net)\n\n# Donation\nIt would be much appreciated if you want to make a small donation to support my work!  \nAlipay, WeChat Pay, PayPal and Bitcoin are available for donation. You can choose any of them.  \n\nAlipay | WeChat Pay\n-|-\n<img src=\"https://www.ventoy.net/static/img/AliPay.png\" width=\"250\" height=\"250\">|<img src=\"https://www.ventoy.net/static/img/WeChatPay.png\" width=\"250\" height=\"250\">\n\n**PayPal**  \nYou can transfer to my paypal account `admin@ventoy.net` or just click [https://www.paypal.me/ventoy](https://www.paypal.me/ventoy)  \n\n**Bitcoin**  \nBitcoin Address `19mZDWzZgzkHCi9YX9H3fYCUuCHq3W6wfT`\n\n\n\n\n\n\n\n\n"
        },
        {
          "name": "SQUASHFS",
          "type": "tree",
          "content": null
        },
        {
          "name": "Unix",
          "type": "tree",
          "content": null
        },
        {
          "name": "VBLADE",
          "type": "tree",
          "content": null
        },
        {
          "name": "Ventoy2Disk",
          "type": "tree",
          "content": null
        },
        {
          "name": "Vlnk",
          "type": "tree",
          "content": null
        },
        {
          "name": "VtoyTool",
          "type": "tree",
          "content": null
        },
        {
          "name": "ZSTD",
          "type": "tree",
          "content": null
        },
        {
          "name": "cryptsetup",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.1,
          "content": "version: '2'\n\nservices:\n  ventoy:\n    build: .\n    privileged: true\n    volumes:\n     - .:/ventoy\n"
        },
        {
          "name": "vtoycli",
          "type": "tree",
          "content": null
        },
        {
          "name": "vtoyfat",
          "type": "tree",
          "content": null
        },
        {
          "name": "vtoygpt",
          "type": "tree",
          "content": null
        },
        {
          "name": "vtoyjump",
          "type": "tree",
          "content": null
        },
        {
          "name": "wimboot",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "kdn251/interviews",
      "stars": 63790,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".DS_Store",
          "type": "blob",
          "size": 6,
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.01,
          "content": "/bin/\n.idea\n"
        },
        {
          "name": ".project",
          "type": "blob",
          "size": 0.2,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<projectDescription>\n\t<name>interviews</name>\n\t<comment></comment>\n\t<projects>\n\t</projects>\n\t<buildSpec>\n\t</buildSpec>\n\t<natures>\n\t</natures>\n</projectDescription>\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.05,
          "content": "MIT License\n\nCopyright (c) 2018 Kevin Naughton Jr.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README-zh-cn.md",
          "type": "blob",
          "size": 18.2,
          "content": "> * 原文地址：[github.com/kdn251/interviews](https://github.com/kdn251/interviews)\n> * 译文出自：[掘金翻译计划](https://github.com/xitu/gold-miner)\n> * 译者：[王下邀月熊](https://github.com/wxyyxc1992)\n> * 校对者：[PhxNirvana](https://github.com/phxnirvana)、[根号三](https://github.com/sqrthree)\n> * 这个 [链接](https://github.com/xitu/interviews/compare/master...kdn251:master) 用来查看本翻译与英文版是否有差别（如果你没有看到 README.md 发生变化，那就意味着这份翻译文档是最新的）。\n\n# Interviews\n> 软件工程技术面试个人指南。\n>\n> Maintainer - [Kevin Naughton Jr.](https://github.com/kdn251)\n\n## 其他语言版本\n\n- [English](./README.md)\n\n## 目录\n- [在线练习](#在线练习)\n- [在线面试编程](#在线面试编程)\n- [数据结构](#数据结构)\n- [算法](#算法)\n- [位运算](#位运算)\n- [算法复杂度分析](#算法复杂度分析)\n- [视频教程](#视频教程)\n- [面试书籍](#面试书籍)\n- [计算机科学与技术资讯](#计算机科学与技术资讯)\n- [文件结构](#文件结构)\n\n## 在线练习\n* [LeetCode](https://leetcode.com/)\n* [Virtual Judge](https://vjudge.net/)\n* [CareerCup](https://www.careercup.com/)\n* [HackerRank](https://www.hackerrank.com/)\n* [CodeFights](https://codefights.com/)\n* [Kattis](https://open.kattis.com/)\n* [HackerEarth](https://www.hackerearth.com)\n* [Codility](https://codility.com/programmers/lessons/1-iterations/)\n* [Code Forces](http://codeforces.com/)\n* [Code Chef](https://www.codechef.com/)\n* [Sphere Online Judge - SPOJ](http://www.spoj.com/)\n* [InterviewBit](https://www.interviewbit.com/)\n\n## 在线面试编程\n* [Pramp](https://www.pramp.com/ref/gt4-cn)\n* [Gainlo](http://www.gainlo.co/#!/)\n* [Refdash](https://refdash.com/)\n* [Interviewing.io](https://www.interviewing.io/)\n\n## 数据结构\n### Linked List\n * 链表即是由节点（Node）组成的线性集合，每个节点可以利用指针指向其他节点。它是一种包含了多个节点的、能够用于表示序列的数据结构。\n * **单向链表**: 链表中的节点仅指向下一个节点，并且最后一个节点指向空。\n * **双向链表**: 其中每个节点具有两个指针 p、n，使得 p 指向先前节点并且 n 指向下一个节点；最后一个节点的 n 指针指向 null。\n * **循环链表**：每个节点指向下一个节点并且最后一个节点指向第一个节点的链表。\n * 时间复杂度:\n   * 索引: `O(n)`\n   * 搜索: `O(n)`\n   * 插入: `O(1)`\n   * 移除: `O(1)`\n\n### Stack\n * 栈是元素的集合，其包含了两个基本操作：push 操作可以用于将元素压入栈，pop 操作可以将栈顶元素移除。\n * 遵循后入先出（LIFO）原则。\n * 时间复杂度:\n  * 索引: `O(n)`\n  * 搜索: `O(n)`\n  * 插入: `O(1)`\n  * 移除: `O(1)`\n\n### Queue\n * 队列是元素的集合，其包含了两个基本操作：enqueue 操作可以用于将元素插入到队列中，而 dequeue 操作则是将元素从队列中移除。\n * 遵循先入先出原则 (FIFO)。\n * 时间复杂度:\n  * 索引: `O(n)`\n  * 搜索: `O(n)`\n  * 插入: `O(1)`\n  * 移除: `O(1)`\n\n### Tree\n* 树是无向、连通的无环图。\n\n### Binary Tree\n * 二叉树即是每个节点最多包含左子节点与右子节点这两个节点的树形数据结构。\n * **满二叉树**: 树中的每个节点仅包含 0 或 2 个节点。\n * **完美二叉树（Perfect Binary Tree）**: 二叉树中的每个叶节点都拥有两个子节点，并且具有相同的高度。\n * **完全二叉树**: 除最后一层外，每一层上的结点数均达到最大值；在最后一层上只缺少右边的若干结点。\n\n### Binary Search Tree\n\n* 二叉搜索树（BST）是一种特殊的二叉树，其任何节点中的值都会大于或者等于其左子树中存储的值并且小于或者等于其右子树中存储的值。\n* 时间复杂度:\n  * 索引: `O(log(n))`\n  * 搜索: `O(log(n))`\n  * 插入: `O(log(n))`\n  * 删除: `O(log(n))`\n\n<img src=\"/images/BST.png?raw=true\" alt=\"Binary Search Tree\" width=\"400\" height=\"500\">\n\n### Trie\n* 字典树，又称基数树或者前缀树，能够用于存储键为字符串的动态集合或者关联数组的搜索树。树中的节点并没有直接存储关联键值，而是该节点在树中的挂载位置决定了其关联键值。某个节点的所有子节点都拥有相同的前缀，整棵树的根节点则是空字符串。\n\n![Alt text](/images/trie.png?raw=true \"Trie\")\n\n### Fenwick Tree\n* 树状数组又称 Binary Indexed Tree，其表现形式为树，不过本质上是以数组实现。数组中的下标代表着树中的顶点，每个顶点的父节点或者子节点的下标能够通过位运算获得。数组中的每个元素包含了预计算的区间值之和，在整棵树更新的过程中同样会更新这些预计算的值。\n* 时间复杂度:\n  * 区间求值: `O(log(n))`\n  * 更新: `O(log(n))`\n\n![Alt text](/images/fenwickTree.png?raw=true \"Fenwick Tree\")\n\n### Segment Tree\n* 线段树是用于存放间隔或者线段的树形数据结构，它允许快速的查找某一个节点在若干条线段中出现的次数.\n* 时间复杂度:\n  * 区间查询: `O(log(n))`\n  * 更新: `O(log(n))`\n\n![Alt text](/images/segmentTree.png?raw=true \"Segment Tree\")\n\n### Heap\n* 堆是一种特殊的基于树的满足某些特性的数据结构，整个堆中的所有父子节点的键值都会满足相同的排序条件。堆更准确地可以分为最大堆与最小堆，在最大堆中，父节点的键值永远大于或者等于子节点的值，并且整个堆中的最大值存储于根节点；而最小堆中，父节点的键值永远小于或者等于其子节点的键值，并且整个堆中的最小值存储于根节点。\n* 时间复杂度:\n  * 访问最大值 / 最小值: `O(1)`\n  * 插入: `O(log(n))`\n  * 移除最大值 / 最小值: `O(log(n))`\n\n<img src=\"/images/heap.png?raw=true\" alt=\"Max Heap\" width=\"400\" height=\"500\">\n\n\n### Hashing\n* 哈希能够将任意长度的数据映射到固定长度的数据。哈希函数返回的即是哈希值，如果两个不同的键得到相同的哈希值，即将这种现象称为碰撞。\n* **Hash Map**: Hash Map 是一种能够建立起键与值之间关系的数据结构，Hash Map 能够使用哈希函数将键转化为桶或者槽中的下标，从而优化对于目标值的搜索速度。\n* 碰撞解决\n  * **链地址法（Separate Chaining）**: 链地址法中，每个桶是相互独立的，包含了一系列索引的列表。搜索操作的时间复杂度即是搜索桶的时间（固定时间）与遍历列表的时间之和。\n  * **开地址法（Open Addressing）**: 在开地址法中，当插入新值时，会判断该值对应的哈希桶是否存在，如果存在则根据某种算法依次选择下一个可能的位置，直到找到一个尚未被占用的地址。所谓开地址法也是指某个元素的位置并不永远由其哈希值决定。\n\n![Alt text](/images/hash.png?raw=true \"Hashing\")\n\n### Graph\n* 图是一种数据元素间为多对多关系的数据结构，加上一组基本操作构成的抽象数据类型。\n    * **无向图（Undirected Graph）**: 无向图具有对称的邻接矩阵，因此如果存在某条从节点 u 到节点 v 的边，反之从 v 到 u 的边也存在。\n    * **有向图（Directed Graph）**: 有向图的邻接矩阵是非对称的，即如果存在从 u 到 v 的边并不意味着一定存在从 v 到 u 的边。\n\n<img src=\"/images/graph.png?raw=true\" alt=\"Graph\" width=\"400\" height=\"500\">\n\n## 算法\n\n### 排序\n\n#### 快速排序\n* 稳定: 否\n* 时间复杂度:\n  * 最优时间: `O(nlog(n))`\n  * 最坏时间: `O(n^2)`\n  * 平均时间: `O(nlog(n))`\n\n![Alt text](/images/quicksort.gif?raw=true \"Quicksort\")\n\n#### 归并排序\n* 归并排序是典型的分治算法，它不断地将某个数组分为两个部分，分别对左子数组与右子数组进行排序，然后将两个数组合并为新的有序数组。\n* 稳定: 是\n* 时间复杂度:\n  * 最优时间: `O(nlog(n))`\n  * 最坏时间: `O(nlog(n))`\n  * 平均时间: `O(nlog(n))`\n\n![Alt text](/images/mergesort.gif?raw=true \"Mergesort\")\n\n#### 桶排序\n* 桶排序将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。\n* 时间复杂度:\n  * 最优时间: `Ω(n + k)`\n  * 最坏时间: `O(n^2)`\n  * 平均时间:`Θ(n + k)`\n\n\n![Alt text](/images/bucketsort.png?raw=true \"Bucket Sort\")\n\n#### 基数排序\n* 基数排序类似于桶排序，将数组分割到有限数目的桶中；不过其在分割之后并没有让每个桶单独地进行排序，而是直接进行了合并操作。\n* 时间复杂度:\n  * 最优时间: `Ω(nk)`\n  * 最坏时间: `O(nk)`\n  * 平均时间: `Θ(nk)`\n\n### 图算法\n\n#### 深度优先搜索\n* 深度优先算法是一种优先遍历子节点而不是回溯的算法。\n* 时间复杂度: `O(|V| + |E|)`\n\n![Alt text](/images/dfsbfs.gif?raw=true \"DFS / BFS Traversal\")\n\n#### 广度优先搜索\n* 广度优先搜索是优先遍历邻居节点而不是子节点的图遍历算法。\n* 时间复杂度: `O(|V| + |E|)`\n\n![Alt text](/images/dfsbfs.gif?raw=true \"DFS / BFS Traversal\")\n\n#### 拓扑排序\n* 拓扑排序是对于有向图节点的线性排序，如果存在某条从 u 到 v 的边，则认为 u 的下标先于 v。\n* 时间复杂度: `O(|V| + |E|)`\n\n#### Dijkstra 算法\n* **Dijkstra 算法** 用于计算有向图中单源最短路径问题。\n* 时间复杂度: `O(|V|^2)`\n\n![Alt text](/images/dijkstra.gif?raw=true \"Dijkstra's\")\n\n#### Bellman-Ford 算法\n* **Bellman-Ford 算法**是在带权图中计算从单一源点出发到其他节点的最短路径的算法。\n* 尽管算法复杂度大于 Dijkstra 算法，但是它适用于包含了负值边的图。\n* 时间复杂度:\n  * 最优时间: `O(|E|)`\n  - 最坏时间: `O(|V||E|)`\n\n![Alt text](/images/bellman-ford.gif?raw=true \"Bellman-Ford\")\n\n#### Floyd-Warshall 算法\n* **Floyd-Warshall 算法** 能够用于在无环带权图中寻找任意节点的最短路径。\n* 时间复杂度:\n  * 最优时间: `O(|V|^3)`\n  * 最坏时间: `O(|V|^3)`\n  * 平均时间: `O(|V|^3)`\n\n#### Prim 算法\n* **Prim 算法**是用于在带权无向图中计算最小生成树的贪婪算法。换言之，Prim 算法能够在图中抽取出连接所有节点的边的最小代价子集。\n* 时间复杂度: `O(|V|^2)`\n\n![Alt text](/images/prim.gif?raw=true \"Prim's Algorithm\")\n\n#### Kruskal 算法\n* **Kruskal 算法**同样是计算图的最小生成树的算法，与 Prim 的区别在于并不需要图是连通的。\n* 时间复杂度: `O(|E|log|V|)`\n\n![Alt text](/images/kruskal.gif?raw=true \"Kruskal's Algorithm\")\n\n## 位运算\n* 位运算即是在位级别进行操作的技术，合适的位运算能够帮助我们得到更快地运算速度与更小的内存使用。\n* 测试第 k 位: `s & (1 << k)`\n* 设置第 k 位: `s |= (1 << k)`\n* 第 k 位置零: `s &= ~(1 << k)`\n* 切换第 k 位值: `s ^= ~(1 << k)`\n* 乘以 2<sup>n</sup>: `s << n`\n* 除以 2<sup>n</sup>: `s >> n`\n* 交集: `s & t`\n* 并集: `s | t`\n* 减法: `s & ~t`\n* 交换 `x = x ^ y ^ (y = x)`\n* 取出最小非 0 位（Extract lowest set bit）: `s & (-s)`\n* 取出最小 0 位（Extract lowest unset bit）: `~s & (s + 1)`\n* 交换值:\n             ```\n                x ^= y;\n                y ^= x;\n                x ^= y;\n             ```\n\n## 算法复杂度分析\n\n#### 大 O 表示\n* **大 O 表示** 用于表示某个算法的上限，往往用于描述最坏的情况。\n\n![Alt text](/images/bigO.png?raw=true \"Theta Notation\")\n\n#### 小 O 表示\n* **小 O 表示**用于描述某个算法的渐进上界，不过二者要更为紧密。\n\n#### 大 Ω 表示\n* **大 Ω 表示**用于描述某个算法的渐进下界。\n\n![Alt text](/images/bigOmega.png?raw=true \"Theta Notation\")\n\n#### 小 ω 表示\n* **Little Omega Notation**用于描述某个特定算法的下界，不过不一定很靠近。\n\n#### Theta Θ 表示\n* **Theta Notation**用于描述某个确定算法的确界。\n\n![Alt text](/images/theta.png?raw=true \"Theta Notation\")\n\n## 视频教程\n* Data Structures\n  * [UC Berkeley Data Structures](https://www.youtube.com/watch?v=mFPmKGIrQs4&index=1&list=PL-XXv-cvA_iAlnI-BQr9hjqADPBtujFJd)\n  * [MIT Advanced Data Structures](https://www.youtube.com/watch?v=T0yzrZL1py0&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&index=1)\n* Algorithms\n  * [MIT Introduction to Algorithms](https://www.youtube.com/watch?v=HtSuA80QTyo&list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&index=1)\n  * [MIT Advanced Algorithms](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c)\n\n## 面试书籍\n* Competitive Programming 3 - Steven Halim & Felix Halim\n* Cracking The Coding Interview - Gayle Laakmann McDowell\n* Cracking The PM Interview - Gayle Laakmann McDowell & Jackie Bavaro\n\n## 计算机科学与技术资讯\n* [Hacker News](https://news.ycombinator.com/)\n* [Lobsters](https://lobste.rs/)\n\n## 文件结构\n\n```\n.\n├── Array\n│   ├── bestTimeToBuyAndSellStock.java\n│   ├── findTheCelebrity.java\n│   ├── gameOfLife.java\n│   ├── increasingTripletSubsequence.java\n│   ├── insertInterval.java\n│   ├── longestConsecutiveSequence.java\n│   ├── maximumProductSubarray.java\n│   ├── maximumSubarray.java\n│   ├── mergeIntervals.java\n│   ├── missingRanges.java\n│   ├── productOfArrayExceptSelf.java\n│   ├── rotateImage.java\n│   ├── searchInRotatedSortedArray.java\n│   ├── spiralMatrixII.java\n│   ├── subsetsII.java\n│   ├── subsets.java\n│   ├── summaryRanges.java\n│   ├── wiggleSort.java\n│   └── wordSearch.java\n├── Backtracking\n│   ├── androidUnlockPatterns.java\n│   ├── generalizedAbbreviation.java\n│   └── letterCombinationsOfAPhoneNumber.java\n├── BinarySearch\n│   ├── closestBinarySearchTreeValue.java\n│   ├── firstBadVersion.java\n│   ├── guessNumberHigherOrLower.java\n│   ├── pow(x,n).java\n│   └── sqrt(x).java\n├── BitManipulation\n│   ├── binaryWatch.java\n│   ├── countingBits.java\n│   ├── hammingDistance.java\n│   ├── maximumProductOfWordLengths.java\n│   ├── numberOf1Bits.java\n│   ├── sumOfTwoIntegers.java\n│   └── utf-8Validation.java\n├── BreadthFirstSearch\n│   ├── binaryTreeLevelOrderTraversal.java\n│   ├── cloneGraph.java\n│   ├── pacificAtlanticWaterFlow.java\n│   ├── removeInvalidParentheses.java\n│   ├── shortestDistanceFromAllBuildings.java\n│   ├── symmetricTree.java\n│   └── wallsAndGates.java\n├── DepthFirstSearch\n│   ├── balancedBinaryTree.java\n│   ├── battleshipsInABoard.java\n│   ├── convertSortedArrayToBinarySearchTree.java\n│   ├── maximumDepthOfABinaryTree.java\n│   ├── numberOfIslands.java\n│   ├── populatingNextRightPointersInEachNode.java\n│   └── sameTree.java\n├── Design\n│   └── zigzagIterator.java\n├── DivideAndConquer\n│   ├── expressionAddOperators.java\n│   └── kthLargestElementInAnArray.java\n├── DynamicProgramming\n│   ├── bombEnemy.java\n│   ├── climbingStairs.java\n│   ├── combinationSumIV.java\n│   ├── countingBits.java\n│   ├── editDistance.java\n│   ├── houseRobber.java\n│   ├── paintFence.java\n│   ├── paintHouseII.java\n│   ├── regularExpressionMatching.java\n│   ├── sentenceScreenFitting.java\n│   ├── uniqueBinarySearchTrees.java\n│   └── wordBreak.java\n├── HashTable\n│   ├── binaryTreeVerticalOrderTraversal.java\n│   ├── findTheDifference.java\n│   ├── groupAnagrams.java\n│   ├── groupShiftedStrings.java\n│   ├── islandPerimeter.java\n│   ├── loggerRateLimiter.java\n│   ├── maximumSizeSubarraySumEqualsK.java\n│   ├── minimumWindowSubstring.java\n│   ├── sparseMatrixMultiplication.java\n│   ├── strobogrammaticNumber.java\n│   ├── twoSum.java\n│   └── uniqueWordAbbreviation.java\n├── LinkedList\n│   ├── addTwoNumbers.java\n│   ├── deleteNodeInALinkedList.java\n│   ├── mergeKSortedLists.java\n│   ├── palindromeLinkedList.java\n│   ├── plusOneLinkedList.java\n│   ├── README.md\n│   └── reverseLinkedList.java\n├── Queue\n│   └── movingAverageFromDataStream.java\n├── README.md\n├── Sort\n│   ├── meetingRoomsII.java\n│   └── meetingRooms.java\n├── Stack\n│   ├── binarySearchTreeIterator.java\n│   ├── decodeString.java\n│   ├── flattenNestedListIterator.java\n│   └── trappingRainWater.java\n├── String\n│   ├── addBinary.java\n│   ├── countAndSay.java\n│   ├── decodeWays.java\n│   ├── editDistance.java\n│   ├── integerToEnglishWords.java\n│   ├── longestPalindrome.java\n│   ├── longestSubstringWithAtMostKDistinctCharacters.java\n│   ├── minimumWindowSubstring.java\n│   ├── multiplyString.java\n│   ├── oneEditDistance.java\n│   ├── palindromePermutation.java\n│   ├── README.md\n│   ├── reverseVowelsOfAString.java\n│   ├── romanToInteger.java\n│   ├── validPalindrome.java\n│   └── validParentheses.java\n├── Tree\n│   ├── binaryTreeMaximumPathSum.java\n│   ├── binaryTreePaths.java\n│   ├── inorderSuccessorInBST.java\n│   ├── invertBinaryTree.java\n│   ├── lowestCommonAncestorOfABinaryTree.java\n│   ├── sumOfLeftLeaves.java\n│   └── validateBinarySearchTree.java\n├── Trie\n│   ├── addAndSearchWordDataStructureDesign.java\n│   ├── implementTrie.java\n│   └── wordSquares.java\n└── TwoPointers\n    ├── 3Sum.java\n    ├── 3SumSmaller.java\n    ├── mergeSortedArray.java\n    ├── minimumSizeSubarraySum.java\n    ├── moveZeros.java\n    ├── removeDuplicatesFromSortedArray.java\n    ├── reverseString.java\n    └── sortColors.java\n\n18 directories, 124 files\n```\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.59,
          "content": "# Interviews\n> Your personal guide to Software Engineering technical interviews. Video\n> solutions to the following interview problems with detailed explanations can be found [here](https://www.youtube.com/channel/UCKvwPt6BifPP54yzH99ff1g).\n<a href=\"https://www.youtube.com/channel/UCKvwPt6BifPP54yzH99ff1g\" style=\"display:block;\"><img src=\"/images/youtube.png?raw=true\"></a>\n>\n> Maintainer - [Kevin Naughton Jr.](https://github.com/kdn251)\n\n## Translations\n\n- [简体中文](./README-zh-cn.md)\n\n## Table of Contents\n- [YouTube](#youtube)\n- [The Daily Byte](#the-daily-byte)\n- [Instagram](#instagram)\n- [Articles](#articles)\n- [Online Judges](#online-judges)\n- [Live Coding Practice](#live-coding-practice)\n- [Data Structures](#data-structures)\n- [Algorithms](#algorithms)\n- [Greedy Algorithms](#greedy-algorithms)\n- [Bitmasks](#bitmasks)\n- [Runtime Analysis](#runtime-analysis)\n- [Video Lectures](#video-lectures)\n- [Interview Books](#interview-books)\n- [Computer Science News](#computer-science-news)\n- [Directory Tree](#directory-tree)\n\n## YouTube\n* [Kevin Naughton Jr.](https://www.youtube.com/channel/UCKvwPt6BifPP54yzH99ff1g)\n\n## The Daily Byte\n* [FAANG Interview Prep](https://bit.ly/2BaaSaK)\n\n## Instagram \n* [Kevin Naughton Jr.](https://bit.ly/2SM8SLZ)\n\n## Articles\n* [Starting Work](https://medium.com/@Naughton/starting-work-b06e10f6007e)\n\n## Online Judges\n* [LeetCode](https://leetcode.com/)\n* [Virtual Judge](https://vjudge.net/)\n* [CareerCup](https://www.careercup.com/)\n* [HackerRank](https://www.hackerrank.com/)\n* [CodeFights](https://codefights.com/)\n* [Kattis](https://open.kattis.com/)\n* [HackerEarth](https://www.hackerearth.com)\n* [Codility](https://codility.com/programmers/lessons/1-iterations/)\n* [Code Forces](http://codeforces.com/)\n* [Code Chef](https://www.codechef.com/)\n* [Sphere Online Judge - SPOJ](http://www.spoj.com/)\n* [InterviewBit](https://www.interviewbit.com/)\n\n## Live Coding Practice\n* [Pramp](https://www.pramp.com/ref/gt4)\n* [Gainlo](http://www.gainlo.co/#!/)\n* [Refdash](https://refdash.com/)\n* [Interviewing.io](https://www.interviewing.io/)\n\n## Data Structures\n### Linked List\n * A *Linked List* is a linear collection of data elements, called nodes, each\n   pointing to the next node by means of a pointer. It is a data structure\n   consisting of a group of nodes which together represent a sequence.\n * **Singly-linked list**: linked list in which each node points to the next node and the last node points to null\n * **Doubly-linked list**: linked list in which each node has two pointers, p and n, such that p points to the previous node and n points to the next node; the last node's n pointer points to null\n * **Circular-linked list**: linked list in which each node points to the next node and the last node points back to the first node\n * Time Complexity:\n   * Access: `O(n)`\n   * Search: `O(n)`\n   * Insert: `O(1)`\n   * Remove: `O(1)`\n\n### Stack\n * A *Stack* is a collection of elements, with two principle operations: *push*, which adds to the collection, and\n   *pop*, which removes the most recently added element\n * **Last in, first out data structure (LIFO)**: the most recently added object is the first to be removed\n * Time Complexity:\n   * Access: `O(n)`\n   * Search: `O(n)`\n   * Insert: `O(1)`\n   * Remove: `O(1)`\n\n### Queue\n * A *Queue* is a collection of elements, supporting two principle operations: *enqueue*, which inserts an element\n   into the queue, and *dequeue*, which removes an element from the queue\n * **First in, first out data structure (FIFO)**: the oldest added object is the first to be removed\n * Time Complexity:\n   * Access: `O(n)`\n   * Search: `O(n)`\n   * Insert: `O(1)`\n   * Remove: `O(1)`\n\n### Tree\n * A *Tree* is an undirected, connected, acyclic graph\n\n### Binary Tree\n * A *Binary Tree* is a tree data structure in which each node has at most two children, which are referred to as\n   the *left child* and *right child*\n * **Full Tree**: a tree in which every node has either 0 or 2 children\n * **Perfect Binary Tree**: a binary tree in which all interior nodes have two children and all leave have the same depth\n * **Complete Tree**: a binary tree in which every level *except possibly the last* is full and all nodes in the last\n   level are as far left as possible\n\n### Binary Search Tree\n * A binary search tree, sometimes called BST, is a type of binary tree which maintains the property that the value in each\n   node must be greater than or equal to any value stored in the left sub-tree, and less than or equal to any value stored\n   in the right sub-tree\n * Time Complexity:\n   * Access: `O(log(n))`\n   * Search: `O(log(n))`\n   * Insert: `O(log(n))`\n   * Remove: `O(log(n))`\n\n<img src=\"/images/BST.png?raw=true\" alt=\"Binary Search Tree\" width=\"400\" height=\"500\">\n\n### Trie\n* A trie, sometimes called a radix or prefix tree, is a kind of search tree that is used to store a dynamic set or associative\n  array where the keys are usually Strings. No node in the tree stores the key associated with that node; instead, its position \n  in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the String associated \n  with that node, and the root is associated with the empty String.\n\n![Alt text](/images/trie.png?raw=true \"Trie\")\n\n### Fenwick Tree\n* A Fenwick tree, sometimes called a binary indexed tree, is a tree in concept, but in practice is implemented as an implicit data\n  structure using an array. Given an index in the array representing a vertex, the index of a vertex's parent or child is calculated\n  through bitwise operations on the binary representation of its index. Each element of the array contains the pre-calculated sum of\n  a range of values, and by combining that sum with additional ranges encountered during an upward traversal to the root, the prefix\n  sum is calculated\n* Time Complexity:\n  * Range Sum: `O(log(n))`\n  * Update: `O(log(n))`\n\n![Alt text](/images/fenwickTree.png?raw=true \"Fenwick Tree\")\n\n### Segment Tree\n* A Segment tree, is a tree data structure for storing intervals, or segments. It allows querying which of the stored segments contain\n  a given point\n* Time Complexity:\n  * Range Query: `O(log(n))`\n  * Update: `O(log(n))`\n\n![Alt text](/images/segmentTree.png?raw=true \"Segment Tree\")\n\n### Heap\n* A *Heap* is a specialized tree based structure data structure that satisfies the *heap* property: if A is a parent node of\nB, then the key (the value) of node A is ordered with respect to the key of node B with the same ordering applying across the entire heap.\nA heap can be classified further as either a \"max heap\" or a \"min heap\". In a max heap, the keys of parent nodes are always greater\nthan or equal to those of the children and the highest key is in the root node. In a min heap, the keys of parent nodes are less than\nor equal to those of the children and the lowest key is in the root node\n* Time Complexity:\n  * Access Max / Min: `O(1)`\n  * Insert: `O(log(n))`\n  * Remove Max / Min: `O(log(n))`\n\n<img src=\"/images/heap.png?raw=true\" alt=\"Max Heap\" width=\"400\" height=\"500\">\n\n\n### Hashing\n* *Hashing* is used to map data of an arbitrary size to data of a fixed size. The values returned by a hash\n  function are called hash values, hash codes, or simply hashes. If two keys map to the same value, a collision occurs\n* **Hash Map**: a *hash map* is a structure that can map keys to values. A hash map uses a hash function to compute\n  an index into an array of buckets or slots, from which the desired value can be found.\n* Collision Resolution\n * **Separate Chaining**: in *separate chaining*, each bucket is independent, and contains a list of entries for each index. The\n time for hash map operations is the time to find the bucket (constant time), plus the time to iterate through the list\n * **Open Addressing**: in *open addressing*, when a new entry is inserted, the buckets are examined, starting with the\n hashed-to-slot and proceeding in some sequence, until an unoccupied slot is found. The name open addressing refers to\n the fact that the location of an item is not always determined by its hash value\n\n\n![Alt text](/images/hash.png?raw=true \"Hashing\")\n\n### Graph\n* A *Graph* is an ordered pair of G = (V, E) comprising a set V of vertices or nodes together with a set E of edges or arcs,\n  which are 2-element subsets of V (i.e. an edge is associated with two vertices, and that association takes the form of the\n  unordered pair comprising those two vertices)\n * **Undirected Graph**: a graph in which the adjacency relation is symmetric. So if there exists an edge from node u to node\n v (u -> v), then it is also the case that there exists an edge from node v to node u (v -> u)\n * **Directed Graph**: a graph in which the adjacency relation is not symmetric. So if there exists an edge from node u to node v\n (u -> v), this does *not* imply that there exists an edge from node v to node u (v -> u)\n\n\n<img src=\"/images/graph.png?raw=true\" alt=\"Graph\" width=\"400\" height=\"500\">\n\n## Algorithms\n\n### Sorting\n\n#### Quicksort\n* Stable: `No`\n* Time Complexity:\n  * Best Case: `O(nlog(n))`\n  * Worst Case: `O(n^2)`\n  * Average Case: `O(nlog(n))`\n\n![Alt text](/images/quicksort.gif?raw=true \"Quicksort\")\n\n#### Mergesort\n* *Mergesort* is also a divide and conquer algorithm. It continuously divides an array into two halves, recurses on both the\n  left subarray and right subarray and then merges the two sorted halves\n* Stable: `Yes`\n* Time Complexity:\n  * Best Case: `O(nlog(n))`\n  * Worst Case: `O(nlog(n))`\n  * Average Case: `O(nlog(n))`\n\n![Alt text](/images/mergesort.gif?raw=true \"Mergesort\")\n\n#### Bucket Sort\n* *Bucket Sort* is a sorting algorithm that works by distributing the elements of an array into a number of buckets. Each bucket\n  is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sorting algorithm\n* Time Complexity:\n  * Best Case: `Ω(n + k)`\n  * Worst Case: `O(n^2)`\n  * Average Case:`Θ(n + k)`\n\n![Alt text](/images/bucketsort.png?raw=true \"Bucket Sort\")\n\n#### Radix Sort\n* *Radix Sort* is a sorting algorithm that like bucket sort, distributes elements of an array into a number of buckets. However, radix\n  sort differs from bucket sort by 're-bucketing' the array after the initial pass as opposed to sorting each bucket and merging\n* Time Complexity:\n  * Best Case: `Ω(nk)`\n  * Worst Case: `O(nk)`\n  * Average Case: `Θ(nk)`\n\n### Graph Algorithms\n\n#### Depth First Search\n* *Depth First Search* is a graph traversal algorithm which explores as far as possible along each branch before backtracking\n* Time Complexity: `O(|V| + |E|)`\n\n![Alt text](/images/dfsbfs.gif?raw=true \"DFS / BFS Traversal\")\n\n#### Breadth First Search\n* *Breadth First Search* is a graph traversal algorithm which explores the neighbor nodes first, before moving to the next\n  level neighbors\n* Time Complexity: `O(|V| + |E|)`\n\n![Alt text](/images/dfsbfs.gif?raw=true \"DFS / BFS Traversal\")\n\n#### Topological Sort\n* *Topological Sort* is the linear ordering of a directed graph's nodes such that for every edge from node u to node v, u\n  comes before v in the ordering\n* Time Complexity: `O(|V| + |E|)`\n\n#### Dijkstra's Algorithm\n* *Dijkstra's Algorithm* is an algorithm for finding the shortest path between nodes in a graph\n* Time Complexity: `O(|V|^2)`\n\n![Alt text](/images/dijkstra.gif?raw=true \"Dijkstra's\")\n\n#### Bellman-Ford Algorithm\n* *Bellman-Ford Algorithm* is an algorithm that computes the shortest paths from a single source node to all other nodes in a weighted graph\n* Although it is slower than Dijkstra's, it is more versatile, as it is capable of handling graphs in which some of the edge weights are\n  negative numbers\n* Time Complexity:\n  * Best Case: `O(|E|)`\n  * Worst Case: `O(|V||E|)`\n\n![Alt text](/images/bellman-ford.gif?raw=true \"Bellman-Ford\")\n\n#### Floyd-Warshall Algorithm\n* *Floyd-Warshall Algorithm* is an algorithm for finding the shortest paths in a weighted graph with positive or negative edge weights, but\n  no negative cycles\n* A single execution of the algorithm will find the lengths (summed weights) of the shortest paths between *all* pairs of nodes\n* Time Complexity:\n  * Best Case: `O(|V|^3)`\n  * Worst Case: `O(|V|^3)`\n  * Average Case: `O(|V|^3)`\n\n#### Prim's Algorithm\n* *Prim's Algorithm* is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. In other words, Prim's find a\n  subset of edges that forms a tree that includes every node in the graph\n* Time Complexity: `O(|V|^2)`\n\n![Alt text](/images/prim.gif?raw=true \"Prim's Algorithm\")\n\n#### Kruskal's Algorithm\n* *Kruskal's Algorithm* is also a greedy algorithm that finds a minimum spanning tree in a graph. However, in Kruskal's, the graph does not\n  have to be connected\n* Time Complexity: `O(|E|log|V|)`\n\n![Alt text](/images/kruskal.gif?raw=true \"Kruskal's Algorithm\")\n\n## Greedy Algorithms\n* *Greedy Algorithms* are algorithms that make locally optimal choices at each step in the hope of eventually reaching the globally optimal solution\n* Problems must exhibit two properties in order to implement a Greedy solution:\n * Optimal Substructure\n    * An optimal solution to the problem contains optimal solutions to the given problem's subproblems\n * The Greedy Property\n    * An optimal solution is reached by \"greedily\" choosing the locally optimal choice without ever reconsidering previous choices\n* Example - Coin Change\n    * Given a target amount V cents and a list of denominations of n coins, i.e. we have coinValue[i] (in cents) for coin types i from [0...n - 1],\n      what is the minimum number of coins that we must use to represent amount V? Assume that we have an unlimited supply of coins of any type\n    * Coins - Penny (1 cent), Nickel (5 cents), Dime (10 cents), Quarter (25 cents)\n    * Assume V = 41. We can use the Greedy algorithm of continuously selecting the largest coin denomination less than or equal to V, subtract that\n      coin's value from V, and repeat.\n    * V = 41 | 0 coins used\n    * V = 16 | 1 coin used (41 - 25 = 16)\n    * V = 6  | 2 coins used (16 - 10 = 6)\n    * V = 1  | 3 coins used (6 - 5 = 1)\n    * V = 0  | 4 coins used (1 - 1 = 0)\n    * Using this algorithm, we arrive at a total of 4 coins which is optimal\n\n## Bitmasks\n* Bitmasking is a technique used to perform operations at the bit level. Leveraging bitmasks often leads to faster runtime complexity and\n  helps limit memory usage\n* Test kth bit: `s & (1 << k);`\n* Set kth bit: `s |= (1 << k);`\n* Turn off kth bit: `s &= ~(1 << k);`\n* Toggle kth bit: `s ^= (1 << k);`\n* Multiple by 2<sup>n</sup>: `s << n;`\n* Divide by 2<sup>n</sup>: `s >> n;`\n* Intersection: `s & t;`\n* Union: `s | t;`\n* Set Subtraction: `s & ~t;`\n* Extract lowest set bit: `s & (-s);`\n* Extract lowest unset bit: `~s & (s + 1);`\n* Swap Values:\n             ```\n                x ^= y;\n                y ^= x;\n                x ^= y;\n             ```\n\n## Runtime Analysis\n\n#### Big O Notation\n* *Big O Notation* is used to describe the upper bound of a particular algorithm. Big O is used to describe worst case scenarios\n\n![Alt text](/images/bigO.png?raw=true \"Theta Notation\")\n\n#### Little O Notation\n* *Little O Notation* is also used to describe an upper bound of a particular algorithm; however, Little O provides a bound\n  that is not asymptotically tight\n\n#### Big Ω Omega Notation\n* *Big Omega Notation* is used to provide an asymptotic lower bound on a particular algorithm\n\n![Alt text](/images/bigOmega.png?raw=true \"Theta Notation\")\n\n#### Little ω Omega Notation\n* *Little Omega Notation* is used to provide a lower bound on a particular algorithm that is not asymptotically tight\n\n#### Theta Θ Notation\n* *Theta Notation* is used to provide a bound on a particular algorithm such that it can be \"sandwiched\" between\n  two constants (one for an upper limit and one for a lower limit) for sufficiently large values\n\n![Alt text](/images/theta.png?raw=true \"Theta Notation\")\n\n## Video Lectures\n* Data Structures\n    * [UC Berkeley Data Structures](https://archive.org/details/ucberkeley-webcast?&and[]=subject%3A%22Computer%20Science%22&and[]=subject%3A%22CS%22)\n    * [MIT Advanced Data Structures](https://www.youtube.com/watch?v=T0yzrZL1py0&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&index=1)\n* Algorithms\n    * [MIT Introduction to Algorithms](https://www.youtube.com/watch?v=HtSuA80QTyo&list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&index=1)\n    * [MIT Advanced Algorithms](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c)\n    * [UC Berkeley Algorithms](https://archive.org/details/ucberkeley-webcast?&and[]=subject%3A%22Computer%20Science%22&and[]=subject%3A%22CS%22)\n\n## Interview Books\n* [Competitive Programming 3 - Steven Halim & Felix Halim](https://www.amazon.com/Competitive-Programming-3rd-Steven-Halim/dp/B00FG8MNN8) \n* [Cracking The Coding Interview - Gayle Laakmann McDowell](https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850/ref=sr_1_1?s=books&ie=UTF8)\n* [Cracking The PM Interview - Gayle Laakmann McDowell & Jackie Bavaro](https://www.amazon.com/Cracking-PM-Interview-Product-Technology-ebook/dp/B00ISYMUR6/ref=sr_1_1?s=books&ie=UTF8)\n* [Introduction to Algorithms -  Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest & Clifford Stein](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/ref=sr_1_1?ie=UTF8&qid=1490295989&sr=8-1&keywords=Introduction+to+Algorithms)\n\n## Computer Science News\n* [Hacker News](https://news.ycombinator.com/)\n* [Lobsters](https://lobste.rs/)\n\n## Directory Tree\n\n```\n.\n├── Array\n│   ├── bestTimeToBuyAndSellStock.java\n│   ├── findTheCelebrity.java\n│   ├── gameOfLife.java\n│   ├── increasingTripletSubsequence.java\n│   ├── insertInterval.java\n│   ├── longestConsecutiveSequence.java\n│   ├── maximumProductSubarray.java\n│   ├── maximumSubarray.java\n│   ├── mergeIntervals.java\n│   ├── missingRanges.java\n│   ├── productOfArrayExceptSelf.java\n│   ├── rotateImage.java\n│   ├── searchInRotatedSortedArray.java\n│   ├── spiralMatrixII.java\n│   ├── subsetsII.java\n│   ├── subsets.java\n│   ├── summaryRanges.java\n│   ├── wiggleSort.java\n│   └── wordSearch.java\n├── Backtracking\n│   ├── androidUnlockPatterns.java\n│   ├── generalizedAbbreviation.java\n│   └── letterCombinationsOfAPhoneNumber.java\n├── BinarySearch\n│   ├── closestBinarySearchTreeValue.java\n│   ├── firstBadVersion.java\n│   ├── guessNumberHigherOrLower.java\n│   ├── pow(x,n).java\n│   └── sqrt(x).java\n├── BitManipulation\n│   ├── binaryWatch.java\n│   ├── countingBits.java\n│   ├── hammingDistance.java\n│   ├── maximumProductOfWordLengths.java\n│   ├── numberOf1Bits.java\n│   ├── sumOfTwoIntegers.java\n│   └── utf-8Validation.java\n├── BreadthFirstSearch\n│   ├── binaryTreeLevelOrderTraversal.java\n│   ├── cloneGraph.java\n│   ├── pacificAtlanticWaterFlow.java\n│   ├── removeInvalidParentheses.java\n│   ├── shortestDistanceFromAllBuildings.java\n│   ├── symmetricTree.java\n│   └── wallsAndGates.java\n├── DepthFirstSearch\n│   ├── balancedBinaryTree.java\n│   ├── battleshipsInABoard.java\n│   ├── convertSortedArrayToBinarySearchTree.java\n│   ├── maximumDepthOfABinaryTree.java\n│   ├── numberOfIslands.java\n│   ├── populatingNextRightPointersInEachNode.java\n│   └── sameTree.java\n├── Design\n│   └── zigzagIterator.java\n├── DivideAndConquer\n│   ├── expressionAddOperators.java\n│   └── kthLargestElementInAnArray.java\n├── DynamicProgramming\n│   ├── bombEnemy.java\n│   ├── climbingStairs.java\n│   ├── combinationSumIV.java\n│   ├── countingBits.java\n│   ├── editDistance.java\n│   ├── houseRobber.java\n│   ├── paintFence.java\n│   ├── paintHouseII.java\n│   ├── regularExpressionMatching.java\n│   ├── sentenceScreenFitting.java\n│   ├── uniqueBinarySearchTrees.java\n│   └── wordBreak.java\n├── HashTable\n│   ├── binaryTreeVerticalOrderTraversal.java\n│   ├── findTheDifference.java\n│   ├── groupAnagrams.java\n│   ├── groupShiftedStrings.java\n│   ├── islandPerimeter.java\n│   ├── loggerRateLimiter.java\n│   ├── maximumSizeSubarraySumEqualsK.java\n│   ├── minimumWindowSubstring.java\n│   ├── sparseMatrixMultiplication.java\n│   ├── strobogrammaticNumber.java\n│   ├── twoSum.java\n│   └── uniqueWordAbbreviation.java\n├── LinkedList\n│   ├── addTwoNumbers.java\n│   ├── deleteNodeInALinkedList.java\n│   ├── mergeKSortedLists.java\n│   ├── palindromeLinkedList.java\n│   ├── plusOneLinkedList.java\n│   ├── README.md\n│   └── reverseLinkedList.java\n├── Queue\n│   └── movingAverageFromDataStream.java\n├── README.md\n├── Sort\n│   ├── meetingRoomsII.java\n│   └── meetingRooms.java\n├── Stack\n│   ├── binarySearchTreeIterator.java\n│   ├── decodeString.java\n│   ├── flattenNestedListIterator.java\n│   └── trappingRainWater.java\n├── String\n│   ├── addBinary.java\n│   ├── countAndSay.java\n│   ├── decodeWays.java\n│   ├── editDistance.java\n│   ├── integerToEnglishWords.java\n│   ├── longestPalindrome.java\n│   ├── longestSubstringWithAtMostKDistinctCharacters.java\n│   ├── minimumWindowSubstring.java\n│   ├── multiplyString.java\n│   ├── oneEditDistance.java\n│   ├── palindromePermutation.java\n│   ├── README.md\n│   ├── reverseVowelsOfAString.java\n│   ├── romanToInteger.java\n│   ├── validPalindrome.java\n│   └── validParentheses.java\n├── Tree\n│   ├── binaryTreeMaximumPathSum.java\n│   ├── binaryTreePaths.java\n│   ├── inorderSuccessorInBST.java\n│   ├── invertBinaryTree.java\n│   ├── lowestCommonAncestorOfABinaryTree.java\n│   ├── sumOfLeftLeaves.java\n│   └── validateBinarySearchTree.java\n├── Trie\n│   ├── addAndSearchWordDataStructureDesign.java\n│   ├── implementTrie.java\n│   └── wordSquares.java\n└── TwoPointers\n    ├── 3Sum.java\n    ├── 3SumSmaller.java\n    ├── mergeSortedArray.java\n    ├── minimumSizeSubarraySum.java\n    ├── moveZeros.java\n    ├── removeDuplicatesFromSortedArray.java\n    ├── reverseString.java\n    └── sortColors.java\n\n18 directories, 124 files\n```\n"
        },
        {
          "name": "company",
          "type": "tree",
          "content": null
        },
        {
          "name": "cracking-the-coding-interview",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "interviews.iml",
          "type": "blob",
          "size": 0.33,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<module type=\"JAVA_MODULE\" version=\"4\">\n  <component name=\"NewModuleRootManager\" inherit-compiler-output=\"false\">\n    <output url=\"file://$MODULE_DIR$/bin\" />\n    <exclude-output />\n    <content url=\"file://$MODULE_DIR$\" />\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\n  </component>\n</module>"
        },
        {
          "name": "leetcode",
          "type": "tree",
          "content": null
        },
        {
          "name": "uva",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "apache/superset",
      "stars": 63747,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 2.89,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# https://cwiki.apache.org/confluence/display/INFRA/.asf.yaml+features+for+git+repositories\n---\ngithub:\n  description: \"Apache Superset is a Data Visualization and Data Exploration Platform\"\n  homepage: https://superset.apache.org/\n  labels:\n    - superset\n    - apache\n    - apache-superset\n    - data-visualization\n    - data-viz\n    - analytics\n    - business-intelligence\n    - data-science\n    - data-engineering\n    - asf\n    - bi\n    - business-analytics\n    - data-analytics\n    - data-analysis\n    - data-science\n    - python\n    - react\n    - sql-editor\n    - flask\n  features:\n    # Enable issues management\n    issues: true\n    # Enable projects for project management boards\n    projects: true\n    # Enable wiki for documentation\n    wiki: true\n\n  enabled_merge_buttons:\n    squash: true\n    merge: false\n    rebase: false\n\n  ghp_branch:  gh-pages\n  ghp_path: /\n\n  protected_branches:\n    master:\n      required_status_checks:\n        # strict means \"Require branches to be up to date before merging\".\n        strict: false\n        # contexts are the names of checks that must pass\n        # unfortunately AFAICT for `matrix:` jobs, we have to itemize every\n        # combination here.\n        contexts:\n          - lint-check\n          - cypress-matrix (0, chrome)\n          - cypress-matrix (1, chrome)\n          - cypress-matrix (2, chrome)\n          - cypress-matrix (3, chrome)\n          - cypress-matrix (4, chrome)\n          - cypress-matrix (5, chrome)\n          - dependency-review\n          - frontend-build\n          - pre-commit (current)\n          - pre-commit (previous)\n          - test-mysql\n          - test-postgres (current)\n          - test-postgres-hive\n          - test-postgres-presto\n          - test-sqlite\n          - unit-tests (current)\n\n      required_pull_request_reviews:\n        dismiss_stale_reviews: false\n        require_code_owner_reviews: true\n        required_approving_review_count: 1\n\n      required_signatures: false\n    gh-pages:\n      required_pull_request_reviews:\n        dismiss_stale_reviews: false\n        require_code_owner_reviews: true\n        required_approving_review_count: 1\n\n      required_signatures: false\n"
        },
        {
          "name": ".codecov.yml",
          "type": "blob",
          "size": 0.89,
          "content": "codecov:\n    notify:\n        after_n_builds: 4\nignore:\n  - \"superset/migrations/versions/*.py\"\n  - \"superset-frontend/packages/superset-ui-demo/**/*\"\n  - \"**/*.stories.tsx\"\n  - \"**/*.stories.jsx\"\ncoverage:\n  status:\n    project:\n      default:\n        informational: true\n        # Commits pushed to master should not make the overall\n        # project coverage decrease:\n        target: auto\n        threshold: 0%\n      core-packages-ts:\n        target: 100%\n        paths:\n          - 'superset-frontend/packages'\n          - '!superset-frontend/packages/**/*.jsx'\n          - '!superset-frontend/packages/**/*.tsx'\n      core-packages-tsx:\n        target: 50%\n        paths:\n          - 'superset-frontend/packages/**/*.jsx'\n          - 'superset-frontend/packages/**/*.tsx'\n    patch:\n      default:\n        informational: true\n        threshold: 0%\nflag_management:\n  default_rules:\n    carryforward: true\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 1.21,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n**/__pycache__/\n**/.git\n**/.apache_superset.egg-info\n**/.github\n**/.mypy_cache\n**/.pytest_cache\n**/.tox\n**/.vscode\n**/.idea\n**/.coverage\n**/.DS_Store\n**/.eggs\n**/.python-version\n**/*.egg-info\n**/*.bak\n**/*.db\n**/*.pyc\n**/*.sqllite\n**/*.swp\n**/.terser-plugin-cache/\n**/node_modules/\n\ntests/\ndocs/\ninstall/\nsuperset-frontend/cypress-base/\nsuperset-frontend/coverage/\nsuperset-frontend/.temp_cache/\nsuperset/static/assets/\nsuperset-websocket/dist/\nvenv\n.venv\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 1.33,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# EditorConfig is awesome: https://EditorConfig.org\n\n# top-most EditorConfig file\nroot = true\n\n# Unix-style newlines with a newline ending every file\n[*]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\n\n# 4 space indentation for Python files\n[*.py]\nindent_style = space\nindent_size = 4\nmax_line_length=88\n\n# 2 space indentation for Frontend files\n[*.{js,jsx,ts,tsx,html,less,css}]\nindent_style = space\nindent_size = 2\n\n# 2 space indentation for json and yaml files\n[*.{json,yml}]\nindent_style = space\nindent_size = 2\n\n# Tab indentation\n[Makefile]\nindent_style = tab\n"
        },
        {
          "name": ".flaskenv",
          "type": "blob",
          "size": 0.82,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nFLASK_APP=\"superset.app:create_app()\"\nFLASK_DEBUG=true\n"
        },
        {
          "name": ".fossa.yml",
          "type": "blob",
          "size": 1.15,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Generated by FOSSA CLI (https://github.com/fossas/fossa-cli)\n# Visit https://fossa.com to learn more\n\nversion: 2\ncli:\n  server: https://app.fossa.com\n  fetcher: custom\nanalyze:\n  modules:\n  - name: assets\n    type: npm\n    target: superset-frontend\n    path: superset-frontend\n  - name: base\n    type: pip\n    target: .\n    path: .\n    options:\n      requirements: ./requirements/base.txt\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.05,
          "content": "docker/**/*.sh text eol=lf\n*.svg binary\n*.ipynb binary\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.31,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n*.bak\n*.db\n*.pyc\n*.sqllite\n*.swp\n__pycache__\n\n.local\n.cache\n.bento*\n.cache-loader\n.coverage\ncover\n.DS_Store\n.eggs\n.env\n.envrc\n.idea\n.mypy_cache\n.python-version\n.tox\n.vscode\n_build\n_images\n_modules\n_static\nbuild\napp.db\napache_superset.egg-info/\nchangelog.sh\ndist\ndump.rdb\nenv\nvenv*\nenv_py3\nenvpy3\nenv36\nlocal_config.py\n/superset_config.py\n/superset_text.yml\nsuperset.egg-info/\nsuperset/bin/supersetc\ntmp\nrat-results.txt\nsuperset/app/\nsuperset-websocket/config.json\n\n# Node.js, webpack artifacts, storybook\n*.entry.js\n*.js.map\nnode_modules\nnpm-debug.log*\nsuperset/static/assets\nsuperset/static/version_info.json\nsuperset-frontend/**/esm/*\nsuperset-frontend/**/lib/*\nsuperset-frontend/**/storybook-static/*\nsuperset-frontend/migration-storybook.log\nyarn-error.log\n*.map\n*.min.js\ntest-changelog.md\n*.tsbuildinfo\n\n# Ignore package-lock in packages\nplugins/*/package-lock.json\npackages/*/package-lock.json\n\n# For country map geojson conversion script\n.ipynb_checkpoints/\nscripts/*.zip\n\n# IntelliJ\n*.iml\nvenv\n@eaDir/\n\n# PyCharm\n.run\n\n# Test data\ncelery_results.sqlite\ncelerybeat-schedule\ncelerydb.sqlite\ncelerybeat.pid\ngeckodriver.log\nghostdriver.log\ntestCSV.csv\n.terser-plugin-cache/\napache-superset-*.tar.gz*\nrelease.json\n\n# Translation-related files\n# these json files are generated by ./scripts/po2json.sh\nsuperset/translations/**/messages.json\n# these mo binary files are generated by `pybabel compile`\nsuperset/translations/**/messages.mo\n\ndocker/requirements-local.txt\n\ncache/\ndocker/*local*\n\n.temp_cache\n\n# Jest test report\ntest-report.html\nsuperset/static/stats/statistics.html\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 1.94,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n[submodule \".github/actions/latest-tag\"]\n\tpath = .github/actions/latest-tag\n\turl = https://github.com/EndBug/latest-tag\n[submodule \".github/actions/pr-lint-action\"]\n\tpath = .github/actions/pr-lint-action\n\turl = https://github.com/morrisoncole/pr-lint-action\n[submodule \".github/actions/file-changes-action\"]\n\tpath = .github/actions/file-changes-action\n\turl = https://github.com/trilom/file-changes-action\n[submodule \".github/actions/cached-dependencies\"]\n\tpath = .github/actions/cached-dependencies\n\turl = https://github.com/apache-superset/cached-dependencies\n[submodule \".github/actions/comment-on-pr\"]\n\tpath = .github/actions/comment-on-pr\n\turl = https://github.com/unsplash/comment-on-pr\n[submodule \".github/actions/chart-testing-action\"]\n\tpath = .github/actions/chart-testing-action\n\turl = https://github.com/helm/chart-testing-action\n[submodule \".github/actions/chart-releaser-action\"]\n\tpath = .github/actions/chart-releaser-action\n\turl = https://github.com/helm/chart-releaser-action\n[submodule \".github/actions/github-action-push-to-another-repository\"]\n\tpath = .github/actions/github-action-push-to-another-repository\n\turl = https://github.com/cpina/github-action-push-to-another-repository\n"
        },
        {
          "name": ".markdownlint.json",
          "type": "blob",
          "size": 0.05,
          "content": "{\n  \"no-bare-urls\": false,\n  \"line-length\": false\n}\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2.8,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nrepos:\n  - repo: https://github.com/MarcoGorelli/auto-walrus\n    rev: 0.3.4\n    hooks:\n      - id: auto-walrus\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.13.0\n    hooks:\n      - id: mypy\n        args: [--check-untyped-defs]\n        additional_dependencies: [\n            types-simplejson,\n            types-python-dateutil,\n            types-requests,\n            # types-redis 4.6.0.5 is failing mypy\n            # because of https://github.com/python/typeshed/pull/10531\n            types-redis==4.6.0.4,\n            types-pytz,\n            types-croniter,\n            types-PyYAML,\n            types-setuptools,\n            types-paramiko,\n            types-Markdown,\n          ]\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-docstring-first\n      - id: check-added-large-files\n        exclude: ^.*\\.(geojson)$|^docs/static/img/screenshots/.*|^superset-frontend/CHANGELOG\\.md$\n      - id: check-yaml\n        exclude: ^helm/superset/templates/\n      - id: debug-statements\n      - id: end-of-file-fixer\n        exclude: .*/lerna\\.json$\n      - id: trailing-whitespace\n        exclude: ^.*\\.(snap)\n        args: [\"--markdown-linebreak-ext=md\"]\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v4.0.0-alpha.8 # Use the sha or tag you want to point at\n    hooks:\n      - id: prettier\n        additional_dependencies:\n          - prettier@3.3.3\n        args: [\"--ignore-path=./superset-frontend/.prettierignore\"]\n        files: \"superset-frontend\"\n  # blacklist unsafe functions like make_url (see #19526)\n  - repo: https://github.com/skorokithakis/blacklist-pre-commit-hook\n    rev: e2f070289d8eddcaec0b580d3bde29437e7c8221\n    hooks:\n      - id: blacklist\n        args: [\"--blacklisted-names=make_url\", \"--ignore=tests/\"]\n  - repo: https://github.com/norwoodj/helm-docs\n    rev: v1.14.2\n    hooks:\n      - id: helm-docs\n        files: helm\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.8.0\n    hooks:\n      - id: ruff\n        args: [ --fix ]\n      - id: ruff-format\n"
        },
        {
          "name": ".rat-excludes",
          "type": "blob",
          "size": 1.07,
          "content": "# Note: these patterns are applied to single files or directories, not full paths\n.gitignore\n.gitattributes\n.gitkeep\n.coverage\n.coveragerc\n.codecov.yml\n.eslintrc\n.eslintignore\n.flake8\n.nvmrc\n.prettierrc\n.rat-excludes\n.*log\n.*pyc\n.*lock\n.*geojson\nDISCLAIMER\nlicenses/*\nnode_modules/*\nrat-results.txt\nbabel-node\ndist\nsuperset/static/*\nbuild\nsuperset.egg-info\napache_superset.egg-info\n.idea\n.*sql\n.*zip\n.*lock\n# json and csv in general cannot have comments\n.*json\n.*csv\n# Generated doc files\nenv/*\ndocs/.htaccess*\n.nojekyll\n_build/*\n_static/*\n.buildinfo\nsearchindex.js\n# auto generated\nrequirements/*\n# vendorized\nvendor/*\n# github configuration\n.github/*\n.*mdx\n\n# skip license check in superset-ui\ntmp/*\nlib/*\nesm/*\ntsconfig.tsbuildinfo\n.*ipynb\n.*yml\n.*iml\n.esprintrc\n.prettierignore\ngenerator-superset/*\ntemporary_superset_ui/*\n\n# skip license checks for auto-generated test snapshots\n.*snap\n\n# docs overrides for third party logos we don't have the rights to\ngoogle-big-query.svg\ngoogle-sheets.svg\nibm-db2.svg\npostgresql.svg\nsnowflake.svg\nydb.svg\n\n# docs-related\nerd.puml\nerd.svg\nintro_header.txt\n"
        },
        {
          "name": "ASF",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 1.54,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n## Change Log\n\n- [1.4.1](./CHANGELOG/1.4.1.md)\n- [1.4.2](./CHANGELOG/1.4.2.md)\n- [1.5.0](./CHANGELOG/1.5.0.md)\n- [1.5.1](./CHANGELOG/1.5.1.md)\n- [1.5.2](./CHANGELOG/1.5.2.md)\n- [1.5.3](./CHANGELOG/1.5.3.md)\n- [2.0.0](./CHANGELOG/2.0.0.md)\n- [2.0.1](./CHANGELOG/2.0.1.md)\n- [2.1.0](./CHANGELOG/2.1.0.md)\n- [2.1.1](./CHANGELOG/2.1.1.md)\n- [2.1.2](./CHANGELOG/2.1.2.md)\n- [2.1.3](./CHANGELOG/2.1.3.md)\n- [3.0.0](./CHANGELOG/3.0.0.md)\n- [3.0.1](./CHANGELOG/3.0.1.md)\n- [3.0.2](./CHANGELOG/3.0.2.md)\n- [3.0.3](./CHANGELOG/3.0.3.md)\n- [3.0.4](./CHANGELOG/3.0.4.md)\n- [3.1.0](./CHANGELOG/3.1.0.md)\n- [3.1.1](./CHANGELOG/3.1.1.md)\n- [3.1.2](./CHANGELOG/3.1.2.md)\n- [3.1.3](./CHANGELOG/3.1.3.md)\n- [4.0.0](./CHANGELOG/4.0.0.md)\n- [4.0.1](./CHANGELOG/4.0.1.md)\n- [4.0.2](./CHANGELOG/4.0.2.md)\n- [4.1.0](./CHANGELOG/4.1.0.md)\n"
        },
        {
          "name": "CHANGELOG",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 12.71,
          "content": "<!--\n    Licensed to the Apache Software Foundation (ASF) under one\n    or more contributor license agreements.  See the NOTICE file\n    distributed with this work for additional information\n    regarding copyright ownership.  The ASF licenses this file\n    to you under the Apache License, Version 2.0 (the\n    \"License\"); you may not use this file except in compliance\n    with the License.  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing,\n    software distributed under the License is distributed on an\n    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n    KIND, either express or implied.  See the License for the\n    specific language governing permissions and limitations\n    under the License.\n-->\n# CODE OF CONDUCT\n\n*The following is copied for your convenience from <https://www.apache.org/foundation/policies/conduct.html>. If there's a discrepancy between the two, let us know or submit a PR to fix it.*\n\n## INTRODUCTION\n\nThis code of conduct applies to all spaces managed by the Apache Software Foundation, including IRC, all public and private mailing lists, issue trackers, wikis, blogs, Twitter, and any other communication channel used by our communities. A code of conduct which is specific to in-person events (ie., conferences) is codified in the published ASF anti-harassment policy.\n\nWe expect this code of conduct to be honored by everyone who participates in the Apache community formally or informally, or claims any affiliation with the Foundation, in any Foundation-related activities and especially when representing the ASF, in any role.\n\nThis code is __not exhaustive or complete__. It serves to distill our common understanding of a collaborative, shared environment and goals. We expect it to be followed in spirit as much as in the letter, so that it can enrich all of us and the technical communities in which we participate.\n\n## SPECIFIC GUIDELINES\n\nWe strive to:\n\n1. **Be open.** We invite anyone to participate in our community. We preferably use public methods of communication for project-related messages, unless discussing something sensitive. This applies to messages for help or project-related support, too; not only is a public support request much more likely to result in an answer to a question, it also makes sure that any inadvertent mistakes made by people answering will be more easily detected and corrected.\n\n2. **Be empathetic, welcoming, friendly, and patient.** We work together to resolve conflict, assume good intentions, and do our best to act in an empathetic fashion. We may all experience some frustration from time to time, but we do not allow frustration to turn into a personal attack. A community where people feel uncomfortable or threatened is not a productive one. We should be respectful when dealing with other community members as well as with people outside our community.\n\n3. **Be collaborative.** Our work will be used by other people, and in turn we will depend on the work of others. When we make something for the benefit of the project, we are willing to explain to others how it works, so that they can build on the work to make it even better. Any decision we make will affect users and colleagues, and we take those consequences seriously when making decisions.\n\n4. **Be inquisitive.** Nobody knows everything! Asking questions early avoids many problems later, so questions are encouraged, though they may be directed to the appropriate forum. Those who are asked should be responsive and helpful, within the context of our shared goal of improving Apache project code.\n\n5. **Be careful in the words that we choose.** Whether we are participating as professionals or volunteers, we value professionalism in all interactions, and take responsibility for our own speech. Be kind to others. Do not insult or put down other participants. Harassment and other exclusionary behavior are not acceptable. This includes, but is not limited to:\n    * Violent threats or language directed against another person.\n    * Sexist, racist, or otherwise discriminatory jokes and language.\n    * Posting sexually explicit or violent material.\n    * Posting (or threatening to post) other people's personally identifying information (\"doxing\").\n    * Sharing private content, such as emails sent privately or non-publicly, or unlogged forums such as IRC channel history.\n    * Personal insults, especially those using racist or sexist terms.\n    * Unwelcome sexual attention.\n    * Excessive or unnecessary profanity.\n    * Repeated harassment of others. In general, if someone asks you to stop, then stop.\n    * Advocating for, or encouraging, any of the above behavior.\n\n6. **Be concise.** Keep in mind that what you write once will be read by hundreds of persons. Writing a short email means people can understand the conversation as efficiently as possible. Short emails should always strive to be empathetic, welcoming, friendly and patient. When a long explanation is necessary, consider adding a summary.\n\n    Try to bring new ideas to a conversation so that each mail adds something unique to the thread, keeping in mind that the rest of the thread still contains the other messages with arguments that have already been made.\n\n    Try to stay on topic, especially in discussions that are already fairly large.\n\n7. **Step down considerately.** Members of every project come and go. When somebody leaves or disengages from the project they should tell people they are leaving and take the proper steps to ensure that others can pick up where they left off. In doing so, they should remain respectful of those who continue to participate in the project and should not misrepresent the project's goals or achievements. Likewise, community members should respect any individual's choice to leave the project.\n\n## DIVERSITY STATEMENT\n\nApache welcomes and encourages participation by everyone. We are committed to being a community that everyone feels good about joining. Although we may not be able to satisfy everyone, we will always work to treat everyone well.\n\nNo matter how you identify yourself or how others perceive you: we welcome you. Though no list can hope to be comprehensive, we explicitly honour diversity in: age, culture, ethnicity, genotype, gender identity or expression, language, national origin, neurotype, phenotype, political beliefs, profession, race, religion, sexual orientation, socioeconomic status, subculture and technical ability.\n\nThough we welcome people fluent in all languages, Apache development is conducted in English.\n\nStandards for behaviour in the Apache community are detailed in the Code of Conduct above. We expect participants in our community to meet these standards in all their interactions and to help others to do so as well.\n\n## REPORTING GUIDELINES\n\nWhile this code of conduct should be adhered to by participants, we recognize that sometimes people may have a bad day, or be unaware of some of the guidelines in this code of conduct. When that happens, you may reply to them and point out this code of conduct. Such messages may be in public or in private, whatever is most appropriate. However, regardless of whether the message is public or not, it should still adhere to the relevant parts of this code of conduct; in particular, it should not be abusive or disrespectful.\n\nIf you believe someone is violating this code of conduct, you may reply to them and point out this code of conduct. Such messages may be in public or in private, whatever is most appropriate. Assume good faith; it is more likely that participants are unaware of their bad behaviour than that they intentionally try to degrade the quality of the discussion. Should there be difficulties in dealing with the situation, you may report your compliance issues in confidence to either:\n\n* President of the Apache Software Foundation: Sam Ruby (rubys at intertwingly dot net)\n\nOr one of our volunteers:\n\n* [Mark Thomas](https://www.linkedin.com/in/mark-thomas-b16751158/)\n* [Joan Touzet](https://www.apache.org/foundation/conduct-team/wohali.html)\n* [Sharan Foga](https://www.linkedin.com/in/sfoga/)\n\nIf the violation is in documentation or code, for example inappropriate pronoun usage or word choice within official documentation, we ask that people report these privately to the project in question at <private@project.apache.org>, and, if they have sufficient ability within the project, to resolve or remove the concerning material, being mindful of the perspective of the person originally reporting the issue.\n\n## ENDNOTES\n\nThis Code defines **empathy** as \"a vicarious participation in the emotions, ideas, or opinions of others; the ability to imagine oneself in the condition or predicament of another.\" **Empathetic** is the adjectival form of empathy.\n\nThis statement thanks the following, on which it draws for content and inspiration:\n\n* [CouchDB Project Code of conduct](http://couchdb.apache.org/conduct.html)\n* [Fedora Project Code of Conduct](http://fedoraproject.org/code-of-conduct)\n* [Speak Up! Code of Conduct](http://web.archive.org/web/20141109123859/http://speakup.io/coc.html)\n* [Django Code of Conduct](https://www.djangoproject.com/conduct/)\n* [Debian Code of Conduct](https://www.debian.org/vote/2014/vote_002)\n* [Twitter Open Source Code of Conduct](https://github.com/twitter/code-of-conduct/blob/master/code-of-conduct.md)\n* [Mozilla Code of Conduct/Draft](https://wiki.mozilla.org/Code_of_Conduct/Draft#Conflicts_of_Interest)\n* [Python Diversity Appendix](https://www.python.org/community/diversity/)\n* [Python Mentors Home Page](http://pythonmentors.com)\n\n\n# Slack Community Guidelines\n\nIf you decide to join the [Community Slack](http://bit.ly/join-superset-slack), please adhere to the following rules:\n\n**1. Treat everyone in the community with respect.**\n\n- We strive to make this community a warm place for people from all industries, use cases, geographies, and backgrounds. Harassment of any kind is not acceptable and won’t be tolerated.\n- Please follow the guidelines as outlined in the Superset Community [code of conduct here](https://github.com/apache/superset/blob/master/CODE_OF_CONDUCT.md).\n\n**2. Use the right channel.**\n\n- Channels are an effective way to organize and focus discussions while also empowering members to opt-in to the types of content they’re interested in. When questions are posted or discussions are started in the wrong channel, it dilutes the trust of the members in the channel and, more practically, makes it harder for your questions to be answered.\n\n**3. Ask thoughtful questions.**\n\n- We’re all here to help each other out. The best way to get help is by investing effort into your questions. First check and see if your question is answered in the [Superset documentation](https://superset.apache.org/faq.html) or on [StackOverflow](https://stackoverflow.com/questions/tagged/apache-superset). You can also check GitHub trackers to see if your inquiry has been submitted before: [GitHub discussions](https://github.com/apache/superset/discussions) for questions and feature requests and [GitHub issues](https://github.com/apache/superset/issues) for bug reports. Then, use Slack search to see if your question has already been asked and answered in the past.\n\nIf you still feel the need to ask a question, make sure you include:\n\n- The steps you’ve already taken.\n- Relevant details presented cleanly: text stacktraces, formatted markdown, or screenshots. Please don’t paste large blocks of code unformatted or post photos of your screen from your phone.\n- The specific question you have or the specific type of help you're seeking.\n\n**4. Avoid double posting**\n\n- This Slack community is not a customer support channel and all members are here voluntarily. If you aren’t getting a response to a question you have, make sure you look at rules 1, 2, and 3.  It’s also worth remembering that there may not be someone in the community who has the context to help you out.\n\n**5. Communicate openly**\n\n- Unless you have explicit permission from the person, please avoid sending direct messages to individuals. Communicating in public channels ensures that we’re all respecting each other’s attentions and we can scalably moderate our communication to mitigate harassment or discrimination. Do not use direct messages to pitch products and services. If you are receiving unwelcome direct messages, please notify an admin.\n\n**6. Practice good Slack hygiene by using threads for discussions and emojis for light reactions.**\n\n- The medium is the message. Slack can foster a warm, collaborative, and organized community when used effectively. We want to respect people’s attentions (thread notifications > channel notifications > DM notifications) and we want to improve information density (a member should be able to browse and explore many convo threads, not just see one thread discussed in a top level channel).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.12,
          "content": "<!--\n Licensed to the Apache Software Foundation (ASF) under one\n or more contributor license agreements.  See the NOTICE file\n distributed with this work for additional information\n regarding copyright ownership.  The ASF licenses this file\n to you under the Apache License, Version 2.0 (the\n \"License\"); you may not use this file except in compliance\n with the License.  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing,\n software distributed under the License is distributed on an\n \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n KIND, either express or implied.  See the License for the\n specific language governing permissions and limitations\n under the License.\n-->\nContributions are welcome and are greatly appreciated! Every\nlittle bit helps, and credit will always be given.\n\nAll matters related to contributions have moved to [this section of\nthe official Superset documentation](https://superset.apache.org/docs/contributing/). Source for the documentation is\n[located here](https://github.com/apache/superset/tree/master/docs/docs).\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 9.27,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n######################################################################\n# Node stage to deal with static asset construction\n######################################################################\nARG PY_VER=3.10-slim-bookworm\n\n# If BUILDPLATFORM is null, set it to 'amd64' (or leave as is otherwise).\nARG BUILDPLATFORM=${BUILDPLATFORM:-amd64}\n\n######################################################################\n# superset-node-ci used as a base for building frontend assets and CI\n######################################################################\nFROM --platform=${BUILDPLATFORM} node:20-bullseye-slim AS superset-node-ci\nARG BUILD_TRANSLATIONS=\"false\" # Include translations in the final build\nENV BUILD_TRANSLATIONS=${BUILD_TRANSLATIONS}\nARG DEV_MODE=\"false\"           # Skip frontend build in dev mode\nENV DEV_MODE=${DEV_MODE}\n\nCOPY docker/ /app/docker/\n# Arguments for build configuration\nARG NPM_BUILD_CMD=\"build\"\n\n# Install system dependencies required for node-gyp\nRUN /app/docker/apt-install.sh build-essential python3 zstd\n\n# Define environment variables for frontend build\nENV BUILD_CMD=${NPM_BUILD_CMD} \\\n    PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true\n\n# Run the frontend memory monitoring script\nRUN /app/docker/frontend-mem-nag.sh\n\nWORKDIR /app/superset-frontend\n\n# Create necessary folders to avoid errors in subsequent steps\nRUN mkdir -p /app/superset/static/assets \\\n             /app/superset/translations\n\n# Mount package files and install dependencies if not in dev mode\n# NOTE: we mount packages and plugins as they are referenced in package.json as workspaces\n# ideally we'd COPY only their package.json. Here npm ci will be cached as long\n# as the full content of these folders don't change, yielding a decent cache reuse rate.\n# Note that's it's not possible selectively COPY of mount using blobs.\nRUN --mount=type=bind,source=./superset-frontend/package.json,target=./package.json \\\n    --mount=type=bind,source=./superset-frontend/package-lock.json,target=./package-lock.json \\\n    --mount=type=cache,target=/root/.cache \\\n    --mount=type=cache,target=/root/.npm \\\n    if [ \"$DEV_MODE\" = \"false\" ]; then \\\n        npm ci; \\\n    else \\\n        echo \"Skipping 'npm ci' in dev mode\"; \\\n    fi\n\n# Runs the webpack build process\nCOPY superset-frontend /app/superset-frontend\n\n######################################################################\n# superset-node used for compile frontend assets\n######################################################################\nFROM superset-node-ci AS superset-node\n\n# Build the frontend if not in dev mode\nRUN --mount=type=cache,target=/app/superset-frontend/.temp_cache \\\n    --mount=type=cache,target=/root/.npm \\\n    if [ \"$DEV_MODE\" = \"false\" ]; then \\\n        echo \"Running 'npm run ${BUILD_CMD}'\"; \\\n        npm run ${BUILD_CMD}; \\\n    else \\\n        echo \"Skipping 'npm run ${BUILD_CMD}' in dev mode\"; \\\n    fi;\n\n# Copy translation files\nCOPY superset/translations /app/superset/translations\n\n# Build the frontend if not in dev mode\nRUN if [ \"$BUILD_TRANSLATIONS\" = \"true\" ]; then \\\n        npm run build-translation; \\\n    fi; \\\n    rm -rf /app/superset/translations/*/*/*.po; \\\n    rm -rf /app/superset/translations/*/*/*.mo;\n\n\n######################################################################\n# Base python layer\n######################################################################\nFROM python:${PY_VER} AS python-base\nARG BUILD_TRANSLATIONS=\"false\" # Include translations in the final build\nENV BUILD_TRANSLATIONS=${BUILD_TRANSLATIONS}\nARG DEV_MODE=\"false\"           # Skip frontend build in dev mode\nENV DEV_MODE=${DEV_MODE}\n\nENV LANG=C.UTF-8 \\\n    LC_ALL=C.UTF-8 \\\n    SUPERSET_ENV=production \\\n    FLASK_APP=\"superset.app:create_app()\" \\\n    PYTHONPATH=\"/app/pythonpath\" \\\n    SUPERSET_HOME=\"/app/superset_home\" \\\n    SUPERSET_PORT=8088\n\n\nRUN useradd --user-group -d ${SUPERSET_HOME} -m --no-log-init --shell /bin/bash superset\n\n# Some bash scripts needed throughout the layers\nCOPY --chmod=755 docker/*.sh /app/docker/\n\nRUN pip install --no-cache-dir --upgrade uv\n\n# Using uv as it's faster/simpler than pip\nRUN uv venv /app/.venv\nENV PATH=\"/app/.venv/bin:${PATH}\"\n\n# Install Playwright and optionally setup headless browsers\nARG INCLUDE_CHROMIUM=\"true\"\nARG INCLUDE_FIREFOX=\"false\"\nRUN --mount=type=cache,target=/root/.cache/uv\\\n    if [ \"$INCLUDE_CHROMIUM\" = \"true\" ] || [ \"$INCLUDE_FIREFOX\" = \"true\" ]; then \\\n        uv pip install playwright && \\\n        playwright install-deps && \\\n        if [ \"$INCLUDE_CHROMIUM\" = \"true\" ]; then playwright install chromium; fi && \\\n        if [ \"$INCLUDE_FIREFOX\" = \"true\" ]; then playwright install firefox; fi; \\\n    else \\\n        echo \"Skipping browser installation\"; \\\n    fi\n\n######################################################################\n# Python translation compiler layer\n######################################################################\nFROM python-base AS python-translation-compiler\n\n# Install Python dependencies using docker/pip-install.sh\nCOPY requirements/translations.txt requirements/\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    /app/docker/pip-install.sh --requires-build-essential -r requirements/translations.txt\n\nCOPY superset/translations/ /app/translations_mo/\nRUN if [ \"$BUILD_TRANSLATIONS\" = \"true\" ]; then \\\n        pybabel compile -d /app/translations_mo | true; \\\n    fi; \\\n    rm -f /app/translations_mo/*/*/*.po; \\\n    rm -f /app/translations_mo/*/*/*.json;\n\n######################################################################\n# Python APP common layer\n######################################################################\nFROM python-base AS python-common\n# Copy the entrypoints, make them executable in userspace\nCOPY --chmod=755 docker/entrypoints /app/docker/entrypoints\n\nWORKDIR /app\n# Set up necessary directories and user\nRUN mkdir -p \\\n      ${SUPERSET_HOME} \\\n      ${PYTHONPATH} \\\n      superset/static \\\n      requirements \\\n      superset-frontend \\\n      apache_superset.egg-info \\\n      requirements \\\n    && touch superset/static/version_info.json\n\n# Copy required files for Python build\nCOPY pyproject.toml setup.py MANIFEST.in README.md ./\nCOPY superset-frontend/package.json superset-frontend/\nCOPY scripts/check-env.py scripts/\n\n# keeping for backward compatibility\nCOPY --chmod=755 ./docker/entrypoints/run-server.sh /usr/bin/\n\n# Some debian libs\nRUN /app/docker/apt-install.sh \\\n      curl \\\n      libsasl2-dev \\\n      libsasl2-modules-gssapi-mit \\\n      libpq-dev \\\n      libecpg-dev \\\n      libldap2-dev\n\n# Copy compiled things from previous stages\nCOPY --from=superset-node /app/superset/static/assets superset/static/assets\n\n# TODO, when the next version comes out, use --exclude superset/translations\nCOPY superset superset\n# TODO in the meantime, remove the .po files\nRUN rm superset/translations/*/*/*.po\n\n# Merging translations from backend and frontend stages\nCOPY --from=superset-node /app/superset/translations superset/translations\nCOPY --from=python-translation-compiler /app/translations_mo superset/translations\n\nHEALTHCHECK CMD curl -f \"http://localhost:${SUPERSET_PORT}/health\"\nCMD [\"/app/docker/entrypoints/run-server.sh\"]\nEXPOSE ${SUPERSET_PORT}\n\n######################################################################\n# Final lean image...\n######################################################################\nFROM python-common AS lean\n\n# Install Python dependencies using docker/pip-install.sh\nCOPY requirements/base.txt requirements/\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    /app/docker/pip-install.sh --requires-build-essential -r requirements/base.txt\n# Install the superset package\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install .\n\nRUN python -m compileall /app/superset\n\nUSER superset\n\n######################################################################\n# Dev image...\n######################################################################\nFROM python-common AS dev\n\n# Debian libs needed for dev\nRUN /app/docker/apt-install.sh \\\n    git \\\n    pkg-config \\\n    default-libmysqlclient-dev\n\n# Copy development requirements and install them\nCOPY requirements/*.txt requirements/\n# Install Python dependencies using docker/pip-install.sh\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    /app/docker/pip-install.sh --requires-build-essential -r requirements/development.txt\n# Install the superset package\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install .\n\nRUN python -m compileall /app/superset\n\nUSER superset\n\n######################################################################\n# CI image...\n######################################################################\nFROM lean AS ci\n\nCMD [\"/app/docker/entrypoints/docker-ci.sh\"]\n"
        },
        {
          "name": "INSTALL.md",
          "type": "blob",
          "size": 0.96,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n# INSTALL / BUILD instructions for Apache Superset\n\nAt this time, the docker file at RELEASING/Dockerfile.from_local_tarball\nconstitutes the recipe on how to get to a working release from a source\nrelease tarball.\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 11.31,
          "content": "                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n============================================================================\n   APACHE SUPERSET SUBCOMPONENTS:\n\n   The Apache Superset project contains subcomponents with separate copyright\n   notices and license terms. Your use of the source code for the these\n   subcomponents is subject to the terms and conditions of the following\n   licenses.\n\n========================================================================\nThird party SIL Open Font License v1.1 (OFL-1.1)\n========================================================================\n\n(SIL OPEN FONT LICENSE Version 1.1) The Inter font family (https://github.com/rsms/inter)\n(SIL OPEN FONT LICENSE Version 1.1) The Fira Code font family (https://github.com/tonsky/FiraCode)\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 1.09,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\ninclude NOTICE\ninclude LICENSE.txt\ngraft licenses/\ninclude README.md\ninclude superset-frontend/package.json\nrecursive-include superset/examples *\nrecursive-include superset/migrations *\nrecursive-include superset/templates *\nrecursive-include superset/translations *\nrecursive-include superset/static *\nrecursive-exclude tests *\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.16,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Python version installed; we need 3.10-3.11\nPYTHON=`command -v python3.11 || command -v python3.10`\n\n.PHONY: install superset venv pre-commit\n\ninstall: superset pre-commit\n\nsuperset:\n\t# Install external dependencies\n\tpip install -r requirements/development.txt\n\n\t# Install Superset in editable (development) mode\n\tpip install -e .\n\n\t# Create an admin user in your metadata database\n\tsuperset fab create-admin \\\n                    --username admin \\\n                    --firstname \"Admin I.\"\\\n                    --lastname Strator \\\n                    --email admin@superset.io \\\n                    --password general\n\n\t# Initialize the database\n\tsuperset db upgrade\n\n\t# Create default roles and permissions\n\tsuperset init\n\n\t# Load some data to play with\n\tsuperset load-examples\n\n\t# Install node packages\n\tcd superset-frontend; npm ci\n\nupdate: update-py update-js\n\nupdate-py:\n\t# Install external dependencies\n\tpip install -r requirements/development.txt\n\n\t# Install Superset in editable (development) mode\n\tpip install -e .\n\n\t# Initialize the database\n\tsuperset db upgrade\n\n\t# Create default roles and permissions\n\tsuperset init\n\nupdate-js:\n\t# Install js packages\n\tcd superset-frontend; npm ci\n\nvenv:\n\t# Create a virtual environment and activate it (recommended)\n\tif ! [ -x \"${PYTHON}\" ]; then echo \"You need Python 3.10 or 3.11 installed\"; exit 1; fi\n\ttest -d venv || ${PYTHON} -m venv venv # setup a python3 virtualenv\n\t. venv/bin/activate\n\nactivate:\n\t. venv/bin/activate\n\npre-commit:\n\t# setup pre commit dependencies\n\tpip3 install -r requirements/development.txt\n\tpre-commit install\n\nformat: py-format js-format\n\npy-format: pre-commit\n\tpre-commit run black --all-files\n\njs-format:\n\tcd superset-frontend; npm run prettier\n\nflask-app:\n\tflask run -p 8088 --with-threads --reload --debugger\n\nnode-app:\n\tcd superset-frontend; npm run dev-server\n\nbuild-cypress:\n\tcd superset-frontend; npm run build-instrumented\n\tcd superset-frontend/cypress-base; npm ci\n\nopen-cypress:\n\tif ! [ $(port) ]; then cd superset-frontend/cypress-base; CYPRESS_BASE_URL=http://localhost:9000 npm run cypress open; fi\n\tcd superset-frontend/cypress-base; CYPRESS_BASE_URL=http://localhost:$(port) npm run cypress open\n\nreport-celery-worker:\n\tcelery --app=superset.tasks.celery_app:app worker\n\nreport-celery-beat:\n\tcelery --app=superset.tasks.celery_app:app beat --pidfile /tmp/celerybeat.pid --schedule /tmp/celerybeat-schedulecd\n\nadmin-user:\n\tsuperset fab create-admin\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.17,
          "content": "Apache Superset\nCopyright 2016-2024 The Apache Software Foundation\n\nThis product includes software developed at The Apache Software\nFoundation (http://www.apache.org/).\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.31,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Superset\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/license/apache-2-0)\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/apache/superset?sort=semver)](https://github.com/apache/superset/tree/latest)\n[![Build Status](https://github.com/apache/superset/workflows/Python/badge.svg)](https://github.com/apache/superset/actions)\n[![PyPI version](https://badge.fury.io/py/apache-superset.svg)](https://badge.fury.io/py/apache-superset)\n[![Coverage Status](https://codecov.io/github/apache/superset/coverage.svg?branch=master)](https://codecov.io/github/apache/superset)\n[![PyPI](https://img.shields.io/pypi/pyversions/apache-superset.svg?maxAge=2592000)](https://pypi.python.org/pypi/apache-superset)\n[![Get on Slack](https://img.shields.io/badge/slack-join-orange.svg)](http://bit.ly/join-superset-slack)\n[![Documentation](https://img.shields.io/badge/docs-apache.org-blue.svg)](https://superset.apache.org)\n\n<picture width=\"500\">\n  <source\n    width=\"600\"\n    media=\"(prefers-color-scheme: dark)\"\n    src=\"https://superset.apache.org/img/superset-logo-horiz-dark.svg\"\n    alt=\"Superset logo (dark)\"\n  />\n  <img\n    width=\"600\"\n    src=\"https://superset.apache.org/img/superset-logo-horiz-apache.svg\"\n    alt=\"Superset logo (light)\"\n  />\n</picture>\n\nA modern, enterprise-ready business intelligence web application.\n\n[**Why Superset?**](#why-superset) |\n[**Supported Databases**](#supported-databases) |\n[**Installation and Configuration**](#installation-and-configuration) |\n[**Release Notes**](https://github.com/apache/superset/blob/master/RELEASING/README.md#release-notes-for-recent-releases) |\n[**Get Involved**](#get-involved) |\n[**Contributor Guide**](#contributor-guide) |\n[**Resources**](#resources) |\n[**Organizations Using Superset**](https://github.com/apache/superset/blob/master/RESOURCES/INTHEWILD.md)\n\n## Why Superset?\n\nSuperset is a modern data exploration and data visualization platform. Superset can replace or augment proprietary business intelligence tools for many teams. Superset integrates well with a variety of data sources.\n\nSuperset provides:\n\n- A **no-code interface** for building charts quickly\n- A powerful, web-based **SQL Editor** for advanced querying\n- A **lightweight semantic layer** for quickly defining custom dimensions and metrics\n- Out of the box support for **nearly any SQL** database or data engine\n- A wide array of **beautiful visualizations** to showcase your data, ranging from simple bar charts to geospatial visualizations\n- Lightweight, configurable **caching layer** to help ease database load\n- Highly extensible **security roles and authentication** options\n- An **API** for programmatic customization\n- A **cloud-native architecture** designed from the ground up for scale\n\n## Screenshots & Gifs\n\n**Video Overview**\n<!-- File hosted here https://github.com/apache/superset-site/raw/lfs/superset-video-4k.mp4 -->\n[superset-video-4k.webm](https://github.com/apache/superset/assets/812905/da036bc2-150c-4ee7-80f9-75e63210ff76)\n\n<br/>\n\n**Large Gallery of Visualizations**\n\n<kbd><img title=\"Gallery\" src=\"https://superset.apache.org/img/screenshots/gallery.jpg\"/></kbd><br/>\n\n**Craft Beautiful, Dynamic Dashboards**\n\n<kbd><img title=\"View Dashboards\" src=\"https://superset.apache.org/img/screenshots/slack_dash.jpg\"/></kbd><br/>\n\n**No-Code Chart Builder**\n\n<kbd><img title=\"Slice & dice your data\" src=\"https://superset.apache.org/img/screenshots/explore.jpg\"/></kbd><br/>\n\n**Powerful SQL Editor**\n\n<kbd><img title=\"SQL Lab\" src=\"https://superset.apache.org/img/screenshots/sql_lab.jpg\"/></kbd><br/>\n\n## Supported Databases\n\nSuperset can query data from any SQL-speaking datastore or data engine (Presto, Trino, Athena, [and more](https://superset.apache.org/docs/configuration/databases)) that has a Python DB-API driver and a SQLAlchemy dialect.\n\nHere are some of the major database solutions that are supported:\n\n<p align=\"center\">\n  <img src=\"https://superset.apache.org/img/databases/redshift.png\" alt=\"redshift\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/google-biquery.png\" alt=\"google-biquery\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/snowflake.png\" alt=\"snowflake\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/trino.png\" alt=\"trino\" border=\"0\" width=\"150\" />\n  <img src=\"https://superset.apache.org/img/databases/presto.png\" alt=\"presto\" border=\"0\" width=\"200\"/>\n  <img src=\"https://superset.apache.org/img/databases/databricks.png\" alt=\"databricks\" border=\"0\" width=\"160\" />\n  <img src=\"https://superset.apache.org/img/databases/druid.png\" alt=\"druid\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/firebolt.png\" alt=\"firebolt\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/timescale.png\" alt=\"timescale\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/rockset.png\" alt=\"rockset\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/postgresql.png\" alt=\"postgresql\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/mysql.png\" alt=\"mysql\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/mssql-server.png\" alt=\"mssql-server\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/ibm-db2.svg\" alt=\"db2\" border=\"0\" width=\"220\" />\n  <img src=\"https://superset.apache.org/img/databases/sqlite.png\" alt=\"sqlite\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/sybase.png\" alt=\"sybase\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/mariadb.png\" alt=\"mariadb\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/vertica.png\" alt=\"vertica\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/oracle.png\" alt=\"oracle\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/firebird.png\" alt=\"firebird\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/greenplum.png\" alt=\"greenplum\" border=\"0\" width=\"200\"  />\n  <img src=\"https://superset.apache.org/img/databases/clickhouse.png\" alt=\"clickhouse\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/exasol.png\" alt=\"exasol\" border=\"0\" width=\"160\" />\n  <img src=\"https://superset.apache.org/img/databases/monet-db.png\" alt=\"monet-db\" border=\"0\" width=\"200\"  />\n  <img src=\"https://superset.apache.org/img/databases/apache-kylin.png\" alt=\"apache-kylin\" border=\"0\" width=\"80\"/>\n  <img src=\"https://superset.apache.org/img/databases/hologres.png\" alt=\"hologres\" border=\"0\" width=\"80\"/>\n  <img src=\"https://superset.apache.org/img/databases/netezza.png\" alt=\"netezza\" border=\"0\" width=\"80\"/>\n  <img src=\"https://superset.apache.org/img/databases/pinot.png\" alt=\"pinot\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/teradata.png\" alt=\"teradata\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/yugabyte.png\" alt=\"yugabyte\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/databend.png\" alt=\"databend\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/starrocks.png\" alt=\"starrocks\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/doris.png\" alt=\"doris\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/oceanbase.svg\" alt=\"oceanbase\" border=\"0\" width=\"220\" />\n  <img src=\"https://superset.apache.org/img/databases/sap-hana.png\" alt=\"oceanbase\" border=\"0\" width=\"220\" />\n  <img src=\"https://superset.apache.org/img/databases/denodo.png\" alt=\"denodo\" border=\"0\" width=\"200\" />\n  <img src=\"https://superset.apache.org/img/databases/ydb.svg\" alt=\"ydb\" border=\"0\" width=\"200\" />\n</p>\n\n**A more comprehensive list of supported databases** along with the configuration instructions can be found [here](https://superset.apache.org/docs/configuration/databases).\n\nWant to add support for your datastore or data engine? Read more [here](https://superset.apache.org/docs/frequently-asked-questions#does-superset-work-with-insert-database-engine-here) about the technical requirements.\n\n## Installation and Configuration\n\n[Extended documentation for Superset](https://superset.apache.org/docs/installation/docker-compose)\n\n## Get Involved\n\n- Ask and answer questions on [StackOverflow](https://stackoverflow.com/questions/tagged/apache-superset) using the **apache-superset** tag\n- [Join our community's Slack](http://bit.ly/join-superset-slack)\n  and please read our [Slack Community Guidelines](https://github.com/apache/superset/blob/master/CODE_OF_CONDUCT.md#slack-community-guidelines)\n- [Join our dev@superset.apache.org Mailing list](https://lists.apache.org/list.html?dev@superset.apache.org). To join, simply send an email to [dev-subscribe@superset.apache.org](mailto:dev-subscribe@superset.apache.org)\n- If you want to help troubleshoot GitHub Issues involving the numerous database drivers that Superset supports, please consider adding your name and the databases you have access to on the [Superset Database Familiarity Rolodex](https://docs.google.com/spreadsheets/d/1U1qxiLvOX0kBTUGME1AHHi6Ywel6ECF8xk_Qy-V9R8c/edit#gid=0)\n- Join Superset's Town Hall and [Operational Model](https://preset.io/blog/the-superset-operational-model-wants-you/) recurring meetings.  Meeting info is available on the [Superset Community Calendar](https://superset.apache.org/community)\n\n## Contributor Guide\n\nInterested in contributing? Check out our\n[CONTRIBUTING.md](https://github.com/apache/superset/blob/master/CONTRIBUTING.md)\nto find resources around contributing along with a detailed guide on\nhow to set up a development environment.\n\n## Resources\n\n- [Superset \"In the Wild\"](https://github.com/apache/superset/blob/master/RESOURCES/INTHEWILD.md) - open a PR to add your org to the list!\n- [Feature Flags](https://github.com/apache/superset/blob/master/RESOURCES/FEATURE_FLAGS.md) - the status of Superset's Feature Flags.\n- [Standard Roles](https://github.com/apache/superset/blob/master/RESOURCES/STANDARD_ROLES.md) - How RBAC permissions map to roles.\n- [Superset Wiki](https://github.com/apache/superset/wiki) - Tons of additional community resources: best practices, community content and other information.\n- [Superset SIPs](https://github.com/orgs/apache/projects/170) - The status of Superset's SIPs (Superset Improvement Proposals) for both consensus and implementation status.\n\nUnderstanding the Superset Points of View\n\n- [The Case for Dataset-Centric Visualization](https://preset.io/blog/dataset-centric-visualization/)\n- [Understanding the Superset Semantic Layer](https://preset.io/blog/understanding-superset-semantic-layer/)\n\n- Getting Started with Superset\n  - [Superset in 2 Minutes using Docker Compose](https://superset.apache.org/docs/installation/docker-compose#installing-superset-locally-using-docker-compose)\n  - [Installing Database Drivers](https://superset.apache.org/docs/configuration/databases#installing-database-drivers)\n  - [Building New Database Connectors](https://preset.io/blog/building-database-connector/)\n  - [Create Your First Dashboard](https://superset.apache.org/docs/using-superset/creating-your-first-dashboard/)\n  - [Comprehensive Tutorial for Contributing Code to Apache Superset\n  ](https://preset.io/blog/tutorial-contributing-code-to-apache-superset/)\n- [Resources to master Superset by Preset](https://preset.io/resources/)\n\n- Deploying Superset\n  - [Official Docker image](https://hub.docker.com/r/apache/superset)\n  - [Helm Chart](https://github.com/apache/superset/tree/master/helm/superset)\n\n- Recordings of Past [Superset Community Events](https://preset.io/events)\n  - [Mixed Time Series Charts](https://preset.io/events/mixed-time-series-visualization-in-superset-workshop/)\n  - [How the Bing Team Customized Superset for the Internal Self-Serve Data & Analytics Platform](https://preset.io/events/how-the-bing-team-heavily-customized-superset-for-their-internal-data/)\n  - [Live Demo: Visualizing MongoDB and Pinot Data using Trino](https://preset.io/events/2021-04-13-visualizing-mongodb-and-pinot-data-using-trino/)\n  - [Introduction to the Superset API](https://preset.io/events/introduction-to-the-superset-api/)\n  - [Building a Database Connector for Superset](https://preset.io/events/2021-02-16-building-a-database-connector-for-superset/)\n\n- Visualizations\n  - [Creating Viz Plugins](https://superset.apache.org/docs/contributing/creating-viz-plugins/)\n  - [Managing and Deploying Custom Viz Plugins](https://medium.com/nmc-techblog/apache-superset-manage-custom-viz-plugins-in-production-9fde1a708e55)\n  - [Why Apache Superset is Betting on Apache ECharts](https://preset.io/blog/2021-4-1-why-echarts/)\n\n- [Superset API](https://superset.apache.org/docs/rest-api)\n\n## Repo Activity\n\n<a href=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=39464018\" target=\"_blank\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=39464018&image_size=auto&color_scheme=dark\" width=\"655\" height=\"auto\" />\n    <img alt=\"Performance Stats of apache/superset - Last 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=39464018&image_size=auto&color_scheme=light\" width=\"655\" height=\"auto\" />\n  </picture>\n</a>\n\n<!-- Made with [OSS Insight](https://ossinsight.io/) -->\n\n<!-- telemetry/analytics pixel: -->\n<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=bc1c90cd-bc04-4e11-8c7b-289fb2839492\" />\n"
        },
        {
          "name": "RELEASING",
          "type": "tree",
          "content": null
        },
        {
          "name": "RESOURCES",
          "type": "tree",
          "content": null
        },
        {
          "name": "UPDATING.md",
          "type": "blob",
          "size": 70.07,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Updating Superset\n\nThis file documents any backwards-incompatible changes in Superset and\nassists people when migrating to a new version.\n\n## Next\n\n- [31582](https://github.com/apache/superset/pull/31582) Removed the legacy Area, Bar, Event Flow, Heatmap, Histogram, Line, Sankey, and Sankey Loop charts. They were all automatically migrated to their ECharts counterparts with the exception of the Event Flow and Sankey Loop charts which were removed as they were not actively maintained and not widely used. If you were using the Event Flow or Sankey Loop charts, you will need to find an alternative solution.\n- [31198](https://github.com/apache/superset/pull/31198) Disallows by default the use of the following ClickHouse functions: \"version\", \"currentDatabase\", \"hostName\".\n- [29798](https://github.com/apache/superset/pull/29798) Since 3.1.0, the intial schedule for an alert or report was mistakenly offset by the specified timezone's relation to UTC. The initial schedule should now begin at the correct time.\n- [30021](https://github.com/apache/superset/pull/30021) The `dev` layer in our Dockerfile no long includes firefox binaries, only Chromium to reduce bloat/docker-build-time.\n- [30099](https://github.com/apache/superset/pull/30099) Translations are no longer included in the default docker image builds. If your environment requires translations, you'll want to set the docker build arg `BUILD_TRANSACTION=true`.\n- [31262](https://github.com/apache/superset/pull/31262) NOTE: deprecated `pylint` in favor of `ruff` as our only python linter. Only affect development workflows positively (not the release itself). It should cover most important rules, be much faster, but some things linting rules that were enforced before may not be enforce in the exact same way as before.\n- [31173](https://github.com/apache/superset/pull/31173) Modified `fetch_csrf_token` to align with HTTP standards, particularly regarding how cookies are handled. If you encounter any issues related to CSRF functionality, please report them as a new issue and reference this PR for context.\n- [31385](https://github.com/apache/superset/pull/31385) Significant docker refactor, reducing access levels for the `superset` user, streamlining layer building, ...\n\n### Potential Downtime\n\n## 4.1.0\n\n- [29274](https://github.com/apache/superset/pull/29274): We made it easier to trigger CI on your\n  forks, whether they are public or private. Simply push to a branch that fits `[0-9].[0-9]*` and\n  should run on your fork, giving you flexibility on naming your release branches and triggering\n  CI\n- [27505](https://github.com/apache/superset/pull/27505): We simplified the files under\n  `requirements/` folder. If you use these files for your builds you may want to double\n  check that your builds are not affected. `base.txt` should be the same as before, though\n  `development.txt` becomes a bigger set, incorporating the now defunct local,testing,integration, and docker\n- [27434](https://github.com/apache/superset/pull/27434/files): DO NOT USE our docker compose.\\*\n  files for production use cases! While we never really supported\n  or should have tried to support docker compose for production use cases, we now actively\n  have taken a stance against supporting it. See the PR for details.\n- [24112](https://github.com/apache/superset/pull/24112): Python 3.10 is now the recommended python version to use, 3.9 still\n  supported but getting deprecated in the nearish future. CI/CD runs on py310 so you probably want to align. If you\n  use official dockers, upgrade should happen automatically.\n- [27697](https://github.com/apache/superset/pull/27697) [minor] flask-session bump leads to them\n  deprecating `SESSION_USE_SIGNER`, check your configs as this flag won't do anything moving\n  forward.\n- [27849](https://github.com/apache/superset/pull/27849/) More of an FYI, but we have a\n  new config `SLACK_ENABLE_AVATARS` (False by default) that works in conjunction with\n  set `SLACK_API_TOKEN` to fetch and serve Slack avatar links\n- [28134](https://github.com/apache/superset/pull/28134/) The default logging level was changed\n  from DEBUG to INFO - which is the normal/sane default logging level for most software.\n- [27777](https://github.com/apache/superset/pull/27777) Moves debug logging logic to config.py.\n  See `LOG_LEVEL` in `superset/config.py` for the recommended default.\n- [28205](https://github.com/apache/superset/pull/28205) The permission `all_database_access` now\n  more clearly provides access to all databases, as specified in its name. Before it only allowed\n  listing all databases in CRUD-view and dropdown and didn't provide access to data as it\n  seemed the name would imply.\n- [28483](https://github.com/apache/superset/pull/28483) Starting with this version we bundle\n  translations inside the python package. This includes the .mo files needed by pybabel on the\n  backend, as well as the .json files used by the frontend. If you were doing anything before\n  as part of your bundling to expose translation packages, it's probably not needed anymore.\n- [29264](https://github.com/apache/superset/pull/29264) Slack has updated its file upload api, and we are now supporting this new api in Superset, although the Slack api is not backward compatible. The original Slack integration is deprecated and we will require a new Slack scope `channels:read` to be added to Slack workspaces in order to use this new api. In an upcoming release, we will make this new Slack scope mandatory and remove the old Slack functionality.\n- [30274](https://github.com/apache/superset/pull/30274) Moved SLACK_ENABLE_AVATAR from config.py to the feature flag framework, please adapt your configs.\n\n### Potential Downtime\n\n- [27392](https://github.com/apache/superset/pull/27392): Adds an index to `query.sql_editor_id` to improve performance. This may cause downtime on large deployments.\n\n## 4.0.0\n\n- [27119](https://github.com/apache/superset/pull/27119): Updates various database columns to use the `MediumText` type, potentially requiring a table lock on MySQL dbs or taking some time to complete on large deployments.\n\n- [26450](https://github.com/apache/superset/pull/26450): Deprecates the `KV_STORE` feature flag and its related assets such as the API endpoint and `keyvalue` table. The main dependency of this feature is the `SHARE_QUERIES_VIA_KV_STORE` feature flag which allows sharing SQL Lab queries without the necessity of saving the query. Our intention is to use the permalink feature to implement this use case before 5.0 and that's why we are deprecating the feature flag now.\n\n### Breaking Changes\n\n- [27130](https://github.com/apache/superset/pull/27130): Fixes the DELETE `/database/{id}/ssh_tunnel/` endpoint to now correctly accept a database ID as a parameter, rather than an SSH tunnel ID.\n- [27117](https://github.com/apache/superset/pull/27117): Removes the following deprecated endpoints: `/superset/sqllab`, `/superset/sqllab/history`, `/sqllab/my_queries` use `/sqllab`, `/sqllab/history`, `/savedqueryview/list/?_flt_0_user={get_user_id()}` instead.\n- [26347](https://github.com/apache/superset/issues/26347): Removes the deprecated `VERSIONED_EXPORT` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [26328](https://github.com/apache/superset/issues/26328): Removes the deprecated Filter Box code and it's associated dependencies `react-select` and `array-move`. It also removes the `DeprecatedSelect` and `AsyncSelect` components that were exclusively used by filter boxes. Existing filter boxes will be automatically migrated to native filters.\n- [26330](https://github.com/apache/superset/issues/26330): Removes the deprecated `DASHBOARD_FILTERS_EXPERIMENTAL` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26344](https://github.com/apache/superset/issues/26344): Removes the deprecated `ENABLE_EXPLORE_JSON_CSRF_PROTECTION` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26345](https://github.com/apache/superset/issues/26345): Removes the deprecated `ENABLE_TEMPLATE_REMOVE_FILTERS` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [26346](https://github.com/apache/superset/issues/26346): Removes the deprecated `REMOVE_SLICE_LEVEL_LABEL_COLORS` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26348](https://github.com/apache/superset/issues/26348): Removes the deprecated `CLIENT_CACHE` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26349](https://github.com/apache/superset/issues/26349): Removes the deprecated `DASHBOARD_CACHE` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26369](https://github.com/apache/superset/issues/26369): Removes the Filter Sets feature including the deprecated `DASHBOARD_NATIVE_FILTERS_SET` feature flag and all related API endpoints. The feature is permanently removed as it was not being actively maintained, it was not widely used, and it was full of bugs. We also considered that if we were to provide a similar feature, it would be better to re-implement it from scratch given the amount of technical debt that the current implementation has. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26343](https://github.com/apache/superset/issues/26343): Removes the deprecated `ENABLE_EXPLORE_DRAG_AND_DROP` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [26331](https://github.com/apache/superset/issues/26331): Removes the deprecated `DISABLE_DATASET_SOURCE_EDIT` feature flag. The previous value of the feature flag was `False` and now the feature is permanently removed.\n- [26636](https://github.com/apache/superset/issues/26636): Sets the `DASHBOARD_VIRTUALIZATION` feature flag to `True` by default. This feature was introduced by [21438](https://github.com/apache/superset/pull/21438) and will enable virtualization when rendering a dashboard's charts in an attempt to reduce the number of elements (DOM nodes) rendered at once. This is especially useful for large dashboards.\n- [26637](https://github.com/apache/superset/issues/26637): Sets the `DRILL_BY` feature flag to `True` by default given that the feature has been tested for a while and reached a stable state.\n- [26462](https://github.com/apache/superset/issues/26462): Removes the Profile feature given that it's not actively maintained and not widely used.\n- [26377](https://github.com/apache/superset/pull/26377): Removes the deprecated Redirect API that supported short URLs used before the permalink feature.\n- [26329](https://github.com/apache/superset/issues/26329): Removes the deprecated `DASHBOARD_NATIVE_FILTERS` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n- [25510](https://github.com/apache/superset/pull/25510): Reenforces that any newly defined Python data format (other than epoch) must adhere to the ISO 8601 standard (enforced by way of validation at the API and database level) after a previous relaxation to include slashes in addition to dashes. From now on when specifying new columns, dataset owners will need to use a SQL expression instead to convert their string columns of the form %Y/%m/%d etc. to a `DATE`, `DATETIME`, etc. type.\n- [26372](https://github.com/apache/superset/issues/26372): Removes the deprecated `GENERIC_CHART_AXES` feature flag. The previous value of the feature flag was `True` and now the feature is permanently enabled.\n\n### Potential Downtime\n\n- [26416](https://github.com/apache/superset/pull/26416): Adds two database indexes to the `report_execution_log` table and one database index to the `report_recipient` to improve performance. Scheduled downtime may be required for large deployments.\n- [28482](https://github.com/apache/superset/pull/28482): Potentially augments the `query.executed_sql` and `query.select_sql` columns for MySQL from `MEDIUMTEXT` to `LONGTEXT`. Potential downtime may be required for large deployments which previously ran [27119](https://github.com/apache/superset/pull/27119).\n\n## 3.1.0\n\n- [24657](https://github.com/apache/superset/pull/24657): Bumps the cryptography package to augment the OpenSSL security vulnerability.\n\n### Other\n\n- [24982](https://github.com/apache/superset/pull/24982): By default, physical datasets on Oracle-like dialects like Snowflake will now use denormalized column names. However, existing datasets won't be affected. To change this behavior, the \"Advanced\" section on the dataset modal has a \"Normalize column names\" flag which can be changed to change this behavior.\n\n## 3.0.3\n\n- [26034](https://github.com/apache/superset/issues/26034): Fixes a problem where numeric x-axes were being treated as categorical values. As a consequence of that, the way labels are displayed might change given that ECharts has a different treatment for numerical and categorical values. To revert to the old behavior, users need to manually convert numerical columns to text so that they are treated as categories. Check https://github.com/apache/superset/issues/26159 for more details.\n\n## 3.0.0\n\n- [25053](https://github.com/apache/superset/pull/25053): Extends the `ab_user.email` column from 64 to 320 characters which has an associated unique key constraint. This will be problematic for MySQL metadata databases which use the InnoDB storage engine with the `innodb_large_prefix` parameter disabled as the key prefix limit is 767 bytes. Enabling said parameter and ensuring that the table uses either the `DYNAMIC` or `COMPRESSED` row format should remedy the problem. See [here](https://dev.mysql.com/doc/refman/5.7/en/innodb-limits.html) for more details.\n- [24911](https://github.com/apache/superset/pull/24911): Changes the column type from `TEXT` to `MediumText` in table `logs`, potentially requiring a table lock on MySQL dbs or taking some time to complete on large deployments.\n- [24939](https://github.com/apache/superset/pull/24939): Augments the foreign key constraints for the `embedded_dashboards` table to include an explicit CASCADE ON DELETE to ensure the relevant records are deleted when a dashboard is deleted. Scheduled downtime may be advised.\n- [24938](https://github.com/apache/superset/pull/24938): Augments the foreign key constraints for the `dashboard_slices` table to include an explicit CASCADE ON DELETE to ensure the relevant records are deleted when a dashboard or slice is deleted. Scheduled downtime may be advised.\n- [24628](https://github.com/apache/superset/pull/24628): Augments the foreign key constraints for the `dashboard_owner`, `report_schedule_owner`, and `slice_owner` tables to include an explicit CASCADE ON DELETE to ensure the relevant ownership records are deleted when a dataset is deleted. Scheduled downtime may be advised.\n- [24488](https://github.com/apache/superset/pull/24488): Augments the foreign key constraints for the `sql_metrics`, `sqlatable_user`, and `table_columns` tables which reference the `tables` table to include an explicit CASCADE ON DELETE to ensure the relevant records are deleted when a dataset is deleted. Scheduled downtime may be advised.\n- [24232](https://github.com/apache/superset/pull/24232): Enables ENABLE_TEMPLATE_REMOVE_FILTERS, DRILL_TO_DETAIL, DASHBOARD_CROSS_FILTERS by default, marks VERSIONED_EXPORT and ENABLE_TEMPLATE_REMOVE_FILTERS as deprecated.\n- [23652](https://github.com/apache/superset/pull/23652): Enables GENERIC_CHART_AXES feature flag by default.\n- [23226](https://github.com/apache/superset/pull/23226): Migrated endpoint `/estimate_query_cost/<int:database_id>` to `/api/v1/sqllab/estimate/`. Corresponding permissions are can estimate query cost on SQLLab. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [23890](https://github.com/apache/superset/pull/23890): Removes Python 3.8 support.\n- [24404](https://github.com/apache/superset/pull/24404): FLASK_ENV is getting\n  deprecated, we recommend using SUPERSET_ENV and reviewing your\n  config for ENVIRONMENT_TAG_CONFIG, which enables adding a tag in the navbar to\n  make it more clear which environment your are in.\n  `SUPERSET_ENV=production` and `SUPERSET_ENV=development` are the two\n  supported switches based on the default config.\n- [19242](https://github.com/apache/superset/pull/19242): Adhoc subqueries are now disabled by default for security reasons. To enable them, set the feature flag `ALLOW_ADHOC_SUBQUERY` to `True`.\n\n### Breaking Changes\n\n- [24686](https://github.com/apache/superset/pull/24686): All dataset's custom explore_url are handled as relative URLs on the frontend, behaviour controlled by PREVENT_UNSAFE_DEFAULT_URLS_ON_DATASET.\n- [24262](https://github.com/apache/superset/pull/24262): Enabled `TALISMAN_ENABLED` flag by default and provided stricter default Content Security Policy\n- [24415](https://github.com/apache/superset/pull/24415): Removed the obsolete Druid NoSQL REGEX operator.\n- [24423](https://github.com/apache/superset/pull/24423): Removed deprecated APIs `/superset/slice_json/...`, `/superset/annotation_json/...`\n- [24400](https://github.com/apache/superset/pull/24400): Removed deprecated APIs `/superset/recent_activity/...`, `/superset/fave_dashboards_by_username/...`, `/superset/fave_dashboards/...`, `/superset/created_dashboards/...`, `/superset/user_slices/`, `/superset/created_slices/...`, `/superset/fave_slices/...`, `/superset/favstar/...`,\n- [24401](https://github.com/apache/superset/pull/24401): Removes the deprecated `metrics` column (which was blossomed in [20732](https://github.com/apache/superset/pull/20732)) from the `/api/v1/dataset/` API.\n- [24375](https://github.com/apache/superset/pull/24375): Removed deprecated API `/superset/get_or_create_table/...`, `/superset/sqllab_viz`\n- [24360](https://github.com/apache/superset/pull/24360): Removed deprecated APIs `/superset/stop_query/...`, `/superset/queries/...`, `/superset/search_queries`\n- [24353](https://github.com/apache/superset/pull/24353): Removed deprecated APIs `/copy_dash/int:dashboard_id/`, `/save_dash/int:dashboard_id/`, `/add_slices/int:dashboard_id/`.\n- [24198](https://github.com/apache/superset/pull/24198) The FAB views `User Registrations` and `User's Statistics` have been changed to Admin only. To re-enable them for non-admin users, please add the following perms to your custom role: `menu access on User's Statistics` and `menu access on User Registrations`.\n- [24354](https://github.com/apache/superset/pull/24354): Removed deprecated APIs `/superset/testconn`, `/superset/validate_sql_json/`, `/superset/schemas_access_for_file_upload`, `/superset/extra_table_metadata`\n- [24381](https://github.com/apache/superset/pull/24381): Removed deprecated API `/superset/available_domains/`\n- [24359](https://github.com/apache/superset/pull/24359): Removed deprecated APIs `/superset/estimate_query_cost/..`, `/superset/results/..`, `/superset/sql_json/..`, `/superset/csv/..`\n- [24345](https://github.com/apache/superset/pull/24345) Converts `ENABLE_BROAD_ACTIVITY_ACCESS` and `MENU_HIDE_USER_INFO` into feature flags and changes the value of `ENABLE_BROAD_ACTIVITY_ACCESS` to `False` as it's more secure.\n- [24342](https://github.com/apache/superset/pull/24342): Removed deprecated API `/superset/tables/<int:db_id>/<schema>/...`\n- [24335](https://github.com/apache/superset/pull/24335): Removed deprecated API `/superset/filter/<datasource_type>/<int:datasource_id>/<column>/`\n- [24333](https://github.com/apache/superset/pull/24333): Removed deprecated API `/superset/datasources`\n- [24266](https://github.com/apache/superset/pull/24266) Remove the `ENABLE_ACCESS_REQUEST` config parameter and the associated request/approval workflows.\n- [24330](https://github.com/apache/superset/pull/24330) Removes `getUiOverrideRegistry` from `ExtensionsRegistry`.\n- [23933](https://github.com/apache/superset/pull/23933) Removes the deprecated Multiple Line Charts.\n- [23741](https://github.com/apache/superset/pull/23741) Migrates the TreeMap chart and removes the legacy Treemap code.\n- [23712](https://github.com/apache/superset/pull/23712) Migrates the Pivot Table v1 chart to v2 and removes v1 code.\n- [24029](https://github.com/apache/superset/pull/24029) Removes the `user` and `username` arguments for the `QUERY_LOGGER` and `SQL_QUERY_MUTATOR` methods respectively. If the username for the current user is required, the `superset.utils.core.get_username` method should be used.\n- [24128](https://github.com/apache/superset/pull/24128) The `RLS_BASE_RELATED_FIELD_FILTERS` config parameter has been removed. Now the Tables dropdown will feature the same tables that the user is able to see elsewhere in the application using the standard `DatasourceFilter`, and the Roles dropdown will be filtered using the filter defined in `EXTRA_RELATED_QUERY_FILTERS[\"role\"]`.\n- [23785](https://github.com/apache/superset/pull/23785) Deprecated the following feature flags: `CLIENT_CACHE`, `DASHBOARD_CACHE`, `DASHBOARD_FILTERS_EXPERIMENTAL`, `DASHBOARD_NATIVE_FILTERS`, `DASHBOARD_NATIVE_FILTERS_SET`, `DISABLE_DATASET_SOURCE_EDIT`, `ENABLE_EXPLORE_JSON_CSRF_PROTECTION`, `REMOVE_SLICE_LEVEL_LABEL_COLORS`. It also removed `DASHBOARD_EDIT_CHART_IN_NEW_TAB` as the feature is supported without the need for a feature flag.\n- [22801](https://github.com/apache/superset/pull/22801): The Thumbnails feature has been changed to execute as the currently logged in user by default, falling back to the selenium user for anonymous users. To continue always using the selenium user, please add the following to your `superset_config.py`: `THUMBNAILS_EXECUTE_AS = [\"selenium\"]`\n- [22799](https://github.com/apache/superset/pull/22799): Alerts & Reports has been changed to execute as the owner of the alert/report by default, giving priority to the last modifier and then the creator if either is contained within the list of owners, otherwise the first owner will be used. To continue using the selenium user, please add the following to your `superset_config.py`: `ALERT_REPORTS_EXECUTE_AS = [\"selenium\"]`\n- [23651](https://github.com/apache/superset/pull/23651): Removes UX_BETA feature flag.\n- [23663](https://github.com/apache/superset/pull/23663): Removes deprecated feature flags `ALLOW_DASHBOARD_DOMAIN_SHARDING`, `DISPLAY_MARKDOWN_HTML`, and `FORCE_DATABASE_CONNECTIONS_SSL`.\n- [22325](https://github.com/apache/superset/pull/22325): \"RLS_FORM_QUERY_REL_FIELDS\" is replaced by \"RLS_BASE_RELATED_FIELD_FILTERS\" feature flag. Its value format stays same.\n\n## 2.1.1\n\n- [24185](https://github.com/apache/superset/pull/24185): `/api/v1/database/test_connection` and `api/v1/database/validate_parameters` permissions changed from `can_read` to `can_write`. Only Admin user's have access.\n\n### Other\n\n- [23888](https://github.com/apache/superset/pull/23888): Database Migration for json serialization instead of pickle should upgrade/downgrade correctly when bumping to/from this patch version\n\n## 2.1.0\n\n- [22809](https://github.com/apache/superset/pull/22809): Migrated endpoint `/superset/sql_json` and `/superset/results/` to `/api/v1/sqllab/execute/` and `/api/v1/sqllab/results/` respectively. Corresponding permissions are `can sql_json on Superset` to `can execute on SQLLab`, `can results on Superset` to `can results on SQLLab`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22931](https://github.com/apache/superset/pull/22931): Migrated endpoint `/superset/get_or_create_table/` to `/api/v1/dataset/get_or_create/`. Corresponding permissions are `can get or create table on Superset` to `can get or create dataset on Dataset`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22882](https://github.com/apache/superset/pull/22882): Migrated endpoint `/superset/filter/<datasource_type>/<int:datasource_id>/<column>/` to `/api/v1/datasource/<datasource_type>/<datasource_id>/column/<column_name>/values/`. Corresponding permissions are `can filter on Superset` to `can get column values on Datasource`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22789](https://github.com/apache/superset/pull/22789): Migrated endpoint `/superset/recent_activity/<user_id>/` to `/api/v1/log/recent_activity/<user_id>/`. Corresponding permissions are `can recent activity on Superset` to `can recent activity on Log`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22913](https://github.com/apache/superset/pull/22913): Migrated endpoint `/superset/csv` to `/api/v1/sqllab/export/`. Corresponding permissions are `can csv on Superset` to `can export csv on SQLLab`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22496](https://github.com/apache/superset/pull/22496): Migrated endpoint `/superset/slice_json/<int:layer_id>` to `/api/v1/chart/<int:id>/data/`. Corresponding permissions are `can slice json on Superset` to `can read on Chart`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22624](https://github.com/apache/superset/pull/22624): Migrated endpoint `/superset/stop_query/` to `/api/v1/query/stop`. Corresponding permissions are `can stop query on Superset` to `can read on Query`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22579](https://github.com/apache/superset/pull/22579): Migrated endpoint `/superset/search_queries/` to `/api/v1/query/`. Corresponding permissions are `can search queries on Superset` to `can read on Query`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22501](https://github.com/apache/superset/pull/22501): Migrated endpoint `/superset/tables/<int:db_id>/<schema>/` to `/api/v1/database/<int:id>/tables/`. Corresponding permissions are `can tables on Superset` to `can read on Database`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [22611](https://github.com/apache/superset/pull/22611): Migrated endpoint `/superset/queries/` to `api/v1/query/updated_since`. Corresponding permissions are `can queries on Superset` to `can read on Query`. Make sure you add/replace the necessary permissions on any custom roles you may have.\n- [23186](https://github.com/apache/superset/pull/23186): Superset will refuse to start if a default `SECRET_KEY` is detected on a non Flask debug setting.\n- [22022](https://github.com/apache/superset/pull/22022): HTTP API endpoints `/superset/approve` and `/superset/request_access` have been deprecated and their HTTP methods were changed from GET to POST\n- [20606](https://github.com/apache/superset/pull/20606): When user clicks on chart title or \"Edit chart\" button in Dashboard page, Explore opens in the same tab. Clicking while holding cmd/ctrl opens Explore in a new tab. To bring back the old behaviour (always opening Explore in a new tab), flip feature flag `DASHBOARD_EDIT_CHART_IN_NEW_TAB` to `True`.\n- [20799](https://github.com/apache/superset/pull/20799): Presto and Trino engine will now display tracking URL for running queries in SQL Lab. If for some reason you don't want to show the tracking URL (for example, when your data warehouse hasn't enabled access for to Presto or Trino UI), update `TRACKING_URL_TRANSFORMER` in `config.py` to return `None`.\n- [21002](https://github.com/apache/superset/pull/21002): Support Python 3.10 and bump pandas 1.4 and pyarrow 6.\n- [21163](https://github.com/apache/superset/pull/21163): The time grain will be decoupled from the time filter column and the time grain control will move below the X-Axis control when `GENERIC_CHART_AXES` feature flags set to `True`. The time grain will be applied on the time column in the column-like controls(x axis, dimensions) instead of the time column in the time section.\n- [21284](https://github.com/apache/superset/pull/21284): The non-functional `MAX_TABLE_NAMES` config key has been removed.\n- [21794](https://github.com/apache/superset/pull/21794): Deprecates the undocumented `PRESTO_SPLIT_VIEWS_FROM_TABLES` feature flag. Now for Presto, like other engines, only physical tables are treated as tables.\n- [22798](https://github.com/apache/superset/pull/22798): To make the welcome page more relevant in production environments, the last tab on the welcome page has been changed from to feature all charts/dashboards the user has access to (previously only examples were shown). To keep current behavior unchanged, add the following to your `superset_config.py`: `WELCOME_PAGE_LAST_TAB = \"examples\"`\n- [22328](https://github.com/apache/superset/pull/22328): For deployments that have enabled the \"THUMBNAILS\" feature flag, the function that calculates dashboard digests has been updated to consider additional properties to more accurately identify changes in the dashboard metadata. This change will invalidate all currently cached dashboard thumbnails.\n- [21765](https://github.com/apache/superset/pull/21765): For deployments that have enabled the \"ALERT_REPORTS\" feature flag, Gamma users will no longer have read and write access to Alerts & Reports by default. To give Gamma users the ability to schedule reports from the Dashboard and Explore view like before, create an additional role with \"can read on ReportSchedule\" and \"can write on ReportSchedule\" permissions. To further give Gamma users access to the \"Alerts & Reports\" menu and CRUD view, add \"menu access on Manage\" and \"menu access on Alerts & Report\" permissions to the role.\n\n### Potential Downtime\n\n- [21284](https://github.com/apache/superset/pull/21284): A change which drops the unused `dbs.allow_multi_schema_metadata_fetch` column via a (potentially locking) DDL operation.\n\n### Other\n\n- [23118](https://github.com/apache/superset/pull/23118): Previously the \"database access on <database>\" permission granted access to all datasets on the underlying database, but they didn't show up on the list views. Now all dashboards, charts and datasets that are accessible via this permission will also show up on their respective list views.\n\n## 2.0.1\n\n- [21895](https://github.com/apache/superset/pull/21895): Markdown components had their security increased by adhering to the same sanitization process enforced by GitHub. This means that some HTML elements found in markdowns are not allowed anymore due to the security risks they impose. If you're deploying Superset in a trusted environment and wish to use some of the blocked elements, then you can use the HTML_SANITIZATION_SCHEMA_EXTENSIONS configuration to extend the default sanitization schema. There's also the option to disable HTML sanitization using the HTML_SANITIZATION configuration but we do not recommend this approach because of the security risks. Given the provided configurations, we don't view the improved sanitization as a breaking change but as a security patch.\n\n## Breaking Changes\n\n## Potential Downtime\n\n## Other\n\n## 2.0.0\n\n- [19046](https://github.com/apache/superset/pull/19046): Enables the drag and drop interface in Explore control panel by default. Flips `ENABLE_EXPLORE_DRAG_AND_DROP` and `ENABLE_DND_WITH_CLICK_UX` feature flags to `True`.\n- [18936](https://github.com/apache/superset/pull/18936): Removes legacy SIP-15 interim logic/flags—specifically the `SIP_15_ENABLED`, `SIP_15_GRACE_PERIOD_END`, `SIP_15_DEFAULT_TIME_RANGE_ENDPOINTS`, and `SIP_15_TOAST_MESSAGE` flags. Time range endpoints are no longer configurable and strictly adhere to the `[start, end)` paradigm, i.e., inclusive of the start and exclusive of the end. Additionally this change removes the now obsolete `time_range_endpoints` from the form-data and resulting in the cache being busted.\n- [19570](https://github.com/apache/superset/pull/19570): makes [sqloxide](https://pypi.org/project/sqloxide/) optional so the SIP-68 migration can be run on aarch64. If the migration is taking too long installing sqloxide manually should improve the performance.\n- [20170](https://github.com/apache/superset/pull/20170): Introduced a new endpoint for getting datasets samples.\n\n### Breaking Changes\n\n- [19981](https://github.com/apache/superset/pull/19981): Per [SIP-81](https://github.com/apache/superset/issues/19953) the /explore/form_data api now requires a `datasource_type` in addition to a `datasource_id` for POST and PUT requests\n- [19770](https://github.com/apache/superset/pull/19770): Per [SIP-11](https://github.com/apache/superset/issues/6032) and [SIP-68](https://github.com/apache/superset/issues/14909), the native NoSQL Druid connector is deprecated and has been removed. Druid is still supported through SQLAlchemy via pydruid. The config keys `DRUID_IS_ACTIVE` and `DRUID_METADATA_LINKS_ENABLED` have also been removed.\n- [19274](https://github.com/apache/superset/pull/19274): The `PUBLIC_ROLE_LIKE_GAMMA` config key has been removed, set `PUBLIC_ROLE_LIKE = \"Gamma\"` to have the same functionality.\n- [19273](https://github.com/apache/superset/pull/19273): The `SUPERSET_CELERY_WORKERS` and `SUPERSET_WORKERS` config keys has been removed. Configure Celery directly using `CELERY_CONFIG` on Superset.\n- [19231](https://github.com/apache/superset/pull/19231): The `ENABLE_REACT_CRUD_VIEWS` feature flag has been removed (permanently enabled). Any deployments which had set this flag to false will need to verify that the React views support their use case.\n- [19230](https://github.com/apache/superset/pull/19230): The `ROW_LEVEL_SECURITY` feature flag has been removed (permanently enabled). Any deployments which had set this flag to false will need to verify that the presence of the Row Level Security feature does not interfere with their use case.\n- [19168](https://github.com/apache/superset/pull/19168): Celery upgrade to 5.X resulted in breaking changes to its command line invocation.\n  html#step-1-adjust-your-command-line-invocation) instructions for adjustments. Also consider migrating you Celery config per [here](https://docs.celeryq.dev/en/stable/userguide/configuration.html#conf-old-settings-map).\n- [19142](https://github.com/apache/superset/pull/19142): The `VERSIONED_EXPORT` config key is now `True` by default.\n- [19113](https://github.com/apache/superset/pull/19113): The `ENABLE_JAVASCRIPT_CONTROLS` config key has moved from an app config to a feature flag. Any deployments who overrode this setting will now need to override the feature flag from here onward.\n- [19107](https://github.com/apache/superset/pull/19107): The `SQLLAB_BACKEND_PERSISTENCE` feature flag is now `True` by default, which enables persisting SQL Lab tabs in the backend instead of the browser's `localStorage`.\n- [19083](https://github.com/apache/superset/pull/19083): Updates the mutator function in the config file to take a SQL argument and a list of kwargs. Any `SQL_QUERY_MUTATOR` config function overrides will need to be updated to match the new set of params. It is advised regardless of the dictionary args that you list in your function arguments, to keep `**kwargs` as the last argument to allow for any new kwargs to be passed in.\n- [19049](https://github.com/apache/superset/pull/19049): The `APP_ICON_WIDTH` config key has been removed. Superset should now be able to handle different logo sizes without having to explicitly set an `APP_ICON_WIDTH`. This might affect the size of existing custom logos as the UI will now resize them according to the specified space of maximum 148px and not according to the value of `APP_ICON_WIDTH`.\n- [19017](https://github.com/apache/superset/pull/19017): Removes Python 3.7 support.\n- [18970](https://github.com/apache/superset/pull/18970): The `DISABLE_LEGACY_DATASOURCE_EDITOR` feature flag is now `True` by default which disables the legacy datasource editor from being shown in the client.\n\n## 1.5.3\n\n### Other\n\n- [22022](https://github.com/apache/superset/pull/22022): HTTP API endpoints `/superset/approve` and `/superset/request_access` have been deprecated and their HTTP methods were changed from GET to POST\n- [21895](https://github.com/apache/superset/pull/21895): Markdown components had their security increased by adhering to the same sanitization process enforced by GitHub. This means that some HTML elements found in markdowns are not allowed anymore due to the security risks they impose. If you're deploying Superset in a trusted environment and wish to use some of the blocked elements, then you can use the HTML_SANITIZATION_SCHEMA_EXTENSIONS configuration to extend the default sanitization schema. There's also the option to disable HTML sanitization using the HTML_SANITIZATION configuration but we do not recommend this approach because of the security risks. Given the provided configurations, we don't view the improved sanitization as a breaking change but as a security patch.\n\n## 1.5.2\n\n### Other\n\n- [19570](https://github.com/apache/superset/pull/19570): makes [sqloxide](https://pypi.org/project/sqloxide/) optional so the SIP-68 migration can be run on aarch64. If the migration is taking too long installing sqloxide manually should improve the performance.\n\n## 1.5.0\n\n### Breaking Changes\n\n- [18976](https://github.com/apache/superset/pull/18976): When running the app in debug mode, the app will default to use `SimpleCache` for `FILTER_STATE_CACHE_CONFIG` and `EXPLORE_FORM_DATA_CACHE_CONFIG`. When running in non-debug mode, a cache backend will need to be defined, otherwise the application will fail to start. For installations using Redis or other caching backends, it is recommended to use the same backend for both cache configs.\n- [17881](https://github.com/apache/superset/pull/17881): Previously simple adhoc filter values on string columns were stripped of enclosing single and double quotes. To fully support literal quotes in filters, both single and double quotes will no longer be removed from filter values.\n- [17556](https://github.com/apache/superset/pull/17556): Bumps `mysqlclient` from v1 to v2.\n- [17539](https://github.com/apache/superset/pull/17539): All Superset CLI commands, e.g. `init`, `load_examples`, etc. require setting the `FLASK_APP` environment variable (which is set by default when `.flaskenv` is loaded).\n- [15254](https://github.com/apache/superset/pull/15254): The `QUERY_COST_FORMATTERS_BY_ENGINE`, `SQL_VALIDATORS_BY_ENGINE` and `SCHEDULED_QUERIES` feature flags are now defined as config keys given that feature flags are reserved for boolean only values.\n\n### Potential Downtime\n\n- [16756](https://github.com/apache/incubator-superset/pull/16756): a change which renames the `dbs.allow_csv_upload` column to `dbs.allow_file_upload` via a (potentially locking) DDL operation.\n- [17539](https://github.com/apache/superset/pull/17539): all Superset CLI commands\n  (init, load_examples and etc) require setting the FLASK_APP environment variable\n  (which is set by default when .flaskenv is loaded)\n- [17360](https://github.com/apache/superset/pull/17360): changes the column type from `VARCHAR(32)` to `TEXT` in table `table_columns`, potentially requiring a table lock on MySQL dbs or taking some time to complete on large deployments.\n- [17543](https://github.com/apache/superset/pull/17543): introduces new models from SIP-68. The database migration migrates the old models (`SqlaTable`, `TableColumn`, `SqlMetric`) to the new models (`Column`, `Table`, `Dataset`), and the PR introduces logic to keep the old models in sync with the new ones until they are fully removed. The migration might take considerable time depending on the number of datasets.\n\n### Deprecations\n\n- [18960](https://github.com/apache/superset/pull/18960): Persisting URL params in chart metadata is no longer supported. To set a default value for URL params in Jinja code, use the optional second argument: `url_param(\"my-param\", \"my-default-value\")`.\n\n### Other\n\n- [17589](https://github.com/apache/superset/pull/17589): It is now possible to limit access to users' recent activity data by setting the `ENABLE_BROAD_ACTIVITY_ACCESS` config flag to false, or customizing the `raise_for_user_activity_access` method in the security manager.\n- [17536](https://github.com/apache/superset/pull/17536): introduced a key-value endpoint to store dashboard filter state. This endpoint is backed by Flask-Caching and the default configuration assumes that the values will be stored in the file system. If you are already using another cache backend like Redis or Memcached, you'll probably want to change this setting in `superset_config.py`. The key is `FILTER_STATE_CACHE_CONFIG` and the available settings can be found in Flask-Caching [docs](https://flask-caching.readthedocs.io/en/latest/).\n- [17882](https://github.com/apache/superset/pull/17882): introduced a key-value endpoint to store Explore form data. This endpoint is backed by Flask-Caching and the default configuration assumes that the values will be stored in the file system. If you are already using another cache backend like Redis or Memcached, you'll probably want to change this setting in `superset_config.py`. The key is `EXPLORE_FORM_DATA_CACHE_CONFIG` and the available settings can be found in Flask-Caching [docs](https://flask-caching.readthedocs.io/en/latest/).\n\n## 1.4.1\n\n### Breaking Changes\n\n- [17984](https://github.com/apache/superset/pull/17984): Default Flask SECRET_KEY has changed for security reasons. You should always override with your own secret. Set `PREVIOUS_SECRET_KEY` (ex: PREVIOUS_SECRET_KEY = \"\\2\\1thisismyscretkey\\1\\2\\\\e\\\\y\\\\y\\\\h\") with your previous key and use `superset re-encrypt-secrets` to rotate you current secrets\n\n### Potential Downtime\n\n### Deprecations\n\n### Other\n\n## 1.4.0\n\n### Breaking Changes\n\n- [16660](https://github.com/apache/superset/pull/16660): The `columns` Jinja parameter has been renamed `table_columns` to make the `columns` query object parameter available in the Jinja context.\n- [16711](https://github.com/apache/superset/pull/16711): The `url_param` Jinja function will now by default escape the result. For instance, the value `O'Brien` will now be changed to `O''Brien`. To disable this behavior, call `url_param` with `escape_result` set to `False`: `url_param(\"my_key\", \"my default\", escape_result=False)`.\n\n### Potential Downtime\n\n### Deprecations\n\n### Other\n\n- [16809](https://github.com/apache/superset/pull/16809): When building the superset frontend assets manually, you should now use Node 16 (previously Node 14 was required/recommended). Node 14 will most likely still work for at least some time, but is no longer actively tested for on CI.\n\n## 1.3.0\n\n### Breaking Changes\n\n- [15909](https://github.com/apache/superset/pull/15909): a change which\n  drops a uniqueness criterion (which may or may not have existed) to the tables table. This constraint was obsolete as it is handled by the ORM due to differences in how MySQL, PostgreSQL, etc. handle uniqueness for NULL values.\n\n### Potential Downtime\n\n- [14234](https://github.com/apache/superset/pull/14234): Adds the `limiting_factor` column to the `query` table. Give the migration includes a DDL operation on a heavily trafficked table, potential service downtime may be required.\n- [16454](https://github.com/apache/superset/pull/16454): Adds the `extra` column to the `table_columns` table. Users using MySQL will either need to schedule downtime or use the percona toolkit (or similar) to perform the migration.\n\n## 1.2.0\n\n### Deprecations\n\n- [13440](https://github.com/apache/superset/pull/13440): Dashboard/Charts reports and old Alerts is deprecated. The following config keys are deprecated:\n  - ENABLE_ALERTS\n  - SCHEDULED_EMAIL_DEBUG_MODE\n  - EMAIL_REPORTS_CRON_RESOLUTION\n  - EMAIL_ASYNC_TIME_LIMIT_SEC\n  - EMAIL_REPORT_BCC_ADDRESS\n  - EMAIL_REPORTS_USER\n\n### Other\n\n- [13772](https://github.com/apache/superset/pull/13772): Row level security (RLS) is now enabled by default. To activate the feature, please run `superset init` to expose the RLS menus to Admin users.\n- [13980](https://github.com/apache/superset/pull/13980): Data health checks no longer use the metadata database as an interim cache. Though non-breaking, deployments which implement complex logic should likely memoize the callback function. Refer to documentation in the config.py file for more detail.\n- [14255](https://github.com/apache/superset/pull/14255): The default `CSV_TO_HIVE_UPLOAD_DIRECTORY_FUNC` callable logic has been updated to leverage the specified database and schema to ensure the upload S3 key prefix is unique. Previously tables generated via upload from CSV with the same name but differ schema and/or cluster would use the same S3 key prefix. Note this change does not impact previously imported tables.\n\n## 1.1.0\n\n### Breaking Changes\n\n- This is the first release since we adopted semantic versioning ([SIP-57](https://github.com/apache/superset/issues/12566)). There are no breaking changes in 1.1.0 since this is a minor release.\n\n### Potential Downtime\n\n- [13111](https://github.com/apache/superset/pull/13111) has a database migration that replaces `directed_force` charts with newer `graph_chart` charts based on Apache ECharts.\n- [13216](https://github.com/apache/superset/pull/13216) adds a UUID column to models that are missing it. The original migration script that added the column would incorrectly complete when the column couldn't be added, resulting in a broken schema. The script is optimized for MySQL and Postgres, so depending on the database and the number of objects this migration might take considerable time.\n- [12960](https://github.com/apache/superset/pull/12960) populates the granularity parameter in existing charts. Depending on the number of charts without a `granularity` or `granularity_sqla param` this might take considerable time.\n- [13052](https://github.com/apache/superset/pull/13052) updates the label in existing pie charts, setting `label_type` from `pie_label_type`. Depending on the number of pie charts this might take considerable time.\n- [12680](https://github.com/apache/superset/pull/12680) creates a new table, `dashboard_roles`, for role based dashboard level access.\n- [12552](https://github.com/apache/superset/pull/12552) updates charts that have the time range defined using \"until\" and \"since\". Depending on the number of charts this might take considerable time.\n\n### Deprecations\n\n- [12552](https://github.com/apache/superset/pull/12552) removes the use of unclear time offsets, eg, \"30 days\". An error message is displayed if the user doesn't specify \"ago\" or \"later\", instructing the user of the correct format.\n- [12627](https://github.com/apache/superset/pull/12627) deprecates the legacy alerts module.\n\n### Other\n\n- [shillelagh](https://github.com/betodealmeida/shillelagh/) is now the recommended module to connect Superset to Google Spreadsheets since it's more robust and has extensive test coverage. You should uninstall the `gsheetsdb` module and install the `shillelagh` module in its place. Shillelagh is a drop-in replacement, so no modifications are needed to be done on existing queries, datasets, or charts.\n\n## 1.0.0\n\n### Breaking Changes\n\n- [11509](https://github.com/apache/superset/pull/12491): Dataset metadata updates check user ownership, only owners or an Admin are allowed.\n- Security simplification (SIP-19), the following permission domains were simplified:\n\n  - [12072](https://github.com/apache/superset/pull/12072): `Query` with `can_read`, `can_write`\n  - [12036](https://github.com/apache/superset/pull/12036): `Database` with `can_read`, `can_write`.\n  - [12012](https://github.com/apache/superset/pull/12036): `Dashboard` with `can_read`, `can_write`.\n  - [12061](https://github.com/apache/superset/pull/12061): `Log` with `can_read`, `can_write`.\n  - [12000](https://github.com/apache/superset/pull/12000): `Dataset` with `can_read`, `can_write`.\n  - [12014](https://github.com/apache/superset/pull/12014): `Annotation` with `can_read`, `can_write`.\n  - [11981](https://github.com/apache/superset/pull/11981): `Chart` with `can_read`, `can_write`.\n  - [11853](https://github.com/apache/superset/pull/11853): `ReportSchedule` with `can_read`, `can_write`.\n  - [11856](https://github.com/apache/superset/pull/11856): `CssTemplate` with `can_read`, `can_write`.\n  - [11764](https://github.com/apache/superset/pull/11764): `SavedQuery` with `can_read`, `can_write`.\n    Old permissions will be automatically migrated to these new permissions and applied to all existing security Roles.\n\n- [11499](https://github.com/apache/superset/pull/11499): Breaking change: `STORE_CACHE_KEYS_IN_METADATA_DB` config flag added (default=`False`) to write `CacheKey` records to the metadata DB. `CacheKey` recording was enabled by default previously.\n\n- [11704](https://github.com/apache/superset/pull/11704) Breaking change: Jinja templating for SQL queries has been updated, removing default modules such as `datetime` and `random` and enforcing static template values. To restore or extend functionality, use `JINJA_CONTEXT_ADDONS` and `CUSTOM_TEMPLATE_PROCESSORS` in `superset_config.py`.\n\n- [11509](https://github.com/apache/superset/pull/11509): Config value `TABLE_NAMES_CACHE_CONFIG` has been renamed to `DATA_CACHE_CONFIG`, which will now also hold query results cache from connected datasources (previously held in `CACHE_CONFIG`), in addition to the table names. If you will set `DATA_CACHE_CONFIG` to a new cache backend different than your previous `CACHE_CONFIG`, plan for additional cache warmup to avoid degrading charting performance for the end users.\n\n- [11575](https://github.com/apache/superset/pull/11575) The Row Level Security (RLS) config flag has been moved to a feature flag. To migrate, add `ROW_LEVEL_SECURITY: True` to the `FEATURE_FLAGS` dict in `superset_config.py`.\n\n- [11259](https://github.com/apache/superset/pull/11259): config flag ENABLE_REACT_CRUD_VIEWS has been set to `True` by default, set to `False` if you prefer to the vintage look and feel. However, we may discontinue support on the vintage list view in the future.\n\n- [11244](https://github.com/apache/superset/pull/11244): The `REDUCE_DASHBOARD_BOOTSTRAP_PAYLOAD` feature flag has been removed after being set to True for multiple months.\n\n- [11172](https://github.com/apache/superset/pull/11172): Turning\n  off language selectors by default as i18n is incomplete in most languages\n  and requires more work. You can easily turn on the languages you want\n  to expose in your environment in superset_config.py\n\n- [11172](https://github.com/apache/superset/pull/11172): Breaking change: SQL templating is turned off by default. To turn it on set `ENABLE_TEMPLATE_PROCESSING` to True on `FEATURE_FLAGS`\n\n### Potential Downtime\n\n- [11920](https://github.com/apache/superset/pull/11920): Undoes the DB migration from [11714](https://github.com/apache/superset/pull/11714) to prevent adding new columns to the logs table. Deploying a sha between these two PRs may result in locking your DB.\n\n- [11714](https://github.com/apache/superset/pull/11714): Logs\n  significantly more analytics events (roughly double?), and when\n  using DBEventLogger (default) could result in stressing the metadata\n  database more.\n\n- [11098](https://github.com/apache/superset/pull/11098): includes a database migration that adds a `uuid` column to most models, and updates `Dashboard.position_json` to include chart UUIDs. Depending on number of objects, the migration may take up to 5 minutes, requiring planning for downtime.\n\n### Deprecations\n\n- [11155](https://github.com/apache/superset/pull/11155): The `FAB_UPDATE_PERMS` config parameter is no longer required as the Superset application correctly informs FAB under which context permissions should be updated.\n\n## 0.38.0\n\n- [10887](https://github.com/apache/superset/pull/10887): Breaking change: The custom cache backend changed in order to support the Flask-Caching factory method approach and thus must be registered as a custom type. See [here](https://flask-caching.readthedocs.io/en/latest/#custom-cache-backends) for specifics.\n\n- [10674](https://github.com/apache/superset/pull/10674): Breaking change: PUBLIC_ROLE_LIKE_GAMMA was removed is favour of the new PUBLIC_ROLE_LIKE so it can be set to whatever role you want.\n\n- [10590](https://github.com/apache/superset/pull/10590): Breaking change: this PR will convert iframe chart into dashboard markdown component, and remove all `iframe`, `separator`, and `markup` slices (and support) from Superset. If you have important data in those slices, please backup manually.\n\n- [10562](https://github.com/apache/superset/pull/10562): EMAIL_REPORTS_WEBDRIVER is deprecated use WEBDRIVER_TYPE instead.\n\n- [10567](https://github.com/apache/superset/pull/10567): Default WEBDRIVER_OPTION_ARGS are Chrome-specific. If you're using FF, should be `--headless` only\n\n- [10241](https://github.com/apache/superset/pull/10241): change on Alpha role, users started to have access to \"Annotation Layers\", \"Css Templates\" and \"Import Dashboards\".\n\n- [10324](https://github.com/apache/superset/pull/10324): Facebook Prophet has been introduced as an optional dependency to add support for timeseries forecasting in the chart data API. To enable this feature, install Superset with the optional dependency `prophet` or directly `pip install fbprophet`.\n\n- [10320](https://github.com/apache/superset/pull/10320): References to blacklist/whitelist language have been replaced with more appropriate alternatives. All configs referencing containing `WHITE`/`BLACK` have been replaced with `ALLOW`/`DENY`. Affected config variables that need to be updated: `TIME_GRAIN_BLACKLIST`, `VIZ_TYPE_BLACKLIST`, `DRUID_DATA_SOURCE_BLACKLIST`.\n\n## 0.37.1\n\n- [10794](https://github.com/apache/superset/pull/10794): Breaking change: `uuid` python package is not supported on Jinja2 anymore, only uuid functions are exposed eg: `uuid1`, `uuid3`, `uuid4`, `uuid5`.\n\n## 0.37.0\n\n- [9964](https://github.com/apache/superset/pull/9964): Breaking change on Flask-AppBuilder 3. If you're using OAuth, find out what needs to be changed [here](https://github.com/dpgaspar/Flask-AppBuilder/blob/master/README.rst#change-log).\n\n- [10233](https://github.com/apache/superset/pull/10233): a change which deprecates the `ENABLE_FLASK_COMPRESS` config option in favor of the Flask-Compress `COMPRESS_REGISTER` config option which serves the same purpose.\n\n- [10222](https://github.com/apache/superset/pull/10222): a change which changes how payloads are cached. Previous cached objects cannot be decoded and thus will be reloaded from source.\n\n- [10130](https://github.com/apache/superset/pull/10130): a change which deprecates the `dbs.perm` column in favor of SQLAlchemy [hybrid attributes](https://docs.sqlalchemy.org/en/13/orm/extensions/hybrid.html).\n\n- [10034](https://github.com/apache/superset/pull/10034): a change which deprecates the public security manager `assert_datasource_permission`, `assert_query_context_permission`, `assert_viz_permission`, and `rejected_tables` methods with the `raise_for_access` method which also handles assertion logic for SQL tables.\n\n- [10031](https://github.com/apache/superset/pull/10030): a change which renames the following public security manager methods: `can_access_datasource` to `can_access_table`, `all_datasource_access` to `can_access_all_datasources`, `all_database_access` to `can_access_all_databases`, `database_access` to `can_access_database`, `schema_access` to `can_access_schema`, and\n  `datasource_access` to `can_access_datasource`. Regrettably it is not viable to provide aliases for the deprecated methods as this would result in a name clash. Finally the `can_access_table` (previously `can_access_database`) method signature has changed, i.e., the optional `schema` argument no longer exists.\n\n- [10030](https://github.com/apache/superset/pull/10030): a change which renames the public security manager `schemas_accessible_by_user` method to `get_schemas_accessible_by_user`.\n\n- [9786](https://github.com/apache/superset/pull/9786): with the upgrade of `werkzeug` from version `0.16.0` to `1.0.1`, the `werkzeug.contrib.cache` module has been moved to a standalone package [cachelib](https://pypi.org/project/cachelib/). For example, to import the `RedisCache` class, please use the following import: `from cachelib.redis import RedisCache`.\n\n- [9794](https://github.com/apache/superset/pull/9794): introduces `create view as` functionality in the sqllab. This change will require the `query` table migration and potential service downtime as that table has quite some traffic.\n\n- [9572](https://github.com/apache/superset/pull/9572): a change which by default means that the Jinja `current_user_id`, `current_username`, and `url_param` context calls no longer need to be wrapped via `cache_key_wrapper` in order to be included in the cache key. The `cache_key_wrapper` function should only be required for Jinja add-ons.\n\n## 0.36.0\n\n- [8867](https://github.com/apache/superset/pull/8867): a change which adds the `tmp_schema_name` column to the `query` table which requires locking the table. Given the `query` table is heavily used performance may be degraded during the migration. Scheduled downtime may be advised.\n\n- [9238](https://github.com/apache/superset/pull/9238): the config option `TIME_GRAIN_FUNCTIONS` has been renamed to `TIME_GRAIN_EXPRESSIONS` to better reflect the content of the dictionary.\n\n- [9218](https://github.com/apache/superset/pull/9218): SQLite connections have been disabled by default\n  for analytics databases. You can optionally enable SQLite by setting `PREVENT_UNSAFE_DB_CONNECTIONS` to `False`.\n  It is not recommended to change this setting, as arbitrary SQLite connections can lead to security vulnerabilities.\n\n- [9133](https://github.com/apache/superset/pull/9133): Security list of permissions and list views has been\n  disable by default. You can optionally enable them back again by setting the following config keys:\n  `FAB_ADD_SECURITY_PERMISSION_VIEW`, `FAB_ADD_SECURITY_VIEW_MENU_VIEW`, `FAB_ADD_SECURITY_PERMISSION_VIEWS_VIEW` to `True`.\n\n- [9173](https://github.com/apache/superset/pull/9173): Changes the encoding of the query source from an int to an enum.\n\n- [9120](https://github.com/apache/superset/pull/9120): Changes the default behavior of ad-hoc sharing of\n  queries in SQLLab to one that links to the saved query rather than one that copies the query data into the KVStore\n  model and links to the record there. This is a security-related change that makes SQLLab query\n  sharing respect the existing role-based access controls. Should you wish to retain the existing behavior, set two feature flags:\n  `\"KV_STORE\": True` will re-enable the `/kv/` and `/kv/store/` endpoints, and `\"SHARE_QUERIES_VIA_KV_STORE\": True`\n  will tell the front-end to utilize them for query sharing.\n\n- [9109](https://github.com/apache/superset/pull/9109): Expire `filter_immune_slices` and\n  `filter_immune_filter_fields` to favor dashboard scoped filter metadata `filter_scopes`.\n\n- [9046](https://github.com/apache/superset/pull/9046): Replaces `can_only_access_owned_queries` by\n  `all_query_access` favoring a white list approach. Since a new permission is introduced use `superset init`\n  to create and associate it by default to the `Admin` role. Note that, by default, all non `Admin` users will\n  not be able to access queries they do not own.\n\n- [8901](https://github.com/apache/superset/pull/8901): The datasource's update\n  timestamp has been added to the query object's cache key to ensure updates to\n  datasources are always reflected in associated query results. As a consequence all\n  previously cached results will be invalidated when updating to the next version.\n\n- [8699](https://github.com/apache/superset/pull/8699): A `row_level_security_filters`\n  table has been added, which is many-to-many with `tables` and `ab_roles`. The applicable filters\n  are added to the sqla query, and the RLS ids are added to the query cache keys. If RLS is enabled in config.py (`ENABLE_ROW_LEVEL_SECURITY = True`; by default, it is disabled), they can be\n  accessed through the `Security` menu, or when editing a table.\n\n- [8732](https://github.com/apache/superset/pull/8732): Swagger user interface is now enabled by default.\n  A new permission `show on SwaggerView` is created by `superset init` and given to the `Admin` Role. To disable the UI,\n  set `FAB_API_SWAGGER_UI = False` on config.\n\n- [8721](https://github.com/apache/superset/pull/8721): When using the cache\n  warmup Celery task you should now specify the `SUPERSET_WEBSERVER_PROTOCOL` variable\n  in your configuration (probably either \"http\" or \"https\"). This defaults to \"http\".\n\n- [8512](https://github.com/apache/superset/pull/8512): `DRUID_IS_ACTIVE` now\n  defaults to False. To enable Druid-API-based functionality, override the\n  `DRUID_IS_ACTIVE` configuration variable by setting it to `True` for your deployment.\n\n- [8450](https://github.com/apache/superset/pull/8450): The time range picker\n  now uses UTC for the tooltips and default placeholder timestamps (sans timezone).\n\n- [8418](https://github.com/apache/superset/pull/8418): FLASK_APP / Worker App\n  have changed. FLASK_APP should be updated to `superset.app:create_app()` and Celery Workers\n  should be started with `--app=superset.tasks.celery_app:app`\n\n- [9017](https://github.com/apache/superset/pull/9017): `SIP_15_ENABLED` now\n  defaults to True which ensures that for all new SQL charts the time filter will behave\n  like [start, end). Existing deployments should either disable this feature to keep the\n  status quo or inform their users of this change prior to enabling the flag. The\n  `SIP_15_GRACE_PERIOD_END` option provides a mechanism for specifying how long chart\n  owners have to migrate their charts (the default is indefinite).\n\n## 0.35.0\n\n- [8370](https://github.com/apache/superset/pull/8370): Deprecates\n  the `HTTP_HEADERS` variable in favor of `DEFAULT_HTTP_HEADERS` and\n  `OVERRIDE_HTTP_HEADERS`. To retain the same behavior you should use\n  `OVERRIDE_HTTP_HEADERS` instead of `HTTP_HEADERS`. `HTTP_HEADERS` will still\n  work but may be removed in a future update.\n\n- We're deprecating the concept of \"restricted metric\", this feature\n  was not fully working anyhow.\n- [8117](https://github.com/apache/superset/pull/8117): If you are\n  using `ENABLE_PROXY_FIX = True`, review the newly-introduced variable,\n  `PROXY_FIX_CONFIG`, which changes the proxy behavior in accordance with\n  Werkzeug.\n\n- [8069](https://github.com/apache/superset/pull/8069): introduces\n  [MessagePack](https://github.com/msgpack/msgpack-python) and\n  [PyArrow](https://arrow.apache.org/docs/python/) for async query results\n  backend serialization. To disable set `RESULTS_BACKEND_USE_MSGPACK = False`\n  in your configuration.\n\n- [8371](https://github.com/apache/superset/pull/8371): makes\n  `tables.table_name`, `dbs.database_name`, `datasources.cluster_name`, and `clusters.cluster_name` non-nullable.\n  Depending on the integrity of the data, manual intervention may be required.\n\n## 0.34.0\n\n- [7848](https://github.com/apache/superset/pull/7848): If you are\n  running redis with celery, celery bump to 4.3.0 requires redis-py upgrade to\n  3.2.0 or later.\n\n- [7667](https://github.com/apache/superset/pull/7667): a change to\n  make all Unix timestamp (which by definition are in UTC) comparisons refer\n  to a timestamp in UTC as opposed to local time.\n\n- [7653](https://github.com/apache/superset/pull/7653): a change\n  which deprecates the table_columns.database_expression column. Expressions\n  should be handled by the DB engine spec conversion, Python date format, or\n  custom column expression/type.\n\n- The repo no longer contains translation binaries (`.mo`) files. If you\n  want translations in your build, you now have to run the command\n  `babel-compile --target superset/translations` as part of your builds\n- [5451](https://github.com/apache/superset/pull/5451): a change\n  which adds missing non-nullable fields to the `datasources` table. Depending on\n  the integrity of the data, manual intervention may be required.\n\n- [5452](https://github.com/apache/superset/pull/5452): a change\n  which adds missing non-nullable fields and uniqueness constraints (which may be\n  case insensitive depending on your database configuration) to the `columns`and\n  `table_columns` tables. Depending on the integrity of the data, manual\n  intervention may be required.\n- `fabmanager` command line is deprecated since Flask-AppBuilder 2.0.0, use\n  the new `flask fab <command>` integrated with _Flask cli_.\n- `SUPERSET_UPDATE_PERMS` environment variable was replaced by\n  `FAB_UPDATE_PERMS` config boolean key. To disable automatic\n  creation of permissions set `FAB_UPDATE_PERMS = False` on config.\n- [5453](https://github.com/apache/superset/pull/5453): a change\n  which adds missing non-nullable fields and uniqueness constraints (which may be\n  case insensitive depending on your database configuration) to the metrics\n  and sql_metrics tables. Depending on the integrity of the data, manual\n  intervention may be required.\n- [7616](https://github.com/apache/superset/pull/7616): this bug fix\n  changes time_compare deltas to correctly evaluate to the number of days prior\n  instead of number of days in the future. It will change the data for advanced\n  analytics time_compare so `1 year` from 5/1/2019 will be calculated as 365 days\n  instead of 366 days.\n\n## Superset 0.32.0\n\n- `npm run backend-sync` is deprecated and no longer needed, will fail if called\n- [5445](https://github.com/apache/superset/pull/5445): a change\n  which prevents encoding of empty string from form data in the database.\n  This involves a non-schema changing migration which does potentially impact\n  a large number of records. Scheduled downtime may be advised.\n\n## Superset 0.31.0\n\n- If you use `Hive` or `Presto`, we've moved some dependencies that were\n  in the main package as optional now. To get these packages,\n  run `pip install superset[presto]` and/or `pip install superset[hive]` as\n  required.\n\n- Similarly, if you use Celery's `flower`, `gsheetsdb`, `thrift` or\n  `thrift-sasl`, those dependencies have now been made optional in our\n  package, meaning you may have to install them in your environment post\n  0.31.0\n\n- boto3 / botocore was removed from the dependency list. If you use s3\n  as a place to store your SQL Lab result set or Hive uploads, you may\n  have to rely on an alternate requirements.txt file to install those\n  dependencies.\n- From 0.31.0 onwards, we recommend not using the npm package `yarn` in\n  favor of good old `npm install`. While yarn should still work just fine,\n  you should probably align to guarantee builds similar to the ones we\n  use in testing and across the community in general.\n\n## Superset 0.30.0\n\n- 0.30.0 includes a db_migration that removes allow_run_sync. This may\n  require downtime because during the migration if the db is migrated first,\n  superset will get 500 errors when the code can't find the field (until\n  the deploy finishes).\n\n## Superset 0.29.0\n\n- India was removed from the \"Country Map\" visualization as the geojson\n  file included in the package was very large\n\n- [5933](https://github.com/apache/superset/pull/5933)/[6078](https://github.com/apache/superset/pull/6078): changes which add schema and table metadata cache timeout logic at the database level. If left undefined caching of metadata is disabled.\n\n## Superset 0.28.0\n\n- Support for Python 2 is deprecated, we only support >=3.6 from\n  `0.28.0` onwards\n\n- Superset 0.28 deprecates the previous dashboard layout. While 0.27\n  offered a migration workflow to users and allowed them to validate and\n  publish their migrated dashboards individually, 0.28 forces\n  the migration of all\n  dashboards through an automated db migration script. We\n  do recommend that you take a backup prior to this migration.\n\n- Superset 0.28 deprecates the `median` cluster label aggregator for mapbox visualizations. This particular aggregation is not supported on mapbox visualizations going forward.\n\n- Superset 0.28 upgrades `flask-login` to `>=0.3`, which includes a\n  backwards-incompatible change: `g.user.is_authenticated`,\n  `g.user.is_anonymous`, and `g.user.is_active` are now properties\n  instead of methods.\n\n## Superset 0.27.0\n\n- Superset 0.27 start to use nested layout for dashboard builder, which is not\n  backward-compatible with earlier dashboard grid data. We provide migration script\n  to automatically convert dashboard grid to nested layout data. To be safe, please\n  take a database backup prior to this upgrade. It's the only way people could go\n  back to a previous state.\n\n## Superset 0.26.0\n\n- Superset 0.26.0 deprecates the `superset worker` CLI, which is a simple\n  wrapper around the `celery worker` command, forcing you into crafting\n  your own native `celery worker` command. Your command should look something\n  like `celery worker --app=superset.sql_lab:celery_app --pool=gevent -Ofair`\n\n## Superset 0.25.0\n\nSuperset 0.25.0 contains a backwards incompatible changes.\nIf you run a production system you should schedule downtime for this\nupgrade.\n\nThe PRs below have more information around the breaking changes:\n\n- [9825](https://github.com/apache/superset/pull/9825): Support for Excel sheet upload added. To enable support, install Superset with the optional dependency `excel`\n\n- [4587](https://github.com/apache/superset/pull/4587) : a backward\n  incompatible database migration that requires downtime. Once the\n  db migration succeeds, the web server needs to be restarted with the\n  new version. The previous version will fail\n- [4565](https://github.com/apache/superset/pull/4565) : we've\n  changed the security model a bit where in the past you would have to\n  define your authentication scheme by inheriting from Flask\n  App Builder's\n  `from flask_appbuilder.security.sqla.manager import SecurityManager`,\n  you now have to derive Superset's\n  own derivative `superset.security.SupersetSecurityManager`. This\n  can provide you with more hooks to define your own logic and/or defer\n  permissions to another system as needed. For all implementation, you\n  simply have to import and derive `SupersetSecurityManager` in place\n  of the `SecurityManager`\n- [4835](https://github.com/apache/superset/pull/4835) :\n  our `setup.py` now only pins versions where required, giving you\n  more latitude in using versions of libraries as needed. We do now\n  provide a `requirements.txt` with pinned versions if you want to run\n  the suggested versions that `Superset` builds and runs tests against.\n  Simply `pip install -r requirements.txt` in your build pipeline, likely\n  prior to `pip install superset==0.25.0`\n"
        },
        {
          "name": "docker-compose-image-tag.yml",
          "type": "blob",
          "size": 4.37,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# -----------------------------------------------------------------------\n# We don't support docker compose for production environments.\n# If you choose to use this type of deployment make sure to\n# create you own docker environment file (docker/.env) with your own\n# unique random secure passwords and SECRET_KEY.\n# -----------------------------------------------------------------------\nx-superset-image: &superset-image apachesuperset.docker.scarf.sh/apache/superset:${TAG:-latest-dev}\nx-superset-volumes:\n  &superset-volumes # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container\n  - ./docker:/app/docker\n  - superset_home:/app/superset_home\n\nservices:\n  redis:\n    image: redis:7\n    container_name: superset_cache\n    restart: unless-stopped\n    volumes:\n      - redis:/data\n\n  db:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: postgres:15\n    container_name: superset_db\n    restart: unless-stopped\n    volumes:\n      - db_home:/var/lib/postgresql/data\n      - ./docker/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d\n\n  superset:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: *superset-image\n    container_name: superset_app\n    command: [\"/app/docker/docker-bootstrap.sh\", \"app-gunicorn\"]\n    user: \"root\"\n    restart: unless-stopped\n    ports:\n      - 8088:8088\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    volumes: *superset-volumes\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-init:\n    image: *superset-image\n    container_name: superset_init\n    command: [\"/app/docker/docker-init.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    depends_on:\n      db:\n        condition: service_started\n      redis:\n        condition: service_started\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOAD_EXAMPLES: \"${SUPERSET_LOAD_EXAMPLES:-yes}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker:\n    image: *superset-image\n    container_name: superset_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      test:\n        [\n          \"CMD-SHELL\",\n          \"celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME\",\n        ]\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker-beat:\n    image: *superset-image\n    container_name: superset_worker_beat\n    command: [\"/app/docker/docker-bootstrap.sh\", \"beat\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\nvolumes:\n  superset_home:\n    external: false\n  db_home:\n    external: false\n  redis:\n    external: false\n"
        },
        {
          "name": "docker-compose-non-dev.yml",
          "type": "blob",
          "size": 4.42,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# -----------------------------------------------------------------------\n# We don't support docker compose for production environments.\n# If you choose to use this type of deployment make sure to\n# create you own docker environment file (docker/.env) with your own\n# unique random secure passwords and SECRET_KEY.\n# -----------------------------------------------------------------------\nx-superset-volumes:\n  &superset-volumes # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container\n  - ./docker:/app/docker\n  - superset_home:/app/superset_home\n\nx-common-build: &common-build\n  context: .\n  target: dev\n  cache_from:\n    - apache/superset-cache:3.10-slim-bookworm\n\nservices:\n  redis:\n    image: redis:7\n    container_name: superset_cache\n    restart: unless-stopped\n    volumes:\n      - redis:/data\n\n  db:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: postgres:15\n    container_name: superset_db\n    restart: unless-stopped\n    volumes:\n      - db_home:/var/lib/postgresql/data\n      - ./docker/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d\n\n  superset:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    build:\n      <<: *common-build\n    container_name: superset_app\n    command: [\"/app/docker/docker-bootstrap.sh\", \"app-gunicorn\"]\n    user: \"root\"\n    restart: unless-stopped\n    ports:\n      - 8088:8088\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    volumes: *superset-volumes\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-init:\n    container_name: superset_init\n    build:\n      <<: *common-build\n    command: [\"/app/docker/docker-init.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    depends_on:\n      db:\n        condition: service_started\n      redis:\n        condition: service_started\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOAD_EXAMPLES: \"${SUPERSET_LOAD_EXAMPLES:-yes}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker:\n    build:\n      <<: *common-build\n    container_name: superset_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      test:\n        [\n          \"CMD-SHELL\",\n          \"celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME\",\n        ]\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-worker-beat:\n    build:\n      <<: *common-build\n    container_name: superset_worker_beat\n    command: [\"/app/docker/docker-bootstrap.sh\", \"beat\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: \"root\"\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\nvolumes:\n  superset_home:\n    external: false\n  db_home:\n    external: false\n  redis:\n    external: false\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 8.52,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# -----------------------------------------------------------------------\n# We don't support docker compose for production environments.\n# If you choose to use this type of deployment make sure to\n# create you own docker environment file (docker/.env) with your own\n# unique random secure passwords and SECRET_KEY.\n# -----------------------------------------------------------------------\nx-superset-user: &superset-user root\nx-superset-volumes: &superset-volumes\n  # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container\n  - ./docker:/app/docker\n  - ./superset:/app/superset\n  - ./superset-frontend:/app/superset-frontend\n  - superset_home:/app/superset_home\n  - ./tests:/app/tests\n\nx-common-build: &common-build\n  context: .\n  target: ${SUPERSET_BUILD_TARGET:-dev} # can use `dev` (default) or `lean`\n  cache_from:\n    - apache/superset-cache:3.10-slim-bookworm\n  args:\n    DEV_MODE: \"true\"\n    INCLUDE_CHROMIUM: ${INCLUDE_CHROMIUM:-false}\n    INCLUDE_FIREFOX: ${INCLUDE_FIREFOX:-false}\n    BUILD_TRANSLATIONS: ${BUILD_TRANSLATIONS:-false}\n\nservices:\n  nginx:\n    image: nginx:latest\n    container_name: superset_nginx\n    restart: unless-stopped\n    ports:\n      - \"80:80\"\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    volumes:\n      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n  redis:\n    image: redis:7\n    container_name: superset_cache\n    restart: unless-stopped\n    ports:\n      - \"127.0.0.1:6379:6379\"\n    volumes:\n      - redis:/data\n\n  db:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    image: postgres:15\n    container_name: superset_db\n    restart: unless-stopped\n    ports:\n      - \"127.0.0.1:5432:5432\"\n    volumes:\n      - db_home:/var/lib/postgresql/data\n      - ./docker/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d\n\n  superset:\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    build:\n      <<: *common-build\n    container_name: superset_app\n    command: [\"/app/docker/docker-bootstrap.sh\", \"app\"]\n    restart: unless-stopped\n    ports:\n      - 8088:8088\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    user: *superset-user\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    volumes: *superset-volumes\n    environment:\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-websocket:\n    container_name: superset_websocket\n    build: ./superset-websocket\n    ports:\n      - 8080:8080\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    depends_on:\n      - redis\n    # Mount everything in superset-websocket into container and\n    # then exclude node_modules and dist with bogus volume mount.\n    # This is necessary because host and container need to have\n    # their own, separate versions of these files. .dockerignore\n    # does not seem to work when starting the service through\n    # docker compose.\n    #\n    # For example, node_modules may contain libs with native bindings.\n    # Those bindings need to be compiled for each OS and the container\n    # OS is not necessarily the same as host OS.\n    volumes:\n      - ./superset-websocket:/home/superset-websocket\n      - /home/superset-websocket/node_modules\n      - /home/superset-websocket/dist\n\n      # Mounting a config file that contains a dummy secret required to boot up.\n      # do not use this docker compose in production\n      - ./docker/superset-websocket/config.json:/home/superset-websocket/config.json\n    environment:\n      - PORT=8080\n      - REDIS_HOST=redis\n      - REDIS_PORT=6379\n      - REDIS_SSL=false\n\n  superset-init:\n    build:\n      <<: *common-build\n    container_name: superset_init\n    command: [\"/app/docker/docker-init.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    depends_on:\n      db:\n        condition: service_started\n      redis:\n        condition: service_started\n    user: *superset-user\n    volumes: *superset-volumes\n    environment:\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOAD_EXAMPLES: \"${SUPERSET_LOAD_EXAMPLES:-yes}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n    healthcheck:\n      disable: true\n\n  superset-node:\n    build:\n      context: .\n      target: superset-node\n      args:\n        # This prevents building the frontend bundle since we'll mount local folder\n        # and build it on startup while firing docker-frontend.sh in dev mode, where\n        # it'll mount and watch local files and rebuild as you update them\n        DEV_MODE: \"true\"\n        BUILD_TRANSLATIONS: ${BUILD_TRANSLATIONS:-false}\n    environment:\n      # set this to false if you have perf issues running the npm i; npm run dev in-docker\n      # if you do so, you have to run this manually on the host, which should perform better!\n      BUILD_SUPERSET_FRONTEND_IN_DOCKER: true\n      NPM_RUN_PRUNE: false\n      SCARF_ANALYTICS: \"${SCARF_ANALYTICS:-}\"\n    container_name: superset_node\n    command: [\"/app/docker/docker-frontend.sh\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    volumes: *superset-volumes\n\n  superset-worker:\n    build:\n      <<: *common-build\n    container_name: superset_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    environment:\n      CELERYD_CONCURRENCY: 2\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n    restart: unless-stopped\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: *superset-user\n    volumes: *superset-volumes\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME\"]\n    # Bump memory limit if processing selenium / thumbnails on superset-worker\n    # mem_limit: 2038m\n    # mem_reservation: 128M\n\n  superset-worker-beat:\n    build:\n      <<: *common-build\n    container_name: superset_worker_beat\n    command: [\"/app/docker/docker-bootstrap.sh\", \"beat\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    restart: unless-stopped\n    depends_on:\n      - superset-worker\n    user: *superset-user\n    volumes: *superset-volumes\n    healthcheck:\n      disable: true\n    environment:\n      CYPRESS_CONFIG: \"${CYPRESS_CONFIG:-}\"\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n\n  superset-tests-worker:\n    build:\n      <<: *common-build\n    container_name: superset_tests_worker\n    command: [\"/app/docker/docker-bootstrap.sh\", \"worker\"]\n    env_file:\n      - path: docker/.env # default\n        required: true\n      - path: docker/.env-local # optional override\n        required: false\n    profiles:\n      - optional\n    environment:\n      DATABASE_HOST: localhost\n      DATABASE_DB: test\n      REDIS_CELERY_DB: 2\n      REDIS_RESULTS_DB: 3\n      REDIS_HOST: localhost\n      CELERYD_CONCURRENCY: 8\n      SUPERSET_LOG_LEVEL: \"${SUPERSET_LOG_LEVEL:-info}\"\n    network_mode: host\n    depends_on:\n      superset-init:\n        condition: service_completed_successfully\n    user: *superset-user\n    volumes: *superset-volumes\n    healthcheck:\n      test: [\"CMD-SHELL\", \"celery inspect ping -A superset.tasks.celery_app:app -d celery@$$HOSTNAME\"]\n\nvolumes:\n  superset_home:\n    external: false\n  db_home:\n    external: false\n  redis:\n    external: false\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "dockerize.Dockerfile",
          "type": "blob",
          "size": 1.2,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nFROM alpine:latest\n\nARG DOCKERIZE_VERSION=v0.7.0\n\nRUN apk update --no-cache \\\n    && apk add --no-cache wget openssl \\\n    && case \"$(apk --print-arch)\" in \\\n        x86_64) ARCH=amd64 ;; \\\n        aarch64) ARCH=arm64 ;; \\\n       esac \\\n    && wget -O - https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-${ARCH}-${DOCKERIZE_VERSION}.tar.gz | tar xzf - -C /usr/local/bin \\\n    && apk del wget\n\nUSER 10001\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "helm",
          "type": "tree",
          "content": null
        },
        {
          "name": "lintconf.yaml",
          "type": "blob",
          "size": 1.75,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n---\nrules:\n  braces:\n    min-spaces-inside: 0\n    max-spaces-inside: 1\n    min-spaces-inside-empty: -1\n    max-spaces-inside-empty: -1\n  brackets:\n    min-spaces-inside: -1\n    max-spaces-inside: -1\n    min-spaces-inside-empty: -1\n    max-spaces-inside-empty: -1\n  colons:\n    max-spaces-before: 0\n    max-spaces-after: 1\n  commas:\n    max-spaces-before: 0\n    min-spaces-after: 1\n    max-spaces-after: 1\n  comments:\n    require-starting-space: false\n    min-spaces-from-content: -1\n  document-end: disable\n  document-start: disable # No --- to start a file\n  empty-lines:\n    max: 2\n    max-start: 0\n    max-end: 0\n  hyphens:\n    max-spaces-after: 1\n  indentation:\n    spaces: consistent\n    indent-sequences: whatever # - list indentation will handle both indentation and without\n    check-multi-line-strings: false\n  key-duplicates: enable\n  line-length: disable # Lines can be any length\n  new-line-at-end-of-file: enable\n  new-lines:\n    type: unix\n  trailing-spaces: enable\n  truthy:\n    level: warning\n"
        },
        {
          "name": "null_byte.csv",
          "type": "blob",
          "size": 0.01,
          "content": "A\n\"\u0000\"\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 11.06,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n[build-system]\nrequires = [\"setuptools>=40.9.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"apache-superset\"\ndescription = \"A modern, enterprise-ready business intelligence web application\"\nreadme = \"README.md\"\ndynamic = [\"version\", \"scripts\", \"entry-points\"]\nrequires-python = \">=3.9\"\nlicense = { file=\"LICENSE.txt\" }\nauthors = [\n    { name = \"Apache Software Foundation\", email = \"dev@superset.apache.org\" },\n]\nclassifiers = [\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n]\ndependencies = [\n    \"backoff>=1.8.0\",\n    \"celery>=5.3.6, <6.0.0\",\n    \"click>=8.0.3\",\n    \"click-option-group\",\n    \"colorama\",\n    \"croniter>=0.3.28\",\n    \"cron-descriptor\",\n    \"cryptography>=42.0.4, <44.0.0\",\n    \"deprecation>=2.1.0, <2.2.0\",\n    \"flask>=2.2.5, <3.0.0\",\n    \"flask-appbuilder>=4.5.0, <5.0.0\",\n    \"flask-caching>=2.1.0, <3\",\n    \"flask-compress>=1.13, <2.0\",\n    \"flask-talisman>=1.0.0, <2.0\",\n    \"flask-login>=0.6.0, < 1.0\",\n    \"flask-migrate>=3.1.0, <4.0\",\n    \"flask-session>=0.4.0, <1.0\",\n    \"flask-wtf>=1.1.0, <2.0\",\n    \"geopy\",\n    \"greenlet>=3.0.3, <=3.1.1\",\n    \"gunicorn>=22.0.0; sys_platform != 'win32'\",\n    \"hashids>=1.3.1, <2\",\n    # known issue with holidays 0.26.0 and above related to prophet lib #25017\n    \"holidays>=0.25, <0.26\",\n    \"humanize\",\n    \"importlib_metadata\",\n    \"isodate\",\n    \"jsonpath-ng>=1.6.1, <2\",\n    \"Mako>=1.2.2\",\n    \"markdown>=3.0\",\n    \"msgpack>=1.0.0, <1.1\",\n    \"nh3>=0.2.11, <0.3\",\n    \"numpy==1.23.5\",\n    \"packaging\",\n    # --------------------------\n    # pandas and related (wanting pandas[performance] without numba as it's 100+MB and not needed)\n    \"pandas[excel]>=2.0.3, <2.1\",\n    \"bottleneck\",\n    # --------------------------\n    \"parsedatetime\",\n    \"paramiko>=3.4.0\",\n    \"pgsanity\",\n    \"polyline>=2.0.0, <3.0\",\n    \"pyparsing>=3.0.6, <4\",\n    \"python-dateutil\",\n    \"python-dotenv\",\n    \"python-geohash\",\n    \"pyarrow>=14.0.1, <15\",\n    \"pyyaml>=6.0.0, <7.0.0\",\n    \"PyJWT>=2.4.0, <3.0\",\n    \"redis>=4.6.0, <5.0\",\n    \"selenium>=3.141.0, <4.10.0\",\n    \"shillelagh[gsheetsapi]>=1.2.18, <2.0\",\n    \"shortid\",\n    \"sshtunnel>=0.4.0, <0.5\",\n    \"simplejson>=3.15.0\",\n    \"slack_sdk>=3.19.0, <4\",\n    \"sqlalchemy>=1.4, <2\",\n    \"sqlalchemy-utils>=0.38.3, <0.39\",\n    # known breaking changes in sqlglot 25.25.0\n    #https://github.com/tobymao/sqlglot/blob/main/CHANGELOG.md#v25250---2024-10-14\n    \"sqlglot>=25.24.0,<25.25.0\",\n    \"sqlparse>=0.5.0\",\n    \"tabulate>=0.8.9, <0.9\",\n    \"typing-extensions>=4, <5\",\n    \"waitress; sys_platform == 'win32'\",\n    \"wtforms>=2.3.3, <4\",\n    \"wtforms-json\",\n    \"xlsxwriter>=3.0.7, <3.1\",\n]\n\n[project.optional-dependencies]\n\nathena = [\"pyathena[pandas]>=2, <3\"]\naurora-data-api = [\"preset-sqlalchemy-aurora-data-api>=0.2.8,<0.3\"]\nbigquery = [\n    \"pandas-gbq>=0.19.1\",\n    \"sqlalchemy-bigquery>=1.6.1\",\n    \"google-cloud-bigquery>=3.10.0\",\n]\nclickhouse = [\"clickhouse-connect>=0.5.14, <1.0\"]\ncockroachdb = [\"cockroachdb>=0.3.5, <0.4\"]\ncors = [\"flask-cors>=2.0.0\"]\ncrate = [\"sqlalchemy-cratedb>=0.40.1, <1\"]\ndatabend = [\"databend-sqlalchemy>=0.3.2, <1.0\"]\ndatabricks = [\n    \"databricks-sql-connector>=2.0.2, <3\",\n    \"sqlalchemy-databricks>=0.2.0\",\n]\ndb2 = [\"ibm-db-sa>0.3.8, <=0.4.0\"]\ndenodo = [\"denodo-sqlalchemy~=1.0.6\"]\ndremio = [\"sqlalchemy-dremio>=1.2.1, <4\"]\ndrill = [\"sqlalchemy-drill>=1.1.4, <2\"]\ndruid = [\"pydruid>=0.6.5,<0.7\"]\nduckdb = [\"duckdb-engine>=0.9.5, <0.10\"]\ndynamodb = [\"pydynamodb>=0.4.2\"]\nsolr = [\"sqlalchemy-solr >= 0.2.0\"]\nelasticsearch = [\"elasticsearch-dbapi>=0.2.9, <0.3.0\"]\nexasol = [\"sqlalchemy-exasol >= 2.4.0, <3.0\"]\nexcel = [\"xlrd>=1.2.0, <1.3\"]\nfirebird = [\"sqlalchemy-firebird>=0.7.0, <0.8\"]\nfirebolt = [\"firebolt-sqlalchemy>=1.0.0, <2\"]\ngevent = [\"gevent>=23.9.1\"]\ngsheets = [\"shillelagh[gsheetsapi]>=1.2.18, <2\"]\nhana = [\"hdbcli==2.4.162\", \"sqlalchemy_hana==0.4.0\"]\nhive = [\n    \"pyhive[hive]>=0.6.5;python_version<'3.11'\",\n    \"pyhive[hive_pure_sasl]>=0.7.0\",\n    \"tableschema\",\n    \"thrift>=0.14.1, <1.0.0\",\n    \"thrift_sasl>=0.4.3, < 1.0.0\",\n]\nimpala = [\"impyla>0.16.2, <0.17\"]\nkusto = [\"sqlalchemy-kusto>=2.0.0, <3\"]\nkylin = [\"kylinpy>=2.8.1, <2.9\"]\nmssql = [\"pymssql>=2.2.8, <3\"]\nmysql = [\"mysqlclient>=2.1.0, <3\"]\nocient = [\n    \"sqlalchemy-ocient>=1.0.0\",\n    \"pyocient>=1.0.15, <2\",\n    \"shapely\",\n    \"geojson\",\n]\noracle = [\"cx-Oracle>8.0.0, <8.1\"]\npinot = [\"pinotdb>=5.0.0, <6.0.0\"]\nplaywright = [\"playwright>=1.37.0, <2\"]\npostgres = [\"psycopg2-binary==2.9.6\"]\npresto = [\"pyhive[presto]>=0.6.5\"]\ntrino = [\"trino>=0.328.0\"]\nprophet = [\"prophet>=1.1.5, <2\"]\nredshift = [\"sqlalchemy-redshift>=0.8.1, <0.9\"]\nrockset = [\"rockset-sqlalchemy>=0.0.1, <1\"]\nshillelagh = [\"shillelagh[all]>=1.2.18, <2\"]\nsnowflake = [\"snowflake-sqlalchemy>=1.2.4, <2\"]\nspark = [\n    \"pyhive[hive]>=0.6.5;python_version<'3.11'\",\n    \"pyhive[hive_pure_sasl]>=0.7\",\n    \"tableschema\",\n    \"thrift>=0.14.1, <1\",\n]\nteradata = [\"teradatasql>=16.20.0.23\"]\nthumbnails = [\"Pillow>=10.0.1, <11\"]\nvertica = [\"sqlalchemy-vertica-python>=0.5.9, < 0.6\"]\nnetezza = [\"nzalchemy>=11.0.2\"]\nstarrocks = [\"starrocks>=1.0.0\"]\ndoris = [\"pydoris>=1.0.0, <2.0.0\"]\noceanbase = [\"oceanbase_py>=0.0.1\"]\nydb = [\"ydb-sqlalchemy>=0.1.2\"]\ndevelopment = [\n    \"docker\",\n    \"flask-testing\",\n    \"freezegun\",\n    \"grpcio>=1.55.3\",\n    \"openapi-spec-validator\",\n    \"parameterized\",\n    \"pre-commit\",\n    \"progress>=1.5,<2\",\n    \"psutil\",\n    \"pyfakefs\",\n    \"pyinstrument>=4.0.2,<5\",\n    \"pytest<8.0.0\", # hairy issue with pytest >=8 where current_app proxies are not set in time\n    \"pytest-cov\",\n    \"pytest-mock\",\n    \"python-ldap>=3.4.4\",\n    \"ruff\",\n    \"sqloxide\",\n    \"statsd\",\n]\n\n[project.urls]\nhomepage = \"https://superset.apache.org/\"\ndocumentation = \"https://superset.apache.org/docs/intro\"\n\n\n[tool.isort]\ncombine_as_imports = true\ninclude_trailing_comma = true\nline_length = 88\nknown_first_party = \"superset\"\nknown_third_party = \"alembic, apispec, backoff, celery, click, colorama, cron_descriptor, croniter, cryptography, dateutil, deprecation, flask, flask_appbuilder, flask_babel, flask_caching, flask_compress, flask_jwt_extended, flask_login, flask_migrate, flask_sqlalchemy, flask_talisman, flask_testing, flask_wtf, freezegun, geohash, geopy, holidays, humanize, isodate, jinja2, jwt, markdown, markupsafe, marshmallow, msgpack, nh3, numpy, pandas, parameterized, parsedatetime, pgsanity, polyline, prison, progress, pyarrow, sqlalchemy_bigquery, pyhive, pyparsing, pytest, pytest_mock, pytz, redis, requests, selenium, setuptools, shillelagh, simplejson, slack, sqlalchemy, sqlalchemy_utils, sqlparse, typing_extensions, urllib3, werkzeug, wtforms, wtforms_json, yaml\"\nmulti_line_output = 3\norder_by_type = false\n\n[tool.mypy]\ncheck_untyped_defs = true\ndisallow_any_generics = true\ndisallow_untyped_calls = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\nno_implicit_optional = true\nwarn_unused_ignores = true\n\n[[tool.mypy.overrides]]\nmodule = \"superset.migrations.versions.*\"\nignore_errors = true\n\n[[tool.mypy.overrides]]\nmodule = \"tests.*\"\ncheck_untyped_defs = false\ndisallow_untyped_calls = false\ndisallow_untyped_defs = false\ndisable_error_code = \"annotation-unchecked\"\n\n[tool.ruff]\n# Exclude a variety of commonly ignored directories.\nexclude = [\n    \"**/*.ipynb\",\n    \".bzr\",\n    \".direnv\",\n    \".eggs\",\n    \".git\",\n    \".git-rewrite\",\n    \".hg\",\n    \".ipynb_checkpoints\",\n    \".mypy_cache\",\n    \".nox\",\n    \".pants.d\",\n    \".pyenv\",\n    \".pytest_cache\",\n    \".pytype\",\n    \".ruff_cache\",\n    \".svn\",\n    \".tox\",\n    \".venv\",\n    \".vscode\",\n    \"__pypackages__\",\n    \"_build\",\n    \"buck-out\",\n    \"build\",\n    \"dist\",\n    \"node_modules\",\n    \"site-packages\",\n    \"venv\",\n]\n\n\n# Same as Black.\nline-length = 88\nindent-width = 4\n\n# Assume Python 3.9\ntarget-version = \"py39\"\n\n[tool.ruff.lint]\n# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`)  codes by default.\n# Unlike Flake8, Ruff doesn't enable pycodestyle warnings (`W`) or\n# McCabe complexity (`C901`) by default.\nselect = [\n    \"B904\",\n    \"E4\",\n    \"E7\",\n    \"E9\",\n    \"PT009\",\n    \"TRY201\",\n    \"B\",\n    \"C\",\n    \"E\",\n    \"F\",\n    \"F\",\n    \"I\",\n    \"N\",\n    \"PT\",\n    \"Q\",\n    \"S\",\n    \"T\",\n    \"W\",\n]\nignore = [\n    \"S101\",\n    \"PT006\",\n    \"T201\",\n    \"N999\",\n]\n\nextend-select = [\"I\"]\n\n# Allow fix for all enabled rules (when `--fix`) is provided.\nfixable = [\"ALL\"]\nunfixable = []\n\n# Allow unused variables when underscore-prefixed.\ndummy-variable-rgx = \"^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$\"\n\n[tool.ruff.lint.isort]\ncase-sensitive = false\ncombine-as-imports = true\nforce-sort-within-sections = false\nknown-first-party = []\nknown-third-party = []\nlines-after-imports = -1\norder-by-type = false\nsection-order = [\n    \"future\",\n    \"standard-library\",\n    \"third-party\",\n    \"first-party\",\n    \"local-folder\"\n]\n\n[tool.ruff.format]\n# Like Black, use double quotes for strings.\nquote-style = \"double\"\n\n# Like Black, indent with spaces, rather than tabs.\nindent-style = \"space\"\n\n# Like Black, respect magic trailing commas.\nskip-magic-trailing-comma = false\n\n# Like Black, automatically detect the appropriate line ending.\nline-ending = \"auto\"\n\n# Enable auto-formatting of code examples in docstrings. Markdown,\n# reStructuredText code/literal blocks and doctests are all supported.\n#\n# This is currently disabled by default, but it is planned for this\n# to be opt-out in the future.\ndocstring-code-format = false\n\n# Set the line length limit used when formatting code snippets in\n# docstrings.\n#\n# This only has an effect when the `docstring-code-format` setting is\n# enabled.\ndocstring-code-line-length = \"dynamic\"\n\n[tool.liccheck]\nrequirement_txt_file = \"requirements/base.txt\"\nauthorized_licenses = [\n    \"academic free license (afl)\",\n    \"apache license 2.0\",\n    \"apache software\",\n    \"apache software, bsd\",\n    \"bsd\",\n    \"isc license (iscl)\",\n    \"isc license\",\n    \"mit\",\n    \"mozilla public license 2.0 (mpl 2.0)\",\n    \"osi approved\",\n    \"osi approved\",\n    \"python software foundation\",\n    \"the unlicense (unlicense)\",\n    \"the unlicense\",\n]\n[tool.liccheck.authorized_packages]\n# --------------------------------------------------------------\n# These are ok, checked manually\n# Seems ok, might need legal review\n# https://github.com/urschrei/pypolyline/blob/master/LICENSE.md\npolyline = \"2\"\n# Apache 2.0 https://github.com/hkwi/python-geohash\npython-geohash = \"0\"\n# --------------------------------------------------------------\n\n# TODO REMOVE THESE DEPS FROM CODEBASE\nparamiko = \"3\"  # GPL\npyxlsb = \"1\"  # GPL\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.88,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n[pytest]\ntestpaths =\n    tests\npython_files = *_test.py test_*.py *_tests.py *viz/utils.py\naddopts = -p no:warnings\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.61,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\nimport json\nimport os\nimport subprocess\n\nfrom setuptools import find_packages, setup\n\nBASE_DIR = os.path.abspath(os.path.dirname(__file__))\nPACKAGE_JSON = os.path.join(BASE_DIR, \"superset-frontend\", \"package.json\")\n\n\nwith open(PACKAGE_JSON) as package_file:\n    version_string = json.load(package_file)[\"version\"]\n\n\ndef get_git_sha() -> str:\n    try:\n        output = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"])  # noqa: S603, S607\n        return output.decode().strip()\n    except Exception:  # pylint: disable=broad-except\n        return \"\"\n\n\nGIT_SHA = get_git_sha()\nversion_info = {\"GIT_SHA\": GIT_SHA, \"version\": version_string}\nprint(\"-==-\" * 15)\nprint(\"VERSION: \" + version_string)\nprint(\"GIT SHA: \" + GIT_SHA)\nprint(\"-==-\" * 15)\n\nVERSION_INFO_FILE = os.path.join(BASE_DIR, \"superset\", \"static\", \"version_info.json\")\n\nwith open(VERSION_INFO_FILE, \"w\") as version_file:\n    json.dump(version_info, version_file)\n\n# translating 'no version' from npm to pypi to prevent warning msg\nversion_string = version_string.replace(\"-dev\", \".dev0\")\n\nsetup(\n    version=version_string,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    entry_points={\n        \"console_scripts\": [\"superset=superset.cli.main:superset\"],\n        # the `postgres` and `postgres+psycopg2://` schemes were removed in SQLAlchemy 1.4  # noqa: E501\n        # add an alias here to prevent breaking existing databases\n        \"sqlalchemy.dialects\": [\n            \"postgres.psycopg2 = sqlalchemy.dialects.postgresql:dialect\",\n            \"postgres = sqlalchemy.dialects.postgresql:dialect\",\n            \"superset = superset.extensions.metadb:SupersetAPSWDialect\",\n        ],\n        \"shillelagh.adapter\": [\n            \"superset=superset.extensions.metadb:SupersetShillelaghAdapter\"\n        ],\n    },\n    download_url=\"https://www.apache.org/dist/superset/\" + version_string,\n)\n"
        },
        {
          "name": "superset-embedded-sdk",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset-frontend",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset-websocket",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset",
          "type": "tree",
          "content": null
        },
        {
          "name": "superset_text.yml",
          "type": "blob",
          "size": 1.12,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n\n# To set the images of your preferred database, you may create a mapping here with engine and locations of the relevant images. The image can be hosted locally inside your static/file directory or online (e.g. S3)\n\n# DB_IMAGES:\n#   postgresql: \"path/to/image/postgres.jpg\"\n#   bigquery: \"path/to/s3bucket/bigquery.jpg\"\n#   snowflake: \"path/to/image/snowflake.jpg\"\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "tesseract-ocr/tesseract",
      "stars": 63703,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.47,
          "content": "BasedOnStyle: Google\n\n# Modifications for Tesseract.\n\n# Only merge empty functions.\nAllowShortFunctionsOnASingleLine: Empty\n# Do not allow short if statements.\nAllowShortIfStatementsOnASingleLine: false\nIndentPPDirectives: AfterHash\n\n# Default style for some settings.\n\nAccessModifierOffset: -2\nAllowShortLoopsOnASingleLine: false\n# Enforce always the same pointer alignment.\nDerivePointerAlignment: false\nIncludeBlocks: Preserve\nPointerAlignment: Right\nSpacesBeforeTrailingComments: 1\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.01,
          "content": "* text=auto\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.48,
          "content": "*~\n# Windows\n*.user.*\n*.idea*\n*.log\n*.tlog\n*.cache\n*.obj\n*.sdf\n*.opensdf\n*.lastbuildstate\n*.unsuccessfulbuild\n*.suo\n*.res\n*.ipch\n*.manifest\n\n# Linux\n# ignore local configuration\nconfig.*\nconfig/*\nMakefile\nMakefile.in\n*.m4\n\n# ignore help scripts/files\nconfigure\nlibtool\nstamp-h1\ntesseract.pc\nconfig_auto.h\n/doc/html/*\n/doc/*.1\n/doc/*.5\n/doc/*.html\n/doc/*.xml\n\n# generated version file\n/include/tesseract/version.h\n\n# executables\n/tesseract\n/src/training/ambiguous_words\n/src/training/classifier_tester\n/src/training/cntraining\n/src/training/combine_tessdata\n/src/training/dawg2wordlist\n/src/training/merge_unicharsets\n/src/training/mftraining\n/src/training/set_unicharset_properties\n/src/training/shapeclustering\n/src/training/text2image\n/src/training/unicharset_extractor\n/src/training/wordlist2dawg\n\n*.patch\n\n# files generated by libtool\n/src/training/combine_lang_model\n/src/training/lstmeval\n/src/training/lstmtraining\n\n# ignore compilation files\nbuild/*\n/bin\n/cmake-*\n.deps\n.dirstamp\n/.libs\n*/.libs/*\n*/*/.deps/*\n*/*/.libs/*\n*.lo\n*.la\n*.o\n*.Plo\n*.a\n*.class\n*.jar\n__pycache__\n\n# tessdata\n*.traineddata\ntessdata_*\n\n# build dirs\n/build*\n/*.dll\n/*.lib\n/*.exe\n/*.lnk\n/win*\n.vs*\n.s*\n\n# files generated by \"make check\"\n/tests/.dirstamp\n/unittest/*.trs\n/unittest/tmp/*\n\n# test programs\n/unittest/*_test\n/unittest/primesbitvector\n/unittest/primesmap\n\n# generated files from unlvtests\ntimes.txt\n/unlvtests/results*\n\n# snap packaging specific rules\n/parts/\n/stage/\n/prime/\n/snap/.snapcraft/\n\n/*.snap\n/*_source.tar.bz2\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.19,
          "content": "[submodule \"googletest\"]\n\tpath = unittest/third_party/googletest\n\turl = https://github.com/google/googletest.git\n[submodule \"test\"]\n\tpath = test\n\turl = https://github.com/tesseract-ocr/test.git\n"
        },
        {
          "name": ".mailmap",
          "type": "blob",
          "size": 1.54,
          "content": "Amit Dovev <amitdev2222@gmail.com>\n\nEgor Pugin <egor.pugin@gmail.com>\n\nJeff Breidenbach <breidenbach@gmail.com>\nJeff Breidenbach <breidenbach@gmail.com> <jbreiden@google.com>\n\nJim O'Regan <joregan@gmail.com>\nJim O'Regan <joregan@gmail.com> <joregan@gmail.com@d0cd1f9f-072b-0410-8dd7-cf729c803f20>\nJim O'Regan <joregan@gmail.com> <joregan@d0cd1f9f-072b-0410-8dd7-cf729c803f20>\n\nRay Smith <rays@google.com>\nRay Smith <rays@google.com> <theraysmith@gmail.com>\nRay Smith <rays@google.com> <rays@rays.lon.corp.google.com>\nRay Smith <rays@google.com> <rays@rays-glaptop.roam.corp.google.com>\nRay Smith <rays@google.com> <theraysmith@gmail.com@d0cd1f9f-072b-0410-8dd7-cf729c803f20>\nRay Smith <rays@google.com> <theraysmith@d0cd1f9f-072b-0410-8dd7-cf729c803f20>\n\nShree Devi Kumar <5095331+Shreeshrii@users.noreply.github.com>\nShree Devi Kumar <5095331+Shreeshrii@users.noreply.github.com> <5095331+Shreeshrii@users.noreply.github.com5095331+Shreeshrii@users.noreply.github.com>\n\nStefan Weil <sw@weilnetz.de>\nStefan Weil <sw@weilnetz.de> <sw@weil.de>\nStefan Weil <sw@weilnetz.de> <stefan@v2201612906741603.powersrv.de>\nStefan Weil <sw@weilnetz.de> <stefan.weil@bib.uni-mannheim.de>\nStefan Weil <sw@weilnetz.de> <stweil@ub-backup.bib.uni-mannheim.de>\nStefan Weil <sw@weilnetz.de> <stweil@ub-blade-02.bib.uni-mannheim.de>\n\nZdenko Podobný <zdenop@gmail.com>\nZdenko Podobný <zdenop@gmail.com> <zdenko.podobny@nbazp1.SPS>\nZdenko Podobný <zdenop@gmail.com> <zdenop@gmail.com@d0cd1f9f-072b-0410-8dd7-cf729c803f20>\nZdenko Podobný <zdenop@gmail.com> <zdenop@d0cd1f9f-072b-0410-8dd7-cf729c803f20>\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.77,
          "content": "Ray Smith (lead developer) <theraysmith@gmail.com>\nAhmad Abdulkader\nRika Antonova\nNicholas Beato\nJeff Breidenbach\nSamuel Charron\nPhil Cheatle\nSimon Crouch\nDavid Eger\nSheelagh Huddleston\nDan Johnson\nRajesh Katikam\nThomas Kielbus\nDar-Shyang Lee\nZongyi (Joe) Liu\nRobert Moss\nChris Newton\nMichael Reimer\nMarius Renn\nRaquel Romano\nChristy Russon\nShobhit Saxena\nMark Seaman\nFaisal Shafait\nHiroshi Takenaka\nRanjith Unnikrishnan\nJoern Wanke\nPing Ping Xiu\nAndrew Ziem\nOscar Zuniga\n\nCommunity Contributors:\nZdenko Podobný (Maintainer)\nJim Regan (Maintainer)\nJames R Barlow\nStefan Brechtken\nThomas Breuel\nAmit Dovev\nMartin Ettl\nShree Devi Kumar\nNoah Metzger\nTom Morris\nTobias Müller\nEgor Pugin\nRobert Sachunsky\nRaf Schietekat\nSundar M. Vaidya\nRobin Watts\nStefan Weil\nNick White\nAlexander Zaitsev\n"
        },
        {
          "name": "CITATIONS.bib",
          "type": "blob",
          "size": 2.78,
          "content": "@inproceedings{TableDetect,\n  author = {Faisal Shafait and Ray Smith},\n  booktitle = {Document Analysis Systems},\n  editor = {David S. Doermann and Venu Govindaraju and Daniel P. Lopresti and Premkumar Natarajan},\n  pages = {65--72},\n  publisher = {ACM},\n  series = {ACM International Conference Proceeding Series},\n  title = {Table detection in heterogeneous documents.},\n  url = {http://dblp.uni-trier.de/db/conf/das/das2010.html#ShafaitS10},\n  year = 2010,\n  isbn = {978-1-60558-773-8},\n  date = {2010-07-07}\n}\n\n@inproceedings{Multilingual,\n  author = {Ray Smith and Daria Antonova and Dar-Shyang Lee},\n  booktitle = {MOCR '09: Proceedings of the International Workshop on Multilingual OCR},\n  editor = {Venu Govindaraju and Premkumar Natarajan and Santanu Chaudhury and Daniel P. Lopresti},\n  pages = {1--8},\n  publisher = {ACM},\n  series = {ACM International Conference Proceeding Series},\n  title = {Adapting the Tesseract Open Source OCR Engine for Multilingual OCR.},\n  url = {https://storage.googleapis.com/pub-tools-public-publication-data/pdf/35248.pdf},\n  year = 2009,\n  isbn = {978-1-60558-698-4},\n  date = {2009-07-25},\n  doi = {http://doi.acm.org/10/1145/1577802.1577804},\n  location = {Barcelona, Spain},\n}\n\n@inproceedings{ScriptDetect,\n  author = {Ranjith Unnikrishnan and Ray Smith},\n  title = {Combined Orientation and Script Detection using the Tesseract OCR Engine},\n  booktitle = {MOCR '09: Proceedings of the International Workshop on Multilingual OCR},\n  editor = {Venu Govindaraju and Premkumar Natarajan and Santanu Chaudhury and Daniel P. Lopresti},\n  url = {https://storage.googleapis.com/pub-tools-public-publication-data/pdf/35506.pdf},\n  year = {2009},\n  isbn = {978-1-60558-698-4},\n  pages = {1--7},\n  location = {Barcelona, Spain},\n  doi = {http://doi.acm.org/10.1145/1577802.1577809},\n  publisher = {ACM},\n  address = {New York, NY, USA},\n}\n\n@inproceedings{PageLayout,\n  author = {Ray Smith},\n  title = {Hybrid Page Layout Analysis via Tab-Stop Detection},\n  booktitle = {ICDAR '09: Proceedings of the 2009 10th International Conference on Document Analysis and Recognition},\n  url = {https://storage.googleapis.com/pub-tools-public-publication-data/pdf/35094.pdf},\n  year = {2009},\n  isbn = {978-0-7695-3725-2},\n  pages = {241--245},\n  doi = {http://dx.doi.org/10.1109/ICDAR.2009.257},\n  publisher = {IEEE Computer Society},\n  address = {Washington, DC, USA},\n}\n\n@inproceedings{TessOverview,\n  author = {Ray Smith},\n  title = {An Overview of the Tesseract OCR Engine},\n  booktitle = {ICDAR '07: Proceedings of the Ninth International Conference on Document Analysis and Recognition},\n  url = {https://storage.googleapis.com/pub-tools-public-publication-data/pdf/33418.pdf},\n  year = {2007},\n  isbn = {0-7695-2822-8},\n  pages = {629--633},\n  publisher = {IEEE Computer Society},\n  address = {Washington, DC, USA},\n}\n\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 32.44,
          "content": "#\n# tesseract\n#\n\n# ##############################################################################\n#\n# cmake settings\n#\n# ##############################################################################\n\ncmake_minimum_required(VERSION 3.10 FATAL_ERROR)\n\n# In-source builds are disabled.\nif(\"${CMAKE_CURRENT_SOURCE_DIR}\" STREQUAL \"${CMAKE_CURRENT_BINARY_DIR}\")\n  message(\n    FATAL_ERROR\n      \"CMake generation is not possible within the source directory!\"\n      \"\\n Remove the CMakeCache.txt file and try again from another folder, \"\n      \"e.g.:\\n \"\n      \"\\n rm CMakeCache.txt\"\n      \"\\n mkdir build\"\n      \"\\n cd build\"\n      \"\\n cmake ..\")\nendif()\n\nset(CMAKE_MODULE_PATH \"${CMAKE_MODULE_PATH};${CMAKE_CURRENT_SOURCE_DIR}/cmake\")\n\nset(EXECUTABLE_OUTPUT_PATH \"${CMAKE_BINARY_DIR}/bin\")\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${EXECUTABLE_OUTPUT_PATH}\")\n\n# Use solution folders.\nset_property(GLOBAL PROPERTY USE_FOLDERS ON)\nset_property(GLOBAL PROPERTY PREDEFINED_TARGETS_FOLDER \"CMake Targets\")\n\nif(NOT ${CMAKE_VERSION} VERSION_LESS \"3.15.0\")\n  if(WIN32)\n    cmake_policy(SET CMP0091 NEW)\n    message(STATUS \"Setting policy CMP0091 to NEW\")\n  endif()\nendif()\n\n# ##############################################################################\n#\n# project settings\n#\n# ##############################################################################\n\nproject(tesseract C CXX)\n\n# Get version with components from VERSION file.\nfile(STRINGS \"VERSION\" VERSION_PLAIN)\nstring(REGEX REPLACE \"^([^.]*)\\\\..*\" \"\\\\1\" VERSION_MAJOR ${VERSION_PLAIN})\nstring(REGEX REPLACE \"^[^.]*\\\\.([^.]*)\\\\..*\" \"\\\\1\" VERSION_MINOR\n                     ${VERSION_PLAIN})\nstring(REGEX REPLACE \"^[^.]*\\\\.[^.]*\\\\.([0-9]*).*\" \"\\\\1\" VERSION_PATCH\n                     ${VERSION_PLAIN})\nif(EXISTS ${CMAKE_CURRENT_SOURCE_DIR}/.git)\n  execute_process(COMMAND git --git-dir ${CMAKE_CURRENT_SOURCE_DIR}/.git\n                          describe --abbrev=4 OUTPUT_VARIABLE GIT_REV)\n  string(REGEX REPLACE \"\\n$\" \"\" PACKAGE_VERSION \"${GIT_REV}\")\nendif()\nif(NOT PACKAGE_VERSION)\n  set(PACKAGE_VERSION ${VERSION_PLAIN})\nendif()\n\n# Provide also same macro names as autoconf (see configure.ac).\nset(GENERIC_MAJOR_VERSION ${VERSION_MAJOR})\nset(GENERIC_MINOR_VERSION ${VERSION_MINOR})\nset(GENERIC_MICRO_VERSION ${VERSION_PATCH})\n\nset(MINIMUM_LEPTONICA_VERSION 1.74)\n\n# ##############################################################################\n#\n# options\n#\n# ##############################################################################\n\nmessage(STATUS \"Configuring tesseract version ${PACKAGE_VERSION}...\")\n\nif(WIN32)\n  option(SW_BUILD \"Build with sw\" ON)\nelse()\n  option(SW_BUILD \"Build with sw\" OFF)\nendif()\noption(OPENMP_BUILD \"Build with openmp support\" OFF) # see issue #1662\noption(GRAPHICS_DISABLED \"Disable disable graphics (ScrollView)\" OFF)\noption(DISABLED_LEGACY_ENGINE \"Disable the legacy OCR engine\" OFF)\noption(ENABLE_LTO \"Enable link-time optimization\" OFF)\noption(FAST_FLOAT \"Enable float for LSTM\" ON)\noption(ENABLE_NATIVE\n       \"Enable optimization for host CPU (could break HW compatibility)\" OFF)\n# see\n# https://stackoverflow.com/questions/52653025/why-is-march-native-used-so-rarely\noption(BUILD_TRAINING_TOOLS \"Build training tools\" ON)\noption(BUILD_TESTS \"Build tests\" OFF)\noption(USE_SYSTEM_ICU \"Use system ICU\" OFF)\noption(DISABLE_TIFF \"Disable build with libtiff (if available)\" OFF)\noption(DISABLE_ARCHIVE \"Disable build with libarchive (if available)\" OFF)\noption(DISABLE_CURL \"Disable build with libcurl (if available)\" OFF)\noption(INSTALL_CONFIGS \"Install tesseract configs\" ON)\n\nif(NOT ${CMAKE_VERSION} VERSION_LESS \"3.15.0\")\n  if(WIN32 AND MSVC)\n    option(WIN32_MT_BUILD \"Build with MT flag for MSVC\" OFF)\n  endif()\nendif()\n\n# ##############################################################################\n#\n# compiler and linker\n#\n# ##############################################################################\n\nif(CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  set(CLANG 1)\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n  message(STATUS \"Setting build type to 'Release' as none was specified.\")\n  set(CMAKE_BUILD_TYPE\n      Release\n      CACHE STRING \"Choose the type of build.\" FORCE)\n  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS \"Debug\" \"Release\")\nendif()\n\ninclude(CheckCXXCompilerFlag)\n\nset(CMAKE_CXX_STANDARD 17)\nif(\"cxx_std_20\" IN_LIST CMAKE_CXX_COMPILE_FEATURES)\n  set(CMAKE_CXX_STANDARD 20)\nendif()\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nif(NOT CMAKE_CXX_COMPILER_ID STREQUAL \"GNU\")\n  # cygwin gnu c++ needs to use -std=gnu++17 instead of -std=c++17\n  set(CMAKE_CXX_EXTENSIONS OFF)\nendif()\n\nif(BUILD_SHARED_LIBS)\n  set(CMAKE_CXX_VISIBILITY_PRESET hidden)\nendif()\n\n# LTO\ncmake_policy(SET CMP0069 NEW)\ninclude(CheckIPOSupported)\ncheck_ipo_supported(RESULT LTO_SUPPORTED OUTPUT error)\nif(LTO_SUPPORTED)\n  message(STATUS \"IPO / LTO supported\")\nelse()\n  message(STATUS \"IPO / LTO not supported: <${error}>\")\nendif()\n\nset(MARCH_NATIVE_OPT OFF)\nif(ENABLE_NATIVE)\n  check_cxx_compiler_flag(\"-march=native\" COMPILER_SUPPORTS_MARCH_NATIVE)\n  if(COMPILER_SUPPORTS_MARCH_NATIVE)\n    set(DOTPRODUCT_FLAGS \"${DOTPRODUCT_FLAGS} -march=native\")\n    if(NOT CLANG AND MSVC)\n      # clang-cl does not know this argument\n      set(DOTPRODUCT_FLAGS \"${DOTPRODUCT_FLAGS} -mtune=native\")\n    endif()\n    set(MARCH_NATIVE_OPT ON)\n  endif(COMPILER_SUPPORTS_MARCH_NATIVE)\nendif(ENABLE_NATIVE)\n\nmessage(STATUS \"CMAKE_SYSTEM_PROCESSOR=<${CMAKE_SYSTEM_PROCESSOR}>\")\n\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"x86|x86_64|AMD64|amd64|i386|i686\")\n\n  set(HAVE_NEON FALSE)\n  if(MSVC)\n    set(HAVE_AVX ON)\n    set(AVX_COMPILE_FLAGS \"/arch:AVX\")\n    add_definitions(\"-DHAVE_AVX\")\n\n    set(HAVE_AVX2 ON)\n    set(AVX2_COMPILE_FLAGS \"/arch:AVX2\")\n    add_definitions(\"-DHAVE_AVX2\")\n\n    set(HAVE_AVX512F ON)\n    set(AVX512F_COMPILE_FLAGS \"/arch:AVX512\")\n    add_definitions(\"-DHAVE_AVX512F\")\n\n    set(HAVE_FMA ON)\n    set(FMA_COMPILE_FLAGS \"-D__FMA__\")\n    add_definitions(\"-DHAVE_FMA\")\n\n    set(HAVE_SSE4_1 ON)\n    set(SSE4_1_COMPILE_FLAGS \"-D__SSE4_1__\")\n    add_definitions(\"-DHAVE_SSE4_1\")\n\n    set(DOTPRODUCT_FLAGS \"${DOTPRODUCT_FLAGS} -openmp:experimental\")\n    add_definitions(\"-DOPENMP_SIMD\")\n\n    # clang with MSVC compatibility\n    if(CLANG)\n      set(CMAKE_CXX_FLAGS\n          \"${CMAKE_CXX_FLAGS} -Wno-microsoft-unqualified-friend\")\n      if(HAVE_FMA)\n        set(FMA_COMPILE_FLAGS \"-mfma ${FMA_COMPILE_FLAGS}\")\n      endif(HAVE_FMA)\n      if(HAVE_SSE4_1)\n        set(SSE4_1_COMPILE_FLAGS \"-msse4.1 ${SSE4_1_COMPILE_FLAGS}\")\n      endif(HAVE_SSE4_1)\n    endif(CLANG)\n  else() # if not MSVC\n    check_cxx_compiler_flag(\"-mavx\" HAVE_AVX)\n    if(HAVE_AVX)\n      set(AVX_COMPILE_FLAGS \"-mavx\")\n      add_definitions(\"-DHAVE_AVX\")\n    endif(HAVE_AVX)\n\n    check_cxx_compiler_flag(\"-mavx2\" HAVE_AVX2)\n    if(HAVE_AVX2)\n      set(AVX2_COMPILE_FLAGS \"-mavx2\")\n      add_definitions(\"-DHAVE_AVX2\")\n    endif()\n\n    check_cxx_compiler_flag(\"-mavx512f\" HAVE_AVX512F)\n    if(HAVE_AVX512F)\n      set(AVX512F_COMPILE_FLAGS \"-mavx512f\")\n      add_definitions(\"-DHAVE_AVX512F\")\n    endif()\n\n    check_cxx_compiler_flag(\"-mfma\" HAVE_FMA)\n    if(HAVE_FMA)\n      set(FMA_COMPILE_FLAGS \"-mfma\")\n      add_definitions(\"-DHAVE_FMA\")\n    endif()\n\n    check_cxx_compiler_flag(\"-msse4.1\" HAVE_SSE4_1)\n    if(HAVE_SSE4_1)\n      set(SSE4_1_COMPILE_FLAGS \"-msse4.1\")\n      add_definitions(\"-DHAVE_SSE4_1\")\n    endif()\n\n    check_cxx_compiler_flag(\"-fopenmp-simd\" OPENMP_SIMD)\n    if(OPENMP_SIMD)\n      set(DOTPRODUCT_FLAGS \"${DOTPRODUCT_FLAGS} -fopenmp-simd\")\n      add_definitions(\"-DOPENMP_SIMD\")\n    endif(OPENMP_SIMD)\n  endif(MSVC)\n\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"arm64|aarch64.*|AARCH64.*\")\n\n  set(HAVE_AVX FALSE)\n  set(HAVE_AVX2 FALSE)\n  set(HAVE_AVX512F FALSE)\n  set(HAVE_FMA FALSE)\n  set(HAVE_SSE4_1 FALSE)\n  set(HAVE_NEON TRUE)\n\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"arm.*\")\n\n  set(HAVE_AVX FALSE)\n  set(HAVE_AVX2 FALSE)\n  set(HAVE_AVX512F FALSE)\n  set(HAVE_FMA FALSE)\n  set(HAVE_SSE4_1 FALSE)\n\n  check_cxx_compiler_flag(\"-mfpu=neon\" HAVE_NEON)\n  if(HAVE_NEON)\n    set(NEON_COMPILE_FLAGS \"-mfpu=neon\")\n  endif(HAVE_NEON)\n\nelse()\n\n  set(HAVE_AVX FALSE)\n  set(HAVE_AVX2 FALSE)\n  set(HAVE_AVX512F FALSE)\n  set(HAVE_FMA FALSE)\n  set(HAVE_NEON FALSE)\n  set(HAVE_SSE4_1 FALSE)\n\nendif(CMAKE_SYSTEM_PROCESSOR MATCHES \"x86|x86_64|AMD64|amd64|i386|i686\")\n\nif(HAVE_NEON)\n  message(STATUS \"LTO build is not supported on arm/RBPi.\")\n  set(ENABLE_LTO FALSE)  # enable LTO cause fatal error on arm/RBPi\nendif()\n\n# Compiler specific environment\nif(CMAKE_COMPILER_IS_GNUCXX OR MINGW)\n  set(CMAKE_CXX_FLAGS_DEBUG\n      \"${CMAKE_CXX_FLAGS_DEBUG} -Wall -DDEBUG -pedantic -Og -Wno-unknown-pragmas\")\nelseif(MSVC)\n  add_definitions(-D_CRT_SECURE_NO_WARNINGS)\n  add_definitions(-D_CRT_NONSTDC_NO_DEPRECATE) # strdup\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /utf-8\")\n  if(NOT CLANG)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /MP\")\n  endif()\n  # Hide some warnings for release target wd4244 'argument': conversion from\n  # 'uint64_t' to 'unsigned int', possible loss of data wd4251 needs to have\n  # dll-interface wd4267 return': conversion from 'size_t' to 'int', possible\n  # loss of data wd4275 non dll-interface class wd4305 ...truncation from\n  # 'double' to 'float'\n  set(CMAKE_CXX_FLAGS_RELEASE\n      \"${CMAKE_CXX_FLAGS_RELEASE} /wd4244 /wd4305 /wd4267 /wd4251 /wd4275 /wd4005\"\n  )\n  set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /wd4068\")\n  # Don't use /Wall because it generates too many warnings.\n  set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} /W0 /bigobj\")\n  # MT flag\n  if(WIN32_MT_BUILD)\n    set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>\")\n    message(STATUS \"Building with static CRT.\")\n  endif()\n  # Workaround: When building on VS 2022 17.10 or newer, but using an older runtime,\n  # mutexes can crash\n  # https://stackoverflow.com/questions/78598141/first-stdmutexlock-crashes-in-application-built-with-latest-visual-studio\n  add_definitions(-D_DISABLE_CONSTEXPR_MUTEX_CONSTRUCTOR)\nendif()\nif(CLANG) # clang all platforms\n  set(CMAKE_CXX_FLAGS_RELEASE\n      \"${CMAKE_CXX_FLAGS_RELEASE} -Wno-unused-command-line-argument\")\n  set(CMAKE_CXX_FLAGS_DEBUG\n      \"${CMAKE_CXX_FLAGS_DEBUG} -Wall -DDEBUG -pedantic -O0\")\nendif()\n\nif(OPENMP_BUILD\n   AND MSVC\n   AND \"${MSVC_VERSION}\" LESS 1929)\n  set(OPENMP_BUILD OFF)\nendif()\nif(OPENMP_BUILD)\n  if(MSVC)  # supported from cmake 3.30\n    set(OpenMP_RUNTIME_MSVC \"llvm\")\n  endif(MSVC)\n  find_package(OpenMP)\n  # https://stackoverflow.com/questions/12399422\n  # how-to-set-linker-flags-for-openmp-in-cmakes-try-compile-function\n  if(NOT OpenMP_FOUND\n     AND CLANG\n     AND WIN32)\n    # workaround because find_package(OpenMP) does not work for clang-cl\n    # https://gitlab.kitware.com/cmake/cmake/issues/19404\n    check_include_file_cxx(omp.h HAVE_OMP_H_INCLUDE)\n    find_library(OpenMP_LIBRARY NAMES omp libomp.lib)\n    message(\">> OpenMP_LIBRARY: ${OpenMP_LIBRARY}\")\n    if(MSVC)\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /openmp\")\n    else()\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fopenmp\")\n    endif()\n    set(OpenMP_FOUND 1)\n    # OpenMP 3.1 is fully supported from Clang 3.8.0\n    add_definitions(-D_OPENMP=201107)\n  endif()\n  if(MSVC)\n    # Note: -openmp:llvm is available for X64 from MSVC 16.9 from MSVC 16.10\n    # Preview 2 there is support also for x86 and arm64\n    # https://devblogs.microsoft.com/cppblog/openmp-updates-and-fixes-for-cpp-in-visual-studio-2019-16-10/\n    if(\"${OpenMP_CXX_FLAGS}\" STREQUAL \"-openmp\")\n      set(OpenMP_CXX_FLAGS \"-openmp:llvm\")\n    endif()\n  endif()\n  if(OpenMP_FOUND)\n    message(\">> OpenMP_FOUND ${OpenMP_FOUND} version: ${OpenMP_CXX_VERSION}\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}\")\n    if(NOT TARGET OpenMP::OpenMP_CXX)\n      add_library(OpenMP::OpenMP_CXX IMPORTED INTERFACE)\n    endif()\n  endif()\nendif()\n\nif(CYGWIN)\n  add_definitions(-D__CYGWIN__)\nelseif(UNIX)\n  if(NOT ANDROID)\n    set(LIB_pthread pthread)\n  endif()\nelseif(WIN32)\n  set(LIB_Ws2_32 Ws2_32)\nendif()\n\nadd_definitions(\"-DCMAKE_BUILD\")\n\n# ##############################################################################\n#\n# packages\n#\n# ##############################################################################\ninclude(CheckFunctions)\n\nif(SW_BUILD)\n  find_package(SW REQUIRED)\n  if(BUILD_SHARED_LIBS)\n    set(SW_BUILD_SHARED_LIBS 1)\n  else()\n    set(SW_BUILD_SHARED_LIBS 0)\n  endif()\n  sw_add_package(org.sw.demo.danbloomberg.leptonica\n                 org.sw.demo.libarchive.libarchive)\n  if(BUILD_TRAINING_TOOLS)\n    sw_add_package(org.sw.demo.gnome.pango.pangocairo\n                   org.sw.demo.unicode.icu.i18n)\n  endif()\n  sw_execute()\nelse()\n  find_package(PkgConfig)\n  # Check for required library. option -DLeptonica_DIR=path => cmake hint where\n  # to find leptonica\n  find_package(Leptonica ${MINIMUM_LEPTONICA_VERSION} CONFIG)\n  if(NOT Leptonica_FOUND AND PKG_CONFIG_EXECUTABLE)\n    pkg_check_modules(Leptonica lept>=${MINIMUM_LEPTONICA_VERSION})\n    link_directories(${Leptonica_LIBRARY_DIRS})\n  endif()\n  if(NOT Leptonica_FOUND)\n    message(FATAL_ERROR \"Cannot find required library Leptonica. Quitting!\")\n  else()\n    message(STATUS \"Found leptonica version: ${Leptonica_VERSION}\")\n  endif(NOT Leptonica_FOUND)\n  include_directories(${Leptonica_INCLUDE_DIRS})\n\n  check_leptonica_tiff_support()\n  if ((NOT LEPT_TIFF_RESULT EQUAL 0) AND LEPT_TIFF_COMPILE_SUCCESS)\n    message(NOTICE \"Leptonica was build without TIFF support! Disabling TIFF support...\")\n    set(DISABLE_TIFF ON)\n  elseif(NOT ${CMAKE_VERSION} VERSION_LESS \"3.25\")\n    message(STATUS \"Leptonica was build with TIFF support.\")\n  endif()\n\n  # Check for optional libraries.\n  if(DISABLE_TIFF)\n    set(HAVE_TIFFIO_H OFF)\n    message(STATUS \"TIFF support disabled.\")\n  else(DISABLE_TIFF)\n    find_package(TIFF) # for tesseract\n    if(NOT TIFF_FOUND AND PKG_CONFIG_EXECUTABLE)\n      # try PKG_CONFIG to find libtiff if cmake failed\n      pkg_check_modules(TIFF libtiff-4)\n    endif()\n    if(TIFF_FOUND)\n      set(HAVE_TIFFIO_H ON)\n      include_directories(${TIFF_INCLUDE_DIRS})\n    endif(TIFF_FOUND)\n  endif(DISABLE_TIFF)\n  if(DISABLE_ARCHIVE)\n    set(HAVE_LIBARCHIVE OFF)\n    message(STATUS \"LibArchive support disabled.\")\n  else(DISABLE_ARCHIVE)\n    find_package(LibArchive)\n    if(NOT LibArchive_FOUND AND PKG_CONFIG_EXECUTABLE)\n      # try PKG_CONFIG to find libarchive if cmake failed\n      pkg_check_modules(LibArchive libarchive)\n    endif()\n    if(LibArchive_FOUND)\n      set(HAVE_LIBARCHIVE ON)\n      include_directories(${LibArchive_INCLUDE_DIRS})\n    endif(LibArchive_FOUND)\n  endif(DISABLE_ARCHIVE)\n  if(DISABLE_CURL)\n    set(HAVE_LIBCURL OFF)\n    message(STATUS \"CURL support disabled.\")\n  else(DISABLE_CURL)\n    find_package(CURL)\n    if(NOT CURL_FOUND AND PKG_CONFIG_EXECUTABLE)\n      # try PKG_CONFIG to find libcurl if cmake failed\n      pkg_check_modules(CURL libcurl)\n    endif()\n    if(CURL_FOUND)\n      set(HAVE_LIBCURL ON)\n      include_directories(${CURL_INCLUDE_DIRS})\n    endif(CURL_FOUND)\n  endif(DISABLE_CURL)\nendif()\n\n# ##############################################################################\n#\n# configure\n#\n# ##############################################################################\n\nif(MSVC)\n  set(DOTPRODUCT_FLAGS \"${DOTPRODUCT_FLAGS} /fp:fast\")\nelse()\n  set(DOTPRODUCT_FLAGS \"${DOTPRODUCT_FLAGS} -O3 -ffast-math\")\nendif()\n\ninclude (GNUInstallDirs)\n\nset(AUTOCONFIG_SRC ${CMAKE_CURRENT_BINARY_DIR}/config_auto.h.in)\nset(AUTOCONFIG ${CMAKE_CURRENT_BINARY_DIR}/config_auto.h)\nadd_definitions(-DHAVE_CONFIG_H)\n\nif(GRAPHICS_DISABLED)\n  message(\"ScrollView debugging disabled.\")\nendif()\nset(CMAKE_REQUIRED_INCLUDES\n    ${CMAKE_REQUIRED_INCLUDES} \"${CMAKE_PREFIX_PATH}/include\"\n    ${CMAKE_INSTALL_INCLUDEDIR})\ninclude(Configure)\n\nconfigure_file(${AUTOCONFIG_SRC} ${AUTOCONFIG} @ONLY)\n\nset(INCLUDE_DIR ${CMAKE_INSTALL_INCLUDEDIR})\nset(LIBRARY_DIRS ${CMAKE_INSTALL_LIBDIR})\n\nconfigure_file(${CMAKE_CURRENT_SOURCE_DIR}/include/tesseract/version.h.in\n               ${CMAKE_CURRENT_BINARY_DIR}/include/tesseract/version.h @ONLY)\n\ninclude(CMakePackageConfigHelpers)\ninclude(GenerateExportHeader)\n\n# show summary of configuration\nif(${CMAKE_BUILD_TYPE} MATCHES Debug)\n  set(COMPILER_FLAGS \"${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_DEBUG}\")\nelseif(${CMAKE_BUILD_TYPE} MATCHES Release)\n  set(COMPILER_FLAGS \"${CMAKE_CXX_FLAGS} ${CMAKE_CXX_FLAGS_RELEASE}\")\n  if(LTO_SUPPORTED AND ENABLE_LTO)\n    set(CMAKE_INTERPROCEDURAL_OPTIMIZATION TRUE)\n  else()\n    set(CMAKE_INTERPROCEDURAL_OPTIMIZATION FALSE)\n  endif() # LTO_SUPPORTED\nendif()\n\nif(CMAKE_SIZEOF_VOID_P EQUAL 8)\n  set(BUILD_ARCH \"64 bits\")\nelseif(CMAKE_SIZEOF_VOID_P EQUAL 4)\n  set(BUILD_ARCH \"32 bits\")\nendif()\n\nmessage(STATUS)\nmessage(STATUS \"General configuration for Tesseract ${PACKAGE_VERSION}\")\nmessage(STATUS \"--------------------------------------------------------\")\nmessage(STATUS \"Build type: ${CMAKE_BUILD_TYPE} ${BUILD_ARCH}\")\nmessage(STATUS \"Compiler: ${CMAKE_CXX_COMPILER_ID}\")\nmessage(STATUS \"Compiler version: ${CMAKE_CXX_COMPILER_VERSION}\")\nmessage(STATUS \"Used standard: C++${CMAKE_CXX_STANDARD}\")\nmessage(STATUS \"CXX compiler options: ${COMPILER_FLAGS}\")\nget_directory_property(DirCompDefs COMPILE_DEFINITIONS)\nmessage(STATUS \"Compile definitions = ${DirCompDefs}\")\nmessage(STATUS \"Linker options: ${CMAKE_EXE_LINKER_FLAGS} \"\n               \"${CMAKE_EXE_LINKER_FLAGS_${CMAKE_BUILD_TYPE_UP}}\")\nmessage(STATUS \"Install directory: ${CMAKE_INSTALL_PREFIX}\")\nmessage(STATUS \"HAVE_AVX: ${HAVE_AVX}\")\nmessage(STATUS \"HAVE_AVX2: ${HAVE_AVX2}\")\nmessage(STATUS \"HAVE_AVX512F: ${HAVE_AVX512F}\")\nmessage(STATUS \"HAVE_FMA: ${HAVE_FMA}\")\nmessage(STATUS \"HAVE_SSE4_1: ${HAVE_SSE4_1}\")\nmessage(STATUS \"MARCH_NATIVE_OPT: ${MARCH_NATIVE_OPT}\")\nmessage(STATUS \"HAVE_NEON: ${HAVE_NEON}\")\nmessage(STATUS \"Link-time optimization: ${CMAKE_INTERPROCEDURAL_OPTIMIZATION}\")\nmessage(STATUS \"--------------------------------------------------------\")\nmessage(STATUS \"Build with sw [SW_BUILD]: ${SW_BUILD}\")\nmessage(STATUS \"Build with openmp support [OPENMP_BUILD]: ${OPENMP_BUILD}\")\nmessage(STATUS \"Build with libarchive support [HAVE_LIBARCHIVE]: \"\n               \"${HAVE_LIBARCHIVE}\")\nmessage(STATUS \"Build with libcurl support [HAVE_LIBCURL]: ${HAVE_LIBCURL}\")\nmessage(STATUS \"Enable float for LSTM [FAST_FLOAT]: ${FAST_FLOAT}\")\nmessage(STATUS \"Enable optimization for host CPU (could break HW compatibility)\"\n               \" [ENABLE_NATIVE]: ${ENABLE_NATIVE}\")\nmessage(STATUS \"Disable disable graphics (ScrollView) [GRAPHICS_DISABLED]: \"\n               \"${GRAPHICS_DISABLED}\")\nmessage(STATUS \"Disable the legacy OCR engine [DISABLED_LEGACY_ENGINE]: \"\n               \"${DISABLED_LEGACY_ENGINE}\")\nmessage(STATUS \"Build training tools [BUILD_TRAINING_TOOLS]: \"\n               \"${BUILD_TRAINING_TOOLS}\")\nmessage(STATUS \"Build tests [BUILD_TESTS]: ${BUILD_TESTS}\")\nmessage(STATUS \"Use system ICU Library [USE_SYSTEM_ICU]: ${USE_SYSTEM_ICU}\")\nmessage(\n  STATUS \"Install tesseract configs [INSTALL_CONFIGS]: ${INSTALL_CONFIGS}\")\nmessage(STATUS \"--------------------------------------------------------\")\nmessage(STATUS)\n\n# ##############################################################################\n#\n# build\n#\n# ##############################################################################\n\ninclude(BuildFunctions)\ninclude(SourceGroups)\n\nadd_definitions(-D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS=1)\n\ninclude_directories(${CMAKE_CURRENT_BINARY_DIR})\ninclude_directories(${CMAKE_CURRENT_BINARY_DIR}/include)\nif(ANDROID_TOOLCHAIN)\n  include_directories(${ANDROID_TOOLCHAIN}/sysroot/usr/include)\n  add_compile_definitions(__ANDROID_API_FUTURE__)\nendif()\n\n# ##############################################################################\n# LIBRARY tesseract\n# ##############################################################################\n\nfile(\n  GLOB\n  TESSERACT_SRC\n  src/ccmain/*.cpp\n  src/ccstruct/*.cpp\n  src/ccutil/*.cpp\n  src/classify/*.cpp\n  src/cutil/*.cpp\n  src/dict/*.cpp\n  src/lstm/*.cpp\n  src/textord/*.cpp\n  src/viewer/*.cpp\n  src/wordrec/*.cpp)\n\nif(DISABLED_LEGACY_ENGINE)\n  # prepend path to list of source files\n  function(prepend_path srcs path)\n    set(tmp, \"\")\n    foreach(src IN LISTS ${srcs})\n      list(APPEND tmp ${path}/${src})\n    endforeach(src ${srcs})\n    set(${srcs}\n        ${tmp}\n        PARENT_SCOPE)\n  endfunction()\n\n  set(TESSERACT_SRC_LEGACY\n      src/ccmain/adaptions.cpp\n      src/ccmain/docqual.cpp\n      src/ccmain/equationdetect.cpp\n      src/ccmain/fixspace.cpp\n      src/ccmain/fixxht.cpp\n      src/ccmain/osdetect.cpp\n      src/ccmain/par_control.cpp\n      src/ccmain/recogtraining.cpp\n      src/ccmain/superscript.cpp\n      src/ccmain/tessbox.cpp\n      src/ccmain/tfacepp.cpp\n      src/ccstruct/fontinfo.cpp\n      src/ccstruct/params_training_featdef.cpp\n      src/ccutil/ambigs.cpp\n      src/ccutil/bitvector.cpp\n      src/ccutil/indexmapbidi.cpp\n      src/classify/adaptive.cpp\n      src/classify/adaptmatch.cpp\n      src/classify/blobclass.cpp\n      src/classify/cluster.cpp\n      src/classify/clusttool.cpp\n      src/classify/cutoffs.cpp\n      src/classify/featdefs.cpp\n      src/classify/float2int.cpp\n      src/classify/fpoint.cpp\n      src/classify/intfeaturespace.cpp\n      src/classify/intfx.cpp\n      src/classify/intmatcher.cpp\n      src/classify/intproto.cpp\n      src/classify/kdtree.cpp\n      src/classify/mf.cpp\n      src/classify/mfoutline.cpp\n      src/classify/mfx.cpp\n      src/classify/normfeat.cpp\n      src/classify/normmatch.cpp\n      src/classify/ocrfeatures.cpp\n      src/classify/outfeat.cpp\n      src/classify/picofeat.cpp\n      src/classify/protos.cpp\n      src/classify/shapeclassifier.cpp\n      src/classify/shapetable.cpp\n      src/classify/tessclassifier.cpp\n      src/classify/trainingsample.cpp\n      src/dict/permdawg.cpp\n      src/dict/hyphen.cpp\n      src/wordrec/associate.cpp\n      src/wordrec/chop.cpp\n      src/wordrec/chopper.cpp\n      src/wordrec/drawfx.cpp\n      src/wordrec/findseam.cpp\n      src/wordrec/gradechop.cpp\n      src/wordrec/language_model.cpp\n      src/wordrec/lm_consistency.cpp\n      src/wordrec/lm_pain_points.cpp\n      src/wordrec/lm_state.cpp\n      src/wordrec/outlines.cpp\n      src/wordrec/params_model.cpp\n      src/wordrec/pieces.cpp\n      src/wordrec/plotedges.cpp\n      src/wordrec/render.cpp\n      src/wordrec/segsearch.cpp\n      src/wordrec/wordclass.cpp)\n  prepend_path(TESSERACT_SRC_LEGACY \"${CMAKE_CURRENT_SOURCE_DIR}\")\n  list(REMOVE_ITEM TESSERACT_SRC ${TESSERACT_SRC_LEGACY})\nendif(DISABLED_LEGACY_ENGINE)\n\nlist(APPEND arch_files src/arch/dotproduct.cpp src/arch/simddetect.cpp\n     src/arch/intsimdmatrix.cpp)\n\nif(DOTPRODUCT_FLAGS)\n  set_source_files_properties(src/arch/dotproduct.cpp\n                              PROPERTIES COMPILE_FLAGS ${DOTPRODUCT_FLAGS})\nendif(DOTPRODUCT_FLAGS)\nif(HAVE_AVX)\n  list(APPEND arch_files_opt src/arch/dotproductavx.cpp)\n  set_source_files_properties(src/arch/dotproductavx.cpp\n                              PROPERTIES COMPILE_FLAGS ${AVX_COMPILE_FLAGS})\nendif(HAVE_AVX)\nif(HAVE_AVX2)\n  list(APPEND arch_files_opt src/arch/intsimdmatrixavx2.cpp\n       src/arch/dotproductavx.cpp)\n  set_source_files_properties(src/arch/intsimdmatrixavx2.cpp\n                              PROPERTIES COMPILE_FLAGS ${AVX2_COMPILE_FLAGS})\nendif(HAVE_AVX2)\nif(HAVE_AVX512F)\n  list(APPEND arch_files_opt src/arch/dotproductavx512.cpp)\n  set_source_files_properties(src/arch/dotproductavx512.cpp\n                              PROPERTIES COMPILE_FLAGS ${AVX512F_COMPILE_FLAGS})\nendif(HAVE_AVX512F)\nif(HAVE_FMA)\n  list(APPEND arch_files_opt src/arch/dotproductfma.cpp)\n  set_source_files_properties(src/arch/dotproductfma.cpp\n                              PROPERTIES COMPILE_FLAGS ${FMA_COMPILE_FLAGS})\nendif(HAVE_FMA)\nif(HAVE_SSE4_1)\n  list(APPEND arch_files_opt src/arch/dotproductsse.cpp\n       src/arch/intsimdmatrixsse.cpp)\n  set_source_files_properties(\n    src/arch/dotproductsse.cpp src/arch/intsimdmatrixsse.cpp\n    PROPERTIES COMPILE_FLAGS ${SSE4_1_COMPILE_FLAGS})\nendif(HAVE_SSE4_1)\nif(HAVE_NEON)\n  list(APPEND arch_files_opt src/arch/dotproductneon.cpp\n       src/arch/intsimdmatrixneon.cpp)\n  if(NEON_COMPILE_FLAGS)\n    set_source_files_properties(\n      src/arch/dotproductneon.cpp src/arch/intsimdmatrixneon.cpp\n      PROPERTIES COMPILE_FLAGS ${NEON_COMPILE_FLAGS})\n  endif()\nendif(HAVE_NEON)\n\nfile(\n  GLOB_RECURSE\n  TESSERACT_HDR\n  include/*\n  src/arch/*.h\n  src/ccmain/*.h\n  src/ccstruct/*.h\n  src/ccutil/*.h\n  src/classify/*.h\n  src/cutil/*.h\n  src/dict/*.h\n  src/lstm/*.h\n  src/textord/*.h\n  src/viewer/*.h\n  src/wordrec/*.h)\n\nset(TESSERACT_SRC\n    ${TESSERACT_SRC}\n    src/api/baseapi.cpp\n    src/api/capi.cpp\n    src/api/renderer.cpp\n    src/api/altorenderer.cpp\n    src/api/pagerenderer.cpp\n    src/api/hocrrenderer.cpp\n    src/api/lstmboxrenderer.cpp\n    src/api/pdfrenderer.cpp\n    src/api/wordstrboxrenderer.cpp)\n\nset(TESSERACT_CONFIGS\n    tessdata/configs/alto\n    tessdata/configs/ambigs.train\n    tessdata/configs/api_config\n    tessdata/configs/bazaar\n    tessdata/configs/bigram\n    tessdata/configs/box.train\n    tessdata/configs/box.train.stderr\n    tessdata/configs/digits\n    tessdata/configs/get.images\n    tessdata/configs/hocr\n    tessdata/configs/inter\n    tessdata/configs/kannada\n    tessdata/configs/linebox\n    tessdata/configs/logfile\n    tessdata/configs/lstm.train\n    tessdata/configs/lstmbox\n    tessdata/configs/lstmdebug\n    tessdata/configs/makebox\n    tessdata/configs/page\n    tessdata/configs/pdf\n    tessdata/configs/quiet\n    tessdata/configs/rebox\n    tessdata/configs/strokewidth\n    tessdata/configs/tsv\n    tessdata/configs/txt\n    tessdata/configs/unlv\n    tessdata/configs/wordstrbox)\n\nset(TESSERACT_TESSCONFIGS\n    tessdata/tessconfigs/batch tessdata/tessconfigs/batch.nochop\n    tessdata/tessconfigs/matdemo tessdata/tessconfigs/msdemo\n    tessdata/tessconfigs/nobatch tessdata/tessconfigs/segdemo)\n\nset(LIBTESSFILES ${TESSERACT_SRC} ${arch_files} ${arch_files_opt}\n                 ${TESSERACT_HDR})\n\nsource_group(TREE ${CMAKE_CURRENT_SOURCE_DIR} FILES ${LIBTESSFILES})\n\nadd_library(libtesseract ${LIBTESSFILES})\ntarget_include_directories(\n  libtesseract BEFORE\n  PRIVATE src\n  PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/arch>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/ccmain>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/ccstruct>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/ccutil>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/classify>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/cutil>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/dict>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/lstm>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/textord>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/viewer>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/wordrec>\n         $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src/training>)\nif(BUILD_SHARED_LIBS)\n  target_compile_definitions(\n    libtesseract\n    PRIVATE -DTESS_EXPORTS\n    INTERFACE -DTESS_IMPORTS)\n  # generate_export_header          (libtesseract EXPORT_MACRO_NAME TESS_API)\nendif()\ntarget_link_libraries(libtesseract PRIVATE ${LIB_Ws2_32} ${LIB_pthread})\nif(OpenMP_CXX_FOUND)\n  target_link_libraries(libtesseract PUBLIC OpenMP::OpenMP_CXX)\nendif()\nif(LibArchive_FOUND)\n  target_link_libraries(libtesseract PUBLIC ${LibArchive_LIBRARIES})\nendif(LibArchive_FOUND)\nif(CURL_FOUND)\n  if(NOT CURL_LIBRARIES)\n    target_link_libraries(libtesseract PUBLIC CURL::libcurl)\n  else()\n    target_link_libraries(libtesseract PUBLIC ${CURL_LIBRARIES})\n  endif()\nendif(CURL_FOUND)\n\nset_target_properties(\n  libtesseract PROPERTIES VERSION\n                          ${VERSION_MAJOR}.${VERSION_MINOR}.${VERSION_PATCH})\nset_target_properties(\n  libtesseract PROPERTIES SOVERSION\n                          ${VERSION_MAJOR}.${VERSION_MINOR})\n\nset_target_properties(\n  libtesseract\n  PROPERTIES\n    OUTPUT_NAME\n    tesseract$<$<BOOL:${WIN32}>:${VERSION_MAJOR}${VERSION_MINOR}$<$<CONFIG:DEBUG>:d>>\n)\n\nif(SW_BUILD)\n  target_link_libraries(libtesseract PUBLIC org.sw.demo.danbloomberg.leptonica\n                                            org.sw.demo.libarchive.libarchive)\n  file(WRITE ${CMAKE_CURRENT_BINARY_DIR}/TesseractTargets.cmake\n       \"include(${CMAKE_CURRENT_BINARY_DIR}/cppan.cmake)\\n\")\n  export(\n    TARGETS libtesseract\n    APPEND\n    FILE ${CMAKE_CURRENT_BINARY_DIR}/TesseractTargets.cmake\n    NAMESPACE Tesseract::)\nelse()\n  target_link_libraries(libtesseract PUBLIC ${Leptonica_LIBRARIES})\n  export(\n    TARGETS libtesseract\n    FILE ${CMAKE_CURRENT_BINARY_DIR}/TesseractTargets.cmake\n    NAMESPACE Tesseract::)\nendif()\n\nif(WIN32\n   AND CLANG\n   AND OPENMP_BUILD)\n  # Workaround for \"libomp.lib is not automatically added on Windows\" see:\n  # http://lists.llvm.org/pipermail/openmp-dev/2015-August/000857.html\n  target_link_libraries(libtesseract PRIVATE ${OpenMP_LIBRARY})\nendif()\n\nif(ANDROID)\n  add_definitions(-DANDROID)\n  find_package(CpuFeaturesNdkCompat REQUIRED)\n  target_include_directories(\n    libtesseract\n    PRIVATE \"${CpuFeaturesNdkCompat_DIR}/../../../include/ndk_compat\")\n  target_link_libraries(libtesseract PRIVATE CpuFeatures::ndk_compat)\nendif()\n\n# ##############################################################################\n# EXECUTABLE tesseract\n# ##############################################################################\n\nadd_executable(tesseract src/tesseract.cpp)\ntarget_link_libraries(tesseract libtesseract)\nif(HAVE_TIFFIO_H AND WIN32)\n  target_link_libraries(tesseract ${TIFF_LIBRARIES})\nendif()\n\nif(OPENMP_BUILD AND UNIX)\n  target_link_libraries(tesseract pthread)\nendif()\n\n# ##############################################################################\n\nif(BUILD_TESTS\n   AND EXISTS\n       ${CMAKE_CURRENT_SOURCE_DIR}/unittest/third_party/googletest/CMakeLists.txt\n)\n  enable_testing()\n  add_subdirectory(unittest/third_party/googletest)\n  add_subdirectory(unittest)\nendif()\n\nif(BUILD_TRAINING_TOOLS)\n  add_subdirectory(src/training)\nendif()\n\nget_target_property(tesseract_NAME libtesseract NAME)\nget_target_property(tesseract_VERSION libtesseract VERSION)\nget_target_property(tesseract_OUTPUT_NAME libtesseract OUTPUT_NAME)\n\nconfigure_file(tesseract.pc.cmake ${CMAKE_CURRENT_BINARY_DIR}/tesseract.pc.in\n               @ONLY)\n# to resolve generator expression in OUTPUT_NAME\nfile(\n  GENERATE\n  OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/tesseract_$<CONFIG>.pc\n  INPUT ${CMAKE_CURRENT_BINARY_DIR}/tesseract.pc.in)\n\nconfigure_package_config_file(\n  cmake/templates/TesseractConfig.cmake.in\n  ${CMAKE_CURRENT_BINARY_DIR}/cmake/tesseract/TesseractConfig.cmake\n  INSTALL_DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/tesseract\n  PATH_VARS INCLUDE_DIR LIBRARY_DIRS)\nwrite_basic_package_version_file(\n  ${CMAKE_CURRENT_BINARY_DIR}/cmake/tesseract/TesseractConfigVersion.cmake\n  VERSION ${PACKAGE_VERSION}\n  COMPATIBILITY SameMajorVersion)\n\ninstall(\n  FILES ${CMAKE_CURRENT_BINARY_DIR}/tesseract_$<CONFIG>.pc\n  DESTINATION ${CMAKE_INSTALL_LIBDIR}/pkgconfig\n  RENAME tesseract.pc)\ninstall(TARGETS tesseract DESTINATION bin)\nif (MSVC)\n  install(FILES $<TARGET_PDB_FILE:${PROJECT_NAME}> DESTINATION bin OPTIONAL)\nendif()\ninstall(\n  TARGETS libtesseract\n  EXPORT TesseractTargets\n  RUNTIME DESTINATION bin\n  RUNTIME DESTINATION bin\n  LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n  ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR})\nif (MSVC AND BUILD_SHARED_LIBS)\n  install(FILES $<TARGET_PDB_FILE:libtesseract> DESTINATION bin OPTIONAL)\nendif()\ninstall(\n  EXPORT TesseractTargets\n  NAMESPACE Tesseract::\n  DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/tesseract)\ninstall(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/cmake\n        DESTINATION ${CMAKE_INSTALL_LIBDIR})\n\ninstall(\n  FILES include/tesseract/baseapi.h\n        include/tesseract/capi.h\n        include/tesseract/renderer.h\n        ${CMAKE_CURRENT_BINARY_DIR}/include/tesseract/version.h\n        include/tesseract/ltrresultiterator.h\n        include/tesseract/pageiterator.h\n        include/tesseract/resultiterator.h\n        include/tesseract/osdetect.h\n        include/tesseract/publictypes.h\n        include/tesseract/ocrclass.h\n        include/tesseract/export.h\n        include/tesseract/unichar.h\n        # ${CMAKE_CURRENT_BINARY_DIR}/src/endianness.h\n  DESTINATION include/tesseract)\n\nif(INSTALL_CONFIGS)\n  install(FILES ${TESSERACT_CONFIGS}\n          DESTINATION ${CMAKE_INSTALL_DATAROOTDIR}/tessdata/configs)\n  install(FILES ${TESSERACT_TESSCONFIGS}\n          DESTINATION ${CMAKE_INSTALL_DATAROOTDIR}/tessdata/tessconfigs)\nendif()\n\n# ##############################################################################\n# uninstall target\n# ##############################################################################\nif(NOT TARGET uninstall)\n  configure_file(\n    \"${CMAKE_CURRENT_SOURCE_DIR}/cmake/templates/cmake_uninstall.cmake.in\"\n    \"${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake\" IMMEDIATE @ONLY)\n\n  add_custom_target(\n    uninstall\n    COMMENT \"Uninstall installed files\"\n    COMMAND ${CMAKE_COMMAND} -P\n            ${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake)\nendif()\n\n# ##############################################################################\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.97,
          "content": "# Contributing\n\n**Please follow these rules and advice**.\n\n## Creating an Issue or Using the Forum\n\nIf you think you found a bug in Tesseract, please create an issue.\n\nUse the [user forum](https://groups.google.com/g/tesseract-ocr) instead of creating an issue if ...\n\n* You have problems using Tesseract and need some help.\n* You have problems installing the software.\n* You are not satisfied with the accuracy of the OCR, and want to ask how you can improve it. Note: You should first read the [ImproveQuality](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html) documentation.\n* You are trying to train Tesseract and you have a problem and/or want to ask a question about the training process. Note: You should first read the **official** guides [[1]](https://tesseract-ocr.github.io/tessdoc/) or [[2]](https://tesseract-ocr.github.io/tessdoc/tess5/TrainingTesseract-5.html) found in the project documentation.\n* You have a general question.\n\nAn issue should only be reported if the platform you are using is one of these:\n\n* Linux (but not a version that is more than 4 years old)\n* Windows (Windows 7 or newer version)\n* macOS (last 3 releases)\n\nFor older versions or other operating systems, use the Tesseract forum.\n\nWhen creating an issue, please report your operating system, including its specific version: \"Ubuntu 16.04\", \"Windows 10\", \"Mac OS X 10.11\" etc.\n\nSearch through open and closed issues to see if similar issue has been reported already (and sometimes also has been solved).\n\nSimilarly, before you post your question in the forum, search through past threads to see if similar question has been asked already.\n\nRead the [documentation](https://tesseract-ocr.github.io/tessdoc/) before you report your issue or ask a question in the forum.\n\nOnly report an issue in the latest official release. Optionally, try to check if the issue is not already solved in the latest snapshot in the git repository.\n\nMake sure you are able to replicate the problem with Tesseract command line program. For external programs that use Tesseract (including wrappers and your own program, if you are developer), report the issue to the developers of that software if it's possible. You can also try to find help in the Tesseract forum.\n\nEach version of Tesseract has its own language data you need to obtain. You **must** obtain and install trained data for English (eng) and osd. Verify that Tesseract knows about these two files (and other trained data you installed) with this command:\n`tesseract --list-langs`.\n\nPost example files to demonstrate the problem.\nBUT don't post files with private info (about yourself or others).\n\nWhen attaching a file to the issue report / forum ...\n\n* Do not post a file larger than 20 MB.\n* GitHub supports only few file name extensions like `.png` or `.txt`. If GitHub rejects your files, you can compress them using a program that can produce a zip archive and then load this zip file to GitHub.\n\nDo not attach programs or libraries to your issues/posts.\n\nFor large files or for programs, add a link to a location where they can be downloaded (your site, Git repo, Google Drive, Dropbox etc.)\n\nAttaching a multi-page TIFF image is useful only if you have problem with multi-page functionality, otherwise attach only one or a few single page images.\n\nCopy the error message from the console instead of sending a screenshot of it.\n\nUse the toolbar above the comment edit area to format your comment.\n\nAdd three backticks before and after a code sample or output of a command to format it (The `Insert code` button can help you doing it).\n\nIf your comment includes a code sample or output of a command that exceeds ~25 lines, post it as attached text file (`filename.txt`).\n\nUse `Preview` before you send your issue. Read it again before sending.\n\nNote that most of the people that respond to issues and answer questions are either other 'regular' users or **volunteers** developers. Please be nice to them :-)\n\nThe [tesseract developers](https://groups.google.com/g/tesseract-dev) forum should be used to discuss Tesseract development: bug fixes, enhancements, add-ons for Tesseract.\n\nSometimes you will not get a respond to your issue or question. We apologize in advance! Please don't take it personally. There can be many reasons for this, including: time limits, no one knows the answer (at least not the ones that are available at that time) or just that\nyour question has been asked (and has been answered) many times before...\n\n## For Developers: Creating a Pull Request\n\nYou should always make sure your changes build and run successfully.\n\nFor that, your clone needs to have all submodules (`googletest`, `test`) included. To do so, either specify `--recurse-submodules` during the initial clone, or run `git submodule update --init --recursive NAME` for each `NAME` later. If `configure` already created those directories (blocking the clone), remove them first (or `make distclean`), then clone and reconfigure.\n\nHave a look at [the README](./README.md) and [testing README](https://github.com/tesseract-ocr/test/blob/main/README.md) and the [documentation](https://tesseract-ocr.github.io/tessdoc/Compiling-%E2%80%93-GitInstallation.html#unit-test-builds) on installation.\n\nIn short, after running `configure` from the build directory of your choice, to build the library and CLI, run `make`. To test it, run `make check`. To build the training tools, run `make training`.\n\nAs soon as your changes are building and tests are succeeding, you can publish them. If you have not already, please [fork](https://docs.github.com/en/get-started/quickstart/contributing-to-projects) tesseract (somewhere) on GitHub, and push your changes to that fork (in a new branch). Then [submit as PR](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork).\n\nPlease also keep track of reports from CI (automated build status) and Coverity/CodeQL (quality scan). When the indicators show deterioration after your changes, further action may be required to improve them.\n"
        },
        {
          "name": "ChangeLog",
          "type": "blob",
          "size": 22.5,
          "content": "2024-11-10 - V5.5.0\n* Set hOCR capabilities ocrp_dir and ocrp_lang unconditionally.\n* Calculate row bounding box in single-word mode per (issue #4304).\n* Reduce clock syscalls (#4303).\n* Several small performance and other code fixes.\n* Modernized code.\n* Print time for tessedit_timing_debug in milliseconds.\n* Print time for ErrorCounter::ComputeErrorRate in milliseconds.\n* cmake: Correctly set the soversion based on SemVer properties.\n* Do not export PDBs for static libraries (issue #4279).\n* Several other small fixes and improvements for builds and CI.\n* Modernize code for renderers and remove filename conversion for Windows (#4330).\n* Add build rule for Windows installer.\n* Support symbolic values for --oem and --psm options.\n* Remove Tensorflow support.\n* Add RISC-V V support (#4346).\n* Remove broken GitHub action msys2-4.1.1.\n\n2024-06-11 - V5.4.1\n* Avoid FP overflow in NormEvidenceOf (fixes issue #4257) (#4259)\n* Small build fixes and code improvements (#4262, #4263, #4266, #4267)\n\n2024-06-06 - V5.4.0\n* Small build fixes and code improvements\n  (#4241, #4243, #4244, #4245, #4246, #4248, #4249, #4250, #4253)\n\n2024-05-19 - V5.4.0-rc2\n* Fix setup of datadir on installations with Conda (issue #4230) (#4240)\n* Fix FP exception in Wordrec::angle_change (issue #4242) (#4243)\n\n2024-05-12 - V5.4.0-rc1\n* Build fixes, code refactoring and other smaller changes.\n* Fix grey result of indexed PNG in pdfrenderer.\n* Rename frk -> deu_latf (ISO 639-3, ISO 15924).\n* Remove broken Dockerfile.\n* Fixes for several issues reported by Coverity Scan.\n* Remove unsupported OpenCL code and related API functions (#4220).\n* Facilitate vectorization for generic build (#4223).\n* Add PAGE XML renderer / export (#4214).\n* Support training without lstmf files.\n* Improve CCUtil::main_setup (fixes issue #4230 related to Coda).\n* Allow for text angle/gradient to be retrieved (#4070).\n\n2024-01-18 - V5.3.4\n* Fixes for scrollview\n* Fixes for autoconf, clang and sw builds\n* Improve OCR for an image URL\n  * Fail on curl download errors\n  * New parameter curl_cookiefile\n  * Set User-Agent: header field in HTTP request for curl downloads\n* Output directory list from \"combine_tessdata -d\" to stdout\n* Other small improvements for code and documentation.\n\n2023-10-05 - V5.3.3\n* Small code fixes and improvements to fix Coverity Scan issues.\n* Disable -mfpu=neon for aarch64.\n* Fix build without git clone in cloned directory (required for FreeBSD).\n* Other build fixes for autotools, cmake and sw.\n* Fix regression in layout detection which was introduced in release 5.0.0.\n* Fix regression which prevented loading of submodels, introduced in release 5.0.0-rc2.\n* Other small improvements for code and documentation.\n\n2023-07-11 - V5.3.2\n* Updates for snap package building.\n* Support for Sgaw and W Pwo Karen languages in the Myanmar validator (#4065).\n* Improve format of logging from lstmtraining.\n* Use less digits in filenames of checkpoints written by lstmtraining.\n* Replace deprecated sprintf.\n* Remove unused code in function fix_rep_char.\n* Avoid 32 bit overflow in multiplication (fixes 3 CodeQL CI alerts).\n* Avoid conversions from std::string to char* to std::string.\n* Abort with error message if OSD is requested with LSTM-only model.\n* cmake: allow to disable tiff (-DDISABLE_TIFF=ON).\n* cmake: provide info about disabled LibArchive and CURL.\n* cmake: check if leptonica was build with tiff support.\n* Remove old broken GitHub action vcpkg-4.1.1 (fixes issue #4078).\n* Create config.yml.\n* Fix typos.\n\n2023-04-01 - V5.3.1\n * Bug fixes for some special scenarios:\n   * Fix issue #4010.\n   * textord: Catch empty rows in block iterator (fixes #4039).\n   * Fix FP division by zero (issue #3995).\n * Improve documentation and log messages.\n * Build fixes and improvements (mainly for cmake).\n\n2022-12-22 - V5.3.0\n * Minor updates for documentation and cmake builds.\n\n2022-12-13 - V5.3.0-rc1\n * Fix the training tools for the legacy OCR engine (fix issue #3925).\n * PDF renderer: Ignore non-text blocks (fix issue #3957).\n * Remove colormap before thresholding (fix issue #3940).\n * Fix a number of performance issues reported by Coverity Scan.\n * Training tools: Replace call of exit function by return statement in main function.\n * Fix double free in function vigorous_noise_removal (fix issue #3876).\n * Create to_win if needed in Textord::make_spline_rows (fix issue #3875).\n * Bug fixes for ScrollView viewer:\n   * Fix memory issues in ScrollView::MessageReceiver.\n   * Catch potential nullptr in SVNetwork::SVNetwork.\n   * Move svpaint.cpp from src/viewer to src/.\n   * Add rule for svpaint executable in Autotools.\n * Bug fixes and improvements for build tools:\n   * Fix AMD64 detection with autobuild on FreeBSD (fix issue #3964).\n   * Fix tesseract.pc generated from CMake to match Autotools.\n   * Detect availability of AVX512-VNNI.\n   * configure.ac: fix build on aarch64_be.\n * Drop CI for old versions of macOS and Ubuntu.\n\n2022-07-06 - V5.2.0\n  * Improvements and fixes for continuous integration,\n    autoconf and cmake builds.\n  * Set /Os for some 32 bit MS compilers (fixes #3769).\n  * Improve comments and other documentation.\n  * Add initial support for Intel AVX512F.\n  * Fix for very large PDF files on 32 bit hosts (fixes #3805).\n  * Fix NEON detection on FreeBSD.\n  * Fix regression with UZN files (fixes #3837).\n  * Fix calling delete[] for memory allocated by malloc in C API.\n  * Add an API function to init tesseract with traineddata from memory\n    (fixes #3691).\n  * Replace direct access to Leptonica internal data structures by\n    function calls and support latest releases of Leptonica.\n  * Replace std::regex by std::string functions (fixes issue #3830).\n  * Use compiled-in TESSDATA_PREFIX also on Windows (fixes #3767).\n  * Add new parameter 'invert_threshold', change the default threshold\n    from 0.5 to 0.7 and mark parameter 'tessedit_do_invert' as deprecated.\n\n2022-03-01 - V5.1.0\n  * Handle image and line regions in output formats ALTO, hOCR and text.\n  * New parameter curl_timeout for curl_easy_setop.\n  * Build fixes and improvements.\n  * Catch nullptr in PageIterator::Orientation to improve robustness.\n  * Remove unused code.\n\n2022-01-06 - V5.0.1\n  * Add SPDX-License-Identifier to public include files.\n  * Support redirections when running OCR on a URL.\n  * Lots of fixes and improvements for cmake builds.\n    Distributions should use the autoconf build.\n  * Fix broken msys2 build with gcc 11.\n  * Fix parameter certainty_scale (was duplicated).\n  * Fix some compiler warnings and clean code.\n  * Correctly detect amd64 and i386 on FreeBSD.\n  * Add libarchive and libcurl in continuous integration actions.\n  * Update submodule googletest to release v1.11.0.\n\n2021-11-22 - V5.0.0\n  * Faster training and recognition by default (float instead of\n    double calculations)\n  * More options for binarization\n  * Improved support for ARM NEON\n  * Modernized code\n  * Removed proprietary data types like GenericVector and STRING\n    from public API\n  * pdf.ttf no longer needed, now integrated into the code\n  * Faster flat build with automake\n  * New options for combine_tessdata to show details of traineddata files\n  * Improved training messages\n  * Improved unit tests and fuzzing tests\n  * Lots of bug fixes\n\n2021-11-15 - V4.1.3\n  * Fix build regression for autoconf build\n\n2021-11-14 - V4.1.2\n  * Add RowAttributes getter to PageIterator\n  * Allow line images with larger width for training\n  * Fix memory leaks\n  * Improve build process\n  * Don't output empty ALTO sourceImageInformation (issue #2700)\n  * Extend URI support for Tesseract with libcurl\n  * Abort LSTM training with integer model (fixes issue #1573)\n  * Update documentation\n  * Make automake builds less noisy by default\n  * Don't use -march=native in automake builds\n\n2019-12-26 - V4.1.1\n  * Implemented sw build (cppan is depreciated)\n  * Improved cmake build\n  * Code cleanup and optimization\n  * A lot of bug fixes...\n\n2019-07-07 - V4.1.0\n  * Added new renders Alto, LSTMBox, WordStrBox.\n  * Added character boxes in hOCR output.\n  * Added python training scripts (experimental) as alternative shell scripts.\n  * Better support AVX / AVX2 / SSE.\n  * Disable OpenMP support by default (see e.g. #1171, #1081).\n  * Fix for bounding box problem.\n  * Implemented support for whitelist/blacklist in LSTM engine.\n  * Improved cmake configuration.\n  * Code modernization and improvements.\n  * A lot of bug fixes...\n\n2018-10-29 - V4.0.0\n  * Added new neural network system based on LSTMs, with major accuracy gains.\n  * Improvements to PDF rendering.\n  * Fixes to trainingdata rendering.\n  * Added LSTM models+lang models to 101 languages. (tessdata repository)\n  * Improved multi-page TIFF handling.\n  * Fixed damage to binary images when processing PDFs.\n  * Fixes to training process to allow incremental training from a recognition model.\n  * Made LSTM the default engine, pushed cube out.\n  * Deleted cube code.\n  * Changed OEModes --oem 0 for legacy tesseract engine, --oem 1 for LSTM, --oem 2 for both, --oem 3 for default.\n  * Avoid use of Leptonica debug parameters or functions.\n  * Fixed multi-language mode.\n  * Removed support for VS2010.\n  * Added Support for VS2015 and VS2017 with CPPAN.\n  * Implemented invisible text only for PDF.\n  * Added AVX / SSE support for Windows.\n  * Enabled OpenMP support.\n  * Parameter unlv_tilde_crunching change to false.\n  * Miscellaneous Fixes.\n  * Detailed Changelog can be found at https://tesseract-ocr.github.io/tessdoc/4.0x-Changelog.html and https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html#tesseract-release-notes-oct-29-2018---v400\n\n2017-02-16 - V3.05.00\n  * Made some fine tuning to the hOCR output.\n  * Added TSV as another optional output format.\n  * Fixed ABI break introduced in 3.04.00 with the AnalyseLayout() method.\n  * text2image tool - Enable all OpenType ligatures available in a font. This feature requires Pango 1.38 or newer.\n  * Training tools - Replaced asserts with tprintf() and exit(1).\n  * Fixed Cygwin compatibility.\n  * Improved multipage tiff processing.\n  * Improved the embedded pdf font (pdf.ttf).\n  * Enable selection of OCR engine mode from command line.\n  * Changed tesseract command line parameter '-psm' to '--psm'.\n  * Write output of tesseract --help, --version and --list-langs to stdout instead of stderr.\n  * Added new C API for orientation and script detection, removed the old one.\n  * Increased minimum autoconf version to 2.59.\n  * Removed dead code.\n  * Require Leptonica 1.74 or higher.\n  * Fixed many compiler warning.\n  * Fixed memory and resource leaks.\n  * Fixed some issues with the 'Cube' OCR engine.\n  * Fixed some openCL issues.\n  * Added option to build Tesseract with CMake build system.\n  * Implemented CPPAN support for easy Windows building.\n\n2016-02-17 - V3.04.01\n  * Added OSD renderer for psm 0. Works for single page and multi-page images.\n  * Improve tesstrain.sh script.\n  * Simplify build and run of ScrollView.\n  * Improved PDF output for OS X Preview utility.\n  * INCOMPATIBLE fix to hOCR line height information - commit 134ebc3.\n  * Added option to build Tesseract without Cube OCR engine (-DNO_CUBE_BUILD).\n  * Enable OpenMP support.\n  * Many bug fixes.\n\n2015-07-11 - V3.04.00\n  * Tesseract development is now done with Git and hosted at github.com (Previously we used Subversion as a VCS and code.google.com for hosting).\n  * Tesseract now requires leptonica 1.71 or a higher version.\n  * Removed official support for VS 2008.\n  * Added support for 39 additional scripts/languages, including: amh, asm, aze_cyrl, bod, bos, ceb, cym, dzo, fas, gle, guj, hat, iku, jav, kat, kat_old, kaz, khm, kir, kur, lao, lat, mar, mya, nep, ori, pan, pus, san, sin, srp_latn, syr, tgk, tir, uig, urd, uzb, uzb_cyrl, yid\n  * Major updates to training system as a result of extensive testing on 100 languages.\n  * New training data for over 100 languages\n  * Improved performance with PIC compilation option.\n  * Significant change to invisible font system in pdf output to improve correctness and compatibility with external programs, particularly ghostscript.\n  * Improved font identification.\n  * Major change to improve layout analysis for heavily diacritic languages: Thai, Vietnamese, Kannada, Telugu etc.\n  * Fixed problems with shifted baselines so recognition can recover from layout analysis errors.\n  * Major refactor to improve speed on difficult images, especially when running a heap checker.\n  * Moved params from global in page layout to tesseractclass.\n  * Improved single column layout analysis.\n  * Allow ocr output to multiple formats using tesseract command line executable.\n  * Fixed issues with mixed eng+ara scripts.\n  * Improved script consistency in numbers.\n  * Major refactor of control.cpp to enable line recognition.\n  * Added tesstrain.sh - a master training script.\n  * Added ability to text2image training tool to just list available fonts.\n  * Added ability to text2image to underline words.\n  * Improved efficiency of image processing for PDF output.\n  * Added parameter description for each parameter listed with 'print-parameters' command line option.\n  * Added font info to hOCR output.\n  * Enabled streaming input and output of multi-page documents.\n  * Many bug fixes.\n\n2014-02-04 - V3.03(rc1)\n  * Added new training tool text2image to generate box/tif file pairs from\n    text and truetype fonts.\n  * Added support for PDF output with searchable text.\n  * Removed entire IMAGE class and all code in image directory.\n  * Tesseract executable: support for output to stdout; limited support for one\n    page images from stdin  (especially on Windows)\n  * Added Renderer to API to allow document-level processing and output\n    of document formats, like hOCR, PDF.\n  * Major refactor of word-level recognition, beam search, eliminating dead code.\n  * Refactored classifier to make it easier to add new ones.\n  * Generalized feature extractor to allow feature extraction from greyscale.\n  * Improved sub/superscript treatment.\n  * Improved baseline fit.\n  * Added set_unicharset_properties to training tools.\n  * Many bug fixes.\n  * More training source data included.\n\n2012-02-01 - V3.02\n  * Moved ResultIterator/PageIterator to ccmain.\n  * Added Right-to-left/Bidi capability in the output iterators for Hebrew/Arabic.\n  * Added paragraph detection in layout analysis/post OCR.\n  * Fixed inconsistent xheight during training and over-chopping.\n  * Added simultaneous multi-language capability.\n  * Refactored top-level word recognition module.\n  * Added experimental equation detector.\n  * Improved handling of resolution from input images.\n  * Blamer module added for error analysis.\n  * Cleaned up externally used namespace by removing includes from baseapi.h.\n  * Removed dead memory mangagement code.\n  * Tidied up constraints on control parameters.\n  * Added support for ShapeTable in classifier and training.\n  * Refactored class pruner.\n  * Fixed training leaks and randomness.\n  * Major improvements to layout analysis for better image detection, diacritic detection, better textline finding, better tabstop finding.\n  * Improved line detection and removal.\n  * Added fixed pitch chopper for CJK.\n  * Added UNICHARSET to WERD_CHOICE to make mult-language handling easier.\n  * Fixed problems with internally scaled images.\n  * Added page and bbox to string in tr files to identify source of training data better.\n  * Fixes to Hindi Shiroreka splitter.\n  * Added word bigram correction.\n  * Reduced stack memory consumption and eliminated some ugly typedefs.\n  * Added new uniform classifier API.\n  * Added new training error counter.\n  * Fixed endian bug in dawg reader.\n  * Many other fixes, including the way in which the chopper finds chops and messes with the outline while it does so.\n\n2010-11-29 - V3.01\n  * Removed old/dead serialise/deserialize methods on *LISTIZED classes.\n  * Total rewrite of DENORM to better encapsulate operation and make\n    for potential to extract features from images.\n  * Thread-safety! Moved all critical global and static variables to members of the appropriate class. Tesseract is now thread-safe (multiple instances can be used in parallel in multiple threads.) with the minor exception that some control parameters are still global and affect all threads.\n  * Added Cube, a new recognizer for Arabic. Cube can also be used in combination with normal Tesseract for other languages with an improvement in accuracy at the cost of (much) lower speed. *There is no training module for Cube yet.*\n  * `OcrEngineMode` in `Init` replaces `AccuracyVSpeed` to control cube.\n  * Greatly improved segmentation search with consequent accuracy and speed improvements, especially for Chinese.\n  * Added `PageIterator` and `ResultIterator` as cleaner ways to get the full results out of Tesseract, that are not currently provided by any of the `TessBaseAPI::Get*` methods. All other methods, such as the `ETEXT_STRUCT` in particular are deprecated and will be deleted in the future.\n  * ApplyBoxes totally rewritten to make training easier. It can now cope with touching/overlapping training characters, and a new boxfile format allows word boxes instead of character boxes, BUT to use that you have to have already bootstrapped the language with character boxes. \"Cyclic dependency\" on traineddata.\n  * Auto orientation and script detection added to page layout analysis.\n  * Deleted *lots* of dead code.\n  * Fixxht module replaced with scalable data-driven module.\n  * Output font characteristics accuracy improved.\n  * Removed the double conversion at each classification.\n  * Upgraded oldest structs to be classes and deprecated PBLOB.\n  * Removed non-deterministic baseline fit.\n  * Added fixed length dawgs for Chinese.\n  * Handling of vertical text improved.\n  * Handling of leader dots improved.\n  * Table detection greatly improved.\n  * Fixed a couple of memory leaks.\n  * Fixed font labels on output text. (Not perfect, but a lot better than before.)\n  * Cleanup and more bug fixes\n  * Special treatments for Hindi.\n  * Support for build in VS2010 with Microsoft Windows SDK for Windows 7 (thanks to Michael Lutz)\n\n2010-09-21 - V3.00\n  * Preparations for thread safety:\n     * Changed TessBaseAPI methods to be non-static\n     * Created a class hierarchy for the directories to hold instance data,\n       and began moving code into the classes.\n     * Moved thresholding code to a separate class.\n  * Added major new page layout analysis module.\n  * Added HOCR output (issues 221, 263: thanks to amkryukov).\n  * Added Leptonica as main image I/O and handling. Currently optional,\n    but in future releases linking with Leptonica will be mandatory.\n  * Ambiguity table rewritten to allow definite replacements in place\n    of fix_quotes.\n  * Added TessdataManager to combine data files into a single file.\n  * Some dead code deleted.\n  * VC++6 no longer supported. It can't cope with the use of templates.\n  * Many more languages added.\n  * Doxygenation of most of the function header comments.\n  * Added man pages.\n  * Added bash completion script (issue 247: thanks to neskiem)\n  * Fix integer overview in thresholding (issue 366: thanks to Cyanide.Drake)\n  * Add Danish Fraktur support (issues 300, 360: thanks to\n    dsl602230@vip.cybercity.dk)\n  * Fix file pointer leak (issue 359, thanks to yukihiro.nakadaira)\n  * Fix an error using user-words (Issue 345: thanks to max.markin)\n  * Fix a memory leak in tablefind.cpp (Issue 342, thanks to zdravco)\n  * Fix a segfault due to double fclose (Issue 320, thanks to souther)\n  * Fix an automake error (Issue 318, thanks to ichanjz)\n  * Fix a Win32 crash on fileFormatIsTiff() (Issues 304, 316, 317, 330, 347,\n    349, 352: thanks to nguyenq87, max.markin, zdenop)\n  * Fixed a number of errors in newer (stricter) versions of VC++ (Issues\n    301, among others)\n\n2009-06-30 - V2.04\n  * Integrated bug fixes and patches and misc changes for portability.\n  * Integrated a patch to remove some of the \"access\" macros.\n  * Removed dependence on lua from the viewer, speeding it up\n    dramatically.\n  * Fixed the viewer so it compiles and runs properly!\n  * Specifically fixing issues: 1, 63, 67, 71, 76, 81, 82, 106, 111,\n   112, 128, 129, 130, 133, 135, 142, 143, 145, 147, 153, 154, 160,\n   165, 170, 175, 177, 187, 192, 195, 199, 201, 205, 209, 108, 169\n\n2008-04-22 - V2.03\n  * Fixed crash introduced in 2.02.\n  * Fixed lack of tessembedded.cpp in distribution.\n  * Added test for leptonica header files and conditional test for lib.\n\n2008-04-21 - V2.02 (again)\n  * Fixed namespace collisions with jpeg library (INT32).\n  * Portability fixes for Windows for new code.\n  * Updates to autoconf system for new code.\n\n2008-01-23 - V2.02\n  * Improvements to clustering, training and classifier.\n  * Major internationalization improvements for large-character-set\n  * languages, eg Kannada.\n  * Removed some compiler warnings.\n  * Added multipage tiff support for training and running.\n  * Updated graphics output to talk to new java-based viewer.\n  * Added ability to save n-best lists.\n  * Added leptonica support for more file types.\n  * Improved Init/End to make them safe.\n  * Reduced memory use of dictionaries.\n  * Added some new APIs to TessBaseAPI.\n\n2007-08-27 - V2.01\n  * Fixed UTF8 input problems with box file reader.\n  * Fixed various infinite loops and crashes in dawg code.\n  * Removed include of config_auto.h from host.h.\n  * Added automatic wctype encoding to unicharset_extractor.\n  * Fixed dawg table too full error.\n  * Removed svn files from tarball.\n  * Added new functions to tessdll.\n  * Increased maximum utf8 string in a classification result to 8.\n\n2007-07-02 - V2.00\n  * Converted internal character handling to UTF8.\n  * Trained with 6 languages.\n  * Added unicharset_extractor, wordlist2dawg.\n  * Added boxfile creation mode.\n  * Added UNLV regression test capability.\n  * Fixed problems with copyright and registered symbols.\n  * Fixed extern \"C\" declarations problem.\n\n2007-05-15 - V1.04\n  * Added dll exports for Windows.\n  * Fixed name collisions with stl etc.\n  * Made some preliminary changes ready for unicodeization.\n  * Several bug fixes discovered during unicodeization.\n\n2007-02-02 - V1.03\n  * Added mftraining and cntraining.\n  * Added baseapi with adaptive thresholding for grey and color.\n  * Fixed many memory leaks.\n  * Fixed several bugs including lack of use of adaptive classifier.\n  * Added ifdefs to eliminate graphics code and add embedded platform support.\n  * Incorporated several patches, including 64-bit builds, Mac builds.\n  * Minor accuracy improvements.\n\n2006-10-04 - V1.02\n  * Removed dependency on Aspirin.\n  * Fixed a few missing Apache license headers.\n  * Removed $log.\n\n2006-09-07 - V1.01.\n  * Added mfcpch.cpp and getopt.cpp for VC++.\n  * Fixed problem with greyscale images and no libtiff.\n  * Stopped debug window from being used for the usage output.\n  * Fixed load of inttemp for big-endian architectures.\n  * Fixed some Mac compilation issues.\n\n2006-06-16 - V1.0 of open source Tesseract checked-in.\n"
        },
        {
          "name": "INSTALL",
          "type": "blob",
          "size": 9.09,
          "content": "Copyright 1994, 1995, 1996, 1999, 2000, 2001, 2002 Free Software\nFoundation, Inc.\n\n   This file is free documentation; the Free Software Foundation gives\nunlimited permission to copy, distribute and modify it.\n\nBasic Installation\n==================\n\n   These are generic installation instructions. First you need to run\n`./autogen.sh', that creates `configure' script.\n\n   The `configure' shell script attempts to guess correct values for\nvarious system-dependent variables used during compilation.  It uses\nthose values to create a `Makefile' in each directory of the package.\nIt may also create one or more `.h' files containing system-dependent\ndefinitions.  Finally, it creates a shell script `config.status' that\nyou can run in the future to recreate the current configuration, and a\nfile `config.log' containing compiler output (useful mainly for\ndebugging `configure').\n\n   It can also use an optional file (typically called `config.cache'\nand enabled with `--cache-file=config.cache' or simply `-C') that saves\nthe results of its tests to speed up reconfiguring.  (Caching is\ndisabled by default to prevent problems with accidental use of stale\ncache files.)\n\n   If you need to do unusual things to compile the package, please try\nto figure out how `configure' could check whether to do them, and mail\ndiffs or instructions to the address given in the `README' so they can\nbe considered for the next release.  If you are using the cache, and at\nsome point `config.cache' contains results you don't want to keep, you\nmay remove or edit it.\n\n   The file `configure.ac' (or `configure.in') is used to create\n`configure' by a program called `autoconf'.  You only need\n`configure.ac' if you want to change it or regenerate `configure' using\na newer version of `autoconf'.\n\nThe simplest way to compile this package is:\n\n  1. `cd' to the directory containing the package's source code and type\n     `./configure' to configure the package for your system.  If you're\n     using `csh' on an old version of System V, you might need to type\n     `sh ./configure' instead to prevent `csh' from trying to execute\n     `configure' itself.\n\n     Running `configure' takes a while.  While running, it prints some\n     messages telling which features it is checking for.\n\n  2. Type `make' to compile the package.\n\n  3. Optionally, type `make check' to run any self-tests that come with\n     the package.\n\n  4. Type `make install' to install the programs and any data files and\n     documentation.\n\n  5. You can remove the program binaries and object files from the\n     source code directory by typing `make clean'.  To also remove the\n     files that `configure' created (so you can compile the package for\n     a different kind of computer), type `make distclean'.  There is\n     also a `make maintainer-clean' target, but that is intended mainly\n     for the package's developers.  If you use it, you may have to get\n     all sorts of other programs in order to regenerate files that came\n     with the distribution.\n\nCompilers and Options\n=====================\n\n   Some systems require unusual options for compilation or linking that\nthe `configure' script does not know about.  Run `./configure --help'\nfor details on some of the pertinent environment variables.\n\n   You can give `configure' initial values for configuration parameters\nby setting variables in the command line or in the environment.  Here\nis an example:\n\n     ./configure CC=c89 CFLAGS=-O2 LIBS=-lposix\n\n   *Note Defining Variables::, for more details.\n\nCompiling For Multiple Architectures\n====================================\n\n   You can compile the package for more than one kind of computer at the\nsame time, by placing the object files for each architecture in their\nown directory.  To do this, you must use a version of `make' that\nsupports the `VPATH' variable, such as GNU `make'.  `cd' to the\ndirectory where you want the object files and executables to go and run\nthe `configure' script.  `configure' automatically checks for the\nsource code in the directory that `configure' is in and in `..'.\n\n   If you have to use a `make' that does not support the `VPATH'\nvariable, you have to compile the package for one architecture at a\ntime in the source code directory.  After you have installed the\npackage for one architecture, use `make distclean' before reconfiguring\nfor another architecture.\n\nInstallation Names\n==================\n\n   By default, `make install' will install the package's files in\n`/usr/local/bin', `/usr/local/man', etc.  You can specify an\ninstallation prefix other than `/usr/local' by giving `configure' the\noption `--prefix=PATH'.\n\n   You can specify separate installation prefixes for\narchitecture-specific files and architecture-independent files.  If you\ngive `configure' the option `--exec-prefix=PATH', the package will use\nPATH as the prefix for installing programs and libraries.\nDocumentation and other data files will still use the regular prefix.\n\n   In addition, if you use an unusual directory layout you can give\noptions like `--bindir=PATH' to specify different values for particular\nkinds of files.  Run `configure --help' for a list of the directories\nyou can set and what kinds of files go in them.\n\n   If the package supports it, you can cause programs to be installed\nwith an extra prefix or suffix on their names by giving `configure' the\noption `--program-prefix=PREFIX' or `--program-suffix=SUFFIX'.\n\nOptional Features\n=================\n\n   Some packages pay attention to `--enable-FEATURE' options to\n`configure', where FEATURE indicates an optional part of the package.\nThey may also pay attention to `--with-PACKAGE' options, where PACKAGE\nis something like `gnu-as' or `x' (for the X Window System).  The\n`README' should mention any `--enable-' and `--with-' options that the\npackage recognizes.\n\n   For packages that use the X Window System, `configure' can usually\nfind the X include and library files automatically, but if it doesn't,\nyou can use the `configure' options `--x-includes=DIR' and\n`--x-libraries=DIR' to specify their locations.\n\nSpecifying the System Type\n==========================\n\n   There may be some features `configure' cannot figure out\nautomatically, but needs to determine by the type of machine the package\nwill run on.  Usually, assuming the package is built to be run on the\n_same_ architectures, `configure' can figure that out, but if it prints\na message saying it cannot guess the machine type, give it the\n`--build=TYPE' option.  TYPE can either be a short name for the system\ntype, such as `sun4', or a canonical name which has the form:\n\n     CPU-COMPANY-SYSTEM\n\nwhere SYSTEM can have one of these forms:\n\n     OS KERNEL-OS\n\n   See the file `config.sub' for the possible values of each field.  If\n`config.sub' isn't included in this package, then this package doesn't\nneed to know the machine type.\n\n   If you are _building_ compiler tools for cross-compiling, you should\nuse the `--target=TYPE' option to select the type of system they will\nproduce code for.\n\n   If you want to _use_ a cross compiler, that generates code for a\nplatform different from the build platform, you should specify the\n\"host\" platform (i.e., that on which the generated programs will\neventually be run) with `--host=TYPE'.\n\nSharing Defaults\n================\n\n   If you want to set default values for `configure' scripts to share,\nyou can create a site shell script called `config.site' that gives\ndefault values for variables like `CC', `cache_file', and `prefix'.\n`configure' looks for `PREFIX/share/config.site' if it exists, then\n`PREFIX/etc/config.site' if it exists.  Or, you can set the\n`CONFIG_SITE' environment variable to the location of the site script.\nA warning: not all `configure' scripts look for a site script.\n\nDefining Variables\n==================\n\n   Variables not defined in a site shell script can be set in the\nenvironment passed to `configure'.  However, some packages may run\nconfigure again during the build, and the customized values of these\nvariables may be lost.  In order to avoid this problem, you should set\nthem in the `configure' command line, using `VAR=value'.  For example:\n\n     ./configure CC=/usr/local2/bin/gcc\n\nwill cause the specified gcc to be used as the C compiler (unless it is\noverridden in the site shell script).\n\n`configure' Invocation\n======================\n\n   `configure' recognizes the following options to control how it\noperates.\n\n`--help'\n`-h'\n     Print a summary of the options to `configure', and exit.\n\n`--version'\n`-V'\n     Print the version of Autoconf used to generate the `configure'\n     script, and exit.\n\n`--cache-file=FILE'\n     Enable the cache: use and save the results of the tests in FILE,\n     traditionally `config.cache'.  FILE defaults to `/dev/null' to\n     disable caching.\n\n`--config-cache'\n`-C'\n     Alias for `--cache-file=config.cache'.\n\n`--quiet'\n`--silent'\n`-q'\n     Do not print messages saying which checks are being made.  To\n     suppress all normal output, redirect it to `/dev/null' (any error\n     messages will still be shown).\n\n`--srcdir=DIR'\n     Look for the package's source code in directory DIR.  Usually\n     `configure' can determine that directory automatically.\n\n`configure' also accepts some other, not widely useful, options.  Run\n`configure --help' for more details.\n"
        },
        {
          "name": "INSTALL.GIT.md",
          "type": "blob",
          "size": 2.15,
          "content": "## autotools (LINUX/UNIX , msys...)\n\nIf you have cloned Tesseract from GitHub, you must generate\nthe configure script.\n\nIf you have tesseract 4.0x installation in your system, please remove it\nbefore new build.\n\nYou need Leptonica 1.74.2 (minimum) for Tesseract 4.0x.\n\nKnown dependencies for training tools (excluding leptonica):\n\n* compiler with c++17 support\n* automake\n* pkg-config\n* pango-devel\n* cairo-devel\n* icu-devel\n\nSo, the steps for making Tesseract are:\n\n    ./autogen.sh\n    ./configure\n    make\n    sudo make install\n    sudo ldconfig\n    make training\n    sudo make training-install\n\nYou need to install at least English language and OSD traineddata files to\n`TESSDATA_PREFIX` directory.\n\nYou can retrieve single file with tools like [wget](https://www.gnu.org/software/wget/), [curl](https://curl.haxx.se/), [GithubDownloader](https://github.com/intezer/GithubDownloader) or browser.\n\nAll language data files can be retrieved from git repository (useful only for packagers!).\n(Repository is huge - more that 1.2 GB. You do NOT need to download traineddata files for\nall languages).\n\n    git clone https://github.com/tesseract-ocr/tessdata.git tesseract-ocr.tessdata\n\nYou need an Internet connection and [curl](https://curl.haxx.se/) to compile `ScrollView.jar`\nbecause the build will automatically download\n[piccolo2d-core-3.0.1.jar](https://search.maven.org/remotecontent?filepath=org/piccolo2d/piccolo2d-core/3.0.1/piccolo2d-core-3.0.1.jar) and\n[piccolo2d-extras-3.0.1.jar](https://search.maven.org/remotecontent?filepath=org/piccolo2d/piccolo2d-extras/3.0.1/piccolo2d-extras-3.0.1.jar) and\n[jaxb-api-2.3.1.jar](http://search.maven.org/remotecontent?filepath=javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar) and place them to `tesseract/java`.\n\nJust run:\n\n    make ScrollView.jar\n\nand follow the instruction on [Viewer Debugging](https://tesseract-ocr.github.io/tessdoc/ViewerDebugging.html).\n\n## cmake\n\nThere is alternative build system based on multiplatform [cmake](https://cmake.org/)\n\n### LINUX\n\n    mkdir build\n    cd build && cmake .. && make\n    sudo make install\n\n### WINDOWS\n\nSee the [documentation](https://tesseract-ocr.github.io/tessdoc/) for more information on this.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile.am",
          "type": "blob",
          "size": 60.91,
          "content": "## run autogen.sh to create Makefile.in from this file\nACLOCAL_AMFLAGS = -I m4\n\n.PHONY: doc html install-langs ScrollView.jar install-jars pdf training\n\nCLEANFILES =\n\nSUBDIRS = . tessdata\nif MINGW\nSUBDIRS += nsis\nendif\n\nEXTRA_DIST = README.md LICENSE\nEXTRA_DIST += aclocal.m4 config configure.ac autogen.sh\nEXTRA_DIST += tesseract.pc.in doc\nif !GRAPHICS_DISABLED\nEXTRA_DIST += java\nendif\nEXTRA_DIST += CMakeLists.txt tesseract.pc.cmake cmake VERSION\n\nDIST_SUBDIRS = $(SUBDIRS)\n\nEXTRA_PROGRAMS =\n\nuninstall-hook:\n\trm -rf $(DESTDIR)$(pkgincludedir)\n\ndist-hook:\n# added using EXTRA_DIST. $(distdir)/tessdata would in\n# theory suffice.\n\trm -rf `find $(distdir) -name .deps -type d`\n\t-rm -f $(distdir)/*/Makefile $(distdir)/*/*/Makefile\n\trm -f `find $(distdir) -name '*~'`\n\trm -rf $(distdir)/doc/html/* $(distdir)/doc/*.log\n\nif !GRAPHICS_DISABLED\nScrollView.jar:\n\t@cd \"$(top_builddir)/java\" && $(MAKE) $@\n\ninstall-jars:\n\t@cd \"$(top_builddir)/java\" && $(MAKE) $@\nendif\n\ndoc:\n\t-srcdir=\"$(top_srcdir)\" builddir=\"$(top_builddir)\" \\\n\tversion=\"@PACKAGE_VERSION@\" name=\"@PACKAGE_NAME@\" \\\n\tdoxygen $(top_srcdir)/doc/Doxyfile\n\ndoc-pack: doc\n\t-chmod a+r $(top_builddir)/doc/html/*\n\t @tar --create --directory=$(top_builddir)/doc/html --verbose --file=- . | gzip -c -9 > $(top_builddir)/@PACKAGE_NAME@-@PACKAGE_VERSION@-doc-html.tar.gz;\n\ndoc-clean:\n\trm -rf $(top_builddir)/doc/html/*\n\nif MINGW\nwinsetup: training ScrollView.jar\n\t@cd \"$(top_builddir)/nsis\" && $(MAKE) winsetup\nendif\n\npkgconfigdir = $(libdir)/pkgconfig\npkgconfig_DATA = tesseract.pc\n\npkginclude_HEADERS = $(top_builddir)/include/tesseract/version.h\npkginclude_HEADERS += include/tesseract/baseapi.h\npkginclude_HEADERS += include/tesseract/capi.h\npkginclude_HEADERS += include/tesseract/export.h\npkginclude_HEADERS += include/tesseract/ltrresultiterator.h\npkginclude_HEADERS += include/tesseract/ocrclass.h\npkginclude_HEADERS += include/tesseract/osdetect.h\npkginclude_HEADERS += include/tesseract/pageiterator.h\npkginclude_HEADERS += include/tesseract/publictypes.h\npkginclude_HEADERS += include/tesseract/renderer.h\npkginclude_HEADERS += include/tesseract/resultiterator.h\npkginclude_HEADERS += include/tesseract/unichar.h\n\n# Rules for all subdirectories.\n\nnoinst_HEADERS =\nnoinst_LTLIBRARIES =\n\nAM_CPPFLAGS += -I$(top_srcdir)/include\nAM_CPPFLAGS += -I$(top_builddir)/include\nif VISIBILITY\nAM_CPPFLAGS += -DTESS_EXPORTS\nAM_CPPFLAGS += -fvisibility=hidden -fvisibility-inlines-hidden -fPIC\nendif\n\nAM_CXXFLAGS = $(OPENMP_CXXFLAGS)\n\n# Rules for src/api.\n\nlibtesseract_la_CPPFLAGS = $(AM_CPPFLAGS)\nlibtesseract_la_CPPFLAGS += -DTESS_COMMON_TRAINING_API=\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/arch\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/ccmain\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/ccstruct\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/classify\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/cutil\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/dict\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/lstm\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/textord\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/training/common\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/viewer\nlibtesseract_la_CPPFLAGS += -I$(top_srcdir)/src/wordrec\nlibtesseract_la_CPPFLAGS += $(libcurl_CFLAGS)\n\nlib_LTLIBRARIES = libtesseract.la\nlibtesseract_la_LDFLAGS = $(LEPTONICA_LIBS)\nlibtesseract_la_LDFLAGS += $(libarchive_LIBS)\nlibtesseract_la_LDFLAGS += $(libcurl_LIBS)\nif T_WIN\nlibtesseract_la_LDFLAGS += -no-undefined -lws2_32\nelse\nlibtesseract_la_LDFLAGS += $(NOUNDEFINED)\nendif\nlibtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION)\n\nlibtesseract_la_SOURCES = src/api/baseapi.cpp\nlibtesseract_la_SOURCES += src/api/altorenderer.cpp\nlibtesseract_la_SOURCES += src/api/pagerenderer.cpp\nlibtesseract_la_SOURCES += src/api/capi.cpp\nlibtesseract_la_SOURCES += src/api/hocrrenderer.cpp\nlibtesseract_la_SOURCES += src/api/lstmboxrenderer.cpp\nlibtesseract_la_SOURCES += src/api/pdfrenderer.cpp\nlibtesseract_la_SOURCES += src/api/renderer.cpp\nlibtesseract_la_SOURCES += src/api/wordstrboxrenderer.cpp\n\nlibtesseract_la_LIBADD = libtesseract_ccutil.la\nlibtesseract_la_LIBADD += libtesseract_lstm.la\nlibtesseract_la_LIBADD += libtesseract_native.la\n\n# Rules for src/arch.\n\nnoinst_HEADERS += src/arch/dotproduct.h\nnoinst_HEADERS += src/arch/intsimdmatrix.h\nnoinst_HEADERS += src/arch/simddetect.h\n\nnoinst_LTLIBRARIES += libtesseract_native.la\n\nlibtesseract_native_la_CXXFLAGS = -O3 -ffast-math\nif OPENMP_SIMD\nlibtesseract_native_la_CXXFLAGS += -fopenmp-simd -DOPENMP_SIMD\nendif\nlibtesseract_native_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_native_la_SOURCES = src/arch/dotproduct.cpp\n\nif HAVE_AVX\nlibtesseract_avx_la_CXXFLAGS = -mavx\nlibtesseract_avx_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_avx_la_SOURCES = src/arch/dotproductavx.cpp\nlibtesseract_la_LIBADD += libtesseract_avx.la\nnoinst_LTLIBRARIES += libtesseract_avx.la\nendif\n\nif HAVE_AVX2\nlibtesseract_avx2_la_CXXFLAGS = -mavx2\nlibtesseract_avx2_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_avx2_la_SOURCES = src/arch/intsimdmatrixavx2.cpp\nlibtesseract_la_LIBADD += libtesseract_avx2.la\nnoinst_LTLIBRARIES += libtesseract_avx2.la\nendif\n\nif HAVE_AVX512F\nlibtesseract_avx512_la_CXXFLAGS = -mavx512f\nlibtesseract_avx512_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_avx512_la_SOURCES = src/arch/dotproductavx512.cpp\nlibtesseract_la_LIBADD += libtesseract_avx512.la\nnoinst_LTLIBRARIES += libtesseract_avx512.la\nendif\n\nif HAVE_FMA\nlibtesseract_fma_la_CXXFLAGS = -mfma\nlibtesseract_fma_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_fma_la_SOURCES = src/arch/dotproductfma.cpp\nlibtesseract_la_LIBADD += libtesseract_fma.la\nnoinst_LTLIBRARIES += libtesseract_fma.la\nendif\n\nif HAVE_SSE4_1\nlibtesseract_sse_la_CXXFLAGS = -msse4.1\nlibtesseract_sse_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_sse_la_SOURCES = src/arch/dotproductsse.cpp src/arch/intsimdmatrixsse.cpp\nlibtesseract_la_LIBADD += libtesseract_sse.la\nnoinst_LTLIBRARIES += libtesseract_sse.la\nendif\n\nif HAVE_NEON\nlibtesseract_neon_la_CXXFLAGS = $(NEON_CXXFLAGS)\nlibtesseract_neon_la_CXXFLAGS += -O3\nif OPENMP_SIMD\nlibtesseract_neon_la_CXXFLAGS += -fopenmp-simd -DOPENMP_SIMD\nendif\nlibtesseract_neon_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_neon_la_SOURCES = src/arch/intsimdmatrixneon.cpp\nlibtesseract_neon_la_SOURCES += src/arch/dotproductneon.cpp\nlibtesseract_la_LIBADD += libtesseract_neon.la\nnoinst_LTLIBRARIES += libtesseract_neon.la\nendif\n\nif HAVE_RVV\nlibtesseract_rvv_la_CXXFLAGS = $(RVV_CXXFLAGS)\nlibtesseract_rvv_la_CXXFLAGS += -O3\nlibtesseract_rvv_la_CXXFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_rvv_la_SOURCES = src/arch/intsimdmatrixrvv.cpp\nlibtesseract_la_LIBADD += libtesseract_rvv.la\nnoinst_LTLIBRARIES += libtesseract_rvv.la\nendif\n\nlibtesseract_la_SOURCES += src/arch/intsimdmatrix.cpp\nlibtesseract_la_SOURCES += src/arch/simddetect.cpp\n\n# Rules for src/ccmain.\n\nnoinst_HEADERS += src/ccmain/control.h\nnoinst_HEADERS += src/ccmain/mutableiterator.h\nnoinst_HEADERS += src/ccmain/output.h\nnoinst_HEADERS += src/ccmain/paragraphs.h\nnoinst_HEADERS += src/ccmain/paragraphs_internal.h\nnoinst_HEADERS += src/ccmain/paramsd.h\nnoinst_HEADERS += src/ccmain/pgedit.h\nnoinst_HEADERS += src/ccmain/tesseractclass.h\nnoinst_HEADERS += src/ccmain/tessvars.h\nnoinst_HEADERS += src/ccmain/thresholder.h\nnoinst_HEADERS += src/ccmain/werdit.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/ccmain/docqual.h\nnoinst_HEADERS += src/ccmain/equationdetect.h\nnoinst_HEADERS += src/ccmain/fixspace.h\nnoinst_HEADERS += src/ccmain/reject.h\nendif\n\nlibtesseract_la_SOURCES += src/ccmain/applybox.cpp\nlibtesseract_la_SOURCES += src/ccmain/control.cpp\nlibtesseract_la_SOURCES += src/ccmain/linerec.cpp\nlibtesseract_la_SOURCES += src/ccmain/ltrresultiterator.cpp\nlibtesseract_la_SOURCES += src/ccmain/mutableiterator.cpp\nlibtesseract_la_SOURCES += src/ccmain/output.cpp\nlibtesseract_la_SOURCES += src/ccmain/pageiterator.cpp\nlibtesseract_la_SOURCES += src/ccmain/pagesegmain.cpp\nlibtesseract_la_SOURCES += src/ccmain/pagewalk.cpp\nlibtesseract_la_SOURCES += src/ccmain/paragraphs.cpp\nif !GRAPHICS_DISABLED\nlibtesseract_la_SOURCES += src/ccmain/paramsd.cpp\nlibtesseract_la_SOURCES += src/ccmain/pgedit.cpp\nendif\nlibtesseract_la_SOURCES += src/ccmain/reject.cpp\nlibtesseract_la_SOURCES += src/ccmain/resultiterator.cpp\nlibtesseract_la_SOURCES += src/ccmain/tessedit.cpp\nlibtesseract_la_SOURCES += src/ccmain/tesseractclass.cpp\nlibtesseract_la_SOURCES += src/ccmain/tessvars.cpp\nlibtesseract_la_SOURCES += src/ccmain/thresholder.cpp\nlibtesseract_la_SOURCES += src/ccmain/werdit.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/ccmain/adaptions.cpp\nlibtesseract_la_SOURCES += src/ccmain/docqual.cpp\nlibtesseract_la_SOURCES += src/ccmain/equationdetect.cpp\nlibtesseract_la_SOURCES += src/ccmain/fixspace.cpp\nlibtesseract_la_SOURCES += src/ccmain/fixxht.cpp\nlibtesseract_la_SOURCES += src/ccmain/osdetect.cpp\nlibtesseract_la_SOURCES += src/ccmain/par_control.cpp\nlibtesseract_la_SOURCES += src/ccmain/recogtraining.cpp\nlibtesseract_la_SOURCES += src/ccmain/superscript.cpp\nlibtesseract_la_SOURCES += src/ccmain/tessbox.cpp\nlibtesseract_la_SOURCES += src/ccmain/tfacepp.cpp\nendif\n\n# Rules for src/ccstruct.\n\nnoinst_HEADERS += src/ccstruct/blamer.h\nnoinst_HEADERS += src/ccstruct/blobbox.h\nnoinst_HEADERS += src/ccstruct/blobs.h\nnoinst_HEADERS += src/ccstruct/blread.h\nnoinst_HEADERS += src/ccstruct/boxread.h\nnoinst_HEADERS += src/ccstruct/boxword.h\nnoinst_HEADERS += src/ccstruct/ccstruct.h\nnoinst_HEADERS += src/ccstruct/coutln.h\nnoinst_HEADERS += src/ccstruct/crakedge.h\nnoinst_HEADERS += src/ccstruct/debugpixa.h\nnoinst_HEADERS += src/ccstruct/detlinefit.h\nnoinst_HEADERS += src/ccstruct/dppoint.h\nnoinst_HEADERS += src/ccstruct/image.h\nnoinst_HEADERS += src/ccstruct/imagedata.h\nnoinst_HEADERS += src/ccstruct/linlsq.h\nnoinst_HEADERS += src/ccstruct/matrix.h\nnoinst_HEADERS += src/ccstruct/mod128.h\nnoinst_HEADERS += src/ccstruct/normalis.h\nnoinst_HEADERS += src/ccstruct/ocrblock.h\nnoinst_HEADERS += src/ccstruct/ocrpara.h\nnoinst_HEADERS += src/ccstruct/ocrrow.h\nnoinst_HEADERS += src/ccstruct/otsuthr.h\nnoinst_HEADERS += src/ccstruct/pageres.h\nnoinst_HEADERS += src/ccstruct/pdblock.h\nnoinst_HEADERS += src/ccstruct/points.h\nnoinst_HEADERS += src/ccstruct/polyaprx.h\nnoinst_HEADERS += src/ccstruct/polyblk.h\nnoinst_HEADERS += src/ccstruct/quadlsq.h\nnoinst_HEADERS += src/ccstruct/quadratc.h\nnoinst_HEADERS += src/ccstruct/quspline.h\nnoinst_HEADERS += src/ccstruct/ratngs.h\nnoinst_HEADERS += src/ccstruct/rect.h\nnoinst_HEADERS += src/ccstruct/rejctmap.h\nnoinst_HEADERS += src/ccstruct/seam.h\nnoinst_HEADERS += src/ccstruct/split.h\nnoinst_HEADERS += src/ccstruct/statistc.h\nnoinst_HEADERS += src/ccstruct/stepblob.h\nnoinst_HEADERS += src/ccstruct/werd.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/ccstruct/fontinfo.h\nnoinst_HEADERS += src/ccstruct/params_training_featdef.h\nendif\n\nlibtesseract_la_SOURCES += src/ccstruct/blamer.cpp\nlibtesseract_la_SOURCES += src/ccstruct/blobbox.cpp\nlibtesseract_la_SOURCES += src/ccstruct/blobs.cpp\nlibtesseract_la_SOURCES += src/ccstruct/blread.cpp\nlibtesseract_la_SOURCES += src/ccstruct/boxread.cpp\nlibtesseract_la_SOURCES += src/ccstruct/boxword.cpp\nlibtesseract_la_SOURCES += src/ccstruct/ccstruct.cpp\nlibtesseract_la_SOURCES += src/ccstruct/coutln.cpp\nlibtesseract_la_SOURCES += src/ccstruct/detlinefit.cpp\nlibtesseract_la_SOURCES += src/ccstruct/dppoint.cpp\nlibtesseract_la_SOURCES += src/ccstruct/image.cpp\nlibtesseract_la_SOURCES += src/ccstruct/imagedata.cpp\nlibtesseract_la_SOURCES += src/ccstruct/linlsq.cpp\nlibtesseract_la_SOURCES += src/ccstruct/matrix.cpp\nlibtesseract_la_SOURCES += src/ccstruct/mod128.cpp\nlibtesseract_la_SOURCES += src/ccstruct/normalis.cpp\nlibtesseract_la_SOURCES += src/ccstruct/ocrblock.cpp\nlibtesseract_la_SOURCES += src/ccstruct/ocrpara.cpp\nlibtesseract_la_SOURCES += src/ccstruct/ocrrow.cpp\nlibtesseract_la_SOURCES += src/ccstruct/otsuthr.cpp\nlibtesseract_la_SOURCES += src/ccstruct/pageres.cpp\nlibtesseract_la_SOURCES += src/ccstruct/pdblock.cpp\nlibtesseract_la_SOURCES += src/ccstruct/points.cpp\nlibtesseract_la_SOURCES += src/ccstruct/polyaprx.cpp\nlibtesseract_la_SOURCES += src/ccstruct/polyblk.cpp\nlibtesseract_la_SOURCES += src/ccstruct/quadlsq.cpp\nlibtesseract_la_SOURCES += src/ccstruct/quspline.cpp\nlibtesseract_la_SOURCES += src/ccstruct/ratngs.cpp\nlibtesseract_la_SOURCES += src/ccstruct/rect.cpp\nlibtesseract_la_SOURCES += src/ccstruct/rejctmap.cpp\nlibtesseract_la_SOURCES += src/ccstruct/seam.cpp\nlibtesseract_la_SOURCES += src/ccstruct/split.cpp\nlibtesseract_la_SOURCES += src/ccstruct/statistc.cpp\nlibtesseract_la_SOURCES += src/ccstruct/stepblob.cpp\nlibtesseract_la_SOURCES += src/ccstruct/werd.cpp\n\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/ccstruct/fontinfo.cpp\nlibtesseract_la_SOURCES += src/ccstruct/params_training_featdef.cpp\nendif\n\n# Rules for src/ccutil\n\nlibtesseract_ccutil_la_CPPFLAGS = $(AM_CPPFLAGS)\nlibtesseract_ccutil_la_CPPFLAGS += $(libarchive_CFLAGS)\nif !NO_TESSDATA_PREFIX\nlibtesseract_ccutil_la_CPPFLAGS += -DTESSDATA_PREFIX='\"@datadir@\"'\nendif\n\nnoinst_HEADERS += src/ccutil/ccutil.h\nnoinst_HEADERS += src/ccutil/clst.h\nnoinst_HEADERS += src/ccutil/elst2.h\nnoinst_HEADERS += src/ccutil/elst.h\nnoinst_HEADERS += src/ccutil/errcode.h\nnoinst_HEADERS += src/ccutil/fileerr.h\nnoinst_HEADERS += src/ccutil/genericheap.h\nnoinst_HEADERS += src/ccutil/genericvector.h\nnoinst_HEADERS += src/ccutil/helpers.h\nnoinst_HEADERS += src/ccutil/host.h\nnoinst_HEADERS += src/ccutil/kdpair.h\nnoinst_HEADERS += src/ccutil/lsterr.h\nnoinst_HEADERS += src/ccutil/object_cache.h\nnoinst_HEADERS += src/ccutil/params.h\nnoinst_HEADERS += src/ccutil/qrsequence.h\nnoinst_HEADERS += src/ccutil/sorthelper.h\nnoinst_HEADERS += src/ccutil/scanutils.h\nnoinst_HEADERS += src/ccutil/serialis.h\nnoinst_HEADERS += src/ccutil/tessdatamanager.h\nnoinst_HEADERS += src/ccutil/tprintf.h\nnoinst_HEADERS += src/ccutil/unicharcompress.h\nnoinst_HEADERS += src/ccutil/unicharmap.h\nnoinst_HEADERS += src/ccutil/unicharset.h\nnoinst_HEADERS += src/ccutil/unicity_table.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/ccutil/ambigs.h\nnoinst_HEADERS += src/ccutil/bitvector.h\nnoinst_HEADERS += src/ccutil/indexmapbidi.h\nnoinst_HEADERS += src/ccutil/universalambigs.h\nendif\n\nnoinst_LTLIBRARIES += libtesseract_ccutil.la\n\nlibtesseract_ccutil_la_SOURCES = src/ccutil/ccutil.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/errcode.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/serialis.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/scanutils.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/tessdatamanager.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/tprintf.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/unichar.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/unicharcompress.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/unicharmap.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/unicharset.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/params.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_ccutil_la_SOURCES += src/ccutil/ambigs.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/bitvector.cpp\nlibtesseract_ccutil_la_SOURCES += src/ccutil/indexmapbidi.cpp\nendif\n\n# Rules for src/classify.\n\nnoinst_HEADERS += src/classify/classify.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/classify/adaptive.h\nnoinst_HEADERS += src/classify/cluster.h\nnoinst_HEADERS += src/classify/clusttool.h\nnoinst_HEADERS += src/classify/featdefs.h\nnoinst_HEADERS += src/classify/float2int.h\nnoinst_HEADERS += src/classify/fpoint.h\nnoinst_HEADERS += src/classify/intfeaturespace.h\nnoinst_HEADERS += src/classify/intfx.h\nnoinst_HEADERS += src/classify/intmatcher.h\nnoinst_HEADERS += src/classify/intproto.h\nnoinst_HEADERS += src/classify/kdtree.h\nnoinst_HEADERS += src/classify/mf.h\nnoinst_HEADERS += src/classify/mfdefs.h\nnoinst_HEADERS += src/classify/mfoutline.h\nnoinst_HEADERS += src/classify/mfx.h\nnoinst_HEADERS += src/classify/normfeat.h\nnoinst_HEADERS += src/classify/normmatch.h\nnoinst_HEADERS += src/classify/ocrfeatures.h\nnoinst_HEADERS += src/classify/outfeat.h\nnoinst_HEADERS += src/classify/picofeat.h\nnoinst_HEADERS += src/classify/protos.h\nnoinst_HEADERS += src/classify/shapeclassifier.h\nnoinst_HEADERS += src/classify/shapetable.h\nnoinst_HEADERS += src/classify/tessclassifier.h\nnoinst_HEADERS += src/classify/trainingsample.h\nendif\n\nlibtesseract_la_SOURCES += src/classify/classify.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/classify/adaptive.cpp\nlibtesseract_la_SOURCES += src/classify/adaptmatch.cpp\nlibtesseract_la_SOURCES += src/classify/blobclass.cpp\nlibtesseract_la_SOURCES += src/classify/cluster.cpp\nlibtesseract_la_SOURCES += src/classify/clusttool.cpp\nlibtesseract_la_SOURCES += src/classify/cutoffs.cpp\nlibtesseract_la_SOURCES += src/classify/featdefs.cpp\nlibtesseract_la_SOURCES += src/classify/float2int.cpp\nlibtesseract_la_SOURCES += src/classify/fpoint.cpp\nlibtesseract_la_SOURCES += src/classify/intfeaturespace.cpp\nlibtesseract_la_SOURCES += src/classify/intfx.cpp\nlibtesseract_la_SOURCES += src/classify/intmatcher.cpp\nlibtesseract_la_SOURCES += src/classify/intproto.cpp\nlibtesseract_la_SOURCES += src/classify/kdtree.cpp\nlibtesseract_la_SOURCES += src/classify/mf.cpp\nlibtesseract_la_SOURCES += src/classify/mfoutline.cpp\nlibtesseract_la_SOURCES += src/classify/mfx.cpp\nlibtesseract_la_SOURCES += src/classify/normfeat.cpp\nlibtesseract_la_SOURCES += src/classify/normmatch.cpp\nlibtesseract_la_SOURCES += src/classify/ocrfeatures.cpp\nlibtesseract_la_SOURCES += src/classify/outfeat.cpp\nlibtesseract_la_SOURCES += src/classify/picofeat.cpp\nlibtesseract_la_SOURCES += src/classify/protos.cpp\nlibtesseract_la_SOURCES += src/classify/shapeclassifier.cpp\nlibtesseract_la_SOURCES += src/classify/shapetable.cpp\nlibtesseract_la_SOURCES += src/classify/tessclassifier.cpp\nlibtesseract_la_SOURCES += src/classify/trainingsample.cpp\nendif\n\n# Rules for src/cutil.\n\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/cutil/bitvec.h\nnoinst_HEADERS += src/cutil/oldlist.h\nendif\n\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/cutil/oldlist.cpp\nendif\n\n# Rules for src/dict.\n\nnoinst_HEADERS += src/dict/dawg.h\nnoinst_HEADERS += src/dict/dawg_cache.h\nnoinst_HEADERS += src/dict/dict.h\nnoinst_HEADERS += src/dict/matchdefs.h\nnoinst_HEADERS += src/dict/stopper.h\nnoinst_HEADERS += src/dict/trie.h\n\nlibtesseract_la_SOURCES += src/dict/context.cpp\nlibtesseract_la_SOURCES += src/dict/dawg.cpp\nlibtesseract_la_SOURCES += src/dict/dawg_cache.cpp\nlibtesseract_la_SOURCES += src/dict/dict.cpp\nlibtesseract_la_SOURCES += src/dict/stopper.cpp\nlibtesseract_la_SOURCES += src/dict/trie.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/dict/hyphen.cpp\nlibtesseract_la_SOURCES += src/dict/permdawg.cpp\nendif\n\n# Rules for src/lstm.\n\nlibtesseract_lstm_la_CPPFLAGS = $(AM_CPPFLAGS)\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/arch\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/ccstruct\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/ccutil\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/classify\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/cutil\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/dict\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/lstm\nlibtesseract_lstm_la_CPPFLAGS += -I$(top_srcdir)/src/viewer\nif !NO_TESSDATA_PREFIX\nlibtesseract_lstm_la_CPPFLAGS += -DTESSDATA_PREFIX='\"@datadir@\"'\nendif\n\nnoinst_HEADERS += src/lstm/convolve.h\nnoinst_HEADERS += src/lstm/fullyconnected.h\nnoinst_HEADERS += src/lstm/functions.h\nnoinst_HEADERS += src/lstm/input.h\nnoinst_HEADERS += src/lstm/lstm.h\nnoinst_HEADERS += src/lstm/lstmrecognizer.h\nnoinst_HEADERS += src/lstm/maxpool.h\nnoinst_HEADERS += src/lstm/network.h\nnoinst_HEADERS += src/lstm/networkio.h\nnoinst_HEADERS += src/lstm/networkscratch.h\nnoinst_HEADERS += src/lstm/parallel.h\nnoinst_HEADERS += src/lstm/plumbing.h\nnoinst_HEADERS += src/lstm/recodebeam.h\nnoinst_HEADERS += src/lstm/reconfig.h\nnoinst_HEADERS += src/lstm/reversed.h\nnoinst_HEADERS += src/lstm/series.h\nnoinst_HEADERS += src/lstm/static_shape.h\nnoinst_HEADERS += src/lstm/stridemap.h\nnoinst_HEADERS += src/lstm/weightmatrix.h\n\nnoinst_LTLIBRARIES += libtesseract_lstm.la\n\nlibtesseract_lstm_la_SOURCES = src/lstm/convolve.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/fullyconnected.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/functions.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/input.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/lstm.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/lstmrecognizer.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/maxpool.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/network.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/networkio.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/parallel.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/plumbing.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/recodebeam.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/reconfig.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/reversed.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/series.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/stridemap.cpp\nlibtesseract_lstm_la_SOURCES += src/lstm/weightmatrix.cpp\n\n# Rules for src/textord.\n\nnoinst_HEADERS += src/textord/alignedblob.h\nnoinst_HEADERS += src/textord/baselinedetect.h\nnoinst_HEADERS += src/textord/bbgrid.h\nnoinst_HEADERS += src/textord/blkocc.h\nnoinst_HEADERS += src/textord/blobgrid.h\nnoinst_HEADERS += src/textord/ccnontextdetect.h\nnoinst_HEADERS += src/textord/cjkpitch.h\nnoinst_HEADERS += src/textord/colfind.h\nnoinst_HEADERS += src/textord/colpartition.h\nnoinst_HEADERS += src/textord/colpartitionset.h\nnoinst_HEADERS += src/textord/colpartitiongrid.h\nnoinst_HEADERS += src/textord/devanagari_processing.h\nnoinst_HEADERS += src/textord/drawtord.h\nnoinst_HEADERS += src/textord/edgblob.h\nnoinst_HEADERS += src/textord/edgloop.h\nnoinst_HEADERS += src/textord/fpchop.h\nnoinst_HEADERS += src/textord/gap_map.h\nnoinst_HEADERS += src/textord/imagefind.h\nnoinst_HEADERS += src/textord/linefind.h\nnoinst_HEADERS += src/textord/makerow.h\nnoinst_HEADERS += src/textord/oldbasel.h\nnoinst_HEADERS += src/textord/pithsync.h\nnoinst_HEADERS += src/textord/pitsync1.h\nnoinst_HEADERS += src/textord/scanedg.h\nnoinst_HEADERS += src/textord/sortflts.h\nnoinst_HEADERS += src/textord/strokewidth.h\nnoinst_HEADERS += src/textord/tabfind.h\nnoinst_HEADERS += src/textord/tablefind.h\nnoinst_HEADERS += src/textord/tabvector.h\nnoinst_HEADERS += src/textord/tablerecog.h\nnoinst_HEADERS += src/textord/textlineprojection.h\nnoinst_HEADERS += src/textord/textord.h\nnoinst_HEADERS += src/textord/topitch.h\nnoinst_HEADERS += src/textord/tordmain.h\nnoinst_HEADERS += src/textord/tovars.h\nnoinst_HEADERS += src/textord/underlin.h\nnoinst_HEADERS += src/textord/wordseg.h\nnoinst_HEADERS += src/textord/workingpartset.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/textord/equationdetectbase.h\nendif\n\nlibtesseract_la_SOURCES += src/textord/alignedblob.cpp\nlibtesseract_la_SOURCES += src/textord/baselinedetect.cpp\nlibtesseract_la_SOURCES += src/textord/bbgrid.cpp\nlibtesseract_la_SOURCES += src/textord/blkocc.cpp\nlibtesseract_la_SOURCES += src/textord/blobgrid.cpp\nlibtesseract_la_SOURCES += src/textord/ccnontextdetect.cpp\nlibtesseract_la_SOURCES += src/textord/cjkpitch.cpp\nlibtesseract_la_SOURCES += src/textord/colfind.cpp\nlibtesseract_la_SOURCES += src/textord/colpartition.cpp\nlibtesseract_la_SOURCES += src/textord/colpartitionset.cpp\nlibtesseract_la_SOURCES += src/textord/colpartitiongrid.cpp\nlibtesseract_la_SOURCES += src/textord/devanagari_processing.cpp\nlibtesseract_la_SOURCES += src/textord/drawtord.cpp\nlibtesseract_la_SOURCES += src/textord/edgblob.cpp\nlibtesseract_la_SOURCES += src/textord/edgloop.cpp\nlibtesseract_la_SOURCES += src/textord/fpchop.cpp\nlibtesseract_la_SOURCES += src/textord/gap_map.cpp\nlibtesseract_la_SOURCES += src/textord/imagefind.cpp\nlibtesseract_la_SOURCES += src/textord/linefind.cpp\nlibtesseract_la_SOURCES += src/textord/makerow.cpp\nlibtesseract_la_SOURCES += src/textord/oldbasel.cpp\nlibtesseract_la_SOURCES += src/textord/pithsync.cpp\nlibtesseract_la_SOURCES += src/textord/pitsync1.cpp\nlibtesseract_la_SOURCES += src/textord/scanedg.cpp\nlibtesseract_la_SOURCES += src/textord/sortflts.cpp\nlibtesseract_la_SOURCES += src/textord/strokewidth.cpp\nlibtesseract_la_SOURCES += src/textord/tabfind.cpp\nlibtesseract_la_SOURCES += src/textord/tablefind.cpp\nlibtesseract_la_SOURCES += src/textord/tabvector.cpp\nlibtesseract_la_SOURCES += src/textord/tablerecog.cpp\nlibtesseract_la_SOURCES += src/textord/textlineprojection.cpp\nlibtesseract_la_SOURCES += src/textord/textord.cpp\nlibtesseract_la_SOURCES += src/textord/topitch.cpp\nlibtesseract_la_SOURCES += src/textord/tordmain.cpp\nlibtesseract_la_SOURCES += src/textord/tospace.cpp\nlibtesseract_la_SOURCES += src/textord/tovars.cpp\nlibtesseract_la_SOURCES += src/textord/underlin.cpp\nlibtesseract_la_SOURCES += src/textord/wordseg.cpp\nlibtesseract_la_SOURCES += src/textord/workingpartset.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/textord/equationdetectbase.cpp\nendif\n\n# Rules for src/viewer.\n\nif !GRAPHICS_DISABLED\nnoinst_HEADERS += src/viewer/scrollview.h\nnoinst_HEADERS += src/viewer/svmnode.h\nnoinst_HEADERS += src/viewer/svutil.h\n\nlibtesseract_la_SOURCES += src/viewer/scrollview.cpp\nlibtesseract_la_SOURCES += src/viewer/svmnode.cpp\nlibtesseract_la_SOURCES += src/viewer/svutil.cpp\n\nEXTRA_PROGRAMS += svpaint\nsvpaint_CPPFLAGS = $(AM_CPPFLAGS)\nsvpaint_CPPFLAGS += -I$(top_srcdir)/src/ccstruct\nsvpaint_CPPFLAGS += -I$(top_srcdir)/src/viewer\nsvpaint_SOURCES = src/svpaint.cpp\nsvpaint_LDADD = libtesseract.la\nendif\n\n# Rules for src/wordrec.\n\nnoinst_HEADERS += src/wordrec/wordrec.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/wordrec/associate.h\nnoinst_HEADERS += src/wordrec/chop.h\nnoinst_HEADERS += src/wordrec/drawfx.h\nnoinst_HEADERS += src/wordrec/findseam.h\nnoinst_HEADERS += src/wordrec/language_model.h\nnoinst_HEADERS += src/wordrec/lm_consistency.h\nnoinst_HEADERS += src/wordrec/lm_pain_points.h\nnoinst_HEADERS += src/wordrec/lm_state.h\nnoinst_HEADERS += src/wordrec/outlines.h\nnoinst_HEADERS += src/wordrec/params_model.h\nnoinst_HEADERS += src/wordrec/plotedges.h\nnoinst_HEADERS += src/wordrec/render.h\nendif\n\nlibtesseract_la_SOURCES += src/wordrec/tface.cpp\nlibtesseract_la_SOURCES += src/wordrec/wordrec.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_la_SOURCES += src/wordrec/associate.cpp\nlibtesseract_la_SOURCES += src/wordrec/chop.cpp\nlibtesseract_la_SOURCES += src/wordrec/chopper.cpp\nlibtesseract_la_SOURCES += src/wordrec/drawfx.cpp\nlibtesseract_la_SOURCES += src/wordrec/findseam.cpp\nlibtesseract_la_SOURCES += src/wordrec/gradechop.cpp\nlibtesseract_la_SOURCES += src/wordrec/language_model.cpp\nlibtesseract_la_SOURCES += src/wordrec/lm_consistency.cpp\nlibtesseract_la_SOURCES += src/wordrec/lm_pain_points.cpp\nlibtesseract_la_SOURCES += src/wordrec/lm_state.cpp\nlibtesseract_la_SOURCES += src/wordrec/outlines.cpp\nlibtesseract_la_SOURCES += src/wordrec/params_model.cpp\nlibtesseract_la_SOURCES += src/wordrec/pieces.cpp\nif !GRAPHICS_DISABLED\nlibtesseract_la_SOURCES += src/wordrec/plotedges.cpp\nendif\nlibtesseract_la_SOURCES += src/wordrec/render.cpp\nlibtesseract_la_SOURCES += src/wordrec/segsearch.cpp\nlibtesseract_la_SOURCES += src/wordrec/wordclass.cpp\nendif\n\n# Rules for tesseract executable.\n\nbin_PROGRAMS = tesseract\ntesseract_SOURCES = src/tesseract.cpp\ntesseract_CPPFLAGS = $(AM_CPPFLAGS)\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/arch\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/ccmain\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/ccstruct\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/ccutil\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/classify\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/cutil\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/dict\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/textord\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/viewer\ntesseract_CPPFLAGS += -I$(top_srcdir)/src/wordrec\n\ntesseract_LDFLAGS = $(OPENMP_CXXFLAGS)\n\ntesseract_LDADD = libtesseract.la\ntesseract_LDADD += $(LEPTONICA_LIBS)\ntesseract_LDADD += $(libarchive_LIBS)\ntesseract_LDADD += $(libcurl_LIBS)\n\nif T_WIN\ntesseract_LDADD += -ltiff\ntesseract_LDADD += -lws2_32\nendif\nif ADD_RT\ntesseract_LDADD += -lrt\nendif\n\n# Rules for training tools.\n\nif ENABLE_TRAINING\n\ntraining: $(trainingtools) | $(PROGRAMS)\n\ntraining-install: $(trainingtools)\n\tmkdir -p $(DESTDIR)$(bindir)\n\t$(LIBTOOL) $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=install \\\n\t$(INSTALL) $(INSTALL_STRIP_FLAG) $(trainingtools) $(DESTDIR)$(bindir)\n\ntraining-uninstall:\n\n# Some unit tests use code from training.\ncheck: libtesseract_training.la\n\n# dawg_test runs dawg2wordlist and wordlist2dawg.\ncheck: dawg2wordlist wordlist2dawg\n\nelse\n\ntraining:\n\t@echo \"Need to reconfigure project, so there are no errors\"\n\nendif\n\nCLEANFILES += $(EXTRA_PROGRAMS)\n\ntraining_CPPFLAGS = $(AM_CPPFLAGS)\ntraining_CPPFLAGS += -DPANGO_ENABLE_ENGINE\ntraining_CPPFLAGS += -DTESS_COMMON_TRAINING_API=\ntraining_CPPFLAGS += -DTESS_PANGO_TRAINING_API=\ntraining_CPPFLAGS += -DTESS_UNICHARSET_TRAINING_API=\ntraining_CPPFLAGS += -I$(top_srcdir)/src/training\ntraining_CPPFLAGS += -I$(top_srcdir)/src/training/common\ntraining_CPPFLAGS += -I$(top_srcdir)/src/training/pango\ntraining_CPPFLAGS += -I$(top_srcdir)/src/training/unicharset\ntraining_CPPFLAGS += -I$(top_srcdir)/src/api\ntraining_CPPFLAGS += -I$(top_srcdir)/src/ccmain\ntraining_CPPFLAGS += -I$(top_srcdir)/src/ccutil\ntraining_CPPFLAGS += -I$(top_srcdir)/src/ccstruct\ntraining_CPPFLAGS += -I$(top_srcdir)/src/lstm\ntraining_CPPFLAGS += -I$(top_srcdir)/src/arch\ntraining_CPPFLAGS += -I$(top_srcdir)/src/viewer\ntraining_CPPFLAGS += -I$(top_srcdir)/src/textord\ntraining_CPPFLAGS += -I$(top_srcdir)/src/dict\ntraining_CPPFLAGS += -I$(top_srcdir)/src/classify\ntraining_CPPFLAGS += -I$(top_srcdir)/src/wordrec\ntraining_CPPFLAGS += -I$(top_srcdir)/src/cutil\ntraining_CPPFLAGS += $(ICU_UC_CFLAGS) $(ICU_I18N_CFLAGS)\ntraining_CPPFLAGS += $(pango_CFLAGS)\ntraining_CPPFLAGS += $(cairo_CFLAGS)\n\nif DISABLED_LEGACY_ENGINE\ntraining_CPPFLAGS += -DDISABLED_LEGACY_ENGINE\nendif\n\n# TODO: training programs cannot be linked to shared library created\n# with -fvisibility\nif VISIBILITY\nAM_LDFLAGS += -all-static\nendif\n\nnoinst_HEADERS += src/training/pango/boxchar.h\nnoinst_HEADERS += src/training/common/commandlineflags.h\nnoinst_HEADERS += src/training/common/commontraining.h\nnoinst_HEADERS += src/training/common/ctc.h\nnoinst_HEADERS += src/training/common/networkbuilder.h\nnoinst_HEADERS += src/training/degradeimage.h\nnoinst_HEADERS += src/training/pango/ligature_table.h\nnoinst_HEADERS += src/training/pango/pango_font_info.h\nnoinst_HEADERS += src/training/pango/stringrenderer.h\nnoinst_HEADERS += src/training/pango/tlog.h\nnoinst_HEADERS += src/training/unicharset/icuerrorcode.h\nnoinst_HEADERS += src/training/unicharset/fileio.h\nnoinst_HEADERS += src/training/unicharset/lang_model_helpers.h\nnoinst_HEADERS += src/training/unicharset/lstmtester.h\nnoinst_HEADERS += src/training/unicharset/lstmtrainer.h\nnoinst_HEADERS += src/training/unicharset/normstrngs.h\nnoinst_HEADERS += src/training/unicharset/unicharset_training_utils.h\nnoinst_HEADERS += src/training/unicharset/validate_grapheme.h\nnoinst_HEADERS += src/training/unicharset/validate_indic.h\nnoinst_HEADERS += src/training/unicharset/validate_javanese.h\nnoinst_HEADERS += src/training/unicharset/validate_khmer.h\nnoinst_HEADERS += src/training/unicharset/validate_myanmar.h\nnoinst_HEADERS += src/training/unicharset/validator.h\nif !DISABLED_LEGACY_ENGINE\nnoinst_HEADERS += src/training/common/errorcounter.h\nnoinst_HEADERS += src/training/common/intfeaturedist.h\nnoinst_HEADERS += src/training/common/intfeaturemap.h\nnoinst_HEADERS += src/training/common/mastertrainer.h\nnoinst_HEADERS += src/training/common/sampleiterator.h\nnoinst_HEADERS += src/training/common/trainingsampleset.h\nnoinst_HEADERS += src/training/mergenf.h\nendif\n\nCLEANFILES += libtesseract_training.la\n\nEXTRA_LTLIBRARIES = libtesseract_training.la\n\nlibtesseract_training_la_CPPFLAGS = $(training_CPPFLAGS)\nlibtesseract_training_la_SOURCES = src/training/pango/boxchar.cpp\nlibtesseract_training_la_SOURCES += src/training/common/commandlineflags.cpp\nlibtesseract_training_la_SOURCES += src/training/common/commontraining.cpp\nlibtesseract_training_la_SOURCES += src/training/common/ctc.cpp\nlibtesseract_training_la_SOURCES += src/training/common/networkbuilder.cpp\nlibtesseract_training_la_SOURCES += src/training/degradeimage.cpp\nlibtesseract_training_la_SOURCES += src/training/pango/ligature_table.cpp\nlibtesseract_training_la_SOURCES += src/training/pango/pango_font_info.cpp\nlibtesseract_training_la_SOURCES += src/training/pango/stringrenderer.cpp\nlibtesseract_training_la_SOURCES += src/training/pango/tlog.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/icuerrorcode.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/fileio.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/lang_model_helpers.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/lstmtester.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/lstmtrainer.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/normstrngs.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/unicharset_training_utils.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/validate_grapheme.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/validate_indic.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/validate_javanese.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/validate_khmer.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/validate_myanmar.cpp\nlibtesseract_training_la_SOURCES += src/training/unicharset/validator.cpp\nif !DISABLED_LEGACY_ENGINE\nlibtesseract_training_la_SOURCES += src/training/common/errorcounter.cpp\nlibtesseract_training_la_SOURCES += src/training/common/intfeaturedist.cpp\nlibtesseract_training_la_SOURCES += src/training/common/intfeaturemap.cpp\nlibtesseract_training_la_SOURCES += src/training/common/mastertrainer.cpp\nlibtesseract_training_la_SOURCES += src/training/common/sampleiterator.cpp\nlibtesseract_training_la_SOURCES += src/training/common/trainingsampleset.cpp\nendif\n\ntrainingtools = combine_lang_model$(EXEEXT)\ntrainingtools += combine_tessdata$(EXEEXT)\ntrainingtools += dawg2wordlist$(EXEEXT)\ntrainingtools += lstmeval$(EXEEXT)\ntrainingtools += lstmtraining$(EXEEXT)\ntrainingtools += merge_unicharsets$(EXEEXT)\ntrainingtools += set_unicharset_properties$(EXEEXT)\ntrainingtools += text2image$(EXEEXT)\ntrainingtools += unicharset_extractor$(EXEEXT)\ntrainingtools += wordlist2dawg$(EXEEXT)\nif !DISABLED_LEGACY_ENGINE\ntrainingtools += ambiguous_words$(EXEEXT)\ntrainingtools += classifier_tester$(EXEEXT)\ntrainingtools += cntraining$(EXEEXT)\ntrainingtools += mftraining$(EXEEXT)\ntrainingtools += shapeclustering$(EXEEXT)\nendif\n\n$(trainingtools): libtesseract.la\n\nEXTRA_PROGRAMS += $(trainingtools)\n\nextralib = libtesseract.la\nextralib += $(libarchive_LIBS)\nextralib += $(LEPTONICA_LIBS)\nif T_WIN\nextralib += -lws2_32\nendif\n\nif !DISABLED_LEGACY_ENGINE\nambiguous_words_CPPFLAGS = $(training_CPPFLAGS)\nambiguous_words_SOURCES = src/training/ambiguous_words.cpp\nambiguous_words_LDADD = libtesseract_training.la\nambiguous_words_LDADD += $(extralib)\n\nclassifier_tester_CPPFLAGS = $(training_CPPFLAGS)\nclassifier_tester_SOURCES = src/training/classifier_tester.cpp\nclassifier_tester_LDADD = libtesseract_training.la\nclassifier_tester_LDADD += $(extralib)\n\ncntraining_CPPFLAGS = $(training_CPPFLAGS)\ncntraining_SOURCES = src/training/cntraining.cpp\ncntraining_LDADD = libtesseract_training.la\ncntraining_LDADD += $(extralib)\n\nmftraining_CPPFLAGS = $(training_CPPFLAGS)\nmftraining_SOURCES = src/training/mftraining.cpp src/training/mergenf.cpp\nmftraining_LDADD = libtesseract_training.la\nmftraining_LDADD += $(ICU_UC_LIBS)\nmftraining_LDADD += $(extralib)\n\nshapeclustering_CPPFLAGS = $(training_CPPFLAGS)\nshapeclustering_SOURCES = src/training/shapeclustering.cpp\nshapeclustering_LDADD = libtesseract_training.la\nshapeclustering_LDADD += $(extralib)\nendif\n\ncombine_lang_model_CPPFLAGS = $(training_CPPFLAGS)\ncombine_lang_model_SOURCES = src/training/combine_lang_model.cpp\ncombine_lang_model_LDADD = libtesseract_training.la\ncombine_lang_model_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\ncombine_lang_model_LDADD += $(extralib)\n\ncombine_tessdata_CPPFLAGS = $(training_CPPFLAGS)\ncombine_tessdata_SOURCES = src/training/combine_tessdata.cpp\ncombine_tessdata_LDADD = $(extralib)\n\ndawg2wordlist_CPPFLAGS = $(training_CPPFLAGS)\ndawg2wordlist_SOURCES = src/training/dawg2wordlist.cpp\ndawg2wordlist_LDADD = $(extralib)\n\nlstmeval_CPPFLAGS = $(training_CPPFLAGS)\nlstmeval_SOURCES = src/training/lstmeval.cpp\nlstmeval_LDADD = libtesseract_training.la\nlstmeval_LDADD += $(ICU_UC_LIBS)\nlstmeval_LDADD += $(extralib)\n\nlstmtraining_CPPFLAGS = $(training_CPPFLAGS)\nlstmtraining_SOURCES = src/training/lstmtraining.cpp\nlstmtraining_LDADD = libtesseract_training.la\nlstmtraining_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\nlstmtraining_LDADD += $(extralib)\n\nmerge_unicharsets_CPPFLAGS = $(training_CPPFLAGS)\nmerge_unicharsets_SOURCES = src/training/merge_unicharsets.cpp\nmerge_unicharsets_LDADD = $(extralib)\n\nset_unicharset_properties_CPPFLAGS = $(training_CPPFLAGS)\nset_unicharset_properties_SOURCES = src/training/set_unicharset_properties.cpp\nset_unicharset_properties_LDADD = libtesseract_training.la\nset_unicharset_properties_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\nset_unicharset_properties_LDADD += $(extralib)\n\ntext2image_CPPFLAGS = $(training_CPPFLAGS)\ntext2image_SOURCES = src/training/text2image.cpp\ntext2image_LDADD = libtesseract_training.la\ntext2image_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\ntext2image_LDADD += $(extralib)\ntext2image_LDADD += $(ICU_UC_LIBS) $(cairo_LIBS)\ntext2image_LDADD += $(pango_LIBS) $(pangocairo_LIBS) $(pangoft2_LIBS)\n\nunicharset_extractor_CPPFLAGS = $(training_CPPFLAGS)\nunicharset_extractor_SOURCES = src/training/unicharset_extractor.cpp\nunicharset_extractor_LDADD = libtesseract_training.la\nunicharset_extractor_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\nunicharset_extractor_LDADD += $(extralib)\n\nwordlist2dawg_CPPFLAGS = $(training_CPPFLAGS)\nwordlist2dawg_SOURCES = src/training/wordlist2dawg.cpp\nwordlist2dawg_LDADD = $(extralib)\n\n# fuzzer-api is used for fuzzing tests.\n# They are run by OSS-Fuzz https://oss-fuzz.com/, but can also be run locally.\n# Note: -fsanitize=fuzzer currently requires the clang++ compiler.\n\n# LIB_FUZZING_ENGINE can be overridden by the caller.\n# This is used by OSS-Fuzz.\nLIB_FUZZING_ENGINE ?= -fsanitize=fuzzer\n\nfuzzer-api: libtesseract.la\nfuzzer-api: unittest/fuzzers/fuzzer-api.cpp\n\t$(CXX) $(CXXFLAGS) -g $(LIB_FUZZING_ENGINE) \\\n          -I $(top_srcdir)/include \\\n          -I $(builddir)/include \\\n          -I $(top_srcdir)/src/ccmain \\\n          -I $(top_srcdir)/src/ccstruct \\\n          -I $(top_srcdir)/src/ccutil \\\n          $(LEPTONICA_CFLAGS) \\\n          $(OPENMP_CXXFLAGS) \\\n          $< \\\n          $(builddir)/.libs/libtesseract.a \\\n          $(LEPTONICA_LIBS) \\\n          $(libarchive_LIBS) \\\n          $(libcurl_LIBS) \\\n          -o $@\n\nfuzzer-api-512x256: libtesseract.la\nfuzzer-api-512x256: unittest/fuzzers/fuzzer-api.cpp\n\t$(CXX) $(CXXFLAGS) -g $(LIB_FUZZING_ENGINE) \\\n          -DTESSERACT_FUZZER_WIDTH=512 \\\n          -DTESSERACT_FUZZER_HEIGHT=256 \\\n          -I $(top_srcdir)/include \\\n          -I $(builddir)/include \\\n          -I $(top_srcdir)/src/ccmain \\\n          -I $(top_srcdir)/src/ccstruct \\\n          -I $(top_srcdir)/src/ccutil \\\n          $(LEPTONICA_CFLAGS) \\\n          $(OPENMP_CXXFLAGS) \\\n          $< \\\n          $(builddir)/.libs/libtesseract.a \\\n          $(LEPTONICA_LIBS) \\\n          $(libarchive_LIBS) \\\n          $(libcurl_LIBS) \\\n          -o $@\n\nCLEANFILES += fuzzer-api fuzzer-api-512x256\n\nif ASCIIDOC\n\nman_MANS = doc/combine_lang_model.1\nman_MANS += doc/combine_tessdata.1\nman_MANS += doc/dawg2wordlist.1\nman_MANS += doc/lstmeval.1\nman_MANS += doc/lstmtraining.1\nman_MANS += doc/merge_unicharsets.1\nman_MANS += doc/set_unicharset_properties.1\nman_MANS += doc/tesseract.1\nman_MANS += doc/text2image.1\nman_MANS += doc/unicharset.5\nman_MANS += doc/unicharset_extractor.1\nman_MANS += doc/wordlist2dawg.1\n\nif !DISABLED_LEGACY_ENGINE\nman_MANS += doc/ambiguous_words.1\nman_MANS += doc/classifier_tester.1\nman_MANS += doc/cntraining.1\nman_MANS += doc/mftraining.1\nman_MANS += doc/shapeclustering.1\nman_MANS += doc/unicharambigs.5\nendif\n\nman_xslt = http://docbook.sourceforge.net/release/xsl/current/manpages/docbook.xsl\n\nEXTRA_DIST += $(man_MANS) doc/Doxyfile\n\nhtml: ${man_MANS:%=%.html}\npdf: ${man_MANS:%=%.pdf}\n\nSUFFIXES = .asc .html .pdf\n\n.asc:\nif HAVE_XML_CATALOG_FILES\n\tasciidoc -b docbook -d manpage -o - $< | \\\n\tXML_CATALOG_FILES=$(XML_CATALOG_FILES) xsltproc --nonet -o $@ $(man_xslt) -\nelse\n\tasciidoc -b docbook -d manpage -o - $< | \\\n\txsltproc --nonet -o $@ $(man_xslt) -\nendif\n\n.asc.html:\n\tasciidoc -b html5 -o $@ $<\n\n.asc.pdf:\n\tasciidoc -b docbook -d manpage -o $*.dbk $<\n\tdocbook2pdf -o doc $*.dbk\n\nMAINTAINERCLEANFILES = $(man_MANS) Doxyfile\n\nendif\n\n# Absolute path of directory 'langdata'.\nLANGDATA_DIR=$(shell cd $(top_srcdir) && cd .. && pwd)/langdata_lstm\n\n# Absolute path of directory 'tessdata' with traineddata files\n# (must be on same level as top source directory).\nTESSDATA_DIR=$(shell cd $(top_srcdir) && cd .. && pwd)/tessdata\n\n# Absolute path of directory 'testing' with test images and ground truth texts\n# (using submodule test).\nTESTING_DIR=$(shell cd $(top_srcdir) && pwd)/test/testing\n# Absolute path of directory 'testdata' with test unicharset etc.\n# (using submodule test).\nTESTDATA_DIR=$(shell cd $(top_srcdir) && pwd)/test/testdata\n\n# Suppress some memory leaks reported by LeakSanitizer.\nexport LSAN_OPTIONS=suppressions=$(top_srcdir)/unittest/tesseract_leaksanitizer.supp\n\nunittest_CPPFLAGS = $(AM_CPPFLAGS)\nunittest_CPPFLAGS += -DTESSBIN_DIR=\"\\\"$(abs_top_builddir)\\\"\"\nunittest_CPPFLAGS += -DLANGDATA_DIR=\"\\\"$(LANGDATA_DIR)\\\"\"\nunittest_CPPFLAGS += -DTESSDATA_DIR=\"\\\"$(TESSDATA_DIR)\\\"\"\nunittest_CPPFLAGS += -DTESTING_DIR=\"\\\"$(TESTING_DIR)\\\"\"\nunittest_CPPFLAGS += -DTESTDATA_DIR=\"\\\"$(TESTDATA_DIR)\\\"\"\nunittest_CPPFLAGS += -DPANGO_ENABLE_ENGINE\nif DISABLED_LEGACY_ENGINE\nunittest_CPPFLAGS += -DDISABLED_LEGACY_ENGINE\nendif # DISABLED_LEGACY_ENGINE\nunittest_CPPFLAGS += -DTESS_COMMON_TRAINING_API=\nunittest_CPPFLAGS += -DTESS_PANGO_TRAINING_API=\nunittest_CPPFLAGS += -DTESS_UNICHARSET_TRAINING_API=\nunittest_CPPFLAGS += -I$(top_srcdir)/src/arch\nunittest_CPPFLAGS += -I$(top_srcdir)/src/ccmain\nunittest_CPPFLAGS += -I$(top_srcdir)/src/ccstruct\nunittest_CPPFLAGS += -I$(top_srcdir)/src/ccutil\nunittest_CPPFLAGS += -I$(top_srcdir)/src/classify\nunittest_CPPFLAGS += -I$(top_srcdir)/src/cutil\nunittest_CPPFLAGS += -I$(top_srcdir)/src/dict\nunittest_CPPFLAGS += -I$(top_srcdir)/src/display\nunittest_CPPFLAGS += -I$(top_srcdir)/src/lstm\nunittest_CPPFLAGS += -I$(top_srcdir)/src/textord\nunittest_CPPFLAGS += -I$(top_srcdir)/unittest/base\nunittest_CPPFLAGS += -I$(top_srcdir)/unittest/util\nunittest_CPPFLAGS += $(LEPTONICA_CFLAGS)\nif ENABLE_TRAINING\nunittest_CPPFLAGS += -I$(top_srcdir)/src/training\nunittest_CPPFLAGS += -I$(top_srcdir)/src/training/common\nunittest_CPPFLAGS += -I$(top_srcdir)/src/training/pango\nunittest_CPPFLAGS += -I$(top_srcdir)/src/training/unicharset\nunittest_CPPFLAGS += $(pangocairo_CFLAGS)\nendif # ENABLE_TRAINING\nunittest_CPPFLAGS += -I$(top_srcdir)/src/viewer\nunittest_CPPFLAGS += -I$(top_srcdir)/src/wordrec\nunittest_CPPFLAGS += -I$(top_srcdir)/unittest\n\n# Build googletest:\ncheck_LTLIBRARIES = libgtest.la libgtest_main.la libgmock.la libgmock_main.la\nlibgtest_la_SOURCES = unittest/third_party/googletest/googletest/src/gtest-all.cc\nlibgtest_la_CPPFLAGS = -I$(top_srcdir)/unittest/third_party/googletest/googletest/include\nlibgtest_la_CPPFLAGS += -I$(top_srcdir)/unittest/third_party/googletest/googletest\nlibgtest_la_CPPFLAGS += -pthread\nlibgtest_main_la_SOURCES = unittest/third_party/googletest/googletest/src/gtest_main.cc\nlibgtest_main_la_CPPFLAGS = $(libgtest_la_CPPFLAGS)\n\nGMOCK_INCLUDES = -I$(top_srcdir)/unittest/third_party/googletest/googlemock/include \\\n                 -I$(top_srcdir)/unittest/third_party/googletest/googlemock \\\n                 -I$(top_srcdir)/unittest/third_party/googletest/googletest/include \\\n                 -I$(top_srcdir)/unittest/third_party/googletest/googletest\n\nlibgmock_la_SOURCES = unittest/third_party/googletest/googlemock/src/gmock-all.cc\nlibgmock_la_CPPFLAGS = $(GMOCK_INCLUDES) \\\n                       -pthread\nlibgmock_main_la_SOURCES = unittest/third_party/googletest/googlemock/src/gmock_main.cc\nlibgmock_main_la_CPPFLAGS = $(GMOCK_INCLUDES) \\\n                            -pthread\n\n# Build unittests\nGTEST_LIBS =  libgtest.la libgtest_main.la -lpthread\nGMOCK_LIBS =  libgmock.la libgmock_main.la\nTESS_LIBS = $(GTEST_LIBS)\nTESS_LIBS += libtesseract.la $(libarchive_LIBS)\nTRAINING_LIBS = libtesseract_training.la\nTRAINING_LIBS += $(TESS_LIBS)\nunittest_CPPFLAGS += -isystem $(top_srcdir)/unittest/third_party/googletest/googletest/include\nunittest_CPPFLAGS += -isystem $(top_srcdir)/unittest/third_party/googletest/googlemock/include\n\ncheck_PROGRAMS = apiexample_test\nif ENABLE_TRAINING\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += applybox_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += baseapi_test\ncheck_PROGRAMS += baseapi_thread_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += bitvector_test\nendif # !DISABLED_LEGACY_ENGINE\nendif # ENABLE_TRAINING\ncheck_PROGRAMS += cleanapi_test\ncheck_PROGRAMS += colpartition_test\nif ENABLE_TRAINING\ncheck_PROGRAMS += commandlineflags_test\ncheck_PROGRAMS += dawg_test\nendif # ENABLE_TRAINING\ncheck_PROGRAMS += denorm_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += equationdetect_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += fileio_test\ncheck_PROGRAMS += heap_test\ncheck_PROGRAMS += imagedata_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += indexmapbidi_test\ncheck_PROGRAMS += intfeaturemap_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += intsimdmatrix_test\ncheck_PROGRAMS += lang_model_test\ncheck_PROGRAMS += layout_test\ncheck_PROGRAMS += ligature_table_test\ncheck_PROGRAMS += linlsq_test\ncheck_PROGRAMS += list_test\nif ENABLE_TRAINING\ncheck_PROGRAMS += lstm_recode_test\ncheck_PROGRAMS += lstm_squashed_test\ncheck_PROGRAMS += lstm_test\ncheck_PROGRAMS += lstmtrainer_test\nendif # ENABLE_TRAINING\ncheck_PROGRAMS += loadlang_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += mastertrainer_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += matrix_test\ncheck_PROGRAMS += networkio_test\nif ENABLE_TRAINING\ncheck_PROGRAMS += normstrngs_test\nendif # ENABLE_TRAINING\ncheck_PROGRAMS += nthitem_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += osd_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += pagesegmode_test\nif ENABLE_TRAINING\ncheck_PROGRAMS += pango_font_info_test\nendif # ENABLE_TRAINING\ncheck_PROGRAMS += paragraphs_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += params_model_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += progress_test\ncheck_PROGRAMS += qrsequence_test\ncheck_PROGRAMS += recodebeam_test\ncheck_PROGRAMS += rect_test\ncheck_PROGRAMS += resultiterator_test\ncheck_PROGRAMS += scanutils_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += shapetable_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += stats_test\ncheck_PROGRAMS += stridemap_test\ncheck_PROGRAMS += stringrenderer_test\ncheck_PROGRAMS += tablefind_test\ncheck_PROGRAMS += tablerecog_test\ncheck_PROGRAMS += tabvector_test\ncheck_PROGRAMS += tatweel_test\nif !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += textlineprojection_test\nendif # !DISABLED_LEGACY_ENGINE\ncheck_PROGRAMS += tfile_test\nif ENABLE_TRAINING\ncheck_PROGRAMS += unichar_test\ncheck_PROGRAMS += unicharcompress_test\ncheck_PROGRAMS += unicharset_test\ncheck_PROGRAMS += validate_grapheme_test\ncheck_PROGRAMS += validate_indic_test\ncheck_PROGRAMS += validate_khmer_test\ncheck_PROGRAMS += validate_myanmar_test\ncheck_PROGRAMS += validator_test\nendif # ENABLE_TRAINING\n\ncheck_PROGRAMS: libtesseract.la libtesseract_training.la\n\nTESTS = $(check_PROGRAMS)\n\n# List of source files needed to build the executable:\n\napiexample_test_SOURCES = unittest/apiexample_test.cc\napiexample_test_CPPFLAGS = $(unittest_CPPFLAGS)\napiexample_test_LDFLAGS = $(LEPTONICA_LIBS)\napiexample_test_LDADD = $(TESS_LIBS) $(LEPTONICA_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\napplybox_test_SOURCES = unittest/applybox_test.cc\napplybox_test_CPPFLAGS = $(unittest_CPPFLAGS)\napplybox_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nbaseapi_test_SOURCES = unittest/baseapi_test.cc\nbaseapi_test_CPPFLAGS = $(unittest_CPPFLAGS)\nbaseapi_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\n\nbaseapi_thread_test_SOURCES = unittest/baseapi_thread_test.cc\nbaseapi_thread_test_CPPFLAGS = $(unittest_CPPFLAGS)\nbaseapi_thread_test_LDADD = $(TESS_LIBS) $(LEPTONICA_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nbitvector_test_SOURCES = unittest/bitvector_test.cc\nbitvector_test_CPPFLAGS = $(unittest_CPPFLAGS)\nbitvector_test_LDADD = $(TRAINING_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\ncleanapi_test_SOURCES = unittest/cleanapi_test.cc\ncleanapi_test_CPPFLAGS = $(unittest_CPPFLAGS)\ncleanapi_test_LDADD = $(TESS_LIBS)\n\ncolpartition_test_SOURCES = unittest/colpartition_test.cc\ncolpartition_test_CPPFLAGS = $(unittest_CPPFLAGS)\ncolpartition_test_LDADD = $(TESS_LIBS)\n\ncommandlineflags_test_SOURCES = unittest/commandlineflags_test.cc\ncommandlineflags_test_CPPFLAGS = $(unittest_CPPFLAGS)\ncommandlineflags_test_LDADD = $(TRAINING_LIBS) $(ICU_UC_LIBS)\n\ndawg_test_SOURCES = unittest/dawg_test.cc\ndawg_test_CPPFLAGS = $(unittest_CPPFLAGS)\ndawg_test_LDADD = $(TRAINING_LIBS)\n\ndenorm_test_SOURCES = unittest/denorm_test.cc\ndenorm_test_CPPFLAGS = $(unittest_CPPFLAGS)\ndenorm_test_LDADD = $(TESS_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nequationdetect_test_SOURCES = unittest/equationdetect_test.cc\nequationdetect_test_CPPFLAGS = $(unittest_CPPFLAGS)\nequationdetect_test_LDADD = $(TESS_LIBS) $(LEPTONICA_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nfileio_test_SOURCES = unittest/fileio_test.cc\nfileio_test_CPPFLAGS = $(unittest_CPPFLAGS)\nfileio_test_LDADD = $(TRAINING_LIBS)\n\nheap_test_SOURCES = unittest/heap_test.cc\nheap_test_CPPFLAGS = $(unittest_CPPFLAGS)\nheap_test_LDADD = $(TESS_LIBS)\n\nimagedata_test_SOURCES = unittest/imagedata_test.cc\nimagedata_test_CPPFLAGS = $(unittest_CPPFLAGS)\nimagedata_test_LDADD = $(TRAINING_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nindexmapbidi_test_SOURCES = unittest/indexmapbidi_test.cc\nindexmapbidi_test_CPPFLAGS = $(unittest_CPPFLAGS)\nindexmapbidi_test_LDADD = $(TRAINING_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nif !DISABLED_LEGACY_ENGINE\nintfeaturemap_test_SOURCES = unittest/intfeaturemap_test.cc\nintfeaturemap_test_CPPFLAGS = $(unittest_CPPFLAGS)\nintfeaturemap_test_LDADD = $(TRAINING_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nintsimdmatrix_test_SOURCES = unittest/intsimdmatrix_test.cc\nintsimdmatrix_test_CPPFLAGS = $(unittest_CPPFLAGS)\nif HAVE_AVX2\nintsimdmatrix_test_CPPFLAGS += -DHAVE_AVX2\nendif\nif HAVE_SSE4_1\nintsimdmatrix_test_CPPFLAGS += -DHAVE_SSE4_1\nendif\nintsimdmatrix_test_LDADD = $(TESS_LIBS)\n\nlang_model_test_SOURCES = unittest/lang_model_test.cc\nlang_model_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlang_model_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nlayout_test_SOURCES = unittest/layout_test.cc\nlayout_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlayout_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\n\nligature_table_test_SOURCES = unittest/ligature_table_test.cc\nligature_table_test_CPPFLAGS = $(unittest_CPPFLAGS)\nligature_table_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\nligature_table_test_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\nligature_table_test_LDADD += $(pangocairo_LIBS) $(pangoft2_LIBS)\nligature_table_test_LDADD += $(cairo_LIBS) $(pango_LIBS)\n\nlinlsq_test_SOURCES = unittest/linlsq_test.cc\nlinlsq_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlinlsq_test_LDADD = $(TESS_LIBS)\n\nlist_test_SOURCES = unittest/list_test.cc\nlist_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlist_test_LDADD = $(TESS_LIBS)\n\nloadlang_test_SOURCES = unittest/loadlang_test.cc\nloadlang_test_CPPFLAGS = $(unittest_CPPFLAGS)\nloadlang_test_LDADD = $(TESS_LIBS) $(LEPTONICA_LIBS)\n\nlstm_recode_test_SOURCES = unittest/lstm_recode_test.cc\nlstm_recode_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlstm_recode_test_LDADD = $(TRAINING_LIBS)\n\nlstm_squashed_test_SOURCES = unittest/lstm_squashed_test.cc\nlstm_squashed_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlstm_squashed_test_LDADD = $(TRAINING_LIBS)\n\nlstm_test_SOURCES = unittest/lstm_test.cc\nlstm_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlstm_test_LDADD = $(TRAINING_LIBS)\n\nlstmtrainer_test_SOURCES = unittest/lstmtrainer_test.cc\nlstmtrainer_test_CPPFLAGS = $(unittest_CPPFLAGS)\nlstmtrainer_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nmastertrainer_test_SOURCES = unittest/mastertrainer_test.cc\nmastertrainer_test_CPPFLAGS = $(unittest_CPPFLAGS)\nmastertrainer_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nmatrix_test_SOURCES = unittest/matrix_test.cc\nmatrix_test_CPPFLAGS = $(unittest_CPPFLAGS)\nmatrix_test_LDADD = $(TESS_LIBS)\n\nnetworkio_test_SOURCES = unittest/networkio_test.cc\nnetworkio_test_CPPFLAGS = $(unittest_CPPFLAGS)\nnetworkio_test_LDADD = $(TESS_LIBS)\n\nnormstrngs_test_SOURCES = unittest/normstrngs_test.cc\nnormstrngs_test_CPPFLAGS = $(unittest_CPPFLAGS)\nnormstrngs_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nnthitem_test_SOURCES = unittest/nthitem_test.cc\nnthitem_test_CPPFLAGS = $(unittest_CPPFLAGS)\nnthitem_test_LDADD = $(TESS_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nosd_test_SOURCES = unittest/osd_test.cc\nosd_test_CPPFLAGS = $(unittest_CPPFLAGS)\nosd_test_LDADD = $(TESS_LIBS) $(LEPTONICA_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\npagesegmode_test_SOURCES = unittest/pagesegmode_test.cc\npagesegmode_test_CPPFLAGS = $(unittest_CPPFLAGS)\npagesegmode_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\n\npango_font_info_test_SOURCES = unittest/pango_font_info_test.cc\npango_font_info_test_CPPFLAGS = $(unittest_CPPFLAGS)\npango_font_info_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\npango_font_info_test_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\npango_font_info_test_LDADD += $(pangocairo_LIBS)\npango_font_info_test_LDADD += $(pangoft2_LIBS)\n\nparagraphs_test_SOURCES = unittest/paragraphs_test.cc\nparagraphs_test_CPPFLAGS = $(unittest_CPPFLAGS)\nparagraphs_test_LDADD = $(TESS_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nparams_model_test_SOURCES = unittest/params_model_test.cc\nparams_model_test_CPPFLAGS = $(unittest_CPPFLAGS)\nparams_model_test_LDADD = $(TRAINING_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nprogress_test_SOURCES = unittest/progress_test.cc\nprogress_test_CPPFLAGS = $(unittest_CPPFLAGS)\nprogress_test_LDFLAGS = $(LEPTONICA_LIBS)\nprogress_test_LDADD = $(GTEST_LIBS) $(GMOCK_LIBS) $(TESS_LIBS) $(LEPTONICA_LIBS)\n\nqrsequence_test_SOURCES = unittest/qrsequence_test.cc\nqrsequence_test_CPPFLAGS = $(unittest_CPPFLAGS)\nqrsequence_test_LDADD = $(TESS_LIBS)\n\nrecodebeam_test_SOURCES = unittest/recodebeam_test.cc\nrecodebeam_test_CPPFLAGS = $(unittest_CPPFLAGS)\nrecodebeam_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nrect_test_SOURCES = unittest/rect_test.cc\nrect_test_CPPFLAGS = $(unittest_CPPFLAGS)\nrect_test_LDADD = $(TESS_LIBS)\n\nresultiterator_test_SOURCES = unittest/resultiterator_test.cc\nresultiterator_test_CPPFLAGS = $(unittest_CPPFLAGS)\nresultiterator_test_LDADD = $(TRAINING_LIBS)\nresultiterator_test_LDADD += $(LEPTONICA_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nscanutils_test_SOURCES = unittest/scanutils_test.cc\nscanutils_test_CPPFLAGS = $(unittest_CPPFLAGS)\nscanutils_test_LDADD = $(TRAINING_LIBS)\n\nif !DISABLED_LEGACY_ENGINE\nshapetable_test_SOURCES = unittest/shapetable_test.cc\nshapetable_test_CPPFLAGS = $(unittest_CPPFLAGS)\nshapetable_test_LDADD = $(TRAINING_LIBS)\nendif # !DISABLED_LEGACY_ENGINE\n\nstats_test_SOURCES = unittest/stats_test.cc\nstats_test_CPPFLAGS = $(unittest_CPPFLAGS)\nstats_test_LDADD = $(TESS_LIBS)\n\nstridemap_test_SOURCES = unittest/stridemap_test.cc\nstridemap_test_CPPFLAGS = $(unittest_CPPFLAGS)\nstridemap_test_LDADD = $(TESS_LIBS)\n\nstringrenderer_test_SOURCES = unittest/stringrenderer_test.cc\nstringrenderer_test_CPPFLAGS = $(unittest_CPPFLAGS)\nstringrenderer_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\nstringrenderer_test_LDADD += $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\nstringrenderer_test_LDADD += $(pangocairo_LIBS) $(pangoft2_LIBS)\nstringrenderer_test_LDADD += $(cairo_LIBS) $(pango_LIBS)\n\ntablefind_test_SOURCES = unittest/tablefind_test.cc\ntablefind_test_CPPFLAGS = $(unittest_CPPFLAGS)\ntablefind_test_LDADD = $(TESS_LIBS)\n\ntablerecog_test_SOURCES = unittest/tablerecog_test.cc\ntablerecog_test_CPPFLAGS = $(unittest_CPPFLAGS)\ntablerecog_test_LDADD = $(TESS_LIBS)\n\ntabvector_test_SOURCES = unittest/tabvector_test.cc\ntabvector_test_CPPFLAGS = $(unittest_CPPFLAGS)\ntabvector_test_LDADD = $(TESS_LIBS)\n\ntatweel_test_SOURCES = unittest/tatweel_test.cc\ntatweel_test_SOURCES += unittest/third_party/utf/rune.c\ntatweel_test_SOURCES += unittest/util/utf8/unicodetext.cc\ntatweel_test_SOURCES += unittest/util/utf8/unilib.cc\ntatweel_test_CPPFLAGS = $(unittest_CPPFLAGS)\ntatweel_test_LDADD = $(TRAINING_LIBS)\n\ntextlineprojection_test_SOURCES = unittest/textlineprojection_test.cc\ntextlineprojection_test_CPPFLAGS = $(unittest_CPPFLAGS)\ntextlineprojection_test_LDADD = $(TRAINING_LIBS) $(LEPTONICA_LIBS)\n\ntfile_test_SOURCES = unittest/tfile_test.cc\ntfile_test_CPPFLAGS = $(unittest_CPPFLAGS)\ntfile_test_LDADD = $(TESS_LIBS)\n\nunichar_test_SOURCES = unittest/unichar_test.cc\nunichar_test_CPPFLAGS = $(unittest_CPPFLAGS)\nunichar_test_LDADD = $(TRAINING_LIBS) $(ICU_UC_LIBS)\n\nunicharcompress_test_SOURCES = unittest/unicharcompress_test.cc\nunicharcompress_test_CPPFLAGS = $(unittest_CPPFLAGS)\nunicharcompress_test_LDADD = $(TRAINING_LIBS) $(ICU_UC_LIBS)\n\nunicharset_test_SOURCES = unittest/unicharset_test.cc\nunicharset_test_CPPFLAGS = $(unittest_CPPFLAGS)\nunicharset_test_LDADD = $(TRAINING_LIBS) $(ICU_UC_LIBS)\n\nvalidate_grapheme_test_SOURCES = unittest/validate_grapheme_test.cc\nvalidate_grapheme_test_CPPFLAGS = $(unittest_CPPFLAGS)\nvalidate_grapheme_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nvalidate_indic_test_SOURCES = unittest/validate_indic_test.cc\nvalidate_indic_test_CPPFLAGS = $(unittest_CPPFLAGS)\nvalidate_indic_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nvalidate_khmer_test_SOURCES = unittest/validate_khmer_test.cc\nvalidate_khmer_test_CPPFLAGS = $(unittest_CPPFLAGS)\nvalidate_khmer_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nvalidate_myanmar_test_SOURCES = unittest/validate_myanmar_test.cc\nvalidate_myanmar_test_CPPFLAGS = $(unittest_CPPFLAGS)\nvalidate_myanmar_test_LDADD = $(TRAINING_LIBS) $(ICU_I18N_LIBS) $(ICU_UC_LIBS)\n\nvalidator_test_SOURCES = unittest/validator_test.cc\nvalidator_test_CPPFLAGS = $(unittest_CPPFLAGS)\nvalidator_test_LDADD = $(TRAINING_LIBS) $(ICU_UC_LIBS)\n\n# for windows\nif T_WIN\napiexample_test_LDADD += -lws2_32\nintsimdmatrix_test_LDADD += -lws2_32\nmatrix_test_LDADD += -lws2_32\nif !DISABLED_LEGACY_ENGINE\nosd_test_LDADD += -lws2_32\nendif # !DISABLED_LEGACY_ENGINE\nloadlang_test_LDADD += -lws2_32\nendif\n\nEXTRA_apiexample_test_DEPENDENCIES = $(abs_top_builddir)/test/testing/phototest.tif\nEXTRA_apiexample_test_DEPENDENCIES += $(abs_top_builddir)/test/testing/phototest.txt\n\n$(abs_top_builddir)/test/testing/phototest.tif:\n\tmkdir -p $(top_builddir)/test/testing\n\tln -s $(TESTING_DIR)/phototest.tif $(top_builddir)/test/testing/phototest.tif\n\n$(abs_top_builddir)/test/testing/phototest.txt:\n\tmkdir -p $(top_builddir)/test/testing\n\tln -s $(TESTING_DIR)/phototest.txt $(top_builddir)/test/testing/phototest.txt\n\n# Some tests require a local tmp directory.\n\n$(check_PROGRAMS): | tmp\n\ntmp:\n\tmkdir -p tmp\n\n# Some tests require a well defined set of the following font files.\n\nfonts = ae_Arab.ttf\nfonts += Arial_Bold_Italic.ttf\nfonts += DejaVuSans-ExtraLight.ttf\nfonts += Lohit-Hindi.ttf\nfonts += Times_New_Roman.ttf\nfonts += UnBatang.ttf\nfonts += Verdana.ttf\n\n# These tests depend on installed model files and fonts:\n#\n# apiexample_test baseapi_test lang_model_test layout_test\n# ligature_table_test loadlang_test lstm_recode_test lstm_squashed_test\n# lstm_test lstmtrainer_test mastertrainer_test osd_test\n# pagesegmode_test pango_font_info_test progress_test\n# recodebeam_test resultiterator_test stringrenderer_test\n# textlineprojection_test unicharcompress_test\n#\n# Instead of fine-tuned dependencies the following lines\n# simply require those dependencies for all tests.\n# That can be improved if necessary.\n\n$(check_PROGRAMS): | $(LANGDATA_DIR)\n$(check_PROGRAMS): | $(TESSDATA_DIR)\n$(check_PROGRAMS): | $(TESSDATA_BEST_DIR)\n$(check_PROGRAMS): | $(TESSDATA_FAST_DIR)\n$(check_PROGRAMS): | $(fonts:%=$(TESTING_DIR)/%)\n\n$(LANGDATA_DIR) $(TESSDATA_DIR) $(TESSDATA_BEST_DIR) $(TESSDATA_FAST_DIR):\n\t@echo \"Some unit tests require $@.\"\n\t@echo \"It can be installed manually by running this command:\"\n\t@echo \"  git clone https://github.com/tesseract-ocr/$$(basename $@).git $@\"\n\t@exit 1\n\n$(TESTING_DIR)/Arial_Bold_Italic.ttf:\n\tcurl -sSL -o Arial.exe https://sourceforge.net/projects/corefonts/files/the%20fonts/final/arial32.exe/download\n\tcabextract -F Arialbi.TTF -q Arial.exe\n\trm Arial.exe\n\tmv Arialbi.TTF $@\n\n$(TESTING_DIR)/DejaVuSans-ExtraLight.ttf:\n\tcurl -sSL http://sourceforge.net/projects/dejavu/files/dejavu/2.37/dejavu-fonts-ttf-2.37.tar.bz2 | \\\n\ttar -xjO dejavu-fonts-ttf-2.37/ttf/DejaVuSans-ExtraLight.ttf >$@\n\n$(TESTING_DIR)/Lohit-Hindi.ttf:\n\tcurl -sSL https://releases.pagure.org/lohit/lohit-hindi-ttf-2.4.3.tar.gz | \\\n\ttar -xzO lohit-hindi-ttf-2.4.3/Lohit-Hindi.ttf >$@\n\n$(TESTING_DIR)/Times_New_Roman.ttf:\n\tcurl -sSL -o Times.exe https://sourceforge.net/projects/corefonts/files/the%20fonts/final/times32.exe/download\n\tcabextract -F Times.TTF -q Times.exe\n\trm Times.exe\n\tmv Times.TTF $@\n\n$(TESTING_DIR)/UnBatang.ttf:\n\tcurl -sSL -o $@ https://salsa.debian.org/fonts-team/fonts-unfonts-core/-/raw/master/UnBatang.ttf\n\n$(TESTING_DIR)/Verdana.ttf:\n\tcurl -sSL -o Verdana.exe https://sourceforge.net/projects/corefonts/files/the%20fonts/final/verdan32.exe/download\n\tcabextract -F Verdana.TTF -q Verdana.exe\n\trm Verdana.exe\n\tmv Verdana.TTF $@\n\n$(TESTING_DIR)/ae_Arab.ttf:\n\tcurl -sSL -o $@ https://salsa.debian.org/fonts-team/fonts-arabeyes/-/raw/master/ae_Arab.ttf\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.95,
          "content": "# Tesseract OCR\n\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/tesseract-ocr/badge.svg)](https://scan.coverity.com/projects/tesseract-ocr)\n[![CodeQL](https://github.com/tesseract-ocr/tesseract/workflows/CodeQL/badge.svg)](https://github.com/tesseract-ocr/tesseract/security/code-scanning)\n[![OSS-Fuzz](https://img.shields.io/badge/oss--fuzz-fuzzing-brightgreen)](https://issues.oss-fuzz.com/issues?q=is:open%20title:tesseract-ocr)\n\\\n[![GitHub license](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/LICENSE)\n[![Downloads](https://img.shields.io/badge/download-all%20releases-brightgreen.svg)](https://github.com/tesseract-ocr/tesseract/releases/)\n\n## Table of Contents\n\n* [Tesseract OCR](#tesseract-ocr)\n  * [About](#about)\n  * [Brief history](#brief-history)\n  * [Installing Tesseract](#installing-tesseract)\n  * [Running Tesseract](#running-tesseract)\n  * [For developers](#for-developers)\n  * [Support](#support)\n  * [License](#license)\n  * [Dependencies](#dependencies)\n  * [Latest Version of README](#latest-version-of-readme)\n\n## About\n\nThis package contains an **OCR engine** - `libtesseract` and a **command line program** - `tesseract`.\n\nTesseract 4 adds a new neural net (LSTM) based [OCR engine](https://en.wikipedia.org/wiki/Optical_character_recognition) which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0).\nIt also needs [traineddata](https://tesseract-ocr.github.io/tessdoc/Data-Files.html) files which support the legacy engine, for example those from the [tessdata](https://github.com/tesseract-ocr/tessdata) repository.\n\nStefan Weil is the current lead developer. Ray Smith was the lead developer until 2018. The maintainer is Zdenko Podobny. For a list of contributors see [AUTHORS](https://github.com/tesseract-ocr/tesseract/blob/main/AUTHORS)\nand GitHub's log of [contributors](https://github.com/tesseract-ocr/tesseract/graphs/contributors).\n\nTesseract has **unicode (UTF-8) support**, and can **recognize [more than 100 languages](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html)** \"out of the box\".\n\nTesseract supports **[various image formats](https://tesseract-ocr.github.io/tessdoc/InputFormats)** including PNG, JPEG and TIFF.\n\nTesseract supports **various output formats**: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV, ALTO and PAGE.\n\nYou should note that in many cases, in order to get better OCR results, you'll need to **[improve the quality](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html) of the image** you are giving Tesseract.\n\nThis project **does not include a GUI application**. If you need one, please see the [3rdParty](https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty.html) documentation.\n\nTesseract **can be trained to recognize other languages**.\nSee [Tesseract Training](https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html) for more information.\n\n## Brief history\n\nTesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.\n\nMajor version 5 is the current stable version and started with release\n[5.0.0](https://github.com/tesseract-ocr/tesseract/releases/tag/5.0.0) on November 30, 2021. Newer minor versions and bugfix versions are available from\n[GitHub](https://github.com/tesseract-ocr/tesseract/releases/).\n\nLatest source code is available from [main branch on GitHub](https://github.com/tesseract-ocr/tesseract/tree/main).\nOpen issues can be found in [issue tracker](https://github.com/tesseract-ocr/tesseract/issues),\nand [planning documentation](https://tesseract-ocr.github.io/tessdoc/Planning.html).\n\nSee **[Release Notes](https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html)**\nand **[Change Log](https://github.com/tesseract-ocr/tesseract/blob/main/ChangeLog)** for more details of the releases.\n\n## Installing Tesseract\n\nYou can either [Install Tesseract via pre-built binary package](https://tesseract-ocr.github.io/tessdoc/Installation.html)\nor [build it from source](https://tesseract-ocr.github.io/tessdoc/Compiling.html).\n\nBefore building Tesseract from source, please check that your system has a compiler which is one of the [supported compilers](https://tesseract-ocr.github.io/tessdoc/supported-compilers.html).\n\n## Running Tesseract\n\nBasic **[command line usage](https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html)**:\n\n    tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]\n\nFor more information about the various command line options use `tesseract --help` or `man tesseract`.\n\nExamples can be found in the [documentation](https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image).\n\n## For developers\n\nDevelopers can use `libtesseract` [C](https://github.com/tesseract-ocr/tesseract/blob/main/include/tesseract/capi.h) or\n[C++](https://github.com/tesseract-ocr/tesseract/blob/main/include/tesseract/baseapi.h) API to build their own application. If you need bindings to `libtesseract` for other programming languages, please see the\n[wrapper](https://tesseract-ocr.github.io/tessdoc/AddOns.html#tesseract-wrappers) section in the AddOns documentation.\n\nDocumentation of Tesseract generated from source code by doxygen can be found on [tesseract-ocr.github.io](https://tesseract-ocr.github.io/).\n\n## Support\n\nBefore you submit an issue, please review **[the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/main/CONTRIBUTING.md)**.\n\nFor support, first read the [documentation](https://tesseract-ocr.github.io/tessdoc/),\nparticularly the [FAQ](https://tesseract-ocr.github.io/tessdoc/FAQ.html) to see if your problem is addressed there.\nIf not, search the [Tesseract user forum](https://groups.google.com/g/tesseract-ocr), the [Tesseract developer forum](https://groups.google.com/g/tesseract-dev) and [past issues](https://github.com/tesseract-ocr/tesseract/issues), and if you still can't find what you need, ask for support in the mailing-lists.\n\nMailing-lists:\n\n* [tesseract-ocr](https://groups.google.com/g/tesseract-ocr) - For tesseract users.\n* [tesseract-dev](https://groups.google.com/g/tesseract-dev) - For tesseract developers.\n\nPlease report an issue only for a **bug**, not for asking questions.\n\n## License\n\n    The code in this repository is licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n**NOTE**: This software depends on other packages that may be licensed under different open source licenses.\n\nTesseract uses [Leptonica library](http://leptonica.com/) which essentially\nuses a [BSD 2-clause license](http://leptonica.com/about-the-license.html).\n\n## Dependencies\n\nTesseract uses [Leptonica library](https://github.com/DanBloomberg/leptonica)\nfor opening input images (e.g. not documents like pdf).\nIt is suggested to use leptonica with built-in support for [zlib](https://zlib.net),\n[png](https://sourceforge.net/projects/libpng) and\n[tiff](http://www.simplesystems.org/libtiff) (for multipage tiff).\n\n## Latest Version of README\n\nFor the latest online version of the README.md see:\n\n<https://github.com/tesseract-ocr/tesseract/blob/main/README.md>\n"
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.01,
          "content": "5.5.0\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 1.47,
          "content": "environment:\n  matrix:\n    - APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2022\n      platform: Win64\n\nconfiguration:\n  - Release\n\ncache:\n  - c:/Users/appveyor/.sw -> appveyor.yml\n\nonly_commits:\n  files:\n    - appveyor.yml\n    - '**.cpp'\n    - '**.h'\n    - 'unittest/**.c'\n    - 'unittest/**.cc'\n\nbefore_build:\n  - git submodule update --init --recursive\n  - curl -fsS -L -o dl.zip https://software-network.org/client/sw-master-windows_x86_64-client.zip\n  - 7z x dl.zip\n  - set PATH=%PATH%;%cd%\n\nbuild_script:\n  - sw -version\n  # -show-output - show command output\n  # debug build causes long builds (> 1h), appveyor drops them\n  - sw -platform %platform% -config r build -Dwith-tests=1\n  # test\n  - git clone https://github.com/egorpugin/tessdata tessdata_unittest\n  - ps: Copy-Item -Path \"tessdata_unittest\\fonts\\*\" -Destination \"test\\testing\" -Recurse\n  - sw -platform %platform% -config r test -Dwith-tests=1 -Dskip-tests=lstm,lstm_recode\n\nafter_build:\n  - 7z a tesseract.zip %APPVEYOR_BUILD_FOLDER%\\.sw\\out\\**\\*.exe %APPVEYOR_BUILD_FOLDER%\\.sw\\out\\**\\*.dll\n  #- 7z a tesseract.zip %APPVEYOR_BUILD_FOLDER%\\.sw\\Windows_*_Shared_Release_MSVC_*\\*.exe %APPVEYOR_BUILD_FOLDER%\\.sw\\Windows_*_Shared_Release_MSVC_*\\*.dll\n\non_finish:\n  # gather tests\n  - ps: $wc = New-Object 'System.Net.WebClient'\n  - ps: $wc.UploadFile(\"https://ci.appveyor.com/api/testresults/junit/$($env:APPVEYOR_JOB_ID)\", (Resolve-Path .\\.sw\\test\\results.xml))\n\nartifacts:\n  - path: tesseract.zip\n    name: tesseract-$(APPVEYOR_BUILD_VERSION)\n\n"
        },
        {
          "name": "autogen.sh",
          "type": "blob",
          "size": 3.93,
          "content": "#!/bin/sh\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n# http://www.apache.org/licenses/LICENSE-2.0\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This is a simple script which is meant to help developers\n# better deal with the GNU autotools, specifically:\n#\n#   aclocal\n#   libtoolize\n#   autoconf\n#   autoheader\n#   automake\n#\n# The whole thing is quite complex...\n#\n# The idea is to run this collection of tools on a single platform,\n# typically the main development platform, running a recent version of\n# autoconf. In theory, if we had these tools on each platform where we\n# ever expected to port the software, we would never need to checkin\n# more than a few autotools configuration files. However, the whole\n# idea is to generate a configure script and associated files in a way\n# that is portable across platforms, so we *have* to check in a whole\n# bunch of files generated by all these tools.\n\n# The real source files are:\n#\n# acinclude.m4 (used by aclocal)\n# configure.ac (main autoconf file)\n# Makefile.am, */Makefile.am (automake config files)\n#\n# All the rest is auto-generated.\n\nif [ \"$1\" = \"clean\" ]; then\n    echo \"Cleaning...\"\n    rm configure aclocal.m4\n    rm m4/l*\n    rm config/*\n    rmdir config\n    find . -iname \"Makefile.in\" -type f -exec rm '{}' +\nfi\n\nbail_out()\n{\n    echo\n    echo \"  Something went wrong, bailing out!\"\n    echo\n    exit 1\n}\n\n# Prevent any errors that might result from failing to properly invoke\n# `libtoolize` or `glibtoolize,` whichever is present on your system,\n# from occurring by testing for its existence and capturing the absolute path to\n# its location for caching purposes prior to using it later on in 'Step 2:'\nif command -v libtoolize >/dev/null 2>&1; then\n  LIBTOOLIZE=\"$(command -v libtoolize)\"\nelif command -v glibtoolize >/dev/null 2>&1; then\n  LIBTOOLIZE=\"$(command -v glibtoolize)\"\nelse\n  echo \"Unable to find a valid copy of libtoolize or glibtoolize in your PATH!\"\n  bail_out\nfi\n\n# --- Step 1: Generate aclocal.m4 from:\n#             . acinclude.m4\n#             . config/*.m4 (these files are referenced in acinclude.m4)\n\nmkdir -p config\n\necho \"Running aclocal\"\naclocal -I config || bail_out\n\n# --- Step 2:\n\necho \"Running $LIBTOOLIZE\"\n$LIBTOOLIZE -f -c || bail_out\n$LIBTOOLIZE --automake || bail_out\n\n# Run aclocal a 2nd time because glibtoolize created additional m4 files.\necho \"Running aclocal\"\naclocal -I config || bail_out\n\n# --- Step 3: Generate configure and include/miaconfig.h from:\n#             . configure.ac\n#\n\necho \"Running autoconf\"\nautoconf || bail_out\n\nif grep -q PKG_CHECK_MODULES configure; then\n  # The generated configure is invalid because pkg-config is unavailable.\n  rm configure\n  echo \"Missing pkg-config. Check the build requirements.\"\n  bail_out\nfi\n\n# --- Step 4: Generate config.h.in from:\n#             . configure.ac (look for AM_CONFIG_HEADER tag or AC_CONFIG_HEADER tag)\n\necho \"Running autoheader\"\nautoheader -f || bail_out\n\n# --- Step 5: Generate Makefile.in, src/Makefile.in, and a whole bunch of\n#             files in config (config.guess, config.sub, depcomp,\n#             install-sh, missing, mkinstalldirs) plus COPYING and\n#             INSTALL from:\n#             . Makefile.am\n#             . src/Makefile.am\n#\n# Using --add-missing --copy makes sure that, if these files are missing,\n# they are copied from the system so they can be used in a distribution.\n\necho \"Running automake --add-missing --copy\"\nautomake --add-missing --copy --warnings=all || bail_out\n\necho \"\"\necho \"All done.\"\necho \"To build the software now, do something like:\"\necho \"\"\necho \"$ ./configure [--enable-debug] [...other options]\"\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure.ac",
          "type": "blob",
          "size": 19.52,
          "content": "# -*-Shell-script-*-\n#\n# Copyright (c) Luc Vincent\n\n# ----------------------------------------\n# Initialization\n# ----------------------------------------\nAC_PREREQ([2.69])\nAC_INIT([tesseract],\n        [m4_esyscmd_s([test -d .git && git describe --abbrev=4 2>/dev/null || cat VERSION])],\n        [https://github.com/tesseract-ocr/tesseract/issues],,\n        [https://github.com/tesseract-ocr/tesseract/])\n\n# Store command like options for CXXFLAGS\nOLD_CXXFLAGS=$CXXFLAGS\nAC_PROG_CXX([g++ clang++])\n# reset compiler flags to initial flags\nAC_LANG([C++])\nAC_LANG_COMPILER_REQUIRE\nCXXFLAGS=${CXXFLAGS:-\"\"}\nAC_CONFIG_MACRO_DIR([m4])\nAC_CONFIG_AUX_DIR([config])\nAC_CONFIG_SRCDIR([src/tesseract.cpp])\nAC_PREFIX_DEFAULT([/usr/local])\n\n# Automake configuration. Do not require README file (we use README.md).\nAM_INIT_AUTOMAKE([foreign subdir-objects nostdinc])\n\n# Define date of package, etc. Could be useful in auto-generated\n# documentation.\nPACKAGE_YEAR=2024\nPACKAGE_DATE=\"11/10\"\n\nabs_top_srcdir=`AS_DIRNAME([$0])`\n\nAC_DEFINE_UNQUOTED([PACKAGE_NAME], [\"${PACKAGE_NAME}\"], [Name of package])\nAC_DEFINE_UNQUOTED([PACKAGE_VERSION], [\"${PACKAGE_VERSION}\"], [Version number])\nAC_DEFINE_UNQUOTED([PACKAGE_YEAR], [\"$PACKAGE_YEAR\"], [Official year for this release])\nAC_DEFINE_UNQUOTED([PACKAGE_DATE], [\"$PACKAGE_DATE\"], [Official date of release])\n\nAC_SUBST([PACKAGE_NAME])\nAC_SUBST([PACKAGE_VERSION])\nAC_SUBST([PACKAGE_YEAR])\nAC_SUBST([PACKAGE_DATE])\n\nGENERIC_LIBRARY_NAME=tesseract\n\n# Release versioning. Get versions from PACKAGE_VERSION.\nAX_SPLIT_VERSION\nGENERIC_MAJOR_VERSION=$(echo \"$AX_MAJOR_VERSION\" | $SED 's/^[[^0-9]]*//')\nGENERIC_MINOR_VERSION=$AX_MINOR_VERSION\nGENERIC_MICRO_VERSION=`echo \"$AX_POINT_VERSION\" | $SED 's/^\\([[0-9]][[0-9]]*\\).*/\\1/'`\n\n# API version (often = GENERIC_MAJOR_VERSION.GENERIC_MINOR_VERSION)\nGENERIC_API_VERSION=$GENERIC_MAJOR_VERSION.$GENERIC_MINOR_VERSION\nGENERIC_LIBRARY_VERSION=$GENERIC_MAJOR_VERSION:$GENERIC_MINOR_VERSION\nAC_SUBST([GENERIC_API_VERSION])\nAC_SUBST([GENERIC_MAJOR_VERSION])\nAC_SUBST([GENERIC_MINOR_VERSION])\nAC_SUBST([GENERIC_MICRO_VERSION])\n\nAC_SUBST([GENERIC_LIBRARY_VERSION])\nPACKAGE=$GENERIC_LIBRARY_NAME\nAC_SUBST([GENERIC_LIBRARY_NAME])\n\nGENERIC_VERSION=$GENERIC_MAJOR_VERSION.$GENERIC_MINOR_VERSION.$GENERIC_MICRO_VERSION\nGENERIC_RELEASE=$GENERIC_MAJOR_VERSION.$GENERIC_MINOR_VERSION\nAC_SUBST([GENERIC_RELEASE])\nAC_SUBST([GENERIC_VERSION])\n\nAC_CONFIG_HEADERS([include/config_auto.h:config/config.h.in])\n\n# default conditional\nAM_CONDITIONAL([T_WIN], false)\nAM_CONDITIONAL([MINGW], false)\nAM_CONDITIONAL([GRAPHICS_DISABLED], false)\nAC_SUBST([AM_CPPFLAGS])\n\n# Be less noisy by default.\n# Can be overridden with `configure --disable-silent-rules` or with `make V=1`.\nAM_SILENT_RULES([yes])\n\n#############################\n#\n# Platform specific setup\n#\n#############################\nAC_CANONICAL_HOST\ncase \"${host_os}\" in\n    mingw*)\n        AC_DEFINE_UNQUOTED([MINGW], 1, [This is a MinGW system])\n        AM_CONDITIONAL([T_WIN], true)\n        AM_CONDITIONAL([MINGW], true)\n        AM_CONDITIONAL([ADD_RT], false)\n        AC_SUBST([AM_LDFLAGS], ['-no-undefined'])\n        ;;\n    cygwin*)\n        AM_CONDITIONAL([ADD_RT], false)\n        AC_SUBST([NOUNDEFINED], ['-no-undefined'])\n        ;;\n    solaris*)\n        LIBS=\"$LIBS -lsocket -lnsl -lrt -lxnet\"\n        AM_CONDITIONAL([ADD_RT], true)\n        ;;\n    *darwin*)\n        AM_CONDITIONAL([ADD_RT], false)\n        ;;\n    *android*|openbsd*)\n        AM_CONDITIONAL([ADD_RT], false)\n        ;;\n    powerpc-*-darwin*)\n        ;;\n    *)\n        # default\n        AM_CONDITIONAL([ADD_RT], true)\n        ;;\nesac\n\nWERROR=-Werror\n# The test code used by AX_CHECK_COMPILE_FLAG uses an empty statement\n# and unused macros which must not raise a compiler error, but it must\n# be an error if flags like -avx are ignored on ARM and other\n# architectures because they are unsupported.\nAX_CHECK_COMPILE_FLAG([-Werror=unused-command-line-argument], [WERROR=-Werror=unused-command-line-argument])\n\n## Checks for supported compiler options.\n\nAM_CONDITIONAL([HAVE_AVX], false)\nAM_CONDITIONAL([HAVE_AVX2], false)\nAM_CONDITIONAL([HAVE_AVX512F], false)\nAM_CONDITIONAL([HAVE_FMA], false)\nAM_CONDITIONAL([HAVE_SSE4_1], false)\nAM_CONDITIONAL([HAVE_NEON], false)\nAM_CONDITIONAL([HAVE_RVV], false)\n\ncase \"${host_cpu}\" in\n\n  amd64|*86*)\n\n    AX_CHECK_COMPILE_FLAG([-mavx], [avx=true], [avx=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_AVX], ${avx})\n    if $avx; then\n      AC_DEFINE([HAVE_AVX], [1], [Enable AVX instructions])\n    fi\n\n    AX_CHECK_COMPILE_FLAG([-mavx2], [avx2=true], [avx2=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_AVX2], $avx2)\n    if $avx2; then\n      AC_DEFINE([HAVE_AVX2], [1], [Enable AVX2 instructions])\n    fi\n\n    AX_CHECK_COMPILE_FLAG([-mavx512f], [avx512f=true], [avx512f=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_AVX512F], $avx512f)\n    if $avx512f; then\n      AC_DEFINE([HAVE_AVX512F], [1], [Enable AVX512F instructions])\n    fi\n\n    AX_CHECK_COMPILE_FLAG([-mfma], [fma=true], [fma=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_FMA], $fma)\n    if $fma; then\n      AC_DEFINE([HAVE_FMA], [1], [Enable FMA instructions])\n    fi\n\n    AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=true], [sse41=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_SSE4_1], $sse41)\n    if $sse41; then\n      AC_DEFINE([HAVE_SSE4_1], [1], [Enable SSE 4.1 instructions])\n    fi\n\n    ;;\n\n  aarch64*|arm64)\n\n    # ARMv8 always has NEON and does not need special compiler flags.\n    AM_CONDITIONAL([HAVE_NEON], true)\n    AC_DEFINE([HAVE_NEON], [1], [Enable NEON instructions])\n    ;;\n\n  arm*)\n\n    AX_CHECK_COMPILE_FLAG([-mfpu=neon], [neon=true], [neon=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_NEON], $neon)\n    if $neon; then\n      AC_DEFINE([HAVE_NEON], [1], [Enable NEON instructions])\n      NEON_CXXFLAGS=\"-mfpu=neon\"\n      AC_SUBST([NEON_CXXFLAGS])\n      check_for_neon=1\n    fi\n\n    ;;\n\n  riscv*)\n\n    AX_CHECK_COMPILE_FLAG([-march=rv64gcv], [rvv=true], [rvv=false], [$WERROR])\n    AM_CONDITIONAL([HAVE_RVV], [$rvv])\n    if $rvv; then\n      AC_DEFINE([HAVE_RVV], [1], [Enable RVV instructions])\n      check_for_rvv=1\n    fi\n    ;;\n\n  *)\n\n    AC_MSG_WARN([No compiler options for $host_cpu])\n\nesac\n\n# check whether feenableexcept is supported. some C libraries (e.g. uclibc) don't.\nAC_CHECK_FUNCS([feenableexcept])\n\n# additional checks for NEON targets\nif test x$check_for_neon = x1; then\n  AC_MSG_NOTICE([checking how to detect NEON availability])\n  AC_CHECK_FUNCS([getauxval elf_aux_info android_getCpuFamily])\n\n  if test $ac_cv_func_getauxval = no && test $ac_cv_func_elf_aux_info = no && test $ac_cv_func_android_getCpuFamily = no; then\n      AC_MSG_WARN([NEON is available, but we don't know how to check for it.  Will not be able to use NEON.])\n  fi\nfi\n\n# additional checks for RVV targets\nif test x$check_for_rvv = x1; then\n  AC_MSG_NOTICE([checking how to detect RVV availability])\n  AC_CHECK_FUNCS([getauxval])\n\n  if test $ac_cv_func_getauxval = no; then\n      AC_MSG_WARN([RVV is available, but we don't know how to check for it.  Will not be able to use RVV.])\n  fi\nfi\n\nAX_CHECK_COMPILE_FLAG([-fopenmp-simd], [openmp_simd=true], [openmp_simd=false], [$WERROR])\nAM_CONDITIONAL([OPENMP_SIMD], $openmp_simd)\n\nAC_ARG_WITH([extra-includes],\n            [AS_HELP_STRING([--with-extra-includes=DIR],\n                       [Define an additional directory for include files])],\n            [if test -d \"$withval\" ; then\n               CFLAGS=\"$CFLAGS -I$withval\"\n             else\n               AC_MSG_ERROR([Cannot stat directory $withval])\n             fi])\n\nAC_ARG_WITH([extra-libraries],\n            [AS_HELP_STRING([--with-extra-libraries=DIR],\n                       [Define an additional directory for library files])],\n            [if test -d \"$withval\" ; then\n              LDFLAGS=\"$LDFLAGS -L$withval\"\n             else\n               AC_MSG_ERROR([Cannot stat directory $withval])\n             fi])\n\nAC_MSG_CHECKING([--enable-float32 argument])\nAC_ARG_ENABLE([float32],\n\t      AS_HELP_STRING([--disable-float32], [disable float and enable double for LSTM]))\nAC_MSG_RESULT([$enable_float32])\nif test \"$enable_float32\" != \"no\"; then\n  AC_DEFINE([FAST_FLOAT], [1], [Enable float for LSTM])\nfi\n\nAC_MSG_CHECKING([--enable-graphics argument])\nAC_ARG_ENABLE([graphics],\n  AS_HELP_STRING([--disable-graphics], [disable graphics (ScrollView)]))\nAC_MSG_RESULT([$enable_graphics])\nif test \"$enable_graphics\" = \"no\"; then\n  AC_DEFINE([GRAPHICS_DISABLED], [], [Disable graphics])\n  AM_CONDITIONAL([GRAPHICS_DISABLED], true)\nfi\n\nAC_MSG_CHECKING([--enable-legacy argument])\nAC_ARG_ENABLE([legacy],\n  AS_HELP_STRING([--disable-legacy], [disable the legacy OCR engine]))\nAC_MSG_RESULT([$enable_legacy])\nAM_CONDITIONAL([DISABLED_LEGACY_ENGINE], test \"$enable_legacy\" = \"no\")\nif test \"$enable_legacy\" = \"no\"; then\n  AC_DEFINE([DISABLED_LEGACY_ENGINE], [1], [Disable legacy OCR engine])\nfi\n\n# check whether to build OpenMP support\nAC_OPENMP\n\nhave_tiff=false\n# Note that the first usage of AC_CHECK_HEADERS must be unconditional.\nAC_CHECK_HEADERS([tiffio.h], [have_tiff=true], [have_tiff=false])\n\n# Configure arguments which allow disabling some optional libraries.\nAC_ARG_WITH([archive],\n            AS_HELP_STRING([--with-archive],\n                           [Build with libarchive which supports compressed model files @<:@default=check@:>@]),\n            [], [with_archive=check])\nAC_ARG_WITH([curl],\n            AS_HELP_STRING([--with-curl],\n                           [Build with libcurl which supports processing an image URL @<:@default=check@:>@]),\n            [], [with_curl=check])\n\n# https://lists.apple.com/archives/unix-porting/2009/Jan/msg00026.html\nm4_define([MY_CHECK_FRAMEWORK],\n  [AC_CACHE_CHECK([if -framework $1 works],[my_cv_framework_$1],\n     [save_LIBS=\"$LIBS\"\n     LIBS=\"$LIBS -framework $1\"\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n             [my_cv_framework_$1=yes],\n            [my_cv_framework_$1=no])\n     LIBS=\"$save_LIBS\"\n    ])\n   if test \"$my_cv_framework_$1\"=\"yes\"; then\n     AC_DEFINE(AS_TR_CPP([HAVE_FRAMEWORK_$1]), 1,\n            [Define if you have the $1 framework])\n     AS_TR_CPP([FRAMEWORK_$1])=\"-framework $1\"\n     AC_SUBST(AS_TR_CPP([FRAMEWORK_$1]))\n   fi]\n)\n\ncase \"${host_os}\" in\n  *darwin* | *-macos10*)\n    MY_CHECK_FRAMEWORK([Accelerate])\n    if test $my_cv_framework_Accelerate = yes; then\n      AM_CPPFLAGS=\"-DHAVE_FRAMEWORK_ACCELERATE $AM_CPPFLAGS\"\n      AM_LDFLAGS=\"$AM_LDFLAGS -framework Accelerate\"\n    fi\n    ;;\n  *)\n    # default\n    ;;\nesac\n\n# check whether to build tesseract with -fvisibility=hidden -fvisibility-inlines-hidden\n# http://gcc.gnu.org/wiki/Visibility\n# https://groups.google.com/g/tesseract-dev/c/l2ZFrpgYkSc/m/_cdYSRDSXuUJ\nAC_MSG_CHECKING([--enable-visibility argument])\nAC_ARG_ENABLE([visibility],\n  AS_HELP_STRING([--enable-visibility],\n                 [enable experimental build with -fvisibility [default=no]]))\nAC_MSG_RESULT([$enable_visibility])\nAM_CONDITIONAL([VISIBILITY], [test \"$enable_visibility\" = \"yes\"])\n\n# Check if tessdata-prefix is disabled\nAC_MSG_CHECKING([whether to use tessdata-prefix])\nAC_ARG_ENABLE([tessdata-prefix],\n    [AS_HELP_STRING([--disable-tessdata-prefix],\n            [don't set TESSDATA-PREFIX during compile])],\n    [tessdata_prefix=\"no\"], [tessdata_prefix=\"yes\"])\nAC_MSG_RESULT([$tessdata_prefix])\nAM_CONDITIONAL([NO_TESSDATA_PREFIX], [test \"$tessdata_prefix\" = \"no\"])\n\n\n# Detect Clang compiler\nAC_MSG_CHECKING([if compiling with clang])\nAC_COMPILE_IFELSE(\n[AC_LANG_PROGRAM([], [[\n#ifndef __clang__\n       not clang\n#endif\n]])],\n[CLANG=yes], [CLANG=no])\nAC_MSG_RESULT([$CLANG])\n\n# Check whether to enable debugging\nAC_MSG_CHECKING([whether to enable debugging])\nAC_ARG_ENABLE([debug],\n  AS_HELP_STRING([--enable-debug], [turn on debugging [default=no]]))\nAC_MSG_RESULT([$enable_debug])\nif test x\"$enable_debug\" = x\"yes\"; then\n    CXXFLAGS=${CXXFLAGS:-\"-O2\"}\n    AM_CPPFLAGS=\"$AM_CPPFLAGS -g -Wall -DDEBUG -pedantic\"\n    AM_CXXFLAGS=\"$AM_CXXFLAGS -g -Wall -DDEBUG -pedantic\"\n    if test \"x$CLANG\" = \"xyes\"; then\n        # https://clang.llvm.org/docs/CommandGuide/clang.html\n        # clang treats -Og as -O1\n        AM_CPPFLAGS=\"$AM_CPPFLAGS -O0\"\n        AM_CXXFLAGS=\"$AM_CXXFLAGS -O0\"\n    else\n        AM_CPPFLAGS=\"$AM_CPPFLAGS -Og\"\n        AM_CXXFLAGS=\"$AM_CXXFLAGS -Og\"\n    fi\nelse\n    AM_CXXFLAGS=\"$AM_CXXFLAGS -O2 -DNDEBUG\"\n    AM_CPPFLAGS=\"$AM_CPPFLAGS -O2 -DNDEBUG\"\nfi\n\n# ----------------------------------------\n# Init libtool\n# ----------------------------------------\n\nLT_INIT\n\n\n# ----------------------------------------\n# C++ related options\n# ----------------------------------------\ndnl **********************\ndnl Turn on C++17 or newer\ndnl **********************\n\nCPLUSPLUS=\nAX_CHECK_COMPILE_FLAG([-std=c++17], [CPLUSPLUS=17], [], [$WERROR])\nAX_CHECK_COMPILE_FLAG([-std=c++20], [CPLUSPLUS=20], [], [$WERROR])\n\nif test -z \"$CPLUSPLUS\"; then\n  AC_MSG_ERROR([Your compiler does not have the necessary C++17 support! Cannot proceed.])\nfi\n\n# Set C++17 or newer support based on platform/compiler\ncase \"${host_os}\" in\n  cygwin*)\n    CXXFLAGS=\"$CXXFLAGS -std=gnu++$CPLUSPLUS\"\n    ;;\n  *-darwin* | *-macos10*)\n    CXXFLAGS=\"$CXXFLAGS -std=c++$CPLUSPLUS\"\n    if test \"x$CLANG\" = \"xyes\"; then\n      LDFLAGS=\"$LDFLAGS -stdlib=libc++\"\n    fi\n    ;;\n  *)\n    # default\n    CXXFLAGS=\"$CXXFLAGS -std=c++$CPLUSPLUS\"\n    ;;\nesac\n\n\n# ----------------------------------------\n# Check for libraries\n# ----------------------------------------\n\nAC_SEARCH_LIBS([pthread_create], [pthread])\n\n# Set PKG_CONFIG_PATH for macOS with Homebrew unless it is already set.\nAC_CHECK_PROG([have_brew], brew, true, false)\nif $have_brew; then\n  brew_prefix=$(brew --prefix)\n  if test -z \"$PKG_CONFIG_PATH\"; then\n    PKG_CONFIG_PATH=$brew_prefix/opt/icu4c/lib/pkgconfig:$brew_prefix/opt/libarchive/lib/pkgconfig\n    export PKG_CONFIG_PATH\n  fi\nfi\n\n# ----------------------------------------\n# Check for programs needed to build documentation.\n# ----------------------------------------\n\nAM_CONDITIONAL([ASCIIDOC], false)\nAM_CONDITIONAL([HAVE_XML_CATALOG_FILES], false)\nAC_ARG_ENABLE([doc],\n              AS_HELP_STRING([--disable-doc], [disable build of documentation])\n              [],\n              [: m4_divert_text([DEFAULTS], [enable_doc=check])])\nAS_IF([test \"$enable_doc\" != \"no\"], [\n  AC_CHECK_PROG([have_asciidoc], asciidoc, true, false)\n  AC_CHECK_PROG([have_xsltproc], xsltproc, true, false)\n  # macOS with Homebrew requires the environment variable\n  # XML_CATALOG_FILES for xsltproc.\n  if $have_asciidoc && $have_xsltproc; then\n    AM_CONDITIONAL([ASCIIDOC], true)\n    XML_CATALOG_FILES=\n    if $have_brew; then\n      catalog_file=$brew_prefix/etc/xml/catalog\n      if test -f $catalog_file; then\n        AM_CONDITIONAL([HAVE_XML_CATALOG_FILES], true)\n        XML_CATALOG_FILES=file:$catalog_file\n      else\n        AC_MSG_WARN([Missing file $catalog_file.])\n      fi\n    fi\n    AC_SUBST([XML_CATALOG_FILES])\n  else\n    AS_IF([test \"x$enable_doc\" != xcheck], [\n      AC_MSG_FAILURE(\n        [--enable-doc was given, but test for asciidoc and xsltproc failed])\n    ])\n  fi\n])\n\n# ----------------------------------------\n# Checks for typedefs, structures, and compiler characteristics.\n# ----------------------------------------\n\nAC_CHECK_TYPES([wchar_t],,, [#include \"wchar.h\"])\nAC_CHECK_TYPES([long long int])\n\n# ----------------------------------------\n# Test auxiliary packages\n# ----------------------------------------\n\nAM_CONDITIONAL([HAVE_LIBCURL], false)\nAS_IF([test \"x$with_curl\" != xno], [\n  PKG_CHECK_MODULES([libcurl], [libcurl], [have_libcurl=true], [have_libcurl=false])\n  AM_CONDITIONAL([HAVE_LIBCURL], $have_libcurl)\n  if $have_libcurl; then\n    AC_DEFINE([HAVE_LIBCURL], [1], [Enable libcurl])\n  else\n    AS_IF([test \"x$with_curl\" != xcheck], [\n      AC_MSG_FAILURE(\n        [--with-curl was given, but test for libcurl failed])\n    ])\n  fi\n])\n\nPKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74], [have_lept=true], [have_lept=false])\nif $have_lept; then\n  CPPFLAGS=\"$CPPFLAGS $LEPTONICA_CFLAGS\"\nelse\n  AC_MSG_ERROR([Leptonica 1.74 or higher is required. Try to install libleptonica-dev package.])\nfi\n\nAM_CONDITIONAL([HAVE_LIBARCHIVE], false)\nAS_IF([test \"x$with_archive\" != xno], [\n  PKG_CHECK_MODULES([libarchive], [libarchive], [have_libarchive=true], [have_libarchive=false])\n  AM_CONDITIONAL([HAVE_LIBARCHIVE], [$have_libarchive])\n  if $have_libarchive; then\n    AC_DEFINE([HAVE_LIBARCHIVE], [1], [Enable libarchive])\n    CPPFLAGS=\"$CPPFLAGS $libarchive_CFLAGS\"\n  else\n    AS_IF([test \"x$with_archive\" != xcheck], [\n      AC_MSG_FAILURE(\n        [--with-archive was given, but test for libarchive failed])\n    ])\n  fi\n])\n\nAM_CONDITIONAL([ENABLE_TRAINING], true)\n\n# Check availability of ICU packages.\nPKG_CHECK_MODULES([ICU_UC], [icu-uc >= 52.1], [have_icu_uc=true], [have_icu_uc=false])\nPKG_CHECK_MODULES([ICU_I18N], [icu-i18n >= 52.1], [have_icu_i18n=true], [have_icu_i18n=false])\nif !($have_icu_uc && $have_icu_i18n); then\n  AC_MSG_WARN([icu 52.1 or higher is required, but was not found.])\n  AC_MSG_WARN([Training tools WILL NOT be built.])\n  AC_MSG_WARN([Try to install libicu-dev package.])\n  AM_CONDITIONAL([ENABLE_TRAINING], false)\nfi\n\n# Check location of pango headers\nPKG_CHECK_MODULES([pango], [pango >= 1.38.0], [have_pango=true], [have_pango=false])\nif !($have_pango); then\n        AC_MSG_WARN([pango 1.38.0 or higher is required, but was not found.])\n        AC_MSG_WARN([Training tools WILL NOT be built.])\n        AC_MSG_WARN([Try to install libpango1.0-dev package.])\n        AM_CONDITIONAL([ENABLE_TRAINING], false)\nfi\n\n# Check location of cairo headers\nPKG_CHECK_MODULES([cairo], [cairo], [have_cairo=true], [have_cairo=false])\nif !($have_cairo); then\n        AC_MSG_WARN([Training tools WILL NOT be built because of missing cairo library.])\n        AC_MSG_WARN([Try to install libcairo-dev?? package.])\n        AM_CONDITIONAL([ENABLE_TRAINING], false)\nfi\n\nPKG_CHECK_MODULES([pangocairo], [pangocairo], [], [false])\nPKG_CHECK_MODULES([pangoft2], [pangoft2], [], [false])\n\n# ----------------------------------------\n# Final Tasks and Output\n# ----------------------------------------\n\n# Output files\nAC_CONFIG_FILES([include/tesseract/version.h])\nAC_CONFIG_FILES([Makefile tesseract.pc])\nAC_CONFIG_FILES([tessdata/Makefile])\nAC_CONFIG_FILES([tessdata/configs/Makefile])\nAC_CONFIG_FILES([tessdata/tessconfigs/Makefile])\nAC_CONFIG_FILES([java/Makefile])\nAC_CONFIG_FILES([java/com/Makefile])\nAC_CONFIG_FILES([java/com/google/Makefile])\nAC_CONFIG_FILES([java/com/google/scrollview/Makefile])\nAC_CONFIG_FILES([java/com/google/scrollview/events/Makefile])\nAC_CONFIG_FILES([java/com/google/scrollview/ui/Makefile])\nAC_CONFIG_FILES([nsis/Makefile])\nAC_OUTPUT\n\n# Final message\necho \"\"\necho \"Configuration is done.\"\necho \"You can now build and install $PACKAGE_NAME by running:\"\necho \"\"\necho \"$ make\"\necho \"$ sudo make install\"\necho \"$ sudo ldconfig\"\necho \"\"\n\nAM_COND_IF([ASCIIDOC], [\n  echo \"This will also build the documentation.\"\n], [\n  AS_IF([test \"$enable_doc\" = \"no\"], [\n    echo \"Documentation will not be built because it was disabled.\"\n  ], [\n    echo \"Documentation will not be built because asciidoc or xsltproc is missing.\"\n  ])\n])\n\n# echo \"$ sudo make install LANGS=\\\"eng ara deu\\\"\"\n# echo \"  Or:\"\n# echo \"$ sudo make install-langs\"\necho \"\"\n\nAM_COND_IF([ENABLE_TRAINING],\n  [\n   echo \"Training tools can be built and installed with:\"\n   echo \"\"\n   echo \"$ make training\"\n   echo \"$ sudo make training-install\"\n   echo \"\"],\n  [\n   echo \"You cannot build training tools because of missing dependency.\"\n   echo \"Check configure output for details.\"\n   echo \"\"]\n)\n\n# ----------------------------------------\n# CONFIG Template\n# ----------------------------------------\n\n# Fence added in configuration file\nAH_TOP([\n#ifndef CONFIG_AUTO_H\n#define CONFIG_AUTO_H\n/* config_auto.h: begin */\n])\n\n# Stuff added at bottom of file\nAH_BOTTOM([\n\n/* Miscellaneous defines */\n#define AUTOCONF 1\n\n/* Not used yet\n#ifndef NO_GETTEXT\n#define USING_GETTEXT\n#endif\n*/\n\n/* config_auto.h: end */\n#endif\n])\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.02,
          "content": "tesseract:\n  build: .\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "java",
          "type": "tree",
          "content": null
        },
        {
          "name": "m4",
          "type": "tree",
          "content": null
        },
        {
          "name": "nsis",
          "type": "tree",
          "content": null
        },
        {
          "name": "snap",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "sw.cpp",
          "type": "blob",
          "size": 12.66,
          "content": "void build(Solution &s)\n{\n    auto &tess = s.addProject(\"google.tesseract\", \"main\");\n    tess += Git(\"https://github.com/tesseract-ocr/tesseract\", \"\", \"{v}\");\n\n    auto cppstd = cpp17;\n\n    auto &libtesseract = tess.addTarget<LibraryTarget>(\"libtesseract\");\n    {\n        libtesseract.setChecks(\"libtesseract\");\n\n        libtesseract.PackageDefinitions = true;\n\n        libtesseract += cppstd;\n\n        libtesseract += \"TESS_API\"_api;\n        libtesseract += \"include/.*\"_rr;\n        libtesseract += \"src/.+/.*\"_rr;\n        libtesseract -= \"src/training/.*\"_rr;\n\n        libtesseract.Public += \"include\"_idir;\n        libtesseract.Protected +=\n            \"src/ccmain\"_id,\n            \"src/api\"_id,\n            \"src/dict\"_id,\n            \"src/viewer\"_id,\n            \"src/wordrec\"_id,\n            \"src/ccstruct\"_id,\n            \"src/cutil\"_id,\n            \"src/textord\"_id,\n            \"src/ccutil\"_id,\n            \"src/lstm\"_id,\n            \"src/classify\"_id,\n            \"src/arch\"_id,\n            \"src/training\"_id;\n\n        if (libtesseract.getCompilerType() == CompilerType::MSVC ||\n            libtesseract.getCompilerType() == CompilerType::ClangCl)\n        {\n            libtesseract += \"__SSE4_1__\"_def;\n            libtesseract.CompileOptions.push_back(\"-arch:AVX2\");\n\n            // openmp\n            //if (libtesseract.getOptions()[\"openmp\"] == \"true\")\n            if (0)\n            {\n                if (libtesseract.getCompilerType() == CompilerType::MSVC)\n                    libtesseract.CompileOptions.push_back(\"-openmp\");\n                else\n                    libtesseract.CompileOptions.push_back(\"-fopenmp\");\n                libtesseract += \"_OPENMP=201107\"_def;\n                if (libtesseract.getBuildSettings().Native.ConfigurationType == ConfigurationType::Debug)\n                    libtesseract += \"vcompd.lib\"_slib;\n                else\n                    libtesseract += \"vcomp.lib\"_slib;\n            }\n        }\n\n        auto win_or_mingw =\n            libtesseract.getBuildSettings().TargetOS.Type == OSType::Windows ||\n            libtesseract.getBuildSettings().TargetOS.Type == OSType::Mingw\n            ;\n\n        // check fma flags\n        libtesseract -= \"src/arch/dotproductfma.cpp\";\n        // check arch (arm)\n        libtesseract -= \"src/arch/dotproductneon.cpp\";\n\n        if (libtesseract.getBuildSettings().TargetOS.Type != OSType::Windows &&\n            libtesseract.getBuildSettings().TargetOS.Arch != ArchType::aarch64)\n        {\n            libtesseract[\"src/arch/dotproductavx.cpp\"].args.push_back(\"-mavx\");\n            libtesseract[\"src/arch/dotproductavx512.cpp\"].args.push_back(\"-mavx512f\");\n            libtesseract[\"src/arch/dotproductsse.cpp\"].args.push_back(\"-msse4.1\");\n            libtesseract[\"src/arch/intsimdmatrixsse.cpp\"].args.push_back(\"-msse4.1\");\n            libtesseract[\"src/arch/intsimdmatrixavx2.cpp\"].args.push_back(\"-mavx2\");\n        }\n        if (!win_or_mingw)\n        {\n#if SW_MODULE_ABI_VERSION > 29\n            if (!libtesseract.getBuildSettings().TargetOS.Android)\n#endif\n                libtesseract += \"pthread\"_slib;\n        }\n        if (libtesseract.getBuildSettings().TargetOS.Arch == ArchType::aarch64)\n        {\n            libtesseract += \"src/arch/dotproductneon.cpp\";\n        }\n\n        libtesseract.Public += \"HAVE_CONFIG_H\"_d;\n        libtesseract.Public += \"_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS=1\"_d;\n        libtesseract.Public += \"HAVE_LIBARCHIVE\"_d;\n\n        libtesseract.Public += \"org.sw.demo.danbloomberg.leptonica\"_dep;\n        libtesseract.Public += \"org.sw.demo.libarchive.libarchive\"_dep;\n\n        if (win_or_mingw)\n        {\n            libtesseract.Public += \"ws2_32.lib\"_slib;\n            libtesseract.Protected += \"NOMINMAX\"_def;\n        }\n\n        if (libtesseract.getCompilerType() == CompilerType::MSVC)\n            libtesseract.Protected.CompileOptions.push_back(\"-utf-8\");\n\n        libtesseract.Variables[\"TESSERACT_MAJOR_VERSION\"] = libtesseract.Variables[\"PACKAGE_MAJOR_VERSION\"];\n        libtesseract.Variables[\"TESSERACT_MINOR_VERSION\"] = libtesseract.Variables[\"PACKAGE_MINOR_VERSION\"];\n        libtesseract.Variables[\"TESSERACT_MICRO_VERSION\"] = libtesseract.Variables[\"PACKAGE_PATCH_VERSION\"];\n        libtesseract.Variables[\"TESSERACT_VERSION_STR\"] = \"master\";\n        libtesseract.configureFile(\"include/tesseract/version.h.in\", \"tesseract/version.h\");\n    }\n\n    //\n    auto &tesseract = tess.addExecutable(\"tesseract\");\n    {\n        tesseract += cppstd;\n        tesseract += \"src/tesseract.cpp\";\n        tesseract += libtesseract;\n    }\n\n    auto &svpaint = tess.addExecutable(\"svpaint\");\n    {\n        svpaint += cppstd;\n        svpaint += \"src/svpaint.cpp\";\n        svpaint += libtesseract;\n    }\n\n    auto &training = tess.addDirectory(\"training\");\n\n    //\n    auto &common_training = training.addLibrary(\"common_training\");\n    {\n        common_training += \"TESS_COMMON_TRAINING_API\"_api;\n        common_training += cppstd;\n        common_training += \"src/training/common/.*\"_rr;\n        common_training.Public += \"src/training/common\"_idir;\n        common_training.Public += libtesseract;\n    }\n\n    //\n    auto &unicharset_training = training.addLibrary(\"unicharset_training\");\n    {\n        unicharset_training += \"TESS_UNICHARSET_TRAINING_API\"_api;\n        unicharset_training += cppstd;\n        unicharset_training += \"src/training/unicharset/.*\"_rr;\n        unicharset_training.Public += \"src/training/unicharset\"_idir;\n        unicharset_training.Public += common_training;\n        unicharset_training.Public += \"org.sw.demo.unicode.icu.i18n\"_dep;\n\n        auto win_or_mingw =\n          unicharset_training.getBuildSettings().TargetOS.Type == OSType::Windows ||\n          unicharset_training.getBuildSettings().TargetOS.Type == OSType::Mingw\n          ;\n        if (!win_or_mingw)\n          unicharset_training += \"pthread\"_slib;\n    }\n\n    //\n#define ADD_EXE(n, ...)                     \\\n    auto &n = training.addExecutable(#n);   \\\n    n += cppstd;                            \\\n    n += \"src/training/\" #n \".*\"_rr;        \\\n    n.Public += __VA_ARGS__;                \\\n    n\n\n    ADD_EXE(ambiguous_words, common_training);\n    ADD_EXE(classifier_tester, common_training);\n    ADD_EXE(combine_lang_model, unicharset_training);\n    ADD_EXE(combine_tessdata, common_training);\n    ADD_EXE(cntraining, common_training);\n    ADD_EXE(dawg2wordlist, common_training);\n    ADD_EXE(mftraining, common_training) += \"src/training/mergenf.*\"_rr;\n    ADD_EXE(shapeclustering, common_training);\n    ADD_EXE(unicharset_extractor, unicharset_training);\n    ADD_EXE(wordlist2dawg, common_training);\n    ADD_EXE(lstmeval, unicharset_training);\n    ADD_EXE(lstmtraining, unicharset_training);\n    ADD_EXE(set_unicharset_properties, unicharset_training);\n    ADD_EXE(merge_unicharsets, common_training);\n\n    //\n    auto &pango_training = training.addLibrary(\"pango_training\");\n    {\n        pango_training += \"TESS_PANGO_TRAINING_API\"_api;\n        pango_training += cppstd;\n        pango_training += \"src/training/pango/.*\"_rr;\n        pango_training.Public += \"src/training/pango\"_idir;\n        pango_training.Public += unicharset_training;\n        pango_training.Public += \"org.sw.demo.gnome.pango.pangocairo\"_dep;\n    }\n\n    ADD_EXE(text2image, pango_training);\n    {\n        text2image += cppstd;\n        text2image +=\n            \"src/training/degradeimage.cpp\",\n            \"src/training/degradeimage.h\",\n            \"src/training/text2image.cpp\"\n            ;\n    }\n\n    if (!s.getExternalVariables()[\"with-tests\"])\n        return;\n\n    // tests\n    {\n        auto &test = tess.addDirectory(\"test\");\n        test.Scope = TargetScope::Test;\n\n        String skipped_tests_str;\n        if (s.getExternalVariables()[\"skip-tests\"])\n            skipped_tests_str = s.getExternalVariables()[\"skip-tests\"].getValue();\n        auto skipped_tests = split_string(skipped_tests_str, \",\");\n\n        auto add_test = [&test, &s, &cppstd, &libtesseract, &pango_training, &skipped_tests](const String &name) -> decltype(auto)\n        {\n            auto &t = test.addTarget<ExecutableTarget>(name);\n            t += cppstd;\n            t += FileRegex(\"unittest\", name + \"_test.*\", false);\n            t += \"unittest\"_idir;\n\n            t += \"SW_TESTING\"_def;\n\n            auto datadir = test.SourceDir / \"tessdata_unittest\";\n            if (s.getExternalVariables()[\"test-data-dir\"])\n                datadir = fs::current_path() / s.getExternalVariables()[\"test-data-dir\"].getValue();\n            t += Definition(\"TESSBIN_DIR=\\\"\" + \"\"s + \"\\\"\");\n\n            t += Definition(\"TESTING_DIR=\\\"\" + to_printable_string(normalize_path(test.SourceDir / \"test/testing\")) + \"\\\"\");\n            t += Definition(\"TESTDATA_DIR=\\\"\" + to_printable_string(normalize_path(test.SourceDir / \"test/testdata\")) + \"\\\"\");\n\n            t += Definition(\"LANGDATA_DIR=\\\"\" + to_printable_string(normalize_path(datadir / \"langdata_lstm\")) + \"\\\"\");\n            t += Definition(\"TESSDATA_DIR=\\\"\" + to_printable_string(normalize_path(datadir / \"tessdata\")) + \"\\\"\");\n            t += Definition(\"TESSDATA_BEST_DIR=\\\"\" + to_printable_string(normalize_path(datadir / \"tessdata_best\")) + \"\\\"\");\n\n            // we push all deps to all tests simplify things\n            t += pango_training;\n            t += \"org.sw.demo.google.googletest.gmock.main\"_dep;\n            t += \"org.sw.demo.google.googletest.gtest.main\"_dep;\n\n            if (t.getCompilerType() == CompilerType::MSVC)\n                t.CompileOptions.push_back(\"-utf-8\");\n\n            auto win_or_mingw =\n              t.getBuildSettings().TargetOS.Type == OSType::Windows ||\n              t.getBuildSettings().TargetOS.Type == OSType::Mingw\n              ;\n            if (!win_or_mingw)\n              t += \"pthread\"_slib;\n\n            auto tst = libtesseract.addTest(t, name);\n            for (auto &st : skipped_tests)\n            {\n                std::regex r(st);\n                if (std::regex_match(name, r))\n                {\n                    tst.skip(true);\n                    break;\n                }\n            }\n\n            return t;\n        };\n\n        Strings tests\n        {\n            \"apiexample\",\n            \"applybox\",\n            \"baseapi\",\n            \"baseapi_thread\",\n            \"bitvector\",\n            \"capiexample\",\n            \"capiexample_c\",\n            \"cleanapi\",\n            \"colpartition\",\n            \"commandlineflags\",\n            \"denorm\",\n            \"equationdetect\",\n            \"fileio\",\n            \"heap\",\n            \"imagedata\",\n            \"indexmapbidi\",\n            \"intfeaturemap\",\n            \"intsimdmatrix\",\n            \"lang_model\",\n            \"layout\",\n            \"ligature_table\",\n            \"linlsq\",\n            \"list\",\n            \"lstm_recode\",\n            \"lstm_squashed\",\n            \"lstm\",\n            \"lstmtrainer\",\n            \"loadlang\",\n            \"mastertrainer\",\n            \"matrix\",\n            \"networkio\",\n            \"normstrngs\",\n            \"nthitem\",\n            \"osd\",\n            \"pagesegmode\",\n            \"pango_font_info\",\n            \"paragraphs\",\n            \"params_model\",\n            \"progress\",\n            \"qrsequence\",\n            \"recodebeam\",\n            \"rect\",\n            \"resultiterator\",\n            \"scanutils\",\n            \"shapetable\",\n            \"stats\",\n            \"stringrenderer\",\n            \"stridemap\",\n            \"tablefind\",\n            \"tablerecog\",\n            \"tabvector\",\n            \"textlineprojection\",\n            \"tfile\",\n            \"unichar\",\n            \"unicharcompress\",\n            \"unicharset\",\n            \"validate_grapheme\",\n            \"validate_indic\",\n            \"validate_khmer\",\n            \"validate_myanmar\",\n            \"validator\",\n        };\n        for (auto t : tests)\n            add_test(t);\n        auto &dt = add_test(\"dawg\");\n        dt += Definition(\"wordlist2dawg_prog=\\\"\" + to_printable_string(normalize_path(wordlist2dawg.getOutputFile())) + \"\\\"\");\n        dt += Definition(\"dawg2wordlist_prog=\\\"\" + to_printable_string(normalize_path(dawg2wordlist.getOutputFile())) + \"\\\"\");\n\n        auto &tw = add_test(\"tatweel\");\n        tw += \"unittest/util/.*\"_rr;\n        tw += \"unittest/third_party/utf/.*\"_rr;\n    }\n}\n\nvoid check(Checker &c)\n{\n    auto &s = c.addSet(\"libtesseract\");\n    s.checkFunctionExists(\"getline\");\n    s.checkIncludeExists(\"dlfcn.h\");\n    s.checkIncludeExists(\"inttypes.h\");\n    s.checkIncludeExists(\"memory.h\");\n    s.checkIncludeExists(\"stdint.h\");\n    s.checkIncludeExists(\"stdlib.h\");\n    s.checkIncludeExists(\"string.h\");\n    s.checkIncludeExists(\"sys/stat.h\");\n    s.checkIncludeExists(\"sys/types.h\");\n    s.checkIncludeExists(\"tiffio.h\");\n    s.checkIncludeExists(\"unistd.h\");\n    s.checkTypeSize(\"long long int\");\n    s.checkTypeSize(\"size_t\");\n    s.checkTypeSize(\"void *\");\n    s.checkTypeSize(\"wchar_t\");\n    {\n        auto &c = s.checkSymbolExists(\"snprintf\");\n        c.Parameters.Includes.push_back(\"stdio.h\");\n    }\n}\n\n"
        },
        {
          "name": "tessdata",
          "type": "tree",
          "content": null
        },
        {
          "name": "tesseract.pc.cmake",
          "type": "blob",
          "size": 0.46,
          "content": "prefix=@CMAKE_INSTALL_PREFIX@\nexec_prefix=@CMAKE_INSTALL_PREFIX@\nlibdir=@CMAKE_INSTALL_FULL_LIBDIR@\nincludedir=@CMAKE_INSTALL_FULL_INCLUDEDIR@\n\nName: @tesseract_NAME@\nDescription: An OCR Engine that was developed at HP Labs (1985-1995) and Google (2006-2018).\nURL: https://github.com/tesseract-ocr/tesseract\nVersion: @tesseract_VERSION@\nRequires.private: lept\nLibs: -L${libdir} -l@tesseract_OUTPUT_NAME@ @libarchive_LIBS@ @libcurl_LIBS@\nLibs.private:\nCflags: -I${includedir}\n"
        },
        {
          "name": "tesseract.pc.in",
          "type": "blob",
          "size": 0.45,
          "content": "prefix=@prefix@\nexec_prefix=@exec_prefix@\nbindir=@bindir@\ndatarootdir = @datarootdir@\ndatadir=@datadir@\nlibdir=@libdir@\nincludedir=@includedir@\n\nName: @PACKAGE_NAME@\nDescription: An OCR Engine that was developed at HP Labs (1985-1995) and Google (2006-2018).\nURL: https://github.com/tesseract-ocr/tesseract\nVersion: @VERSION@\nRequires.private: lept\nLibs: -L${libdir} -ltesseract @libarchive_LIBS@ @libcurl_LIBS@\nLibs.private: -lpthread\nCflags: -I${includedir}\n"
        },
        {
          "name": "test",
          "type": "commit",
          "content": null
        },
        {
          "name": "unittest",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "ansible/ansible",
      "stars": 63632,
      "defaultBranch": "devel",
      "files": [
        {
          "name": ".azure-pipelines",
          "type": "tree",
          "content": null
        },
        {
          "name": ".cherry_picker.toml",
          "type": "blob",
          "size": 0.2,
          "content": "team = \"ansible\"\nrepo = \"ansible\"\ncheck_sha = \"f31421576b00f0b167cdbe61217c31c21a41ac02\"  # the very first commit in repo\nfix_commit_msg = false  # Don't replace \"#\" with \"GH-\"\ndefault_branch = \"devel\"\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.25,
          "content": "# .git-blame-ignore-revs\n# Bulk PowerShell sanity fixes\n6def4a3180fe03981ba64c6d8db28fed3bb39c0c\n716631189cb5a3f66b3add98f39e64e98bc17bf7\n# Bulk update of strings from triple single quotes to triple double quotes\na0495fc31497798a7a833ba7406a9729e1528dd8\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.02,
          "content": ".github/ export-ignore\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.84,
          "content": "# build products...\n*.py[co]\nbuild\nAUTHORS.TXT\n# Emacs backup and autosave files...\n*~\n.\\#*\n\\#*\n# RPM stuff...\nMANIFEST\ndist\nrpm-build\n# Eclipse/PyDev stuff...\n.project\n.pydevproject\n# PyCharm stuff...\n.idea\n#IntelliJ IDEA stuff..\n*.iml\n#VSCode stuff..\n.vscode/\n# Mac OS X stuff...\n.DS_Store\n# manpage build stuff...\ndocs/man/man1/ansible*.1\ndocs/man/man1/ansible*.1.asciidoc.in\ndocs/man/man3/*\n# Sublime stuff\n*.sublime-project\n*.sublime-workspace\n# docsite stuff...\ndocs/docsite/_build\ndocs/docsite/*.html\ndocs/docsite/htmlout\ndocs/docsite/rst/conf.py\ndocs/docsite/rst/index.rst\ndocs/docsite/rst/cli/ansible-*.rst\ndocs/docsite/rst/cli/ansible.rst\ndocs/docsite/rst/dev_guide/collections_galaxy_meta.rst\ndocs/docsite/rst/dev_guide/testing/sanity/index.rst.new\ndocs/docsite/rst/dev_guide/index.rst\ndocs/docsite/rst/modules/*.rst\ndocs/docsite/rst/collections/*.rst\n!docs/docsite/rst/collections/all_plugins.rst\ndocs/docsite/rst/collections/*/*.rst\ndocs/docsite/rst/playbooks_directives.rst\ndocs/docsite/rst/plugins_by_category.rst\ndocs/docsite/rst/plugins/*/*.rst\ndocs/docsite/rst/reference_appendices/config.rst\ndocs/docsite/rst/reference_appendices/playbooks_keywords.rst\ndocs/docsite/rst_warnings\ndocs/docsite/searchindex.js\ndocs/docsite/_static/*.gif\ndocs/docsite/_static/*.png\ndocs/docsite/_static/websupport.js\n# Vim swap files\n*.swp\n*.swo\n[._]*.un~\ncredentials.yml\n# test output\n*.retry\n*.out\n.pytest_cache/\n.tox\n.cache\n.pytest_cache\nresults.xml\ncoverage.xml\n/test/units/cover-html\n/test/integration/inventory\n/test/integration/targets/*/backup/\n/test/cache/*\n# Development\n/test/develop\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\nvenv\nenv\nVagrantfile\n.vagrant\n# Backwards compatibility with `stable-2.9` and earlier branches.\n# Also used in the `devel` branch during early Ansible 2.10 development.\n/lib/ansible.egg-info/\n# First used in the `devel` branch during Ansible 2.10 development.\n/lib/ansible_base.egg-info/\n# First used in the `devel` branch during Ansible 2.11 development.\n/lib/ansible_core.egg-info/\n# First used in the `devel` branch during Ansible 2.18 development.\n/ansible_core.egg-info/\n# vendored lib dir\nlib/ansible/_vendor/*\n!lib/ansible/_vendor/__init__.py\n# test stuff\n/test/integration/cloud-config-*.*\n!/test/integration/cloud-config-*.*.template\n.python-version\n# Release directory\npackaging/release/ansible_release\n/.cache/\n/test/results/\n/test/integration/cloud-config-aws.yml\n/test/integration/inventory.networking\n/test/integration/inventory.winrm\n/test/integration/cloud-config-aws.yml\n/test/integration/cloud-config-cs.ini\n# python 'rope' stuff\n.ropeproject\n# local 'ack' config files\n.ackrc\n# default 'coverage html' results\nhtmlcov/\n# default 'coverage' tool data\n.coverage\n# ansible-test coverage results\ntest/units/.coverage.*\n/test/integration/cloud-config-azure.yml\n/SYMLINK_CACHE.json\nchangelogs/.plugin-cache.yaml\n.ansible-test-timeout.json\n"
        },
        {
          "name": ".mailmap",
          "type": "blob",
          "size": 2.15,
          "content": "Michael DeHaan <michael.dehaan@gmail.com> <michael@ansibleworks.com>\nMichael DeHaan <michael.dehaan@gmail.com> Michael DeHaan <michael@ansibleworks.com>\nMichael DeHaan <michael.dehaan@gmail.com> <michael@ansible.com>\n<bcoca@ansible.com> <brian.coca+git@gmail.com>\n<bcoca@ansible.com> <briancoca+ansible@gmail.com>\n<bcoca@ansible.com> <briancoca+dev@gmail.com>\n<bcoca@ansible.com> <bcoca@tablethotels.com>\n<a.badger@gmail.com> <toshio@fedoraproject.org>\nJames Tanner <tanner.jc@gmail.com>\n<jimi@sngx.net> <jcammarata@ansibleworks.com>\nMichael Scherer <misc@zarb.org> mscherer <misc@zarb.org>\n<misc@zarb.org> <misc@ephaone.org>\n<misc@zarb.org> <mscherer@users.noreply.github.com>\nJames Martin <jmartin@ansible.com> <jmartin@basho.com>\nJames Laska <jlaska@ansible.com> <jlaska@redhat.com>\nJames Laska <jlaska@ansible.com> <jlaska@ansibleworks.com>\nJames Laska <jlaska@ansible.com> <jlaska@James-Laskas-MacBook-Pro.local>\nJames Laska <jlaska@ansible.com> <jlaska@users.noreply.github.com>\nJason McKerr <mckerrj@gmail.com> <jmckerr@jmckerr-OSX.local>\nChris Houseknecht <chouseknecht@ansible.com>\nChris Houseknecht <chouseknecht@ansible.com> chouseknecht <chouse@ansible.com>\nChris Houseknecht <chouseknecht@ansible.com> Chris Houseknecht <chouse@ansibleworks.com>\nStephen Fromm <sfromm@gmail.com> Stephen Fromm <stephenf@nero.net>\nSandra Wills <docschick@ansible.com> Sandra Wills <swills@ansible.com>\nWill Thames <will@thames.id.au> willthames <will@thames.id.au>\nWill Thames <will@thames.id.au> Will Thames <willdthames@gmail.com>\nWill Thames <will@thames.id.au> willthames <willdthames@gmail.com>\nWill Thames <will@thames.id.au> willthames <will@musc.org.uk>\nWill Thames <will@thames.id.au> u348095 <will.thames@suncorp.com.au>\nWill Thames <will@thames.id.au> willthames <will.thames@suncorp.com.au>\nWill Thames <will@thames.id.au> Will Thames <will.thames@xvt.com.au>\nnitzmahone <mdavis@ansible.com> Matt Davis <nitzmahone@users.noreply.github.com>\nDag Wieers <dag@wieers.com> Dag Wieërs <dag@wieers.com>\nDag Wieers <dag@wieers.com> Dag Wieers <dag.wieers@gmail.com>\nRene Moser <mail@renemoser.net> René Moser <mail@renemoser.net>\nRene Moser <mail@renemoser.net> Rene Moser <rene.moser@swisstxt.ch>\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 34.33,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<https://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<https://www.gnu.org/licenses/why-not-lgpl.html>.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.35,
          "content": "include COPYING\ninclude changelogs/CHANGELOG*.rst\ninclude changelogs/changelog.yaml\ninclude licenses/*.txt\ninclude requirements.txt\nrecursive-include packaging *.py *.j2\nrecursive-include test/integration *\nrecursive-include test/sanity *.in *.json *.py *.txt *.ini\nrecursive-include test/support *.py *.ps1 *.psm1 *.cs *.md\nrecursive-include test/units *\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.79,
          "content": "[![PyPI version](https://img.shields.io/pypi/v/ansible-core.svg)](https://pypi.org/project/ansible-core)\n[![Docs badge](https://img.shields.io/badge/docs-latest-brightgreen.svg)](https://docs.ansible.com/ansible/latest/)\n[![Chat badge](https://img.shields.io/badge/chat-IRC-brightgreen.svg)](https://docs.ansible.com/ansible/devel/community/communication.html)\n[![Build Status](https://dev.azure.com/ansible/ansible/_apis/build/status/CI?branchName=devel)](https://dev.azure.com/ansible/ansible/_build/latest?definitionId=20&branchName=devel)\n[![Ansible Code of Conduct](https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg)](https://docs.ansible.com/ansible/devel/community/code_of_conduct.html)\n[![Ansible mailing lists](https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg)](https://docs.ansible.com/ansible/devel/community/communication.html#mailing-list-information)\n[![Repository License](https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg)](COPYING)\n[![Ansible CII Best Practices certification](https://bestpractices.coreinfrastructure.org/projects/2372/badge)](https://bestpractices.coreinfrastructure.org/projects/2372)\n\n# Ansible\n\nAnsible is a radically simple IT automation system. It handles\nconfiguration management, application deployment, cloud provisioning,\nad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex\nchanges like zero-downtime rolling updates with load balancers easy. More information on the Ansible [website](https://ansible.com/).\n\n## Design Principles\n\n* Have an extremely simple setup process with a minimal learning curve.\n* Manage machines quickly and in parallel.\n* Avoid custom-agents and additional open ports, be agentless by\n  leveraging the existing SSH daemon.\n* Describe infrastructure in a language that is both machine and human\n  friendly.\n* Focus on security and easy auditability/review/rewriting of content.\n* Manage new remote machines instantly, without bootstrapping any\n  software.\n* Allow module development in any dynamic language, not just Python.\n* Be usable as non-root.\n* Be the easiest IT automation system to use, ever.\n\n## Use Ansible\n\nYou can install a released version of Ansible with `pip` or a package manager. See our\n[installation guide](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html) for details on installing Ansible\non a variety of platforms.\n\nPower users and developers can run the `devel` branch, which has the latest\nfeatures and fixes, directly. Although it is reasonably stable, you are more likely to encounter\nbreaking changes when running the `devel` branch. We recommend getting involved\nin the Ansible community if you want to run the `devel` branch.\n\n## Communication\n\nJoin the Ansible forum to ask questions, get help, and interact with the\ncommunity.\n\n* [Get Help](https://forum.ansible.com/c/help/6): Find help or share your Ansible knowledge to help others.\n  Use tags to filter and subscribe to posts, such as the following:\n  * Posts tagged with [ansible](https://forum.ansible.com/tag/ansible)\n  * Posts tagged with [ansible-core](https://forum.ansible.com/tag/ansible-core)\n  * Posts tagged with [playbook](https://forum.ansible.com/tag/playbook)\n* [Social Spaces](https://forum.ansible.com/c/chat/4): Meet and interact with fellow enthusiasts.\n* [News & Announcements](https://forum.ansible.com/c/news/5): Track project-wide announcements including social events.\n* [Bullhorn newsletter](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn): Get release announcements and important changes.\n\nFor more ways to get in touch, see [Communicating with the Ansible community](https://docs.ansible.com/ansible/devel/community/communication.html).\n\n## Contribute to Ansible\n\n* Check out the [Contributor's Guide](./.github/CONTRIBUTING.md).\n* Read [Community Information](https://docs.ansible.com/ansible/devel/community) for all\n  kinds of ways to contribute to and interact with the project,\n  including how to submit bug reports and code to Ansible.\n* Submit a proposed code update through a pull request to the `devel` branch.\n* Talk to us before making larger changes\n  to avoid duplicate efforts. This not only helps everyone\n  know what is going on, but it also helps save time and effort if we decide\n  some changes are needed.\n\n## Coding Guidelines\n\nWe document our Coding Guidelines in the [Developer Guide](https://docs.ansible.com/ansible/devel/dev_guide/). We particularly suggest you review:\n\n* [Contributing your module to Ansible](https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_checklist.html)\n* [Conventions, tips, and pitfalls](https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_best_practices.html)\n\n## Branch Info\n\n* The `devel` branch corresponds to the release actively under development.\n* The `stable-2.X` branches correspond to stable releases.\n* Create a branch based on `devel` and set up a [dev environment](https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_general.html#common-environment-setup) if you want to open a PR.\n* See the [Ansible release and maintenance](https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html) page for information about active branches.\n\n## Roadmap\n\nBased on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8).\nThe [Ansible Roadmap page](https://docs.ansible.com/ansible/devel/roadmap/) details what is planned and how to influence the roadmap.\n\n## Authors\n\nAnsible was created by [Michael DeHaan](https://github.com/mpdehaan)\nand has contributions from over 5000 users (and growing). Thanks everyone!\n\n[Ansible](https://www.ansible.com) is sponsored by [Red Hat, Inc.](https://www.redhat.com)\n\n## License\n\nGNU General Public License v3.0 or later\n\nSee [COPYING](COPYING) to see the full text.\n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "changelogs",
          "type": "tree",
          "content": null
        },
        {
          "name": "hacking",
          "type": "tree",
          "content": null
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "packaging",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.36,
          "content": "[build-system]\nrequires = [\"setuptools >= 66.1.0, <= 72.1.0\"]  # lower bound to support controller Python versions, upper bound for latest version tested at release\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nrequires-python = \">=3.11\"\nname = \"ansible-core\"\nauthors = [\n    {name = \"Ansible Project\"},\n]\ndescription = \"Radically simple IT automation\"\nreadme = \"README.md\"\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Environment :: Console\",\n    \"Intended Audience :: Developers\",\n    \"Intended Audience :: Information Technology\",\n    \"Intended Audience :: System Administrators\",\n    \"License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)\",\n    \"Natural Language :: English\",\n    \"Operating System :: POSIX\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3.13\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Topic :: System :: Installation/Setup\",\n    \"Topic :: System :: Systems Administration\",\n    \"Topic :: Utilities\",\n]\ndynamic = [\"version\", \"dependencies\"]\n\n[project.urls]\n\"Homepage\" = \"https://ansible.com/\"\n\"Source Code\" = \"https://github.com/ansible/ansible/\"\n\"Bug Tracker\" = \"https://github.com/ansible/ansible/issues/\"\n\"CI: Azure Pipelines\" = \"https://dev.azure.com/ansible/ansible/\"\n\"Documentation\" = \"https://docs.ansible.com/ansible-core/\"\n\"Code of Conduct\" = \"https://docs.ansible.com/ansible/latest/community/code_of_conduct.html\"\n\n[tool.setuptools.dynamic]\nversion = {attr = \"ansible.release.__version__\"}\ndependencies = {file = \"requirements.txt\"}\n\n[tool.setuptools]\ninclude-package-data = false\nlicense-files = [\n    \"COPYING\",\n    \"licenses/*.txt\",\n]\n\n[tool.setuptools.packages.find]\nwhere = [\"lib\", \"test/lib\"]\n\n[tool.setuptools.package-data]\nansible = [\n    \"config/*.yml\",\n    \"executor/powershell/*.ps1\",\n    \"galaxy/data/COPYING\",\n    \"galaxy/data/*.yml\",\n    \"galaxy/data/*/*.j2\",\n    \"galaxy/data/*/*.md\",\n    \"galaxy/data/*/*/*.cfg\",\n    \"galaxy/data/*/*/*.j2\",\n    \"galaxy/data/*/*/*.md\",\n    \"galaxy/data/*/*/*/*.j2\",\n    \"galaxy/data/*/*/*/*.yml\",\n    \"galaxy/data/*/*/*/.git_keep\",\n    \"galaxy/data/*/*/*/inventory\",\n    \"galaxy/data/*/*/.git_keep\",\n    \"galaxy/data/*/*/inventory\",\n    \"keyword_desc.yml\",\n    \"module_utils/csharp/*.cs\",\n    \"module_utils/powershell/*.psm1\",\n    \"plugins/*/*.yml\",\n]\nansible_test = [\n    \"_data/*/*.in\",\n    \"_data/*/*.ps1\",\n    \"_data/*/*.txt\",\n    \"_data/*/*.yml\",\n    \"_data/*/*/*.ini\",\n    \"_data/ansible.cfg\",\n    \"_data/coveragerc\",\n    \"_util/*/*/*.ps1\",\n    \"_util/*/*/*.py\",\n    \"_util/*/*/*.sh\",\n    \"_util/*/*/*/*.ini\",\n    \"_util/*/*/*/*.json\",\n    \"_util/*/*/*/*.ps1\",\n    \"_util/*/*/*/*.psd1\",\n    \"_util/*/*/*/*.py\",\n    \"_util/*/*/*/*.txt\",\n    \"_util/*/*/*/*/*.cfg\",\n    \"_util/*/*/*/*/*.ps1\",\n    \"_util/*/*/*/*/*.py\",\n    \"_util/*/*/*/*/*.yml\",\n    \"config/*.template\",\n    \"config/*.yml\",\n]\n\n[project.scripts]\nansible = \"ansible.cli.adhoc:main\"\nansible-config = \"ansible.cli.config:main\"\nansible-console = \"ansible.cli.console:main\"\nansible-doc = \"ansible.cli.doc:main\"\nansible-galaxy = \"ansible.cli.galaxy:main\"\nansible-inventory = \"ansible.cli.inventory:main\"\nansible-playbook = \"ansible.cli.playbook:main\"\nansible-pull = \"ansible.cli.pull:main\"\nansible-vault = \"ansible.cli.vault:main\"\nansible-test = \"ansible_test._util.target.cli.ansible_test_cli_stub:main\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.82,
          "content": "# Note: this requirements.txt file is used to specify what dependencies are\n# needed to make the package run rather than for deployment of a tested set of\n# packages.  Thus, this should be the loosest set possible (only required\n# packages, not optional ones, and with the widest range of versions that could\n# be suitable)\njinja2 >= 3.0.0\nPyYAML >= 5.1  # PyYAML 5.1 is required for Python 3.8+ support\ncryptography\npackaging\n# NOTE: resolvelib 0.x version bumps should be considered major/breaking\n# NOTE: and we should update the upper cap with care, at least until 1.0\n# NOTE: Ref: https://github.com/sarugaku/resolvelib/issues/69\n# NOTE: When updating the upper bound, also update the latest version used\n# NOTE: in the ansible-galaxy-collection test suite.\nresolvelib >= 0.5.3, < 2.0.0  # dependency resolver used by ansible-galaxy\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "lydiahallie/javascript-questions",
      "stars": 63194,
      "defaultBranch": "master",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.04,
          "content": "MIT License\n\nCopyright (c) 2019 Lydia Hallie\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 141.86,
          "content": "<div align=\"center\">\n  <img height=\"60\" src=\"https://img.icons8.com/color/344/javascript.png\">\n  <h1>JavaScript Questions</h1>\n</div>\n\n> [!NOTE]  \n> This repo was created in 2019 and the questions provided here are therefore based on the JavaScript syntax and behavior at that time. Since JavaScript is a constantly evolving language, there are newer language features that are not covered by the questions here.\n\n---\n\n<p align=\"center\">\nFrom basic to advanced: test how well you know JavaScript, refresh your knowledge a bit or prepare for your coding interview! :muscle: :rocket: I update this repo regularly with new questions. I added the answers in the **collapsed sections** below the questions, simply click on them to expand it. It's just for fun, good luck! :heart:</p>\n\n<p align=\"center\">Feel free to reach out to me! 😊</p>\n\n<p align=\"center\">\n  <a href=\"https://www.instagram.com/theavocoder\">Instagram</a> || <a href=\"https://www.twitter.com/lydiahallie\">Twitter</a> || <a href=\"https://www.linkedin.com/in/lydia-hallie\">LinkedIn</a> || <a href=\"https://www.lydiahallie.io/\">Blog</a>\n</p>\n\n| Feel free to use them in a project! 😃 I would _really_ appreciate a reference to this repo, I create the questions and explanations (yes I'm sad lol) and the community helps me so much to maintain and improve it! 💪🏼 Thank you and have fun! |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n\n<details><summary><strong> See 20 Available Translations 🇸🇦🇪🇬🇧🇦🇩🇪🇪🇸🇫🇷🇮🇩🇯🇵🇰🇷🇳🇱🇧🇷🇷🇺🇹🇭🇹🇷🇺🇦🇻🇳🇨🇳🇹🇼🇽🇰</strong></summary>\n<p>\n\n- [🇸🇦 العربية](./ar-AR/README_AR.md)\n- [🇪🇬 اللغة العامية](./ar-EG/README_ar-EG.md)\n- [🇧🇦 Bosanski](./bs-BS/README-bs_BS.md)\n- [🇩🇪 Deutsch](./de-DE/README.md)\n- [🇪🇸 Español](./es-ES/README-ES.md)\n- [🇫🇷 Français](./fr-FR/README_fr-FR.md)\n- [🇮🇩 Indonesia](./id-ID/README.md)\n- [🇮🇹 Italiano](./it-IT/README.md)\n- [🇯🇵 日本語](./ja-JA/README-ja_JA.md)\n- [🇰🇷 한국어](./ko-KR/README-ko_KR.md)\n- [🇳🇱 Nederlands](./nl-NL/README.md)\n- [🇵🇱 Polski](./pl-PL/README.md)\n- [🇧🇷 Português Brasil](./pt-BR/README_pt_BR.md)\n- [🇷o Română](./ro-RO/README.ro.md)\n- [🇷🇺 Русский](./ru-RU/README.md)\n- [🇽🇰 Shqip](./sq-KS/README_sq_KS.md)\n- [🇹🇭 ไทย](./th-TH/README-th_TH.md)\n- [🇹🇷 Türkçe](./tr-TR/README-tr_TR.md)\n- [🇺🇦 Українська мова](./uk-UA/README.md)\n- [🇻🇳 Tiếng Việt](./vi-VI/README-vi.md)\n- [🇨🇳 简体中文](./zh-CN/README-zh_CN.md)\n- [🇹🇼 繁體中文](./zh-TW/README_zh-TW.md)\n\n</p>\n</details>\n\n---\n\n###### 1. What's the output?\n\n```javascript\nfunction sayHi() {\n  console.log(name);\n  console.log(age);\n  var name = 'Lydia';\n  let age = 21;\n}\n\nsayHi();\n```\n\n- A: `Lydia` and `undefined`\n- B: `Lydia` and `ReferenceError`\n- C: `ReferenceError` and `21`\n- D: `undefined` and `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nWithin the function, we first declare the `name` variable with the `var` keyword. This means that the variable gets hoisted (memory space is set up during the creation phase) with the default value of `undefined`, until we actually get to the line where we define the variable. We haven't defined the variable yet on the line where we try to log the `name` variable, so it still holds the value of `undefined`.\n\nVariables with the `let` keyword (and `const`) are hoisted, but unlike `var`, don't get <i>initialized</i>. They are not accessible before the line we declare (initialize) them. This is called the \"temporal dead zone\". When we try to access the variables before they are declared, JavaScript throws a `ReferenceError`.\n\n</p>\n</details>\n\n---\n\n###### 2. What's the output?\n\n```javascript\nfor (var i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 1);\n}\n\nfor (let i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 1);\n}\n```\n\n- A: `0 1 2` and `0 1 2`\n- B: `0 1 2` and `3 3 3`\n- C: `3 3 3` and `0 1 2`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nBecause of the event queue in JavaScript, the `setTimeout` callback function is called _after_ the loop has been executed. Since the variable `i` in the first loop was declared using the `var` keyword, this value was global. During the loop, we incremented the value of `i` by `1` each time, using the unary operator `++`. By the time the `setTimeout` callback function was invoked, `i` was equal to `3` in the first example.\n\nIn the second loop, the variable `i` was declared using the `let` keyword: variables declared with the `let` (and `const`) keyword are block-scoped (a block is anything between `{ }`). During each iteration, `i` will have a new value, and each value is scoped inside the loop.\n\n</p>\n</details>\n\n---\n\n###### 3. What's the output?\n\n```javascript\nconst shape = {\n  radius: 10,\n  diameter() {\n    return this.radius * 2;\n  },\n  perimeter: () => 2 * Math.PI * this.radius,\n};\n\nconsole.log(shape.diameter());\nconsole.log(shape.perimeter());\n```\n\n- A: `20` and `62.83185307179586`\n- B: `20` and `NaN`\n- C: `20` and `63`\n- D: `NaN` and `63`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nNote that the value of `diameter` is a regular function, whereas the value of `perimeter` is an arrow function.\n\nWith arrow functions, the `this` keyword refers to its current surrounding scope, unlike regular functions! This means that when we call `perimeter`, it doesn't refer to the shape object, but to its surrounding scope (window for example).\n\nSince there is no value `radius` in the scope of the arrow function, `this.radius` returns `undefined` which, when multiplied by `2 * Math.PI`, results in `NaN`.\n\n</p>\n</details>\n\n---\n\n###### 4. What's the output?\n\n```javascript\n+true;\n!'Lydia';\n```\n\n- A: `1` and `false`\n- B: `false` and `NaN`\n- C: `false` and `false`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe unary plus tries to convert an operand to a number. `true` is `1`, and `false` is `0`.\n\nThe string `'Lydia'` is a truthy value. What we're actually asking, is \"Is this truthy value falsy?\". This returns `false`.\n\n</p>\n</details>\n\n---\n\n###### 5. Which one is true?\n\n```javascript\nconst bird = {\n  size: 'small',\n};\n\nconst mouse = {\n  name: 'Mickey',\n  small: true,\n};\n```\n\n- A: `mouse.bird.size` is not valid\n- B: `mouse[bird.size]` is not valid\n- C: `mouse[bird[\"size\"]]` is not valid\n- D: All of them are valid\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nIn JavaScript, all object keys are strings (unless it's a Symbol). Even though we might not _type_ them as strings, they are always converted into strings under the hood.\n\nJavaScript interprets (or unboxes) statements. When we use bracket notation, it sees the first opening bracket `[` and keeps going until it finds the closing bracket `]`. Only then, it will evaluate the statement.\n\n`mouse[bird.size]`: First it evaluates `bird.size`, which is `\"small\"`. `mouse[\"small\"]` returns `true`\n\nHowever, with dot notation, this doesn't happen. `mouse` does not have a key called `bird`, which means that `mouse.bird` is `undefined`. Then, we ask for the `size` using dot notation: `mouse.bird.size`. Since `mouse.bird` is `undefined`, we're actually asking `undefined.size`. This isn't valid, and will throw an error similar to `Cannot read property \"size\" of undefined`.\n\n</p>\n</details>\n\n---\n\n###### 6. What's the output?\n\n```javascript\nlet c = { greeting: 'Hey!' };\nlet d;\n\nd = c;\nc.greeting = 'Hello';\nconsole.log(d.greeting);\n```\n\n- A: `Hello`\n- B: `Hey!`\n- C: `undefined`\n- D: `ReferenceError`\n- E: `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nIn JavaScript, all objects interact by _reference_ when setting them equal to each other.\n\nFirst, variable `c` holds a value to an object. Later, we assign `d` with the same reference that `c` has to the object.\n\n<img src=\"https://i.imgur.com/ko5k0fs.png\" width=\"200\">\n\nWhen you change one object, you change all of them.\n\n</p>\n</details>\n\n---\n\n###### 7. What's the output?\n\n```javascript\nlet a = 3;\nlet b = new Number(3);\nlet c = 3;\n\nconsole.log(a == b);\nconsole.log(a === b);\nconsole.log(b === c);\n```\n\n- A: `true` `false` `true`\n- B: `false` `false` `true`\n- C: `true` `false` `false`\n- D: `false` `true` `true`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\n`new Number()` is a built-in function constructor. Although it looks like a number, it's not really a number: it has a bunch of extra features and is an object.\n\nWhen we use the `==` operator (Equality operator), it only checks whether it has the same _value_. They both have the value of `3`, so it returns `true`.\n\nHowever, when we use the `===` operator (Strict equality operator), both value _and_ type should be the same. It's not: `new Number()` is not a number, it's an **object**. Both return `false.`\n\n</p>\n</details>\n\n---\n\n###### 8. What's the output?\n\n```javascript\nclass Chameleon {\n  static colorChange(newColor) {\n    this.newColor = newColor;\n    return this.newColor;\n  }\n\n  constructor({ newColor = 'green' } = {}) {\n    this.newColor = newColor;\n  }\n}\n\nconst freddie = new Chameleon({ newColor: 'purple' });\nconsole.log(freddie.colorChange('orange'));\n```\n\n- A: `orange`\n- B: `purple`\n- C: `green`\n- D: `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `colorChange` function is static. Static methods are designed to live only on the constructor in which they are created, and cannot be passed down to any children or called upon class instances. Since `freddie` is an instance of class Chameleon, the function cannot be called upon it. A `TypeError` is thrown.\n\n</p>\n</details>\n\n---\n\n###### 9. What's the output?\n\n```javascript\nlet greeting;\ngreetign = {}; // Typo!\nconsole.log(greetign);\n```\n\n- A: `{}`\n- B: `ReferenceError: greetign is not defined`\n- C: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nIt logs the object, because we just created an empty object on the global object! When we mistyped `greeting` as `greetign`, the JS interpreter actually saw this as:\n\n1. `global.greetign = {}` in Node.js\n2. `window.greetign = {}`, `frames.greetign = {}` and `self.greetign` in browsers.\n3. `self.greetign` in web workers.\n4. `globalThis.greetign` in all environments.\n\nIn order to avoid this, we can use `\"use strict\"`. This makes sure that you have declared a variable before setting it equal to anything.\n\n</p>\n</details>\n\n---\n\n###### 10. What happens when we do this?\n\n```javascript\nfunction bark() {\n  console.log('Woof!');\n}\n\nbark.animal = 'dog';\n```\n\n- A: Nothing, this is totally fine!\n- B: `SyntaxError`. You cannot add properties to a function this way.\n- C: `\"Woof\"` gets logged.\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThis is possible in JavaScript, because functions are objects! (Everything besides primitive types are objects)\n\nA function is a special type of object. The code you write yourself isn't the actual function. The function is an object with properties. This property is invocable.\n\n</p>\n</details>\n\n---\n\n###### 11. What's the output?\n\n```javascript\nfunction Person(firstName, lastName) {\n  this.firstName = firstName;\n  this.lastName = lastName;\n}\n\nconst member = new Person('Lydia', 'Hallie');\nPerson.getFullName = function() {\n  return `${this.firstName} ${this.lastName}`;\n};\n\nconsole.log(member.getFullName());\n```\n\n- A: `TypeError`\n- B: `SyntaxError`\n- C: `Lydia Hallie`\n- D: `undefined` `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nIn JavaScript, functions are objects, and therefore, the method `getFullName` gets added to the constructor function object itself. For that reason, we can call `Person.getFullName()`, but `member.getFullName` throws a `TypeError`. \n\nIf you want a method to be available to all object instances, you have to add it to the prototype property:\n\n```js\nPerson.prototype.getFullName = function() {\n  return `${this.firstName} ${this.lastName}`;\n};\n```\n\n</p>\n</details>\n\n---\n\n###### 12. What's the output?\n\n```javascript\nfunction Person(firstName, lastName) {\n  this.firstName = firstName;\n  this.lastName = lastName;\n}\n\nconst lydia = new Person('Lydia', 'Hallie');\nconst sarah = Person('Sarah', 'Smith');\n\nconsole.log(lydia);\nconsole.log(sarah);\n```\n\n- A: `Person {firstName: \"Lydia\", lastName: \"Hallie\"}` and `undefined`\n- B: `Person {firstName: \"Lydia\", lastName: \"Hallie\"}` and `Person {firstName: \"Sarah\", lastName: \"Smith\"}`\n- C: `Person {firstName: \"Lydia\", lastName: \"Hallie\"}` and `{}`\n- D: `Person {firstName: \"Lydia\", lastName: \"Hallie\"}` and `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nFor `sarah`, we didn't use the `new` keyword. When using `new`, `this` refers to the new empty object we create. However, if you don't add `new`, `this` refers to the **global object**!\n\nWe said that `this.firstName` equals `\"Sarah\"` and `this.lastName` equals `\"Smith\"`. What we actually did, is defining `global.firstName = 'Sarah'` and `global.lastName = 'Smith'`. `sarah` itself is left `undefined`, since we don't return a value from the `Person` function.\n\n</p>\n</details>\n\n---\n\n###### 13. What are the three phases of event propagation?\n\n- A: Target > Capturing > Bubbling\n- B: Bubbling > Target > Capturing\n- C: Target > Bubbling > Capturing\n- D: Capturing > Target > Bubbling\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nDuring the **capturing** phase, the event goes through the ancestor elements down to the target element. It then reaches the **target** element, and **bubbling** begins.\n\n<img src=\"https://i.imgur.com/N18oRgd.png\" width=\"200\">\n\n</p>\n</details>\n\n---\n\n###### 14. All object have prototypes.\n\n- A: true\n- B: false\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nAll objects have prototypes, except for the **base object**. The base object is the object created by the user, or an object that is created using the `new` keyword. The base object has access to some methods and properties, such as `.toString`. This is the reason why you can use built-in JavaScript methods! All of such methods are available on the prototype. Although JavaScript can't find it directly on your object, it goes down the prototype chain and finds it there, which makes it accessible for you.\n\n</p>\n</details>\n\n---\n\n###### 15. What's the output?\n\n```javascript\nfunction sum(a, b) {\n  return a + b;\n}\n\nsum(1, '2');\n```\n\n- A: `NaN`\n- B: `TypeError`\n- C: `\"12\"`\n- D: `3`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nJavaScript is a **dynamically typed language**: we don't specify what types certain variables are. Values can automatically be converted into another type without you knowing, which is called _implicit type coercion_. **Coercion** is converting from one type into another.\n\nIn this example, JavaScript converts the number `1` into a string, in order for the function to make sense and return a value. During the addition of a numeric type (`1`) and a string type (`'2'`), the number is treated as a string. We can concatenate strings like `\"Hello\" + \"World\"`, so what's happening here is `\"1\" + \"2\"` which returns `\"12\"`.\n\n</p>\n</details>\n\n---\n\n###### 16. What's the output?\n\n```javascript\nlet number = 0;\nconsole.log(number++);\nconsole.log(++number);\nconsole.log(number);\n```\n\n- A: `1` `1` `2`\n- B: `1` `2` `2`\n- C: `0` `2` `2`\n- D: `0` `1` `2`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe **postfix** unary operator `++`:\n\n1. Returns the value (this returns `0`)\n2. Increments the value (number is now `1`)\n\nThe **prefix** unary operator `++`:\n\n1. Increments the value (number is now `2`)\n2. Returns the value (this returns `2`)\n\nThis returns `0 2 2`.\n\n</p>\n</details>\n\n---\n\n###### 17. What's the output?\n\n```javascript\nfunction getPersonInfo(one, two, three) {\n  console.log(one);\n  console.log(two);\n  console.log(three);\n}\n\nconst person = 'Lydia';\nconst age = 21;\n\ngetPersonInfo`${person} is ${age} years old`;\n```\n\n- A: `\"Lydia\"` `21` `[\"\", \" is \", \" years old\"]`\n- B: `[\"\", \" is \", \" years old\"]` `\"Lydia\"` `21`\n- C: `\"Lydia\"` `[\"\", \" is \", \" years old\"]` `21`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nIf you use tagged template literals, the value of the first argument is always an array of the string values. The remaining arguments get the values of the passed expressions!\n\n</p>\n</details>\n\n---\n\n###### 18. What's the output?\n\n```javascript\nfunction checkAge(data) {\n  if (data === { age: 18 }) {\n    console.log('You are an adult!');\n  } else if (data == { age: 18 }) {\n    console.log('You are still an adult.');\n  } else {\n    console.log(`Hmm.. You don't have an age I guess`);\n  }\n}\n\ncheckAge({ age: 18 });\n```\n\n- A: `You are an adult!`\n- B: `You are still an adult.`\n- C: `Hmm.. You don't have an age I guess`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWhen testing equality, primitives are compared by their _value_, while objects are compared by their _reference_. JavaScript checks if the objects have a reference to the same location in memory.\n\nThe two objects that we are comparing don't have that: the object we passed as a parameter refers to a different location in memory than the object we used in order to check equality.\n\nThis is why both `{ age: 18 } === { age: 18 }` and `{ age: 18 } == { age: 18 }` return `false`.\n\n</p>\n</details>\n\n---\n\n###### 19. What's the output?\n\n```javascript\nfunction getAge(...args) {\n  console.log(typeof args);\n}\n\ngetAge(21);\n```\n\n- A: `\"number\"`\n- B: `\"array\"`\n- C: `\"object\"`\n- D: `\"NaN\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe rest parameter (`...args`) lets us \"collect\" all remaining arguments into an array. An array is an object, so `typeof args` returns `\"object\"`\n\n</p>\n</details>\n\n---\n\n###### 20. What's the output?\n\n```javascript\nfunction getAge() {\n  'use strict';\n  age = 21;\n  console.log(age);\n}\n\ngetAge();\n```\n\n- A: `21`\n- B: `undefined`\n- C: `ReferenceError`\n- D: `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith `\"use strict\"`, you can make sure that you don't accidentally declare global variables. We never declared the variable `age`, and since we use `\"use strict\"`, it will throw a reference error. If we didn't use `\"use strict\"`, it would have worked, since the property `age` would have gotten added to the global object.\n\n</p>\n</details>\n\n---\n\n###### 21. What's the value of `sum`?\n\n```javascript\nconst sum = eval('10*10+5');\n```\n\n- A: `105`\n- B: `\"105\"`\n- C: `TypeError`\n- D: `\"10*10+5\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\n`eval` evaluates code that's passed as a string. If it's an expression, like in this case, it evaluates the expression. The expression is `10 * 10 + 5`. This returns the number `105`.\n\n</p>\n</details>\n\n---\n\n###### 22. How long is cool_secret accessible?\n\n```javascript\nsessionStorage.setItem('cool_secret', 123);\n```\n\n- A: Forever, the data doesn't get lost.\n- B: When the user closes the tab.\n- C: When the user closes the entire browser, not only the tab.\n- D: When the user shuts off their computer.\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nThe data stored in `sessionStorage` is removed after closing the _tab_.\n\nIf you used `localStorage`, the data would've been there forever, unless for example `localStorage.clear()` is invoked.\n\n</p>\n</details>\n\n---\n\n###### 23. What's the output?\n\n```javascript\nvar num = 8;\nvar num = 10;\n\nconsole.log(num);\n```\n\n- A: `8`\n- B: `10`\n- C: `SyntaxError`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the `var` keyword, you can declare multiple variables with the same name. The variable will then hold the latest value.\n\nYou cannot do this with `let` or `const` since they're block-scoped and therefore can't be redeclared.\n\n</p>\n</details>\n\n---\n\n###### 24. What's the output?\n\n```javascript\nconst obj = { 1: 'a', 2: 'b', 3: 'c' };\nconst set = new Set([1, 2, 3, 4, 5]);\n\nobj.hasOwnProperty('1');\nobj.hasOwnProperty(1);\nset.has('1');\nset.has(1);\n```\n\n- A: `false` `true` `false` `true`\n- B: `false` `true` `true` `true`\n- C: `true` `true` `false` `true`\n- D: `true` `true` `true` `true`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nAll object keys (excluding Symbols) are strings under the hood, even if you don't type it yourself as a string. This is why `obj.hasOwnProperty('1')` also returns true.\n\nIt doesn't work that way for a set. There is no `'1'` in our set: `set.has('1')` returns `false`. It has the numeric type `1`, `set.has(1)` returns `true`.\n\n</p>\n</details>\n\n---\n\n###### 25. What's the output?\n\n```javascript\nconst obj = { a: 'one', b: 'two', a: 'three' };\nconsole.log(obj);\n```\n\n- A: `{ a: \"one\", b: \"two\" }`\n- B: `{ b: \"two\", a: \"three\" }`\n- C: `{ a: \"three\", b: \"two\" }`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nIf you have two keys with the same name, the key will be replaced. It will still be in its first position, but with the last specified value.\n\n</p>\n</details>\n\n---\n\n###### 26. The JavaScript global execution context creates two things for you: the global object, and the \"this\" keyword.\n\n- A: true\n- B: false\n- C: it depends\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe base execution context is the global execution context: it's what's accessible everywhere in your code.\n\n</p>\n</details>\n\n---\n\n###### 27. What's the output?\n\n```javascript\nfor (let i = 1; i < 5; i++) {\n  if (i === 3) continue;\n  console.log(i);\n}\n```\n\n- A: `1` `2`\n- B: `1` `2` `3`\n- C: `1` `2` `4`\n- D: `1` `3` `4`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `continue` statement skips an iteration if a certain condition returns `true`.\n\n</p>\n</details>\n\n---\n\n###### 28. What's the output?\n\n```javascript\nString.prototype.giveLydiaPizza = () => {\n  return 'Just give Lydia pizza already!';\n};\n\nconst name = 'Lydia';\n\nconsole.log(name.giveLydiaPizza())\n```\n\n- A: `\"Just give Lydia pizza already!\"`\n- B: `TypeError: not a function`\n- C: `SyntaxError`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\n`String` is a built-in constructor, that we can add properties to. I just added a method to its prototype. Primitive strings are automatically converted into a string object, generated by the string prototype function. So, all strings (string objects) have access to that method!\n\n</p>\n</details>\n\n---\n\n###### 29. What's the output?\n\n```javascript\nconst a = {};\nconst b = { key: 'b' };\nconst c = { key: 'c' };\n\na[b] = 123;\na[c] = 456;\n\nconsole.log(a[b]);\n```\n\n- A: `123`\n- B: `456`\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nObject keys are automatically converted into strings. We are trying to set an object as a key to object `a`, with the value of `123`.\n\nHowever, when we stringify an object, it becomes `\"[object Object]\"`. So what we are saying here, is that `a[\"[object Object]\"] = 123`. Then, we can try to do the same again. `c` is another object that we are implicitly stringifying. So then, `a[\"[object Object]\"] = 456`.\n\nThen, we log `a[b]`, which is actually `a[\"[object Object]\"]`. We just set that to `456`, so it returns `456`.\n\n</p>\n</details>\n\n---\n\n###### 30. What's the output?\n\n```javascript\nconst foo = () => console.log('First');\nconst bar = () => setTimeout(() => console.log('Second'));\nconst baz = () => console.log('Third');\n\nbar();\nfoo();\nbaz();\n```\n\n- A: `First` `Second` `Third`\n- B: `First` `Third` `Second`\n- C: `Second` `First` `Third`\n- D: `Second` `Third` `First`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWe have a `setTimeout` function and invoked it first. Yet, it was logged last.\n\nThis is because in browsers, we don't just have the runtime engine, we also have something called a `WebAPI`. The `WebAPI` gives us the `setTimeout` function to start with, and for example the DOM.\n\nAfter the _callback_ is pushed to the WebAPI, the `setTimeout` function itself (but not the callback!) is popped off the stack.\n\n<img src=\"https://i.imgur.com/X5wsHOg.png\" width=\"200\">\n\nNow, `foo` gets invoked, and `\"First\"` is being logged.\n\n<img src=\"https://i.imgur.com/Pvc0dGq.png\" width=\"200\">\n\n`foo` is popped off the stack, and `baz` gets invoked. `\"Third\"` gets logged.\n\n<img src=\"https://i.imgur.com/WhA2bCP.png\" width=\"200\">\n\nThe WebAPI can't just add stuff to the stack whenever it's ready. Instead, it pushes the callback function to something called the _queue_.\n\n<img src=\"https://i.imgur.com/NSnDZmU.png\" width=\"200\">\n\nThis is where an event loop starts to work. An **event loop** looks at the stack and task queue. If the stack is empty, it takes the first thing on the queue and pushes it onto the stack.\n\n<img src=\"https://i.imgur.com/uyiScAI.png\" width=\"200\">\n\n`bar` gets invoked, `\"Second\"` gets logged, and it's popped off the stack.\n\n</p>\n</details>\n\n---\n\n###### 31. What is the event.target when clicking the button?\n\n```html\n<div onclick=\"console.log('first div')\">\n  <div onclick=\"console.log('second div')\">\n    <button onclick=\"console.log('button')\">\n      Click!\n    </button>\n  </div>\n</div>\n```\n\n- A: Outer `div`\n- B: Inner `div`\n- C: `button`\n- D: An array of all nested elements.\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe deepest nested element that caused the event is the target of the event. You can stop bubbling by `event.stopPropagation`\n\n</p>\n</details>\n\n---\n\n###### 32. When you click the paragraph, what's the logged output?\n\n```html\n<div onclick=\"console.log('div')\">\n  <p onclick=\"console.log('p')\">\n    Click here!\n  </p>\n</div>\n```\n\n- A: `p` `div`\n- B: `div` `p`\n- C: `p`\n- D: `div`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nIf we click `p`, we see two logs: `p` and `div`. During event propagation, there are 3 phases: capturing, targeting, and bubbling. By default, event handlers are executed in the bubbling phase (unless you set `useCapture` to `true`). It goes from the deepest nested element outwards.\n\n</p>\n</details>\n\n---\n\n###### 33. What's the output?\n\n```javascript\nconst person = { name: 'Lydia' };\n\nfunction sayHi(age) {\n  return `${this.name} is ${age}`;\n}\n\nconsole.log(sayHi.call(person, 21));\nconsole.log(sayHi.bind(person, 21));\n```\n\n- A: `undefined is 21` `Lydia is 21`\n- B: `function` `function`\n- C: `Lydia is 21` `Lydia is 21`\n- D: `Lydia is 21` `function`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nWith both, we can pass the object to which we want the `this` keyword to refer to. However, `.call` is also _executed immediately_!\n\n`.bind.` returns a _copy_ of the function, but with a bound context! It is not executed immediately.\n\n</p>\n</details>\n\n---\n\n###### 34. What's the output?\n\n```javascript\nfunction sayHi() {\n  return (() => 0)();\n}\n\nconsole.log(typeof sayHi());\n```\n\n- A: `\"object\"`\n- B: `\"number\"`\n- C: `\"function\"`\n- D: `\"undefined\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nThe `sayHi` function returns the returned value of the immediately invoked function expression (IIFE). This function returned `0`, which is type `\"number\"`.\n\t\nFYI: `typeof` can return the following list of values: `undefined`, `boolean`, `number`, `bigint`, `string`, `symbol`, `function` and `object`. Note that `typeof null` returns `\"object\"`.\n\n</p>\n</details>\n\n---\n\n###### 35. Which of these values are falsy?\n\n```javascript\n0;\nnew Number(0);\n('');\n(' ');\nnew Boolean(false);\nundefined;\n```\n\n- A: `0`, `''`, `undefined`\n- B: `0`, `new Number(0)`, `''`, `new Boolean(false)`, `undefined`\n- C: `0`, `''`, `new Boolean(false)`, `undefined`\n- D: All of them are falsy\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThere are 8 falsy values:\n\n- `undefined`\n- `null`\n- `NaN`\n- `false`\n- `''` (empty string)\n- `0`\n- `-0`\n- `0n` (BigInt(0))\n\nFunction constructors, like `new Number` and `new Boolean` are truthy.\n\n</p>\n</details>\n\n---\n\n###### 36. What's the output?\n\n```javascript\nconsole.log(typeof typeof 1);\n```\n\n- A: `\"number\"`\n- B: `\"string\"`\n- C: `\"object\"`\n- D: `\"undefined\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\n`typeof 1` returns `\"number\"`.\n`typeof \"number\"` returns `\"string\"`\n\n</p>\n</details>\n\n---\n\n###### 37. What's the output?\n\n```javascript\nconst numbers = [1, 2, 3];\nnumbers[10] = 11;\nconsole.log(numbers);\n```\n\n- A: `[1, 2, 3, null x 7, 11]`\n- B: `[1, 2, 3, 11]`\n- C: `[1, 2, 3, empty x 7, 11]`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWhen you set a value to an element in an array that exceeds the length of the array, JavaScript creates something called \"empty slots\". These actually have the value of `undefined`, but you will see something like:\n\n`[1, 2, 3, empty x 7, 11]`\n\ndepending on where you run it (it's different for every browser, node, etc.)\n\n</p>\n</details>\n\n---\n\n###### 38. What's the output?\n\n```javascript\n(() => {\n  let x, y;\n  try {\n    throw new Error();\n  } catch (x) {\n    (x = 1), (y = 2);\n    console.log(x);\n  }\n  console.log(x);\n  console.log(y);\n})();\n```\n\n- A: `1` `undefined` `2`\n- B: `undefined` `undefined` `undefined`\n- C: `1` `1` `2`\n- D: `1` `undefined` `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe `catch` block receives the argument `x`. This is not the same `x` as the variable when we pass arguments. This variable `x` is block-scoped.\n\nLater, we set this block-scoped variable equal to `1`, and set the value of the variable `y`. Now, we log the block-scoped variable `x`, which is equal to `1`.\n\nOutside of the `catch` block, `x` is still `undefined`, and `y` is `2`. When we want to `console.log(x)` outside of the `catch` block, it returns `undefined`, and `y` returns `2`.\n\n</p>\n</details>\n\n---\n\n###### 39. Everything in JavaScript is either a...\n\n- A: primitive or object\n- B: function or object\n- C: trick question! only objects\n- D: number or object\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nJavaScript only has primitive types and objects.\n\nPrimitive types are `boolean`, `null`, `undefined`, `bigint`, `number`, `string`, and `symbol`.\n\nWhat differentiates a primitive from an object is that primitives do not have any properties or methods; however, you'll note that `'foo'.toUpperCase()` evaluates to `'FOO'` and does not result in a `TypeError`. This is because when you try to access a property or method on a primitive like a string, JavaScript will implicitly wrap the primitive type using one of the wrapper classes, i.e. `String`, and then immediately discard the wrapper after the expression evaluates. All primitives except for `null` and `undefined` exhibit this behavior.\n\n</p>\n</details>\n\n---\n\n###### 40. What's the output?\n\n```javascript\n[[0, 1], [2, 3]].reduce(\n  (acc, cur) => {\n    return acc.concat(cur);\n  },\n  [1, 2],\n);\n```\n\n- A: `[0, 1, 2, 3, 1, 2]`\n- B: `[6, 1, 2]`\n- C: `[1, 2, 0, 1, 2, 3]`\n- D: `[1, 2, 6]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\n`[1, 2]` is our initial value. This is the value we start with, and the value of the very first `acc`. During the first round, `acc` is `[1,2]`, and `cur` is `[0, 1]`. We concatenate them, which results in `[1, 2, 0, 1]`.\n\nThen, `[1, 2, 0, 1]` is `acc` and `[2, 3]` is `cur`. We concatenate them, and get `[1, 2, 0, 1, 2, 3]`\n\n</p>\n</details>\n\n---\n\n###### 41. What's the output?\n\n```javascript\n!!null;\n!!'';\n!!1;\n```\n\n- A: `false` `true` `false`\n- B: `false` `false` `true`\n- C: `false` `true` `true`\n- D: `true` `true` `false`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\n`null` is falsy. `!null` returns `true`. `!true` returns `false`.\n\n`\"\"` is falsy. `!\"\"` returns `true`. `!true` returns `false`.\n\n`1` is truthy. `!1` returns `false`. `!false` returns `true`.\n\n</p>\n</details>\n\n---\n\n###### 42. What does the `setInterval` method return in the browser?\n\n```javascript\nsetInterval(() => console.log('Hi'), 1000);\n```\n\n- A: a unique id\n- B: the amount of milliseconds specified\n- C: the passed function\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nIt returns a unique id. This id can be used to clear that interval with the `clearInterval()` function.\n\n</p>\n</details>\n\n---\n\n###### 43. What does this return?\n\n```javascript\n[...'Lydia'];\n```\n\n- A: `[\"L\", \"y\", \"d\", \"i\", \"a\"]`\n- B: `[\"Lydia\"]`\n- C: `[[], \"Lydia\"]`\n- D: `[[\"L\", \"y\", \"d\", \"i\", \"a\"]]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nA string is an iterable. The spread operator maps every character of an iterable to one element.\n\n</p>\n</details>\n\n---\n\n###### 44. What's the output?\n\n```javascript\nfunction* generator(i) {\n  yield i;\n  yield i * 2;\n}\n\nconst gen = generator(10);\n\nconsole.log(gen.next().value);\nconsole.log(gen.next().value);\n```\n\n- A: `[0, 10], [10, 20]`\n- B: `20, 20`\n- C: `10, 20`\n- D: `0, 10 and 10, 20`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nRegular functions cannot be stopped mid-way after invocation. However, a generator function can be \"stopped\" midway, and later continue from where it stopped. Every time a generator function encounters a `yield` keyword, the function yields the value specified after it. Note that the generator function in that case doesn’t _return_ the value, it _yields_ the value.\n\nFirst, we initialize the generator function with `i` equal to `10`. We invoke the generator function using the `next()` method. The first time we invoke the generator function, `i` is equal to `10`. It encounters the first `yield` keyword: it yields the value of `i`. The generator is now \"paused\", and `10` gets logged.\n\nThen, we invoke the function again with the `next()` method. It starts to continue where it stopped previously, still with `i` equal to `10`. Now, it encounters the next `yield` keyword, and yields `i * 2`. `i` is equal to `10`, so it returns `10 * 2`, which is `20`. This results in `10, 20`.\n\n</p>\n</details>\n\n---\n\n###### 45. What does this return?\n\n```javascript\nconst firstPromise = new Promise((res, rej) => {\n  setTimeout(res, 500, 'one');\n});\n\nconst secondPromise = new Promise((res, rej) => {\n  setTimeout(res, 100, 'two');\n});\n\nPromise.race([firstPromise, secondPromise]).then(res => console.log(res));\n```\n\n- A: `\"one\"`\n- B: `\"two\"`\n- C: `\"two\" \"one\"`\n- D: `\"one\" \"two\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWhen we pass multiple promises to the `Promise.race` method, it resolves/rejects the _first_ promise that resolves/rejects. To the `setTimeout` method, we pass a timer: 500ms for the first promise (`firstPromise`), and 100ms for the second promise (`secondPromise`). This means that the `secondPromise` resolves first with the value of `'two'`. `res` now holds the value of `'two'`, which gets logged.\n\n</p>\n</details>\n\n---\n\n###### 46. What's the output?\n\n```javascript\nlet person = { name: 'Lydia' };\nconst members = [person];\nperson = null;\n\nconsole.log(members);\n```\n\n- A: `null`\n- B: `[null]`\n- C: `[{}]`\n- D: `[{ name: \"Lydia\" }]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nFirst, we declare a variable `person` with the value of an object that has a `name` property.\n\n<img src=\"https://i.imgur.com/TML1MbS.png\" width=\"200\">\n\nThen, we declare a variable called `members`. We set the first element of that array equal to the value of the `person` variable. Objects interact by _reference_ when setting them equal to each other. When you assign a reference from one variable to another, you make a _copy_ of that reference. (note that they don't have the _same_ reference!)\n\n<img src=\"https://i.imgur.com/FSG5K3F.png\" width=\"300\">\n\nThen, we set the variable `person` equal to `null`.\n\n<img src=\"https://i.imgur.com/sYjcsMT.png\" width=\"300\">\n\nWe are only modifying the value of the `person` variable, and not the first element in the array, since that element has a different (copied) reference to the object. The first element in `members` still holds its reference to the original object. When we log the `members` array, the first element still holds the value of the object, which gets logged.\n\n</p>\n</details>\n\n---\n\n###### 47. What's the output?\n\n```javascript\nconst person = {\n  name: 'Lydia',\n  age: 21,\n};\n\nfor (const item in person) {\n  console.log(item);\n}\n```\n\n- A: `{ name: \"Lydia\" }, { age: 21 }`\n- B: `\"name\", \"age\"`\n- C: `\"Lydia\", 21`\n- D: `[\"name\", \"Lydia\"], [\"age\", 21]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith a `for-in` loop, we can iterate through object keys, in this case `name` and `age`. Under the hood, object keys are strings (if they're not a Symbol). On every loop, we set the value of `item` equal to the current key it’s iterating over. First, `item` is equal to `name`, and gets logged. Then, `item` is equal to `age`, which gets logged.\n\n</p>\n</details>\n\n---\n\n###### 48. What's the output?\n\n```javascript\nconsole.log(3 + 4 + '5');\n```\n\n- A: `\"345\"`\n- B: `\"75\"`\n- C: `12`\n- D: `\"12\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nOperator associativity is the order in which the compiler evaluates the expressions, either left-to-right or right-to-left. This only happens if all operators have the _same_ precedence. We only have one type of operator: `+`. For addition, the associativity is left-to-right.\n\n`3 + 4` gets evaluated first. This results in the number `7`.\n\n`7 + '5'` results in `\"75\"` because of coercion. JavaScript converts the number `7` into a string, see question 15. We can concatenate two strings using the `+`operator. `\"7\" + \"5\"` results in `\"75\"`.\n\n</p>\n</details>\n\n---\n\n###### 49. What's the value of `num`?\n\n```javascript\nconst num = parseInt('7*6', 10);\n```\n\n- A: `42`\n- B: `\"42\"`\n- C: `7`\n- D: `NaN`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nOnly the first number in the string is returned. Based on the _radix_ (the second argument in order to specify what type of number we want to parse it to: base 10, hexadecimal, octal, binary, etc.), the `parseInt` checks whether the characters in the string are valid. Once it encounters a character that isn't a valid number in the radix, it stops parsing and ignores the following characters.\n\n`*` is not a valid number. It only parses `\"7\"` into the decimal `7`. `num` now holds the value of `7`.\n\n</p>\n</details>\n\n---\n\n###### 50. What's the output?\n\n```javascript\n[1, 2, 3].map(num => {\n  if (typeof num === 'number') return;\n  return num * 2;\n});\n```\n\n- A: `[]`\n- B: `[null, null, null]`\n- C: `[undefined, undefined, undefined]`\n- D: `[ 3 x empty ]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWhen mapping over the array, the value of `num` is equal to the element it’s currently looping over. In this case, the elements are numbers, so the condition of the if statement `typeof num === \"number\"` returns `true`. The map function creates a new array and inserts the values returned from the function.\n\nHowever, we don’t return a value. When we don’t return a value from the function, the function returns `undefined`. For every element in the array, the function block gets called, so for each element we return `undefined`.\n\n</p>\n</details>\n\n---\n\n###### 51. What's the output?\n\n```javascript\nfunction getInfo(member, year) {\n  member.name = 'Lydia';\n  year = '1998';\n}\n\nconst person = { name: 'Sarah' };\nconst birthYear = '1997';\n\ngetInfo(person, birthYear);\n\nconsole.log(person, birthYear);\n```\n\n- A: `{ name: \"Lydia\" }, \"1997\"`\n- B: `{ name: \"Sarah\" }, \"1998\"`\n- C: `{ name: \"Lydia\" }, \"1998\"`\n- D: `{ name: \"Sarah\" }, \"1997\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nArguments are passed by _value_, unless their value is an object, then they're passed by _reference_. `birthYear` is passed by value, since it's a string, not an object. When we pass arguments by value, a _copy_ of that value is created (see question 46).\n\nThe variable `birthYear` has a reference to the value `\"1997\"`. The argument `year` also has a reference to the value `\"1997\"`, but it's not the same value as `birthYear` has a reference to. When we update the value of `year` by setting `year` equal to `\"1998\"`, we are only updating the value of `year`. `birthYear` is still equal to `\"1997\"`.\n\nThe value of `person` is an object. The argument `member` has a (copied) reference to the _same_ object. When we modify a property of the object `member` has a reference to, the value of `person` will also be modified, since they both have a reference to the same object. `person`'s `name` property is now equal to the value `\"Lydia\"`\n\n</p>\n</details>\n\n---\n\n###### 52. What's the output?\n\n```javascript\nfunction greeting() {\n  throw 'Hello world!';\n}\n\nfunction sayHi() {\n  try {\n    const data = greeting();\n    console.log('It worked!', data);\n  } catch (e) {\n    console.log('Oh no an error:', e);\n  }\n}\n\nsayHi();\n```\n\n- A: `It worked! Hello world!`\n- B: `Oh no an error: undefined`\n- C: `SyntaxError: can only throw Error objects`\n- D: `Oh no an error: Hello world!`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nWith the `throw` statement, we can create custom errors. With this statement, you can throw exceptions. An exception can be a <b>string</b>, a <b>number</b>, a <b>boolean</b> or an <b>object</b>. In this case, our exception is the string `'Hello world!'`.\n\nWith the `catch` statement, we can specify what to do if an exception is thrown in the `try` block. An exception is thrown: the string `'Hello world!'`. `e` is now equal to that string, which we log. This results in `'Oh an error: Hello world!'`.\n\n</p>\n</details>\n\n---\n\n###### 53. What's the output?\n\n```javascript\nfunction Car() {\n  this.make = 'Lamborghini';\n  return { make: 'Maserati' };\n}\n\nconst myCar = new Car();\nconsole.log(myCar.make);\n```\n\n- A: `\"Lamborghini\"`\n- B: `\"Maserati\"`\n- C: `ReferenceError`\n- D: `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWhen a constructor function is called with the `new` keyword, it creates an object and sets the `this` keyword to refer to that object. By default, if the constructor function doesn't explicitly return anything, it will return the newly created object.\n\nIn this case, the constructor function `Car` explicitly returns a new object with `make` set to `\"Maserati\"`, which overrides the default behavior. Therefore, when `new Car()` is called, the _returned_ object is assigned to `myCar`, resulting in the output being `\"Maserati\"` when `myCar.make` is accessed.\n\n</p>\n</details>\n\n---\n\n###### 54. What's the output?\n\n```javascript\n(() => {\n  let x = (y = 10);\n})();\n\nconsole.log(typeof x);\nconsole.log(typeof y);\n```\n\n- A: `\"undefined\", \"number\"`\n- B: `\"number\", \"number\"`\n- C: `\"object\", \"number\"`\n- D: `\"number\", \"undefined\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\n`let x = (y = 10);` is actually shorthand for:\n\n```javascript\ny = 10;\nlet x = y;\n```\n\nWhen we set `y` equal to `10`, we actually add a property `y` to the global object (`window` in the browser, `global` in Node). In a browser, `window.y` is now equal to `10`.\n\nThen, we declare a variable `x` with the value of `y`, which is `10`. Variables declared with the `let` keyword are _block scoped_, they are only defined within the block they're declared in; the immediately invoked function expression (IIFE) in this case. When we use the `typeof` operator, the operand `x` is not defined: we are trying to access `x` outside of the block it's declared in. This means that `x` is not defined. Values who haven't been assigned a value or declared are of type `\"undefined\"`. `console.log(typeof x)` returns `\"undefined\"`.\n\nHowever, we created a global variable `y` when setting `y` equal to `10`. This value is accessible anywhere in our code. `y` is defined, and holds a value of type `\"number\"`. `console.log(typeof y)` returns `\"number\"`.\n\n</p>\n</details>\n\n---\n\n###### 55. What's the output?\n\n```javascript\nclass Dog {\n  constructor(name) {\n    this.name = name;\n  }\n}\n\nDog.prototype.bark = function() {\n  console.log(`Woof I am ${this.name}`);\n};\n\nconst pet = new Dog('Mara');\n\npet.bark();\n\ndelete Dog.prototype.bark;\n\npet.bark();\n```\n\n- A: `\"Woof I am Mara\"`, `TypeError`\n- B: `\"Woof I am Mara\"`, `\"Woof I am Mara\"`\n- C: `\"Woof I am Mara\"`, `undefined`\n- D: `TypeError`, `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWe can delete properties from objects using the `delete` keyword, also on the prototype. By deleting a property on the prototype, it is not available anymore in the prototype chain. In this case, the `bark` function is not available anymore on the prototype after `delete Dog.prototype.bark`, yet we still try to access it.\n\nWhen we try to invoke something that is not a function, a `TypeError` is thrown. In this case `TypeError: pet.bark is not a function`, since `pet.bark` is `undefined`.\n\n</p>\n</details>\n\n---\n\n###### 56. What's the output?\n\n```javascript\nconst set = new Set([1, 1, 2, 3, 4]);\n\nconsole.log(set);\n```\n\n- A: `[1, 1, 2, 3, 4]`\n- B: `[1, 2, 3, 4]`\n- C: `{1, 1, 2, 3, 4}`\n- D: `{1, 2, 3, 4}`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `Set` object is a collection of _unique_ values: a value can only occur once in a set.\n\nWe passed the iterable `[1, 1, 2, 3, 4]` with a duplicate value `1`. Since we cannot have two of the same values in a set, one of them is removed. This results in `{1, 2, 3, 4}`.\n\n</p>\n</details>\n\n---\n\n###### 57. What's the output?\n\n```javascript\n// counter.js\nlet counter = 10;\nexport default counter;\n```\n\n```javascript\n// index.js\nimport myCounter from './counter';\n\nmyCounter += 1;\n\nconsole.log(myCounter);\n```\n\n- A: `10`\n- B: `11`\n- C: `Error`\n- D: `NaN`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nAn imported module is _read-only_: you cannot modify the imported module. Only the module that exports them can change its value.\n\nWhen we try to increment the value of `myCounter`, it throws an error: `myCounter` is read-only and cannot be modified.\n\n</p>\n</details>\n\n---\n\n###### 58. What's the output?\n\n```javascript\nconst name = 'Lydia';\nage = 21;\n\nconsole.log(delete name);\nconsole.log(delete age);\n```\n\n- A: `false`, `true`\n- B: `\"Lydia\"`, `21`\n- C: `true`, `true`\n- D: `undefined`, `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe `delete` operator returns a boolean value: `true` on a successful deletion, else it'll return `false`. However, variables declared with the `var`, `const`, or `let` keywords cannot be deleted using the `delete` operator.\n\nThe `name` variable was declared with a `const` keyword, so its deletion is not successful: `false` is returned. When we set `age` equal to `21`, we actually added a property called `age` to the global object. You can successfully delete properties from objects this way, also the global object, so `delete age` returns `true`.\n\n</p>\n</details>\n\n---\n\n###### 59. What's the output?\n\n```javascript\nconst numbers = [1, 2, 3, 4, 5];\nconst [y] = numbers;\n\nconsole.log(y);\n```\n\n- A: `[[1, 2, 3, 4, 5]]`\n- B: `[1, 2, 3, 4, 5]`\n- C: `1`\n- D: `[1]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWe can unpack values from arrays or properties from objects through destructuring. For example:\n\n```javascript\n[a, b] = [1, 2];\n```\n\n<img src=\"https://i.imgur.com/ADFpVop.png\" width=\"200\">\n\nThe value of `a` is now `1`, and the value of `b` is now `2`. What we actually did in the question, is:\n\n```javascript\n[y] = [1, 2, 3, 4, 5];\n```\n\n<img src=\"https://i.imgur.com/NzGkMNk.png\" width=\"200\">\n\nThis means that the value of `y` is equal to the first value in the array, which is the number `1`. When we log `y`, `1` is returned.\n\n</p>\n</details>\n\n---\n\n###### 60. What's the output?\n\n```javascript\nconst user = { name: 'Lydia', age: 21 };\nconst admin = { admin: true, ...user };\n\nconsole.log(admin);\n```\n\n- A: `{ admin: true, user: { name: \"Lydia\", age: 21 } }`\n- B: `{ admin: true, name: \"Lydia\", age: 21 }`\n- C: `{ admin: true, user: [\"Lydia\", 21] }`\n- D: `{ admin: true }`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nIt's possible to combine objects using the spread operator `...`. It lets you create copies of the key/value pairs of one object, and add them to another object. In this case, we create copies of the `user` object, and add them to the `admin` object. The `admin` object now contains the copied key/value pairs, which results in `{ admin: true, name: \"Lydia\", age: 21 }`.\n\n</p>\n</details>\n\n---\n\n###### 61. What's the output?\n\n```javascript\nconst person = { name: 'Lydia' };\n\nObject.defineProperty(person, 'age', { value: 21 });\n\nconsole.log(person);\nconsole.log(Object.keys(person));\n```\n\n- A: `{ name: \"Lydia\", age: 21 }`, `[\"name\", \"age\"]`\n- B: `{ name: \"Lydia\", age: 21 }`, `[\"name\"]`\n- C: `{ name: \"Lydia\"}`, `[\"name\", \"age\"]`\n- D: `{ name: \"Lydia\"}`, `[\"age\"]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the `defineProperty` method, we can add new properties to an object, or modify existing ones. When we add a property to an object using the `defineProperty` method, they are by default _not enumerable_. The `Object.keys` method returns all _enumerable_ property names from an object, in this case only `\"name\"`.\n\nProperties added using the `defineProperty` method are immutable by default. You can override this behavior using the `writable`, `configurable` and `enumerable` properties. This way, the `defineProperty` method gives you a lot more control over the properties you're adding to an object.\n\n</p>\n</details>\n\n---\n\n###### 62. What's the output?\n\n```javascript\nconst settings = {\n  username: 'lydiahallie',\n  level: 19,\n  health: 90,\n};\n\nconst data = JSON.stringify(settings, ['level', 'health']);\nconsole.log(data);\n```\n\n- A: `\"{\"level\":19, \"health\":90}\"`\n- B: `\"{\"username\": \"lydiahallie\"}\"`\n- C: `\"[\"level\", \"health\"]\"`\n- D: `\"{\"username\": \"lydiahallie\", \"level\":19, \"health\":90}\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe second argument of `JSON.stringify` is the _replacer_. The replacer can either be a function or an array, and lets you control what and how the values should be stringified.\n\nIf the replacer is an _array_, only the property names included in the array will be added to the JSON string. In this case, only the properties with the names `\"level\"` and `\"health\"` are included, `\"username\"` is excluded. `data` is now equal to `\"{\"level\":19, \"health\":90}\"`.\n\nIf the replacer is a _function_, this function gets called on every property in the object you're stringifying. The value returned from this function will be the value of the property when it's added to the JSON string. If the value is `undefined`, this property is excluded from the JSON string.\n\n</p>\n</details>\n\n---\n\n###### 63. What's the output?\n\n```javascript\nlet num = 10;\n\nconst increaseNumber = () => num++;\nconst increasePassedNumber = number => number++;\n\nconst num1 = increaseNumber();\nconst num2 = increasePassedNumber(num1);\n\nconsole.log(num1);\nconsole.log(num2);\n```\n\n- A: `10`, `10`\n- B: `10`, `11`\n- C: `11`, `11`\n- D: `11`, `12`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe unary operator `++` _first returns_ the value of the operand, _then increments_ the value of the operand. The value of `num1` is `10`, since the `increaseNumber` function first returns the value of `num`, which is `10`, and only increments the value of `num` afterward.\n\n`num2` is `10`, since we passed `num1` to the `increasePassedNumber`. `number` is equal to `10`(the value of `num1`). Again, the unary operator `++` _first returns_ the value of the operand, _then increments_ the value of the operand. The value of `number` is `10`, so `num2` is equal to `10`.\n\n</p>\n</details>\n\n---\n\n###### 64. What's the output?\n\n```javascript\nconst value = { number: 10 };\n\nconst multiply = (x = { ...value }) => {\n  console.log((x.number *= 2));\n};\n\nmultiply();\nmultiply();\nmultiply(value);\nmultiply(value);\n```\n\n- A: `20`, `40`, `80`, `160`\n- B: `20`, `40`, `20`, `40`\n- C: `20`, `20`, `20`, `40`\n- D: `NaN`, `NaN`, `20`, `40`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nIn ES6, we can initialize parameters with a default value. The value of the parameter will be the default value, if no other value has been passed to the function, or if the value of the parameter is `\"undefined\"`. In this case, we spread the properties of the `value` object into a new object, so `x` has the default value of `{ number: 10 }`.\n\nThe default argument is evaluated at _call time_! Every time we call the function, a _new_ object is created. We invoke the `multiply` function the first two times without passing a value: `x` has the default value of `{ number: 10 }`. We then log the multiplied value of that number, which is `20`.\n\nThe third time we invoke multiply, we do pass an argument: the object called `value`. The `*=` operator is actually shorthand for `x.number = x.number * 2`: we modify the value of `x.number`, and log the multiplied value `20`.\n\nThe fourth time, we pass the `value` object again. `x.number` was previously modified to `20`, so `x.number *= 2` logs `40`.\n\n</p>\n</details>\n\n---\n\n###### 65. What's the output?\n\n```javascript\n[1, 2, 3, 4].reduce((x, y) => console.log(x, y));\n```\n\n- A: `1` `2` and `3` `3` and `6` `4`\n- B: `1` `2` and `2` `3` and `3` `4`\n- C: `1` `undefined` and `2` `undefined` and `3` `undefined` and `4` `undefined`\n- D: `1` `2` and `undefined` `3` and `undefined` `4`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe first argument that the `reduce` method receives is the _accumulator_, `x` in this case. The second argument is the _current value_, `y`. With the reduce method, we execute a callback function on every element in the array, which could ultimately result in one single value.\n\nIn this example, we are not returning any values, we are simply logging the values of the accumulator and the current value.\n\nThe value of the accumulator is equal to the previously returned value of the callback function. If you don't pass the optional `initialValue` argument to the `reduce` method, the accumulator is equal to the first element on the first call.\n\nOn the first call, the accumulator (`x`) is `1`, and the current value (`y`) is `2`. We don't return from the callback function, we log the accumulator, and the current values: `1` and `2` get logged.\n\nIf you don't return a value from a function, it returns `undefined`. On the next call, the accumulator is `undefined`, and the current value is `3`. `undefined` and `3` get logged.\n\nOn the fourth call, we again don't return from the callback function. The accumulator is again `undefined`, and the current value is `4`. `undefined` and `4` get logged.\n\n</p>\n</details>\n  \n---\n\n###### 66. With which constructor can we successfully extend the `Dog` class?\n\n```javascript\nclass Dog {\n  constructor(name) {\n    this.name = name;\n  }\n};\n\nclass Labrador extends Dog {\n  // 1\n  constructor(name, size) {\n    this.size = size;\n  }\n  // 2\n  constructor(name, size) {\n    super(name);\n    this.size = size;\n  }\n  // 3\n  constructor(size) {\n    super(name);\n    this.size = size;\n  }\n  // 4\n  constructor(name, size) {\n    this.name = name;\n    this.size = size;\n  }\n\n};\n```\n\n- A: 1\n- B: 2\n- C: 3\n- D: 4\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nIn a derived class, you cannot access the `this` keyword before calling `super`. If you try to do that, it will throw a ReferenceError: 1 and 4 would throw a reference error.\n\nWith the `super` keyword, we call that parent class's constructor with the given arguments. The parent's constructor receives the `name` argument, so we need to pass `name` to `super`.\n\nThe `Labrador` class receives two arguments, `name` since it extends `Dog`, and `size` as an extra property on the `Labrador` class. They both need to be passed to the constructor function on `Labrador`, which is done correctly using constructor 2.\n\n</p>\n</details>\n\n---\n\n###### 67. What's the output?\n\n```javascript\n// index.js\nconsole.log('running index.js');\nimport { sum } from './sum.js';\nconsole.log(sum(1, 2));\n\n// sum.js\nconsole.log('running sum.js');\nexport const sum = (a, b) => a + b;\n```\n\n- A: `running index.js`, `running sum.js`, `3`\n- B: `running sum.js`, `running index.js`, `3`\n- C: `running sum.js`, `3`, `running index.js`\n- D: `running index.js`, `undefined`, `running sum.js`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the `import` keyword, all imported modules are _pre-parsed_. This means that the imported modules get run _first_, and the code in the file that imports the module gets executed _after_.\n\nThis is a difference between `require()` in CommonJS and `import`! With `require()`, you can load dependencies on demand while the code is being run. If we had used `require` instead of `import`, `running index.js`, `running sum.js`, `3` would have been logged to the console.\n\n</p>\n</details>\n\n---\n\n###### 68. What's the output?\n\n```javascript\nconsole.log(Number(2) === Number(2));\nconsole.log(Boolean(false) === Boolean(false));\nconsole.log(Symbol('foo') === Symbol('foo'));\n```\n\n- A: `true`, `true`, `false`\n- B: `false`, `true`, `false`\n- C: `true`, `false`, `true`\n- D: `true`, `true`, `true`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nEvery Symbol is entirely unique. The purpose of the argument passed to the Symbol is to give the Symbol a description. The value of the Symbol is not dependent on the passed argument. As we test equality, we are creating two entirely new symbols: the first `Symbol('foo')`, and the second `Symbol('foo')`. These two values are unique and not equal to each other, `Symbol('foo') === Symbol('foo')` returns `false`.\n\n</p>\n</details>\n\n---\n\n###### 69. What's the output?\n\n```javascript\nconst name = 'Lydia Hallie';\nconsole.log(name.padStart(13));\nconsole.log(name.padStart(2));\n```\n\n- A: `\"Lydia Hallie\"`, `\"Lydia Hallie\"`\n- B: `\" Lydia Hallie\"`, `\" Lydia Hallie\"` (`\"[13x whitespace]Lydia Hallie\"`, `\"[2x whitespace]Lydia Hallie\"`)\n- C: `\" Lydia Hallie\"`, `\"Lydia Hallie\"` (`\"[1x whitespace]Lydia Hallie\"`, `\"Lydia Hallie\"`)\n- D: `\"Lydia Hallie\"`, `\"Lyd\"`,\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith the `padStart` method, we can add padding to the beginning of a string. The value passed to this method is the _total_ length of the string together with the padding. The string `\"Lydia Hallie\"` has a length of `12`. `name.padStart(13)` inserts 1 space at the start of the string, because 12 + 1 is 13.\n\nIf the argument passed to the `padStart` method is smaller than the length of the array, no padding will be added.\n\n</p>\n</details>\n\n---\n\n###### 70. What's the output?\n\n```javascript\nconsole.log('🥑' + '💻');\n```\n\n- A: `\"🥑💻\"`\n- B: `257548`\n- C: A string containing their code points\n- D: Error\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWith the `+` operator, you can concatenate strings. In this case, we are concatenating the string `\"🥑\"` with the string `\"💻\"`, resulting in `\"🥑💻\"`.\n\n</p>\n</details>\n\n---\n\n###### 71. How can we log the values that are commented out after the console.log statement?\n\n```javascript\nfunction* startGame() {\n  const answer = yield 'Do you love JavaScript?';\n  if (answer !== 'Yes') {\n    return \"Oh wow... Guess we're done here\";\n  }\n  return 'JavaScript loves you back ❤️';\n}\n\nconst game = startGame();\nconsole.log(/* 1 */); // Do you love JavaScript?\nconsole.log(/* 2 */); // JavaScript loves you back ❤️\n```\n\n- A: `game.next(\"Yes\").value` and `game.next().value`\n- B: `game.next.value(\"Yes\")` and `game.next.value()`\n- C: `game.next().value` and `game.next(\"Yes\").value`\n- D: `game.next.value()` and `game.next.value(\"Yes\")`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nA generator function \"pauses\" its execution when it sees the `yield` keyword. First, we have to let the function yield the string \"Do you love JavaScript?\", which can be done by calling `game.next().value`.\n\nEvery line is executed, until it finds the first `yield` keyword. There is a `yield` keyword on the first line within the function: the execution stops with the first yield! _This means that the variable `answer` is not defined yet!_\n\nWhen we call `game.next(\"Yes\").value`, the previous `yield` is replaced with the value of the parameters passed to the `next()` function, `\"Yes\"` in this case. The value of the variable `answer` is now equal to `\"Yes\"`. The condition of the if-statement returns `false`, and `JavaScript loves you back ❤️` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 72. What's the output?\n\n```javascript\nconsole.log(String.raw`Hello\\nworld`);\n```\n\n- A: `Hello world!`\n- B: `Hello` <br />&nbsp; &nbsp; &nbsp;`world`\n- C: `Hello\\nworld`\n- D: `Hello\\n` <br /> &nbsp; &nbsp; &nbsp;`world`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\n`String.raw` returns a string where the escapes (`\\n`, `\\v`, `\\t` etc.) are ignored! Backslashes can be an issue since you could end up with something like:\n\n`` const path = `C:\\Documents\\Projects\\table.html` ``\n\nWhich would result in:\n\n`\"C:DocumentsProjects able.html\"`\n\nWith `String.raw`, it would simply ignore the escape and print:\n\n`C:\\Documents\\Projects\\table.html`\n\nIn this case, the string is `Hello\\nworld`, which gets logged.\n\n</p>\n</details>\n\n---\n\n###### 73. What's the output?\n\n```javascript\nasync function getData() {\n  return await Promise.resolve('I made it!');\n}\n\nconst data = getData();\nconsole.log(data);\n```\n\n- A: `\"I made it!\"`\n- B: `Promise {<resolved>: \"I made it!\"}`\n- C: `Promise {<pending>}`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nAn async function always returns a promise. The `await` still has to wait for the promise to resolve: a pending promise gets returned when we call `getData()` in order to set `data` equal to it.\n\nIf we wanted to get access to the resolved value `\"I made it\"`, we could have used the `.then()` method on `data`:\n\n`data.then(res => console.log(res))`\n\nThis would've logged `\"I made it!\"`\n\n</p>\n</details>\n\n---\n\n###### 74. What's the output?\n\n```javascript\nfunction addToList(item, list) {\n  return list.push(item);\n}\n\nconst result = addToList('apple', ['banana']);\nconsole.log(result);\n```\n\n- A: `['apple', 'banana']`\n- B: `2`\n- C: `true`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nThe `.push()` method returns the _length_ of the new array! Previously, the array contained one element (the string `\"banana\"`) and had a length of `1`. After adding the string `\"apple\"` to the array, the array contains two elements, and has a length of `2`. This gets returned from the `addToList` function.\n\nThe `push` method modifies the original array. If you wanted to return the _array_ from the function rather than the _length of the array_, you should have returned `list` after pushing `item` to it.\n\n</p>\n</details>\n\n---\n\n###### 75. What's the output?\n\n```javascript\nconst box = { x: 10, y: 20 };\n\nObject.freeze(box);\n\nconst shape = box;\nshape.x = 100;\n\nconsole.log(shape);\n```\n\n- A: `{ x: 100, y: 20 }`\n- B: `{ x: 10, y: 20 }`\n- C: `{ x: 100 }`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\n`Object.freeze` makes it impossible to add, remove, or modify properties of an object (unless the property's value is another object).\n\nWhen we create the variable `shape` and set it equal to the frozen object `box`, `shape` also refers to a frozen object. You can check whether an object is frozen by using `Object.isFrozen`. In this case, `Object.isFrozen(shape)` would return true, since the variable `shape` has a reference to a frozen object.\n\nSince `shape` is frozen, and since the value of `x` is not an object, we cannot modify the property `x`. `x` is still equal to `10`, and `{ x: 10, y: 20 }` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 76. What's the output?\n\n```javascript\nconst { firstName: myName } = { firstName: 'Lydia' };\n\nconsole.log(firstName);\n```\n\n- A: `\"Lydia\"`\n- B: `\"myName\"`\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nBy using [destructuring assignment](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment) syntax we can unpack values from arrays, or properties from objects, into distinct variables:\n\n```javascript\nconst { firstName } = { firstName: 'Lydia' };\n// ES5 version:\n// var firstName = { firstName: 'Lydia' }.firstName;\n\nconsole.log(firstName); // \"Lydia\"\n```\n\nAlso, a property can be unpacked from an object and assigned to a variable with a different name than the object property:\n\n```javascript\nconst { firstName: myName } = { firstName: 'Lydia' };\n// ES5 version:\n// var myName = { firstName: 'Lydia' }.firstName;\n\nconsole.log(myName); // \"Lydia\"\nconsole.log(firstName); // Uncaught ReferenceError: firstName is not defined\n```\n\nTherefore, `firstName` does not exist as a variable, thus attempting to access its value will raise a `ReferenceError`.\n\n**Note:** Be aware of the `global scope` properties:\n\n```javascript\nconst { name: myName } = { name: 'Lydia' };\n\nconsole.log(myName); // \"lydia\"\nconsole.log(name); // \"\" ----- Browser e.g. Chrome\nconsole.log(name); // ReferenceError: name is not defined  ----- NodeJS\n\n```\n\nWhenever Javascript is unable to find a variable within the _current scope_, it climbs up the [Scope chain](https://github.com/getify/You-Dont-Know-JS/blob/2nd-ed/scope-closures/ch3.md) and searches for it and if it reaches the top-level scope, aka **Global scope**, and still doesn't find it, it will throw a `ReferenceError`.\n\n- In **Browsers** such as _Chrome_, `name` is a _deprecated global scope property_. In this example, the code is running inside _global scope_ and there is no user-defined local variable for `name`, therefore it searches the predefined _variables/properties_ in the global scope which is in the case of browsers, it searches through `window` object and it will extract the [window.name](https://developer.mozilla.org/en-US/docs/Web/API/Window/name) value which is equal to an **empty string**.\n\n- In **NodeJS**, there is no such property on the `global` object, thus attempting to access a non-existent variable will raise a [ReferenceError](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Not_defined).\n\n</p>\n</details>\n\n---\n\n###### 77. Is this a pure function?\n\n```javascript\nfunction sum(a, b) {\n  return a + b;\n}\n```\n\n- A: Yes\n- B: No\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nA pure function is a function that _always_ returns the same result, if the same arguments are passed.\n\nThe `sum` function always returns the same result. If we pass `1` and `2`, it will _always_ return `3` without side effects. If we pass `5` and `10`, it will _always_ return `15`, and so on. This is the definition of a pure function.\n\n</p>\n</details>\n\n---\n\n###### 78. What is the output?\n\n```javascript\nconst add = () => {\n  const cache = {};\n  return num => {\n    if (num in cache) {\n      return `From cache! ${cache[num]}`;\n    } else {\n      const result = num + 10;\n      cache[num] = result;\n      return `Calculated! ${result}`;\n    }\n  };\n};\n\nconst addFunction = add();\nconsole.log(addFunction(10));\nconsole.log(addFunction(10));\nconsole.log(addFunction(5 * 2));\n```\n\n- A: `Calculated! 20` `Calculated! 20` `Calculated! 20`\n- B: `Calculated! 20` `From cache! 20` `Calculated! 20`\n- C: `Calculated! 20` `From cache! 20` `From cache! 20`\n- D: `Calculated! 20` `From cache! 20` `Error`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `add` function is a _memoized_ function. With memoization, we can cache the results of a function in order to speed up its execution. In this case, we create a `cache` object that stores the previously returned values.\n\nIf we call the `addFunction` function again with the same argument, it first checks whether it has already gotten that value in its cache. If that's the case, the cache value will be returned, which saves execution time. Otherwise, if it's not cached, it will calculate the value and store it afterward.\n\nWe call the `addFunction` function three times with the same value: on the first invocation, the value of the function when `num` is equal to `10` isn't cached yet. The condition of the if-statement `num in cache` returns `false`, and the else block gets executed: `Calculated! 20` gets logged, and the value of the result gets added to the cache object. `cache` now looks like `{ 10: 20 }`.\n\nThe second time, the `cache` object contains the value that gets returned for `10`. The condition of the if-statement `num in cache` returns `true`, and `'From cache! 20'` gets logged.\n\nThe third time, we pass `5 * 2` to the function which gets evaluated to `10`. The `cache` object contains the value that gets returned for `10`. The condition of the if-statement `num in cache` returns `true`, and `'From cache! 20'` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 79. What is the output?\n\n```javascript\nconst myLifeSummedUp = ['☕', '💻', '🍷', '🍫'];\n\nfor (let item in myLifeSummedUp) {\n  console.log(item);\n}\n\nfor (let item of myLifeSummedUp) {\n  console.log(item);\n}\n```\n\n- A: `0` `1` `2` `3` and `\"☕\"` `\"💻\"` `\"🍷\"` `\"🍫\"`\n- B: `\"☕\"` `\"💻\"` `\"🍷\"` `\"🍫\"` and `\"☕\"` `\"💻\"` `\"🍷\"` `\"🍫\"`\n- C: `\"☕\"` `\"💻\"` `\"🍷\"` `\"🍫\"` and `0` `1` `2` `3`\n- D: `0` `1` `2` `3` and `{0: \"☕\", 1: \"💻\", 2: \"🍷\", 3: \"🍫\"}`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWith a _for-in_ loop, we can iterate over **enumerable** properties. In an array, the enumerable properties are the \"keys\" of array elements, which are actually their indexes. You could see an array as:\n\n`{0: \"☕\", 1: \"💻\", 2: \"🍷\", 3: \"🍫\"}`\n\nWhere the keys are the enumerable properties. `0` `1` `2` `3` get logged.\n\nWith a _for-of_ loop, we can iterate over **iterables**. An array is an iterable. When we iterate over the array, the variable \"item\" is equal to the element it's currently iterating over, `\"☕\"` `\"💻\"` `\"🍷\"` `\"🍫\"` get logged.\n\n</p>\n</details>\n\n---\n\n###### 80. What is the output?\n\n```javascript\nconst list = [1 + 2, 1 * 2, 1 / 2];\nconsole.log(list);\n```\n\n- A: `[\"1 + 2\", \"1 * 2\", \"1 / 2\"]`\n- B: `[\"12\", 2, 0.5]`\n- C: `[3, 2, 0.5]`\n- D: `[1, 1, 1]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nArray elements can hold any value. Numbers, strings, objects, other arrays, null, boolean values, undefined, and other expressions such as dates, functions, and calculations.\n\nThe element will be equal to the returned value. `1 + 2` returns `3`, `1 * 2` returns `2`, and `1 / 2` returns `0.5`.\n\n</p>\n</details>\n\n---\n\n###### 81. What is the output?\n\n```javascript\nfunction sayHi(name) {\n  return `Hi there, ${name}`;\n}\n\nconsole.log(sayHi());\n```\n\n- A: `Hi there,`\n- B: `Hi there, undefined`\n- C: `Hi there, null`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nBy default, arguments have the value of `undefined`, unless a value has been passed to the function. In this case, we didn't pass a value for the `name` argument. `name` is equal to `undefined` which gets logged.\n\nIn ES6, we can overwrite this default `undefined` value with default parameters. For example:\n\n`function sayHi(name = \"Lydia\") { ... }`\n\nIn this case, if we didn't pass a value or if we passed `undefined`, `name` would always be equal to the string `Lydia`\n\n</p>\n</details>\n\n---\n\n###### 82. What is the output?\n\n```javascript\nvar status = '😎';\n\nsetTimeout(() => {\n  const status = '😍';\n\n  const data = {\n    status: '🥑',\n    getStatus() {\n      return this.status;\n    },\n  };\n\n  console.log(data.getStatus());\n  console.log(data.getStatus.call(this));\n}, 0);\n```\n\n- A: `\"🥑\"` and `\"😍\"`\n- B: `\"🥑\"` and `\"😎\"`\n- C: `\"😍\"` and `\"😎\"`\n- D: `\"😎\"` and `\"😎\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nThe value of the `this` keyword is dependent on where you use it. In a **method**, like the `getStatus` method, the `this` keyword refers to _the object that the method belongs to_. The method belongs to the `data` object, so `this` refers to the `data` object. When we log `this.status`, the `status` property on the `data` object gets logged, which is `\"🥑\"`.\n\nWith the `call` method, we can change the object to which the `this` keyword refers. In **functions**, the `this` keyword refers to the _the object that the function belongs to_. We declared the `setTimeout` function on the _global object_, so within the `setTimeout` function, the `this` keyword refers to the _global object_. On the global object, there is a variable called _status_ with the value of `\"😎\"`. When logging `this.status`, `\"😎\"` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 83. What is the output?\n\n```javascript\nconst person = {\n  name: 'Lydia',\n  age: 21,\n};\n\nlet city = person.city;\ncity = 'Amsterdam';\n\nconsole.log(person);\n```\n\n- A: `{ name: \"Lydia\", age: 21 }`\n- B: `{ name: \"Lydia\", age: 21, city: \"Amsterdam\" }`\n- C: `{ name: \"Lydia\", age: 21, city: undefined }`\n- D: `\"Amsterdam\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWe set the variable `city` equal to the value of the property called `city` on the `person` object. There is no property on this object called `city`, so the variable `city` has the value of `undefined`.\n\nNote that we are _not_ referencing the `person` object itself! We simply set the variable `city` equal to the current value of the `city` property on the `person` object.\n\nThen, we set `city` equal to the string `\"Amsterdam\"`. This doesn't change the person object: there is no reference to that object.\n\nWhen logging the `person` object, the unmodified object gets returned.\n\n</p>\n</details>\n\n---\n\n###### 84. What is the output?\n\n```javascript\nfunction checkAge(age) {\n  if (age < 18) {\n    const message = \"Sorry, you're too young.\";\n  } else {\n    const message = \"Yay! You're old enough!\";\n  }\n\n  return message;\n}\n\nconsole.log(checkAge(21));\n```\n\n- A: `\"Sorry, you're too young.\"`\n- B: `\"Yay! You're old enough!\"`\n- C: `ReferenceError`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nVariables with the `const` and `let` keywords are _block-scoped_. A block is anything between curly brackets (`{ }`). In this case, the curly brackets of the if/else statements. You cannot reference a variable outside of the block it's declared in, a ReferenceError gets thrown.\n\n</p>\n</details>\n\n---\n\n###### 85. What kind of information would get logged?\n\n```javascript\nfetch('https://www.website.com/api/user/1')\n  .then(res => res.json())\n  .then(res => console.log(res));\n```\n\n- A: The result of the `fetch` method.\n- B: The result of the second invocation of the `fetch` method.\n- C: The result of the callback in the previous `.then()`.\n- D: It would always be undefined.\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe value of `res` in the second `.then` is equal to the returned value of the previous `.then`. You can keep chaining `.then`s like this, where the value is passed to the next handler.\n\n</p>\n</details>\n\n---\n\n###### 86. Which option is a way to set `hasName` equal to `true`, provided you cannot pass `true` as an argument?\n\n```javascript\nfunction getName(name) {\n  const hasName = //\n}\n```\n\n- A: `!!name`\n- B: `name`\n- C: `new Boolean(name)`\n- D: `name.length`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWith `!!name`, we determine whether the value of `name` is truthy or falsy. If the name is truthy, which we want to test for, `!name` returns `false`. `!false` (which is what `!!name` practically is) returns `true`.\n\nBy setting `hasName` equal to `name`, you set `hasName` equal to whatever value you passed to the `getName` function, not the boolean value `true`.\n\n`new Boolean(true)` returns an object wrapper, not the boolean value itself.\n\n`name.length` returns the length of the passed argument, not whether it's `true`.\n\n</p>\n</details>\n\n---\n\n###### 87. What's the output?\n\n```javascript\nconsole.log('I want pizza'[0]);\n```\n\n- A: `\"\"\"`\n- B: `\"I\"`\n- C: `SyntaxError`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nIn order to get a character at a specific index of a string, you can use bracket notation. The first character in the string has index 0, and so on. In this case, we want to get the element with index 0, the character `\"I'`, which gets logged.\n\nNote that this method is not supported in IE7 and below. In that case, use `.charAt()`.\n\n</p>\n</details>\n\n---\n\n###### 88. What's the output?\n\n```javascript\nfunction sum(num1, num2 = num1) {\n  console.log(num1 + num2);\n}\n\nsum(10);\n```\n\n- A: `NaN`\n- B: `20`\n- C: `ReferenceError`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nYou can set a default parameter's value equal to another parameter of the function, as long as they've been defined _before_ the default parameter. We pass the value `10` to the `sum` function. If the `sum` function only receives 1 argument, it means that the value for `num2` is not passed, and the value of `num1` is equal to the passed value `10` in this case. The default value of `num2` is the value of `num1`, which is `10`. `num1 + num2` returns `20`.\n\nIf you're trying to set a default parameter's value equal to a parameter that is defined _after_ (to the right), the parameter's value hasn't been initialized yet, which will throw an error.\n\n</p>\n</details>\n\n---\n\n###### 89. What's the output?\n\n```javascript\n// module.js\nexport default () => 'Hello world';\nexport const name = 'Lydia';\n\n// index.js\nimport * as data from './module';\n\nconsole.log(data);\n```\n\n- A: `{ default: function default(), name: \"Lydia\" }`\n- B: `{ default: function default() }`\n- C: `{ default: \"Hello world\", name: \"Lydia\" }`\n- D: Global object of `module.js`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWith the `import * as name` syntax, we import _all exports_ from the `module.js` file into the `index.js` file as a new object called `data` is created. In the `module.js` file, there are two exports: the default export, and a named export. The default export is a function that returns the string `\"Hello World\"`, and the named export is a variable called `name` which has the value of the string `\"Lydia\"`.\n\nThe `data` object has a `default` property for the default export, other properties have the names of the named exports and their corresponding values.\n\n</p>\n</details>\n\n---\n\n###### 90. What's the output?\n\n```javascript\nclass Person {\n  constructor(name) {\n    this.name = name;\n  }\n}\n\nconst member = new Person('John');\nconsole.log(typeof member);\n```\n\n- A: `\"class\"`\n- B: `\"function\"`\n- C: `\"object\"`\n- D: `\"string\"`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nClasses are syntactical sugar for function constructors. The equivalent of the `Person` class as a function constructor would be:\n\n```javascript\nfunction Person(name) {\n  this.name = name;\n}\n```\n\nCalling a function constructor with `new` results in the creation of an instance of `Person`, `typeof` keyword returns `\"object\"` for an instance. `typeof member` returns `\"object\"`.\n\n</p>\n</details>\n\n---\n\n###### 91. What's the output?\n\n```javascript\nlet newList = [1, 2, 3].push(4);\n\nconsole.log(newList.push(5));\n```\n\n- A: `[1, 2, 3, 4, 5]`\n- B: `[1, 2, 3, 5]`\n- C: `[1, 2, 3, 4]`\n- D: `Error`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `.push` method returns the _new length_ of the array, not the array itself! By setting `newList` equal to `[1, 2, 3].push(4)`, we set `newList` equal to the new length of the array: `4`.\n\nThen, we try to use the `.push` method on `newList`. Since `newList` is the numerical value `4`, we cannot use the `.push` method: a TypeError is thrown.\n\n</p>\n</details>\n\n---\n\n###### 92. What's the output?\n\n```javascript\nfunction giveLydiaPizza() {\n  return 'Here is pizza!';\n}\n\nconst giveLydiaChocolate = () =>\n  \"Here's chocolate... now go hit the gym already.\";\n\nconsole.log(giveLydiaPizza.prototype);\nconsole.log(giveLydiaChocolate.prototype);\n```\n\n- A: `{ constructor: ...}` `{ constructor: ...}`\n- B: `{}` `{ constructor: ...}`\n- C: `{ constructor: ...}` `{}`\n- D: `{ constructor: ...}` `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nRegular functions, such as the `giveLydiaPizza` function, have a `prototype` property, which is an object (prototype object) with a `constructor` property. Arrow functions however, such as the `giveLydiaChocolate` function, do not have this `prototype` property. `undefined` gets returned when trying to access the `prototype` property using `giveLydiaChocolate.prototype`.\n\n</p>\n</details>\n\n---\n\n###### 93. What's the output?\n\n```javascript\nconst person = {\n  name: 'Lydia',\n  age: 21,\n};\n\nfor (const [x, y] of Object.entries(person)) {\n  console.log(x, y);\n}\n```\n\n- A: `name` `Lydia` and `age` `21`\n- B: `[\"name\", \"Lydia\"]` and `[\"age\", 21]`\n- C: `[\"name\", \"age\"]` and `undefined`\n- D: `Error`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\n`Object.entries(person)` returns an array of nested arrays, containing the keys and objects:\n\n`[ [ 'name', 'Lydia' ], [ 'age', 21 ] ]`\n\nUsing the `for-of` loop, we can iterate over each element in the array, the subarrays in this case. We can destructure the subarrays instantly in the for-of loop, using `const [x, y]`. `x` is equal to the first element in the subarray, `y` is equal to the second element in the subarray.\n\nThe first subarray is `[ \"name\", \"Lydia\" ]`, with `x` equal to `\"name\"`, and `y` equal to `\"Lydia\"`, which get logged.\nThe second subarray is `[ \"age\", 21 ]`, with `x` equal to `\"age\"`, and `y` equal to `21`, which get logged.\n\n</p>\n</details>\n\n---\n\n###### 94. What's the output?\n\n```javascript\nfunction getItems(fruitList, ...args, favoriteFruit) {\n  return [...fruitList, ...args, favoriteFruit]\n}\n\ngetItems([\"banana\", \"apple\"], \"pear\", \"orange\")\n```\n\n- A: `[\"banana\", \"apple\", \"pear\", \"orange\"]`\n- B: `[[\"banana\", \"apple\"], \"pear\", \"orange\"]`\n- C: `[\"banana\", \"apple\", [\"pear\"], \"orange\"]`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\n`...args` is a rest parameter. The rest parameter's value is an array containing all remaining arguments, **and can only be the last parameter**! In this example, the rest parameter was the second parameter. This is not possible, and will throw a syntax error.\n\n```javascript\nfunction getItems(fruitList, favoriteFruit, ...args) {\n  return [...fruitList, ...args, favoriteFruit];\n}\n\ngetItems(['banana', 'apple'], 'pear', 'orange');\n```\n\nThe above example works. This returns the array `[ 'banana', 'apple', 'orange', 'pear' ]`\n\n</p>\n</details>\n\n---\n\n###### 95. What's the output?\n\n```javascript\nfunction nums(a, b) {\n  if (a > b) console.log('a is bigger');\n  else console.log('b is bigger');\n  return\n  a + b;\n}\n\nconsole.log(nums(4, 2));\nconsole.log(nums(1, 2));\n```\n\n- A: `a is bigger`, `6` and `b is bigger`, `3`\n- B: `a is bigger`, `undefined` and `b is bigger`, `undefined`\n- C: `undefined` and `undefined`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nIn JavaScript, we don't _have_ to write the semicolon (`;`) explicitly, however the JavaScript engine still adds them after statements. This is called **Automatic Semicolon Insertion**. A statement can for example be variables, or keywords like `throw`, `return`, `break`, etc.\n\nHere, we wrote a `return` statement, and another value `a + b` on a _new line_. However, since it's a new line, the engine doesn't know that it's actually the value that we wanted to return. Instead, it automatically added a semicolon after `return`. You could see this as:\n\n```javascript\nreturn;\na + b;\n```\n\nThis means that `a + b` is never reached, since a function stops running after the `return` keyword. If no value gets returned, like here, the function returns `undefined`. Note that there is no automatic insertion after `if/else` statements!\n\n</p>\n</details>\n\n---\n\n###### 96. What's the output?\n\n```javascript\nclass Person {\n  constructor() {\n    this.name = 'Lydia';\n  }\n}\n\nPerson = class AnotherPerson {\n  constructor() {\n    this.name = 'Sarah';\n  }\n};\n\nconst member = new Person();\nconsole.log(member.name);\n```\n\n- A: `\"Lydia\"`\n- B: `\"Sarah\"`\n- C: `Error: cannot redeclare Person`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWe can set classes equal to other classes/function constructors. In this case, we set `Person` equal to `AnotherPerson`. The name on this constructor is `Sarah`, so the name property on the new `Person` instance `member` is `\"Sarah\"`.\n\n</p>\n</details>\n\n---\n\n###### 97. What's the output?\n\n```javascript\nconst info = {\n  [Symbol('a')]: 'b',\n};\n\nconsole.log(info);\nconsole.log(Object.keys(info));\n```\n\n- A: `{Symbol('a'): 'b'}` and `[\"{Symbol('a')\"]`\n- B: `{}` and `[]`\n- C: `{ a: \"b\" }` and `[\"a\"]`\n- D: `{Symbol('a'): 'b'}` and `[]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nA Symbol is not _enumerable_. The Object.keys method returns all _enumerable_ key properties on an object. The Symbol won't be visible, and an empty array is returned. When logging the entire object, all properties will be visible, even non-enumerable ones.\n\nThis is one of the many qualities of a symbol: besides representing an entirely unique value (which prevents accidental name collision on objects, for example when working with 2 libraries that want to add properties to the same object), you can also \"hide\" properties on objects this way (although not entirely. You can still access symbols using the `Object.getOwnPropertySymbols()` method).\n\n</p>\n</details>\n\n---\n\n###### 98. What's the output?\n\n```javascript\nconst getList = ([x, ...y]) => [x, y]\nconst getUser = user => { name: user.name, age: user.age }\n\nconst list = [1, 2, 3, 4]\nconst user = { name: \"Lydia\", age: 21 }\n\nconsole.log(getList(list))\nconsole.log(getUser(user))\n```\n\n- A: `[1, [2, 3, 4]]` and `SyntaxError`\n- B: `[1, [2, 3, 4]]` and `{ name: \"Lydia\", age: 21 }`\n- C: `[1, 2, 3, 4]` and `{ name: \"Lydia\", age: 21 }`\n- D: `Error` and `{ name: \"Lydia\", age: 21 }`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe `getList` function receives an array as its argument. Between the parentheses of the `getList` function, we destructure this array right away. You could see this as:\n\n`[x, ...y] = [1, 2, 3, 4]`\n\nWith the rest parameter `...y`, we put all \"remaining\" arguments in an array. The remaining arguments are `2`, `3` and `4` in this case. The value of `y` is an array, containing all the rest parameters. The value of `x` is equal to `1` in this case, so when we log `[x, y]`, `[1, [2, 3, 4]]` gets logged.\n\nThe `getUser` function receives an object. With arrow functions, we don't _have_ to write curly brackets if we just return one value. However, if you want to instantly return an _object_ from an arrow function, you have to write it between parentheses, otherwise everything between the two braces will be interpreted as a block statement. In this case the code between the braces is not a valid JavaScript code, so a `SyntaxError` gets thrown. \n\nThe following function would have returned an object:\n\n`const getUser = user => ({ name: user.name, age: user.age })`\n\n</p>\n</details>\n\n---\n\n###### 99. What's the output?\n\n```javascript\nconst name = 'Lydia';\n\nconsole.log(name());\n```\n\n- A: `SyntaxError`\n- B: `ReferenceError`\n- C: `TypeError`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe variable `name` holds the value of a string, which is not a function, and thus cannot be invoked.\n\nTypeErrors get thrown when a value is not of the expected type. JavaScript expected `name` to be a function since we're trying to invoke it. It was a string however, so a TypeError gets thrown: name is not a function!\n\nSyntaxErrors get thrown when you've written something that isn't valid JavaScript, for example when you've written the word `return` as `retrun`.\nReferenceErrors get thrown when JavaScript isn't able to find a reference to a value that you're trying to access.\n\n</p>\n</details>\n\n---\n\n###### 100. What's the value of output?\n\n```javascript\n// 🎉✨ This is my 100th question! ✨🎉\n\nconst output = `${[] && 'Im'}possible!\nYou should${'' && `n't`} see a therapist after so much JavaScript lol`;\n```\n\n- A: `possible! You should see a therapist after so much JavaScript lol`\n- B: `Impossible! You should see a therapist after so much JavaScript lol`\n- C: `possible! You shouldn't see a therapist after so much JavaScript lol`\n- D: `Impossible! You shouldn't see a therapist after so much JavaScript lol`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\n`[]` is a truthy value. With the `&&` operator, the right-hand value will be returned if the left-hand value is a truthy value. In this case, the left-hand value `[]` is a truthy value, so `\"Im'` gets returned.\n\n`\"\"` is a falsy value. If the left-hand value is falsy, nothing gets returned. `n't` doesn't get returned.\n\n</p>\n</details>\n\n---\n\n###### 101. What's the value of output?\n\n```javascript\nconst one = false || {} || null;\nconst two = null || false || '';\nconst three = [] || 0 || true;\n\nconsole.log(one, two, three);\n```\n\n- A: `false` `null` `[]`\n- B: `null` `\"\"` `true`\n- C: `{}` `\"\"` `[]`\n- D: `null` `null` `true`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith the `||` operator, we can return the first truthy operand. If all values are falsy, the last operand gets returned.\n\n`(false || {} || null)`: the empty object `{}` is a truthy value. This is the first (and only) truthy value, which gets returned. `one` is equal to `{}`.\n\n`(null || false || \"\")`: all operands are falsy values. This means that the last operand, `\"\"` gets returned. `two` is equal to `\"\"`.\n\n`([] || 0 || \"\")`: the empty array`[]` is a truthy value. This is the first truthy value, which gets returned. `three` is equal to `[]`.\n\n</p>\n</details>\n\n---\n\n###### 102. What's the value of output?\n\n```javascript\nconst myPromise = () => Promise.resolve('I have resolved!');\n\nfunction firstFunction() {\n  myPromise().then(res => console.log(res));\n  console.log('second');\n}\n\nasync function secondFunction() {\n  console.log(await myPromise());\n  console.log('second');\n}\n\nfirstFunction();\nsecondFunction();\n```\n\n- A: `I have resolved!`, `second` and `I have resolved!`, `second`\n- B: `second`, `I have resolved!` and `second`, `I have resolved!`\n- C: `I have resolved!`, `second` and `second`, `I have resolved!`\n- D: `second`, `I have resolved!` and `I have resolved!`, `second`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nWith a promise, we basically say _I want to execute this function, but I'll put it aside for now while it's running since this might take a while. Only when a certain value is resolved (or rejected), and when the call stack is empty, I want to use this value._\n\nWe can get this value with both `.then` and the `await` keywords in an `async` function. Although we can get a promise's value with both `.then` and `await`, they work a bit differently.\n\nIn the `firstFunction`, we (sort of) put the myPromise function aside while it was running, but continued running the other code, which is `console.log('second')` in this case. Then, the function resolved with the string `I have resolved`, which then got logged after it saw that the callstack was empty.\n\nWith the await keyword in `secondFunction`, we literally pause the execution of an async function until the value has been resolved before moving to the next line.\n\nThis means that it waited for the `myPromise` to resolve with the value `I have resolved`, and only once that happened, we moved to the next line: `second` got logged.\n\n</p>\n</details>\n\n---\n\n###### 103. What's the value of output?\n\n```javascript\nconst set = new Set();\n\nset.add(1);\nset.add('Lydia');\nset.add({ name: 'Lydia' });\n\nfor (let item of set) {\n  console.log(item + 2);\n}\n```\n\n- A: `3`, `NaN`, `NaN`\n- B: `3`, `7`, `NaN`\n- C: `3`, `Lydia2`, `[object Object]2`\n- D: `\"12\"`, `Lydia2`, `[object Object]2`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `+` operator is not only used for adding numerical values, but we can also use it to concatenate strings. Whenever the JavaScript engine sees that one or more values are not a number, it coerces the number into a string.\n\nThe first one is `1`, which is a numerical value. `1 + 2` returns the number 3.\n\nHowever, the second one is a string `\"Lydia\"`. `\"Lydia\"` is a string and `2` is a number: `2` gets coerced into a string. `\"Lydia\"` and `\"2\"` get concatenated, which results in the string `\"Lydia2\"`.\n\n`{ name: \"Lydia\" }` is an object. Neither a number nor an object is a string, so it stringifies both. Whenever we stringify a regular object, it becomes `\"[object Object]\"`. `\"[object Object]\"` concatenated with `\"2\"` becomes `\"[object Object]2\"`.\n\n</p>\n</details>\n\n---\n\n###### 104. What's its value?\n\n```javascript\nPromise.resolve(5);\n```\n\n- A: `5`\n- B: `Promise {<pending>: 5}`\n- C: `Promise {<fulfilled>: 5}`\n- D: `Error`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWe can pass any type of value we want to `Promise.resolve`, either a promise or a non-promise. The method itself returns a promise with the resolved value (`<fulfilled>`). If you pass a regular function, it'll be a resolved promise with a regular value. If you pass a promise, it'll be a resolved promise with the resolved value of that passed promise.\n\nIn this case, we just passed the numerical value `5`. It returns a resolved promise with the value `5`.\n\n</p>\n</details>\n\n---\n\n###### 105. What's its value?\n\n```javascript\nfunction compareMembers(person1, person2 = person) {\n  if (person1 !== person2) {\n    console.log('Not the same!');\n  } else {\n    console.log('They are the same!');\n  }\n}\n\nconst person = { name: 'Lydia' };\n\ncompareMembers(person);\n```\n\n- A: `Not the same!`\n- B: `They are the same!`\n- C: `ReferenceError`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nObjects are passed by reference. When we check objects for strict equality (`===`), we're comparing their references.\n\nWe set the default value for `person2` equal to the `person` object, and passed the `person` object as the value for `person1`.\n\nThis means that both values have a reference to the same spot in memory, thus they are equal.\n\nThe code block in the `else` statement gets run, and `They are the same!` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 106. What's its value?\n\n```javascript\nconst colorConfig = {\n  red: true,\n  blue: false,\n  green: true,\n  black: true,\n  yellow: false,\n};\n\nconst colors = ['pink', 'red', 'blue'];\n\nconsole.log(colorConfig.colors[1]);\n```\n\n- A: `true`\n- B: `false`\n- C: `undefined`\n- D: `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nIn JavaScript, we have two ways to access properties on an object: bracket notation, or dot notation. In this example, we use dot notation (`colorConfig.colors`) instead of bracket notation (`colorConfig[\"colors\"]`).\n\nWith dot notation, JavaScript tries to find the property on the object with that exact name. In this example, JavaScript tries to find a property called `colors` on the `colorConfig` object. There is no property called `colors`, so this returns `undefined`. Then, we try to access the value of the first element by using `[1]`. We cannot do this on a value that's `undefined`, so it throws a `TypeError`: `Cannot read property '1' of undefined`.\n\nJavaScript interprets (or unboxes) statements. When we use bracket notation, it sees the first opening bracket `[` and keeps going until it finds the closing bracket `]`. Only then, it will evaluate the statement. If we would've used `colorConfig[colors[1]]`, it would have returned the value of the `red` property on the `colorConfig` object.\n\n</p>\n</details>\n\n---\n\n###### 107. What's its value?\n\n```javascript\nconsole.log('❤️' === '❤️');\n```\n\n- A: `true`\n- B: `false`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nUnder the hood, emojis are unicodes. The unicodes for the heart emoji is `\"U+2764 U+FE0F\"`. These are always the same for the same emojis, so we're comparing two equal strings to each other, which returns true.\n\n</p>\n</details>\n\n---\n\n###### 108. Which of these methods modifies the original array?\n\n```javascript\nconst emojis = ['✨', '🥑', '😍'];\n\nemojis.map(x => x + '✨');\nemojis.filter(x => x !== '🥑');\nemojis.find(x => x !== '🥑');\nemojis.reduce((acc, cur) => acc + '✨');\nemojis.slice(1, 2, '✨');\nemojis.splice(1, 2, '✨');\n```\n\n- A: `All of them`\n- B: `map` `reduce` `slice` `splice`\n- C: `map` `slice` `splice`\n- D: `splice`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nWith `splice` method, we modify the original array by deleting, replacing or adding elements. In this case, we removed 2 items from index 1 (we removed `'🥑'` and `'😍'`) and added the ✨ emoji instead.\n\n`map`, `filter` and `slice` return a new array, `find` returns an element, and `reduce` returns a reduced value.\n\n</p>\n</details>\n\n---\n\n###### 109. What's the output?\n\n```javascript\nconst food = ['🍕', '🍫', '🥑', '🍔'];\nconst info = { favoriteFood: food[0] };\n\ninfo.favoriteFood = '🍝';\n\nconsole.log(food);\n```\n\n- A: `['🍕', '🍫', '🥑', '🍔']`\n- B: `['🍝', '🍫', '🥑', '🍔']`\n- C: `['🍝', '🍕', '🍫', '🥑', '🍔']`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWe set the value of the `favoriteFood` property on the `info` object equal to the string with the pizza emoji, `'🍕'`. A string is a primitive data type. In JavaScript, primitive data types don't interact by reference.\n\nIn JavaScript, primitive data types (everything that's not an object) interact by _value_. In this case, we set the value of the `favoriteFood` property on the `info` object equal to the value of the first element in the `food` array, the string with the pizza emoji in this case (`'🍕'`). A string is a primitive data type, and interact by value (see my [blogpost](https://www.theavocoder.com/complete-javascript/2018/12/21/by-value-vs-by-reference) if you're interested in learning more)\n\nThen, we change the value of the `favoriteFood` property on the `info` object. The `food` array hasn't changed, since the value of `favoriteFood` was merely a _copy_ of the value of the first element in the array, and doesn't have a reference to the same spot in memory as the element on `food[0]`. When we log food, it's still the original array, `['🍕', '🍫', '🥑', '🍔']`.\n\n</p>\n</details>\n\n---\n\n###### 110. What does this method do?\n\n```javascript\nJSON.parse();\n```\n\n- A: Parses JSON to a JavaScript value\n- B: Parses a JavaScript object to JSON\n- C: Parses any JavaScript value to JSON\n- D: Parses JSON to a JavaScript object only\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWith the `JSON.parse()` method, we can parse JSON string to a JavaScript value.\n\n```javascript\n// Stringifying a number into valid JSON, then parsing the JSON string to a JavaScript value:\nconst jsonNumber = JSON.stringify(4); // '4'\nJSON.parse(jsonNumber); // 4\n\n// Stringifying an array value into valid JSON, then parsing the JSON string to a JavaScript value:\nconst jsonArray = JSON.stringify([1, 2, 3]); // '[1, 2, 3]'\nJSON.parse(jsonArray); // [1, 2, 3]\n\n// Stringifying an object  into valid JSON, then parsing the JSON string to a JavaScript value:\nconst jsonArray = JSON.stringify({ name: 'Lydia' }); // '{\"name\":\"Lydia\"}'\nJSON.parse(jsonArray); // { name: 'Lydia' }\n```\n\n</p>\n</details>\n\n---\n\n###### 111. What's the output?\n\n```javascript\nlet name = 'Lydia';\n\nfunction getName() {\n  console.log(name);\n  let name = 'Sarah';\n}\n\ngetName();\n```\n\n- A: Lydia\n- B: Sarah\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nEach function has its own _execution context_ (or _scope_). The `getName` function first looks within its own context (scope) to see if it contains the variable `name` we're trying to access. In this case, the `getName` function contains its own `name` variable: we declare the variable `name` with the `let` keyword, and with the value of `'Sarah'`.\n\nVariables with the `let` keyword (and `const`) are hoisted, but unlike `var`, don't get <i>initialized</i>. They are not accessible before the line we declare (initialize) them. This is called the \"temporal dead zone\". When we try to access the variables before they are declared, JavaScript throws a `ReferenceError`.\n\nIf we wouldn't have declared the `name` variable within the `getName` function, the javascript engine would've looked down the _scope chain_. The outer scope has a variable called `name` with the value of `Lydia`. In that case, it would've logged `Lydia`.\n\n```javascript\nlet name = 'Lydia';\n\nfunction getName() {\n  console.log(name);\n}\n\ngetName(); // Lydia\n```\n\n</p>\n</details>\n\n---\n\n###### 112. What's the output?\n\n```javascript\nfunction* generatorOne() {\n  yield ['a', 'b', 'c'];\n}\n\nfunction* generatorTwo() {\n  yield* ['a', 'b', 'c'];\n}\n\nconst one = generatorOne();\nconst two = generatorTwo();\n\nconsole.log(one.next().value);\nconsole.log(two.next().value);\n```\n\n- A: `a` and `a`\n- B: `a` and `undefined`\n- C: `['a', 'b', 'c']` and `a`\n- D: `a` and `['a', 'b', 'c']`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith the `yield` keyword, we `yield` values in a generator function. With the `yield*` keyword, we can yield values from another generator function, or iterable object (for example an array).\n\nIn `generatorOne`, we yield the entire array `['a', 'b', 'c']` using the `yield` keyword. The value of `value` property on the object returned by the `next` method on `one` (`one.next().value`) is equal to the entire array `['a', 'b', 'c']`.\n\n```javascript\nconsole.log(one.next().value); // ['a', 'b', 'c']\nconsole.log(one.next().value); // undefined\n```\n\nIn `generatorTwo`, we use the `yield*` keyword. This means that the first yielded value of `two`, is equal to the first yielded value in the iterator. The iterator is the array `['a', 'b', 'c']`. The first yielded value is `a`, so the first time we call `two.next().value`, `a` is returned.\n\n```javascript\nconsole.log(two.next().value); // 'a'\nconsole.log(two.next().value); // 'b'\nconsole.log(two.next().value); // 'c'\nconsole.log(two.next().value); // undefined\n```\n\n</p>\n</details>\n\n---\n\n###### 113. What's the output?\n\n```javascript\nconsole.log(`${(x => x)('I love')} to program`);\n```\n\n- A: `I love to program`\n- B: `undefined to program`\n- C: `${(x => x)('I love') to program`\n- D: `TypeError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nExpressions within template literals are evaluated first. This means that the string will contain the returned value of the expression, the immediately invoked function `(x => x)('I love')` in this case. We pass the value `'I love'` as an argument to the `x => x` arrow function. `x` is equal to `'I love'`, which gets returned. This results in `I love to program`.\n\n</p>\n</details>\n\n---\n\n###### 114. What will happen?\n\n```javascript\nlet config = {\n  alert: setInterval(() => {\n    console.log('Alert!');\n  }, 1000),\n};\n\nconfig = null;\n```\n\n- A: The `setInterval` callback won't be invoked\n- B: The `setInterval` callback gets invoked once\n- C: The `setInterval` callback will still be called every second\n- D: We never invoked `config.alert()`, config is `null`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nNormally when we set objects equal to `null`, those objects get _garbage collected_ as there is no reference anymore to that object. However, since the callback function within `setInterval` is an arrow function (thus bound to the `config` object), the callback function still holds a reference to the `config` object. \nAs long as there is a reference, the object won't get garbage collected. \nSince this is an interval, setting `config` to `null` or `delete`-ing `config.alert` won't garbage-collect the interval, so the interval will still be called. \nIt should be cleared with `clearInterval(config.alert)` to remove it from memory.\nSince it was not cleared, the `setInterval` callback function will still get invoked every 1000ms (1s).\n\n</p>\n</details>\n\n---\n\n###### 115. Which method(s) will return the value `'Hello world!'`?\n\n```javascript\nconst myMap = new Map();\nconst myFunc = () => 'greeting';\n\nmyMap.set(myFunc, 'Hello world!');\n\n//1\nmyMap.get('greeting');\n//2\nmyMap.get(myFunc);\n//3\nmyMap.get(() => 'greeting');\n```\n\n- A: 1\n- B: 2\n- C: 2 and 3\n- D: All of them\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWhen adding a key/value pair using the `set` method, the key will be the value of the first argument passed to the `set` function, and the value will be the second argument passed to the `set` function. The key is the _function_ `() => 'greeting'` in this case, and the value `'Hello world'`. `myMap` is now `{ () => 'greeting' => 'Hello world!' }`.\n\n1 is wrong, since the key is not `'greeting'` but `() => 'greeting'`.\n3 is wrong, since we're creating a new function by passing it as a parameter to the `get` method. Object interacts by _reference_. Functions are objects, which is why two functions are never strictly equal, even if they are identical: they have a reference to a different spot in memory.\n\n</p>\n</details>\n\n---\n\n###### 116. What's the output?\n\n```javascript\nconst person = {\n  name: 'Lydia',\n  age: 21,\n};\n\nconst changeAge = (x = { ...person }) => (x.age += 1);\nconst changeAgeAndName = (x = { ...person }) => {\n  x.age += 1;\n  x.name = 'Sarah';\n};\n\nchangeAge(person);\nchangeAgeAndName();\n\nconsole.log(person);\n```\n\n- A: `{name: \"Sarah\", age: 22}`\n- B: `{name: \"Sarah\", age: 23}`\n- C: `{name: \"Lydia\", age: 22}`\n- D: `{name: \"Lydia\", age: 23}`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nBoth the `changeAge` and `changeAgeAndName` functions have a default parameter, namely a _newly_ created object `{ ...person }`. This object has copies of all the key/values in the `person` object.\n\nFirst, we invoke the `changeAge` function and pass the `person` object as its argument. This function increases the value of the `age` property by 1. `person` is now `{ name: \"Lydia\", age: 22 }`.\n\nThen, we invoke the `changeAgeAndName` function, however we don't pass a parameter. Instead, the value of `x` is equal to a _new_ object: `{ ...person }`. Since it's a new object, it doesn't affect the values of the properties on the `person` object. `person` is still equal to `{ name: \"Lydia\", age: 22 }`.\n\n</p>\n</details>\n\n---\n\n###### 117. Which of the following options will return `6`?\n\n```javascript\nfunction sumValues(x, y, z) {\n  return x + y + z;\n}\n```\n\n- A: `sumValues([...1, 2, 3])`\n- B: `sumValues([...[1, 2, 3]])`\n- C: `sumValues(...[1, 2, 3])`\n- D: `sumValues([1, 2, 3])`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith the spread operator `...`, we can _spread_ iterables to individual elements. The `sumValues` function receives three arguments: `x`, `y` and `z`. `...[1, 2, 3]` will result in `1, 2, 3`, which we pass to the `sumValues` function.\n\n</p>\n</details>\n\n---\n\n###### 118. What's the output?\n\n```javascript\nlet num = 1;\nconst list = ['🥳', '🤠', '🥰', '🤪'];\n\nconsole.log(list[(num += 1)]);\n```\n\n- A: `🤠`\n- B: `🥰`\n- C: `SyntaxError`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the `+=` operator, we're incrementing the value of `num` by `1`. `num` had the initial value `1`, so `1 + 1` is `2`. The item on the second index in the `list` array is 🥰, `console.log(list[2])` prints 🥰.\n\n</p>\n</details>\n\n---\n\n###### 119. What's the output?\n\n```javascript\nconst person = {\n  firstName: 'Lydia',\n  lastName: 'Hallie',\n  pet: {\n    name: 'Mara',\n    breed: 'Dutch Tulip Hound',\n  },\n  getFullName() {\n    return `${this.firstName} ${this.lastName}`;\n  },\n};\n\nconsole.log(person.pet?.name);\nconsole.log(person.pet?.family?.name);\nconsole.log(person.getFullName?.());\nconsole.log(member.getLastName?.());\n```\n\n- A: `undefined` `undefined` `undefined` `undefined`\n- B: `Mara` `undefined` `Lydia Hallie` `ReferenceError`\n- C: `Mara` `null` `Lydia Hallie` `null`\n- D: `null` `ReferenceError` `null` `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the optional chaining operator `?.`, we no longer have to explicitly check whether the deeper nested values are valid or not. If we're trying to access a property on an `undefined` or `null` value (_nullish_), the expression short-circuits and returns `undefined`.\n\n`person.pet?.name`: `person` has a property named `pet`: `person.pet` is not nullish. It has a property called `name`, and returns `Mara`.\n`person.pet?.family?.name`: `person` has a property named `pet`: `person.pet` is not nullish. `pet` does _not_ have a property called `family`, `person.pet.family` is nullish. The expression returns `undefined`.\n`person.getFullName?.()`: `person` has a property named `getFullName`: `person.getFullName()` is not nullish and can get invoked, which returns `Lydia Hallie`.\n`member.getLastName?.()`: variable `member` is non-existent therefore a `ReferenceError` gets thrown!\n\n</p>\n</details>\n\n---\n\n###### 120. What's the output?\n\n```javascript\nconst groceries = ['banana', 'apple', 'peanuts'];\n\nif (groceries.indexOf('banana')) {\n  console.log('We have to buy bananas!');\n} else {\n  console.log(`We don't have to buy bananas!`);\n}\n```\n\n- A: We have to buy bananas!\n- B: We don't have to buy bananas\n- C: `undefined`\n- D: `1`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWe passed the condition `groceries.indexOf(\"banana\")` to the if-statement. `groceries.indexOf(\"banana\")` returns `0`, which is a falsy value. Since the condition in the if-statement is falsy, the code in the `else` block runs, and `We don't have to buy bananas!` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 121. What's the output?\n\n```javascript\nconst config = {\n  languages: [],\n  set language(lang) {\n    return this.languages.push(lang);\n  },\n};\n\nconsole.log(config.language);\n```\n\n- A: `function language(lang) { this.languages.push(lang }`\n- B: `0`\n- C: `[]`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `language` method is a `setter`. Setters don't hold an actual value, their purpose is to _modify_ properties. When calling a `setter` method, `undefined` gets returned.\n\n</p>\n</details>\n\n---\n\n###### 122. What's the output?\n\n```javascript\nconst name = 'Lydia Hallie';\n\nconsole.log(!typeof name === 'object');\nconsole.log(!typeof name === 'string');\n```\n\n- A: `false` `true`\n- B: `true` `false`\n- C: `false` `false`\n- D: `true` `true`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\n`typeof name` returns `\"string\"`. The string `\"string\"` is a truthy value, so `!typeof name` returns the boolean value `false`. `false === \"object\"` and `false === \"string\"` both return`false`.\n\n(If we wanted to check whether the type was (un)equal to a certain type, we should've written `!==` instead of `!typeof`)\n\n</p>\n</details>\n\n---\n\n###### 123. What's the output?\n\n```javascript\nconst add = x => y => z => {\n  console.log(x, y, z);\n  return x + y + z;\n};\n\nadd(4)(5)(6);\n```\n\n- A: `4` `5` `6`\n- B: `6` `5` `4`\n- C: `4` `function` `function`\n- D: `undefined` `undefined` `6`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe `add` function returns an arrow function, which returns an arrow function, which returns an arrow function (still with me?). The first function receives an argument `x` with the value of `4`. We invoke the second function, which receives an argument `y` with the value `5`. Then we invoke the third function, which receives an argument `z` with the value `6`. When we're trying to access the value `x`, `y` and `z` within the last arrow function, the JS engine goes up the scope chain in order to find the values for `x` and `y` accordingly. This returns `4` `5` `6`.\n\n</p>\n</details>\n\n---\n\n###### 124. What's the output?\n\n```javascript\nasync function* range(start, end) {\n  for (let i = start; i <= end; i++) {\n    yield Promise.resolve(i);\n  }\n}\n\n(async () => {\n  const gen = range(1, 3);\n  for await (const item of gen) {\n    console.log(item);\n  }\n})();\n```\n\n- A: `Promise {1}` `Promise {2}` `Promise {3}`\n- B: `Promise {<pending>}` `Promise {<pending>}` `Promise {<pending>}`\n- C: `1` `2` `3`\n- D: `undefined` `undefined` `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe generator function `range` returns an async object with promises for each item in the range we pass: `Promise{1}`, `Promise{2}`, `Promise{3}`. We set the variable `gen` equal to the async object, after which we loop over it using a `for await ... of` loop. We set the variable `item` equal to the returned Promise values: first `Promise{1}`, then `Promise{2}`, then `Promise{3}`. Since we're _awaiting_ the value of `item`, the resolved promise, the resolved _values_ of the promises get returned: `1`, `2`, then `3`.\n\n</p>\n</details>\n\n---\n\n###### 125. What's the output?\n\n```javascript\nconst myFunc = ({ x, y, z }) => {\n  console.log(x, y, z);\n};\n\nmyFunc(1, 2, 3);\n```\n\n- A: `1` `2` `3`\n- B: `{1: 1}` `{2: 2}` `{3: 3}`\n- C: `{ 1: undefined }` `undefined` `undefined`\n- D: `undefined` `undefined` `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\n`myFunc` expects an object with properties `x`, `y` and `z` as its argument. Since we're only passing three separate numeric values (1, 2, 3) instead of one object with properties `x`, `y` and `z` ({x: 1, y: 2, z: 3}), `x`, `y` and `z` have their default value of `undefined`.\n\n</p>\n</details>\n\n---\n\n###### 126. What's the output?\n\n```javascript\nfunction getFine(speed, amount) {\n  const formattedSpeed = new Intl.NumberFormat('en-US', {\n    style: 'unit',\n    unit: 'mile-per-hour'\n  }).format(speed);\n\n  const formattedAmount = new Intl.NumberFormat('en-US', {\n    style: 'currency',\n    currency: 'USD'\n  }).format(amount);\n\n  return `The driver drove ${formattedSpeed} and has to pay ${formattedAmount}`;\n}\n\nconsole.log(getFine(130, 300))\n```\n\n- A: The driver drove 130 and has to pay 300\n- B: The driver drove 130 mph and has to pay \\$300.00\n- C: The driver drove undefined and has to pay undefined\n- D: The driver drove 130.00 and has to pay 300.00\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the `Intl.NumberFormat` method, we can format numeric values to any locale. We format the numeric value `130` to the `en-US` locale as a `unit` in `mile-per-hour`, which results in `130 mph`. The numeric value `300` to the `en-US` locale as a `currency` in `USD` results in `$300.00`.\n\n</p>\n</details>\n\n---\n\n###### 127. What's the output?\n\n```javascript\nconst spookyItems = ['👻', '🎃', '🕸'];\n({ item: spookyItems[3] } = { item: '💀' });\n\nconsole.log(spookyItems);\n```\n\n- A: `[\"👻\", \"🎃\", \"🕸\"]`\n- B: `[\"👻\", \"🎃\", \"🕸\", \"💀\"]`\n- C: `[\"👻\", \"🎃\", \"🕸\", { item: \"💀\" }]`\n- D: `[\"👻\", \"🎃\", \"🕸\", \"[object Object]\"]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nBy destructuring objects, we can unpack values from the right-hand object, and assign the unpacked value to the value of the same property name on the left-hand object. In this case, we're assigning the value \"💀\" to `spookyItems[3]`. This means that we're modifying the `spookyItems` array, we're adding the \"💀\" to it. When logging `spookyItems`, `[\"👻\", \"🎃\", \"🕸\", \"💀\"]` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 128. What's the output?\n\n```javascript\nconst name = 'Lydia Hallie';\nconst age = 21;\n\nconsole.log(Number.isNaN(name));\nconsole.log(Number.isNaN(age));\n\nconsole.log(isNaN(name));\nconsole.log(isNaN(age));\n```\n\n- A: `true` `false` `true` `false`\n- B: `true` `false` `false` `false`\n- C: `false` `false` `true` `false`\n- D: `false` `true` `false` `true`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith the `Number.isNaN` method, you can check if the value you pass is a _numeric value_ and equal to `NaN`. `name` is not a numeric value, so `Number.isNaN(name)` returns `false`. `age` is a numeric value, but is not equal to `NaN`, so `Number.isNaN(age)` returns `false`.\n\nWith the `isNaN` method, you can check if the value you pass is not a number. `name` is not a number, so `isNaN(name)` returns true. `age` is a number, so `isNaN(age)` returns `false`.\n\n</p>\n</details>\n\n---\n\n###### 129. What's the output?\n\n```javascript\nconst randomValue = 21;\n\nfunction getInfo() {\n  console.log(typeof randomValue);\n  const randomValue = 'Lydia Hallie';\n}\n\ngetInfo();\n```\n\n- A: `\"number\"`\n- B: `\"string\"`\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nVariables declared with the `const` keyword are not referenceable before their initialization: this is called the _temporal dead zone_. In the `getInfo` function, the variable `randomValue` is scoped in the functional scope of `getInfo`. On the line where we want to log the value of `typeof randomValue`, the variable `randomValue` isn't initialized yet: a `ReferenceError` gets thrown! The engine didn't go down the scope chain since we declared the variable `randomValue` in the `getInfo` function.\n\n</p>\n</details>\n\n---\n\n###### 130. What's the output?\n\n```javascript\nconst myPromise = Promise.resolve('Woah some cool data');\n\n(async () => {\n  try {\n    console.log(await myPromise);\n  } catch {\n    throw new Error(`Oops didn't work`);\n  } finally {\n    console.log('Oh finally!');\n  }\n})();\n```\n\n- A: `Woah some cool data`\n- B: `Oh finally!`\n- C: `Woah some cool data` `Oh finally!`\n- D: `Oops didn't work` `Oh finally!`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nIn the `try` block, we're logging the awaited value of the `myPromise` variable: `\"Woah some cool data\"`. Since no errors were thrown in the `try` block, the code in the `catch` block doesn't run. The code in the `finally` block _always_ runs, `\"Oh finally!\"` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 131. What's the output?\n\n```javascript\nconst emojis = ['🥑', ['✨', '✨', ['🍕', '🍕']]];\n\nconsole.log(emojis.flat(1));\n```\n\n- A: `['🥑', ['✨', '✨', ['🍕', '🍕']]]`\n- B: `['🥑', '✨', '✨', ['🍕', '🍕']]`\n- C: `['🥑', ['✨', '✨', '🍕', '🍕']]`\n- D: `['🥑', '✨', '✨', '🍕', '🍕']`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWith the `flat` method, we can create a new, flattened array. The depth of the flattened array depends on the value that we pass. In this case, we passed the value `1` (which we didn't have to, that's the default value), meaning that only the arrays on the first depth will be concatenated. `['🥑']` and `['✨', '✨', ['🍕', '🍕']]` in this case. Concatenating these two arrays results in `['🥑', '✨', '✨', ['🍕', '🍕']]`.\n\n</p>\n</details>\n\n---\n\n###### 132. What's the output?\n\n```javascript\nclass Counter {\n  constructor() {\n    this.count = 0;\n  }\n\n  increment() {\n    this.count++;\n  }\n}\n\nconst counterOne = new Counter();\ncounterOne.increment();\ncounterOne.increment();\n\nconst counterTwo = counterOne;\ncounterTwo.increment();\n\nconsole.log(counterOne.count);\n```\n\n- A: `0`\n- B: `1`\n- C: `2`\n- D: `3`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\n`counterOne` is an instance of the `Counter` class. The counter class contains a `count` property on its constructor, and an `increment` method. First, we invoked the `increment` method twice by calling `counterOne.increment()`. Currently, `counterOne.count` is `2`.\n\n<img src=\"https://i.imgur.com/KxLlTm9.png\" width=\"400\">\n\nThen, we create a new variable `counterTwo`, and set it equal to `counterOne`. Since objects interact by reference, we're just creating a new reference to the same spot in memory that `counterOne` points to. Since it has the same spot in memory, any changes made to the object that `counterTwo` has a reference to, also apply to `counterOne`. Currently, `counterTwo.count` is `2`.\n\nWe invoke `counterTwo.increment()`, which sets `count` to `3`. Then, we log the count on `counterOne`, which logs `3`.\n\n<img src=\"https://i.imgur.com/BNBHXmc.png\" width=\"400\">\n\n</p>\n</details>\n\n---\n\n###### 133. What's the output?\n\n```javascript\nconst myPromise = Promise.resolve(Promise.resolve('Promise'));\n\nfunction funcOne() {\n  setTimeout(() => console.log('Timeout 1!'), 0);\n  myPromise.then(res => res).then(res => console.log(`${res} 1!`));\n  console.log('Last line 1!');\n}\n\nasync function funcTwo() {\n  const res = await myPromise;\n  console.log(`${res} 2!`)\n  setTimeout(() => console.log('Timeout 2!'), 0);\n  console.log('Last line 2!');\n}\n\nfuncOne();\nfuncTwo();\n```\n\n- A: `Promise 1! Last line 1! Promise 2! Last line 2! Timeout 1! Timeout 2!`\n- B: `Last line 1! Timeout 1! Promise 1! Last line 2! Promise2! Timeout 2! `\n- C: `Last line 1! Promise 2! Last line 2! Promise 1! Timeout 1! Timeout 2!`\n- D: `Timeout 1! Promise 1! Last line 1! Promise 2! Timeout 2! Last line 2!`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nFirst, we invoke `funcOne`. On the first line of `funcOne`, we call the _asynchronous_ `setTimeout` function, from which the callback is sent to the Web API. (see my article on the event loop <a href=\"https://dev.to/lydiahallie/javascript-visualized-event-loop-3dif\">here</a>.)\n\nThen we call the `myPromise` promise, which is an _asynchronous_ operation. Pay attention, that now only the first then clause was added to the microtask queue.\n\nBoth the promise and the timeout are asynchronous operations, the function keeps on running while it's busy completing the promise and handling the `setTimeout` callback. This means that `Last line 1!` gets logged first, since this is not an asynchonous operation. \n\nSince the callstack is not empty yet, the `setTimeout` function and promise in `funcOne` cannot get added to the callstack yet.\n\nIn `funcTwo`, the variable `res` gets `Promise` because `Promise.resolve(Promise.resolve('Promise'))` is equivalent to `Promise.resolve('Promise')` since resolving a promise just resolves it's value. The `await` in this line stops the execution of the function until it receives the resolution of the promise and then keeps on running synchronously until completion, so `Promise 2!` and then `Last line 2!` are logged and the `setTimeout` is sent to the Web API. If the first then clause in `funcOne` had its own log statement, it would be printed before `Promise 2!`. Howewer, it executed silently and put the second then clause in microtask queue. So, the second clause will be printed after `Promise 2!`.\n\nThen the call stack is empty. Promises are _microtasks_ so they are resolved first when the call stack is empty so `Promise 1!` gets to be logged.\n\nNow, since `funcTwo` popped off the call stack, the call stack is empty. The callbacks waiting in the queue (`() => console.log(\"Timeout 1!\")` from `funcOne`, and `() => console.log(\"Timeout 2!\")` from `funcTwo`) get added to the call stack one by one. The first callback logs `Timeout 1!`, and gets popped off the stack. Then, the second callback logs `Timeout 2!`, and gets popped off the stack.\n\n</p>\n</details>\n\n---\n\n###### 134. How can we invoke `sum` in `sum.js` from `index.js?`\n\n```javascript\n// sum.js\nexport default function sum(x) {\n  return x + x;\n}\n\n// index.js\nimport * as sum from './sum';\n```\n\n- A: `sum(4)`\n- B: `sum.sum(4)`\n- C: `sum.default(4)`\n- D: Default aren't imported with `*`, only named exports\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith the asterisk `*`, we import all exported values from that file, both default and named. If we had the following file:\n\n```javascript\n// info.js\nexport const name = 'Lydia';\nexport const age = 21;\nexport default 'I love JavaScript';\n\n// index.js\nimport * as info from './info';\nconsole.log(info);\n```\n\nThe following would get logged:\n\n```javascript\n{\n  default: \"I love JavaScript\",\n  name: \"Lydia\",\n  age: 21\n}\n```\n\nFor the `sum` example, it means that the imported value `sum` looks like this:\n\n```javascript\n{ default: function sum(x) { return x + x } }\n```\n\nWe can invoke this function, by calling `sum.default`\n\n</p>\n</details>\n\n---\n\n###### 135. What's the output?\n\n```javascript\nconst handler = {\n  set: () => console.log('Added a new property!'),\n  get: () => console.log('Accessed a property!'),\n};\n\nconst person = new Proxy({}, handler);\n\nperson.name = 'Lydia';\nperson.name;\n```\n\n- A: `Added a new property!`\n- B: `Accessed a property!`\n- C: `Added a new property!` `Accessed a property!`\n- D: Nothing gets logged\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nWith a Proxy object, we can add custom behavior to an object that we pass to it as the second argument. In this case, we pass the `handler` object which contains two properties: `set` and `get`. `set` gets invoked whenever we _set_ property values, and `get` gets invoked whenever we _get_ (access) property values.\n\nThe first argument is an empty object `{}`, which is the value of `person`. To this object, the custom behavior specified in the `handler` object gets added. If we add a property to the `person` object, `set` will get invoked. If we access a property on the `person` object, `get` gets invoked.\n\nFirst, we added a new property `name` to the proxy object (`person.name = \"Lydia\"`). `set` gets invoked, and logs `\"Added a new property!\"`.\n\nThen, we access a property value on the proxy object, and the `get` property on the handler object is invoked. `\"Accessed a property!\"` gets logged.\n\n</p>\n</details>\n\n---\n\n###### 136. Which of the following will modify the `person` object?\n\n```javascript\nconst person = { name: 'Lydia Hallie' };\n\nObject.seal(person);\n```\n\n- A: `person.name = \"Evan Bacon\"`\n- B: `person.age = 21`\n- C: `delete person.name`\n- D: `Object.assign(person, { age: 21 })`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWith `Object.seal` we can prevent new properties from being _added_, or existing properties to be _removed_.\n\nHowever, you can still modify the value of existing properties.\n\n</p>\n</details>\n\n---\n\n###### 137. Which of the following will modify the `person` object?\n\n```javascript\nconst person = {\n  name: 'Lydia Hallie',\n  address: {\n    street: '100 Main St',\n  },\n};\n\nObject.freeze(person);\n```\n\n- A: `person.name = \"Evan Bacon\"`\n- B: `delete person.address`\n- C: `person.address.street = \"101 Main St\"`\n- D: `person.pet = { name: \"Mara\" }`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `Object.freeze` method _freezes_ an object. No properties can be added, modified, or removed.\n\nHowever, it only _shallowly_ freezes the object, meaning that only _direct_ properties on the object are frozen. If the property is another object, like `address` in this case, the properties on that object aren't frozen, and can be modified.\n\n</p>\n</details>\n\n---\n\n###### 138. What's the output?\n\n```javascript\nconst add = x => x + x;\n\nfunction myFunc(num = 2, value = add(num)) {\n  console.log(num, value);\n}\n\nmyFunc();\nmyFunc(3);\n```\n\n- A: `2` `4` and `3` `6`\n- B: `2` `NaN` and `3` `NaN`\n- C: `2` `Error` and `3` `6`\n- D: `2` `4` and `3` `Error`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nFirst, we invoked `myFunc()` without passing any arguments. Since we didn't pass arguments, `num` and `value` got their default values: num is `2`, and `value` is the returned value of the function `add`. To the `add` function, we pass `num` as an argument, which had the value of `2`. `add` returns `4`, which is the value of `value`.\n\nThen, we invoked `myFunc(3)` and passed the value `3` as the value for the argument `num`. We didn't pass an argument for `value`. Since we didn't pass a value for the `value` argument, it got the default value: the returned value of the `add` function. To `add`, we pass `num`, which has the value of `3`. `add` returns `6`, which is the value of `value`.\n\n</p>\n</details>\n\n---\n\n###### 139. What's the output?\n\n```javascript\nclass Counter {\n  #number = 10\n\n  increment() {\n    this.#number++\n  }\n\n  getNum() {\n    return this.#number\n  }\n}\n\nconst counter = new Counter()\ncounter.increment()\n\nconsole.log(counter.#number)\n```\n\n- A: `10`\n- B: `11`\n- C: `undefined`\n- D: `SyntaxError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nIn ES2020, we can add private variables in classes by using the `#`. We cannot access these variables outside of the class. When we try to log `counter.#number`, a SyntaxError gets thrown: we cannot access it outside the `Counter` class!\n\n</p>\n</details>\n\n---\n\n###### 140. What's missing?\n\n```javascript\nconst teams = [\n  { name: 'Team 1', members: ['Paul', 'Lisa'] },\n  { name: 'Team 2', members: ['Laura', 'Tim'] },\n];\n\nfunction* getMembers(members) {\n  for (let i = 0; i < members.length; i++) {\n    yield members[i];\n  }\n}\n\nfunction* getTeams(teams) {\n  for (let i = 0; i < teams.length; i++) {\n    // ✨ SOMETHING IS MISSING HERE ✨\n  }\n}\n\nconst obj = getTeams(teams);\nobj.next(); // { value: \"Paul\", done: false }\nobj.next(); // { value: \"Lisa\", done: false }\n```\n\n- A: `yield getMembers(teams[i].members)`\n- B: `yield* getMembers(teams[i].members)`\n- C: `return getMembers(teams[i].members)`\n- D: `return yield getMembers(teams[i].members)`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nIn order to iterate over the `members` in each element in the `teams` array, we need to pass `teams[i].members` to the `getMembers` generator function. The generator function returns a generator object. In order to iterate over each element in this generator object, we need to use `yield*`.\n\nIf we would've written `yield`, `return yield`, or `return`, the entire generator function would've gotten returned the first time we called the `next` method.\n\n</p>\n</details>\n\n---\n\n###### 141. What's the output?\n\n```javascript\nconst person = {\n  name: 'Lydia Hallie',\n  hobbies: ['coding'],\n};\n\nfunction addHobby(hobby, hobbies = person.hobbies) {\n  hobbies.push(hobby);\n  return hobbies;\n}\n\naddHobby('running', []);\naddHobby('dancing');\naddHobby('baking', person.hobbies);\n\nconsole.log(person.hobbies);\n```\n\n- A: `[\"coding\"]`\n- B: `[\"coding\", \"dancing\"]`\n- C: `[\"coding\", \"dancing\", \"baking\"]`\n- D: `[\"coding\", \"running\", \"dancing\", \"baking\"]`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `addHobby` function receives two arguments, `hobby` and `hobbies` with the default value of the `hobbies` array on the `person` object.\n\nFirst, we invoke the `addHobby` function, and pass `\"running\"` as the value for `hobby` and an empty array as the value for `hobbies`. Since we pass an empty array as the value for `hobbies`, `\"running\"` gets added to this empty array.\n\nThen, we invoke the `addHobby` function, and pass `\"dancing\"` as the value for `hobby`. We didn't pass a value for `hobbies`, so it gets the default value, the `hobbies` property on the `person` object. We push the hobby `dancing` to the `person.hobbies` array.\n\nLast, we invoke the `addHobby` function, and pass `\"baking\"` as the value for `hobby`, and the `person.hobbies` array as the value for `hobbies`. We push the hobby `baking` to the `person.hobbies` array.\n\nAfter pushing `dancing` and `baking`, the value of `person.hobbies` is `[\"coding\", \"dancing\", \"baking\"]`\n\n</p>\n</details>\n\n---\n\n###### 142. What's the output?\n\n```javascript\nclass Bird {\n  constructor() {\n    console.log(\"I'm a bird. 🦢\");\n  }\n}\n\nclass Flamingo extends Bird {\n  constructor() {\n    console.log(\"I'm pink. 🌸\");\n    super();\n  }\n}\n\nconst pet = new Flamingo();\n```\n\n- A: `I'm pink. 🌸`\n- B: `I'm pink. 🌸` `I'm a bird. 🦢`\n- C: `I'm a bird. 🦢` `I'm pink. 🌸`\n- D: Nothing, we didn't call any method\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nWe create the variable `pet` which is an instance of the `Flamingo` class. When we instantiate this instance, the `constructor` on `Flamingo` gets called. First, `\"I'm pink. 🌸\"` gets logged, after which we call `super()`. `super()` calls the constructor of the parent class, `Bird`. The constructor in `Bird` gets called, and logs `\"I'm a bird. 🦢\"`.\n\n</p>\n</details>\n\n---\n\n###### 143. Which of the options result(s) in an error?\n\n```javascript\nconst emojis = ['🎄', '🎅🏼', '🎁', '⭐'];\n\n/* 1 */ emojis.push('🦌');\n/* 2 */ emojis.splice(0, 2);\n/* 3 */ emojis = [...emojis, '🥂'];\n/* 4 */ emojis.length = 0;\n```\n\n- A: 1\n- B: 1 and 2\n- C: 3 and 4\n- D: 3\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `const` keyword simply means we cannot _redeclare_ the value of that variable, it's _read-only_. However, the value itself isn't immutable. The properties on the `emojis` array can be modified, for example by pushing new values, splicing them, or setting the length of the array to 0.\n\n</p>\n</details>\n\n---\n\n###### 144. What do we need to add to the `person` object to get `[\"Lydia Hallie\", 21]` as the output of `[...person]`?\n\n```javascript\nconst person = {\n  name: \"Lydia Hallie\",\n  age: 21\n}\n\n[...person] // [\"Lydia Hallie\", 21]\n```\n\n- A: Nothing, object are iterable by default\n- B: `*[Symbol.iterator]() { for (let x in this) yield* this[x] }`\n- C: `*[Symbol.iterator]() { yield* Object.values(this) }`\n- D: `*[Symbol.iterator]() { for (let x in this) yield this }`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nObjects aren't iterable by default. An iterable is an iterable if the iterator protocol is present. We can add this manually by adding the iterator symbol `[Symbol.iterator]`, which has to return a generator object, for example by making it a generator function `*[Symbol.iterator]() {}`. This generator function has to yield the `Object.values` of the `person` object if we want it to return the array `[\"Lydia Hallie\", 21]`: `yield* Object.values(this)`.\n\n</p>\n</details>\n\n---\n\n###### 145. What's the output?\n\n```javascript\nlet count = 0;\nconst nums = [0, 1, 2, 3];\n\nnums.forEach(num => {\n\tif (num) count += 1\n})\n\nconsole.log(count)\n```\n\n- A: 1\n- B: 2\n- C: 3\n- D: 4\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `if` condition within the `forEach` loop checks whether the value of `num` is truthy or falsy. Since the first number in the `nums` array is `0`, a falsy value, the `if` statement's code block won't be executed. `count` only gets incremented for the other 3 numbers in the `nums` array, `1`, `2` and `3`. Since `count` gets incremented by `1` 3 times, the value of `count` is `3`.\n\n</p>\n</details>\n\n---\n\n###### 146. What's the output?\n\n```javascript\nfunction getFruit(fruits) {\n\tconsole.log(fruits?.[1]?.[1])\n}\n\ngetFruit([['🍊', '🍌'], ['🍍']])\ngetFruit()\ngetFruit([['🍍'], ['🍊', '🍌']])\n```\n\n- A: `null`, `undefined`, 🍌\n- B: `[]`, `null`, 🍌\n- C: `[]`, `[]`, 🍌\n- D: `undefined`, `undefined`, 🍌\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `?` allows us to optionally access deeper nested properties within objects. We're trying to log the item on index `1` within the subarray that's on index `1` of the `fruits` array. If the subarray on index `1` in the `fruits` array doesn't exist, it'll simply return `undefined`. If the subarray on index `1` in the `fruits` array exists, but this subarray doesn't have an item on its `1` index, it'll also return `undefined`. \n\nFirst, we're trying to log the second item in the `['🍍']` subarray of `[['🍊', '🍌'], ['🍍']]`. This subarray only contains one item, which means there is no item on index `1`, and returns `undefined`.\n\nThen, we're invoking the `getFruits` function without passing a value as an argument, which means that `fruits` has a value of `undefined` by default. Since we're conditionally chaining the item on index `1` of`fruits`, it returns `undefined` since this item on index `1` does not exist. \n\nLastly, we're trying to log the second item in the `['🍊', '🍌']` subarray of `['🍍'], ['🍊', '🍌']`. The item on index `1` within this subarray is `🍌`, which gets logged.\n\n</p>\n</details>\n\n---\n\n###### 147. What's the output?\n\n```javascript\nclass Calc {\n\tconstructor() {\n\t\tthis.count = 0 \n\t}\n\n\tincrease() {\n\t\tthis.count++\n\t}\n}\n\nconst calc = new Calc()\nnew Calc().increase()\n\nconsole.log(calc.count)\n```\n\n- A: `0`\n- B: `1`\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nWe set the variable `calc` equal to a new instance of the `Calc` class. Then, we instantiate a new instance of `Calc`, and invoke the `increase` method on this instance. Since the count property is within the constructor of the `Calc` class, the count property is not shared on the prototype of `Calc`. This means that the value of count has not been updated for the instance calc points to, count is still `0`.\n\n</p>\n</details>\n\n---\n\n###### 148. What's the output?\n\n```javascript\nconst user = {\n\temail: \"e@mail.com\",\n\tpassword: \"12345\"\n}\n\nconst updateUser = ({ email, password }) => {\n\tif (email) {\n\t\tObject.assign(user, { email })\n\t}\n\n\tif (password) {\n\t\tuser.password = password\n\t}\n\n\treturn user\n}\n\nconst updatedUser = updateUser({ email: \"new@email.com\" })\n\nconsole.log(updatedUser === user)\n```\n\n- A: `false`\n- B: `true`\n- C: `TypeError`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nThe `updateUser` function updates the values of the `email` and `password` properties on user, if their values are passed to the function, after which the function returns the `user` object. The returned value of the `updateUser` function is the `user` object, which means that the value of updatedUser is a reference to the same `user` object that `user` points to. `updatedUser === user` equals `true`.\n\n</p>\n</details>\n\n---\n\n###### 149. What's the output?\n\n```javascript\nconst fruit = ['🍌', '🍊', '🍎']\n\nfruit.slice(0, 1)\nfruit.splice(0, 1)\nfruit.unshift('🍇')\n\nconsole.log(fruit)\n```\n\n- A: `['🍌', '🍊', '🍎']`\n- B: `['🍊', '🍎']`\n- C: `['🍇', '🍊', '🍎']`\n- D: `['🍇', '🍌', '🍊', '🍎']`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nFirst, we invoke the `slice` method on the fruit array. The slice method does not modify the original array, but returns the value that it sliced off the array: the banana emoji.\nThen, we invoke the `splice` method on the fruit array. The splice method does modify the original array, which means that the fruit array now consists of `['🍊', '🍎']`.\nAt last, we invoke the `unshift` method on the `fruit` array, which modifies the original array by adding the provided value, ‘🍇’ in this case,  as the first element in the array.  The fruit array now consists of `['🍇', '🍊', '🍎']`.\n\n</p>\n</details>\n\n---\n\n###### 150. What's the output?\n\n```javascript\nconst animals = {};\nlet dog = { emoji: '🐶' }\nlet cat = { emoji: '🐈' }\n\nanimals[dog] = { ...dog, name: \"Mara\" }\nanimals[cat] = { ...cat, name: \"Sara\" }\n\nconsole.log(animals[dog])\n```\n\n- A: `{ emoji: \"🐶\", name: \"Mara\" }`\n- B: `{ emoji: \"🐈\", name: \"Sara\" }`\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nObject keys are converted to strings. \n\nSince the value of  `dog` is an object,  `animals[dog]` actually means that we’re creating a new property called `\"[object Object]\"` equal to the new object. `animals[\"[object Object]\"]` is now equal to `{ emoji: \"🐶\", name: \"Mara\"}`.\n\n`cat` is also an object, which means that `animals[cat]` actually means that we’re overwriting the value of  `animals[\"[object Object]\"]` with the new cat properties. \n\nLogging `animals[dog]`, or actually `animals[\"[object Object]\"]` since converting the `dog` object to a string results `\"[object Object]\"`, returns the `{ emoji: \"🐈\", name: \"Sara\" }`.\n\n</p>\n</details>\n\n---\n\n###### 151. What's the output?\n\n```javascript\nconst user = {\n\temail: \"my@email.com\",\n\tupdateEmail: email => {\n\t\tthis.email = email\n\t}\n}\n\nuser.updateEmail(\"new@email.com\")\nconsole.log(user.email)\n```\n\n- A: `my@email.com`\n- B: `new@email.com`\n- C: `undefined`\n- D: `ReferenceError`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: A\n\nThe `updateEmail` function is an arrow function, and is not bound to the `user` object. This means that the `this` keyword is not referring to the `user` object, but refers to  the global scope in this case. The value of `email` within the `user` object does not get updated. When logging the value of `user.email`, the original value of `my@email.com` gets returned. \n\n</p>\n</details>\n\n---\n\n###### 152. What's the output?\n\n```javascript\nconst promise1 = Promise.resolve('First')\nconst promise2 = Promise.resolve('Second')\nconst promise3 = Promise.reject('Third')\nconst promise4 = Promise.resolve('Fourth')\n\nconst runPromises = async () => {\n\tconst res1 = await Promise.all([promise1, promise2])\n\tconst res2  = await Promise.all([promise3, promise4])\n\treturn [res1, res2]\n}\n\nrunPromises()\n\t.then(res => console.log(res))\n\t.catch(err => console.log(err))\n```\n\n- A: `[['First', 'Second'], ['Fourth']]`\n- B: `[['First', 'Second'], ['Third', 'Fourth']]`\n- C: `[['First', 'Second']]`\n- D: `'Third'`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: D\n\nThe `Promise.all` method runs the passed promises in parallel. If one promise fails, the `Promise.all` method _rejects_ with the value of the rejected promise. In this case, `promise3` is rejected with the value `\"Third\"`. We’re catching the rejected value in the chained `catch` method on the `runPromises` invocation to catch any errors  within the `runPromises` function. Only `\"Third\"` gets logged, since `promise3` is rejected with this value.\n\n</p>\n</details>\n\n---\n\n###### 153. What should the value of `method` be to log `{ name: \"Lydia\", age: 22 }`? \n\n```javascript\nconst keys = [\"name\", \"age\"]\nconst values = [\"Lydia\", 22]\n\nconst method = /* ?? */\nObject[method](keys.map((_, i) => {\n\treturn [keys[i], values[i]]\n})) // { name: \"Lydia\", age: 22 }\n```\n\n- A: `entries`\n- B: `values`\n- C: `fromEntries`\n- D: `forEach`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe `fromEntries` method turns a 2d array into an object. The first element in each subarray will be the key, and the second element in each subarray will be the value. In this case, we’re mapping over the `keys` array, which returns an array that the first element is the item on the key array on the current index, and the second element is the item of the values array on the current index. \n\nThis creates an array of subarrays containing the correct keys and values, which results in `{ name: \"Lydia\", age: 22 }`\n\n</p>\n</details>\n\n---\n\n###### 154. What's the output?\n\n```javascript\nconst createMember = ({ email, address = {}}) => {\n\tconst validEmail = /.+\\@.+\\..+/.test(email)\n\tif (!validEmail) throw new Error(\"Valid email pls\")\n\n\treturn {\n\t\temail,\n\t\taddress: address ? address : null\n\t}\n}\n\nconst member = createMember({ email: \"my@email.com\" })\nconsole.log(member)\n```\n\n- A: `{ email: \"my@email.com\", address: null }`\n- B: `{ email: \"my@email.com\" }`\n- C: `{ email: \"my@email.com\", address: {} }`\n- D: `{ email: \"my@email.com\", address: undefined }`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: C\n\nThe default value of `address` is an empty object `{}`. When we set the variable `member` equal to the object returned by the `createMember` function, we didn't pass a value for the address, which means that the value of the address is the default empty object `{}`. An empty object is a truthy value, which means that the condition of the `address ? address : null` conditional returns `true`. The value of the address is the empty object `{}`.\n\n</p>\n</details>\n\n---\n\n###### 155. What's the output?\n\n```javascript\nlet randomValue = { name: \"Lydia\" }\nrandomValue = 23\n\nif (!typeof randomValue === \"string\") {\n\tconsole.log(\"It's not a string!\")\n} else {\n\tconsole.log(\"Yay it's a string!\")\n}\n```\n\n- A: `It's not a string!`\n- B: `Yay it's a string!`\n- C: `TypeError`\n- D: `undefined`\n\n<details><summary><b>Answer</b></summary>\n<p>\n\n#### Answer: B\n\nThe condition within the `if` statement checks whether the value of `!typeof randomValue` is equal to `\"string\"`. The `!` operator converts the value to a boolean value. If the value is truthy, the returned value will be `false`, if the value is falsy, the returned value will be `true`. In this case, the returned value of `typeof randomValue` is the truthy value `\"number\"`, meaning that the value of `!typeof randomValue` is the boolean value `false`.\n\n`!typeof randomValue === \"string\"` always returns false, since we're actually checking `false === \"string\"`. Since the condition returned `false`, the code block of the `else` statement gets run, and `Yay it's a string!` gets logged.\n\n</p>\n</details>\n"
        },
        {
          "name": "ar-AR",
          "type": "tree",
          "content": null
        },
        {
          "name": "ar-EG",
          "type": "tree",
          "content": null
        },
        {
          "name": "bs-BS",
          "type": "tree",
          "content": null
        },
        {
          "name": "de-DE",
          "type": "tree",
          "content": null
        },
        {
          "name": "es-ES",
          "type": "tree",
          "content": null
        },
        {
          "name": "fr-FR",
          "type": "tree",
          "content": null
        },
        {
          "name": "id-ID",
          "type": "tree",
          "content": null
        },
        {
          "name": "it-IT",
          "type": "tree",
          "content": null
        },
        {
          "name": "ja-JA",
          "type": "tree",
          "content": null
        },
        {
          "name": "ko-KR",
          "type": "tree",
          "content": null
        },
        {
          "name": "nl-NL",
          "type": "tree",
          "content": null
        },
        {
          "name": "pl-PL",
          "type": "tree",
          "content": null
        },
        {
          "name": "pt-BR",
          "type": "tree",
          "content": null
        },
        {
          "name": "ro-RO",
          "type": "tree",
          "content": null
        },
        {
          "name": "ru-RU",
          "type": "tree",
          "content": null
        },
        {
          "name": "sq-KS",
          "type": "tree",
          "content": null
        },
        {
          "name": "th-TH",
          "type": "tree",
          "content": null
        },
        {
          "name": "tr-TR",
          "type": "tree",
          "content": null
        },
        {
          "name": "uk-UA",
          "type": "tree",
          "content": null
        },
        {
          "name": "vi-VI",
          "type": "tree",
          "content": null
        },
        {
          "name": "zh-CN",
          "type": "tree",
          "content": null
        },
        {
          "name": "zh-TW",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "comfyanonymous/ComfyUI",
      "stars": 63055,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".ci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.06,
          "content": "/web/assets/** linguist-generated\n/web/** linguist-vendored\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.33,
          "content": "__pycache__/\n*.py[cod]\n/output/\n/input/\n!/input/example.png\n/models/\n/temp/\n/custom_nodes/\n!custom_nodes/example_node.py.example\nextra_model_paths.yaml\n/.vs\n.vscode/\n.idea/\nvenv/\n.venv/\n/web/extensions/*\n!/web/extensions/logging.js.example\n!/web/extensions/core/\n/tests-ui/data/object_info.json\n/user/\n*.log\nweb_custom_versions/\n.DS_Store\n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 1.09,
          "content": "# Admins\n* @comfyanonymous\n\n# Note: Github teams syntax cannot be used here as the repo is not owned by Comfy-Org.\n# Inlined the team members for now.\n\n# Maintainers\n*.md @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata @Kosinkadink\n/tests/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata @Kosinkadink\n/tests-unit/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata @Kosinkadink\n/notebooks/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata @Kosinkadink\n/script_examples/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata @Kosinkadink\n/.github/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata @Kosinkadink\n\n# Python web server\n/api_server/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata\n/app/ @yoland68 @robinjhuang @huchenlei @webfiltered @pythongosssss @ltdrdata\n\n# Frontend assets\n/web/ @huchenlei @webfiltered @pythongosssss @yoland68 @robinjhuang\n\n# Extra nodes\n/comfy_extras/ @yoland68 @robinjhuang @huchenlei @pythongosssss @ltdrdata @Kosinkadink\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.84,
          "content": "# Contributing to ComfyUI\n\nWelcome, and thank you for your interest in contributing to ComfyUI!\n\nThere are several ways in which you can contribute, beyond writing code. The goal of this document is to provide a high-level overview of how you can get involved.\n\n## Asking Questions\n\nHave a question? Instead of opening an issue, please ask on [Discord](https://comfy.org/discord) or [Matrix](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) channels. Our team and the community will help you.\n\n## Providing Feedback\n\nYour comments and feedback are welcome, and the development team is available via a handful of different channels.\n\nSee the `#bug-report`, `#feature-request` and `#feedback` channels on Discord.\n\n## Reporting Issues\n\nHave you identified a reproducible problem in ComfyUI? Do you have a feature request? We want to hear about it! Here's how you can report your issue as effectively as possible.\n\n\n### Look For an Existing Issue\n\nBefore you create a new issue, please do a search in [open issues](https://github.com/comfyanonymous/ComfyUI/issues) to see if the issue or feature request has already been filed.\n\nIf you find your issue already exists, make relevant comments and add your [reaction](https://github.com/blog/2119-add-reactions-to-pull-requests-issues-and-comments). Use a reaction in place of a \"+1\" comment:\n\n* 👍 - upvote\n* 👎 - downvote\n\nIf you cannot find an existing issue that describes your bug or feature, create a new issue. We have an issue template in place to organize new issues.\n\n\n### Creating Pull Requests\n\n* Please refer to the article on [creating pull requests](https://github.com/comfyanonymous/ComfyUI/wiki/How-to-Contribute-Code) and contributing to this project.\n\n\n## Thank You\n\nYour contributions to open source, large or small, make great projects like this possible. Thank you for taking the time to contribute.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.33,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<https://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<https://www.gnu.org/licenses/why-not-lgpl.html>.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 21.86,
          "content": "<div align=\"center\">\n\n# ComfyUI\n**The most powerful and modular diffusion model GUI and backend.**\n\n\n[![Website][website-shield]][website-url]\n[![Dynamic JSON Badge][discord-shield]][discord-url]\n[![Matrix][matrix-shield]][matrix-url]\n<br>\n[![][github-release-shield]][github-release-link]\n[![][github-release-date-shield]][github-release-link]\n[![][github-downloads-shield]][github-downloads-link]\n[![][github-downloads-latest-shield]][github-downloads-link]\n\n[matrix-shield]: https://img.shields.io/badge/Matrix-000000?style=flat&logo=matrix&logoColor=white\n[matrix-url]: https://app.element.io/#/room/%23comfyui_space%3Amatrix.org\n[website-shield]: https://img.shields.io/badge/ComfyOrg-4285F4?style=flat\n[website-url]: https://www.comfy.org/\n<!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 -->\n[discord-shield]: https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&query=%24.approximate_member_count&logo=discord&logoColor=white&label=Discord&color=green&suffix=%20total\n[discord-url]: https://www.comfy.org/discord\n\n[github-release-shield]: https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&sort=semver\n[github-release-link]: https://github.com/comfyanonymous/ComfyUI/releases\n[github-release-date-shield]: https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat\n[github-downloads-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat\n[github-downloads-latest-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&label=downloads%40latest\n[github-downloads-link]: https://github.com/comfyanonymous/ComfyUI/releases\n\n![ComfyUI Screenshot](https://github.com/user-attachments/assets/7ccaf2c1-9b72-41ae-9a89-5688c94b7abe)\n</div>\n\nThis ui will let you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. For some workflow examples and see what ComfyUI can do you can check out:\n### [ComfyUI Examples](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n### [Installing ComfyUI](#installing)\n\n## Features\n- Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.\n- Image Models\n   - SD1.x, SD2.x,\n   - [SDXL](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/), [SDXL Turbo](https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/)\n   - [Stable Cascade](https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/)\n   - [SD3 and SD3.5](https://comfyanonymous.github.io/ComfyUI_examples/sd3/)\n   - Pixart Alpha and Sigma\n   - [AuraFlow](https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/)\n   - [HunyuanDiT](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/)\n   - [Flux](https://comfyanonymous.github.io/ComfyUI_examples/flux/)\n- Video Models\n   - [Stable Video Diffusion](https://comfyanonymous.github.io/ComfyUI_examples/video/)\n   - [Mochi](https://comfyanonymous.github.io/ComfyUI_examples/mochi/)\n   - [LTX-Video](https://comfyanonymous.github.io/ComfyUI_examples/ltxv/)\n   - [Hunyuan Video](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/)\n- [Stable Audio](https://comfyanonymous.github.io/ComfyUI_examples/audio/)\n- Asynchronous Queue system\n- Many optimizations: Only re-executes the parts of the workflow that changes between executions.\n- Smart memory management: can automatically run models on GPUs with as low as 1GB vram.\n- Works even if you don't have a GPU with: ```--cpu``` (slow)\n- Can load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs and CLIP models.\n- Embeddings/Textual inversion\n- [Loras (regular, locon and loha)](https://comfyanonymous.github.io/ComfyUI_examples/lora/)\n- [Hypernetworks](https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/)\n- Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.\n- Saving/Loading workflows as Json files.\n- Nodes interface can be used to create complex workflows like one for [Hires fix](https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/) or much more advanced ones.\n- [Area Composition](https://comfyanonymous.github.io/ComfyUI_examples/area_composition/)\n- [Inpainting](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/) with both regular and inpainting models.\n- [ControlNet and T2I-Adapter](https://comfyanonymous.github.io/ComfyUI_examples/controlnet/)\n- [Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)](https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/)\n- [unCLIP Models](https://comfyanonymous.github.io/ComfyUI_examples/unclip/)\n- [GLIGEN](https://comfyanonymous.github.io/ComfyUI_examples/gligen/)\n- [Model Merging](https://comfyanonymous.github.io/ComfyUI_examples/model_merging/)\n- [LCM models and Loras](https://comfyanonymous.github.io/ComfyUI_examples/lcm/)\n- Latent previews with [TAESD](#how-to-show-high-quality-previews)\n- Starts up very fast.\n- Works fully offline: will never download anything.\n- [Config file](extra_model_paths.yaml.example) to set the search paths for models.\n\nWorkflow examples can be found on the [Examples page](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n## Shortcuts\n\n| Keybind                            | Explanation                                                                                                        |\n|------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n| `Ctrl` + `Enter`                      | Queue up current graph for generation                                                                              |\n| `Ctrl` + `Shift` + `Enter`              | Queue up current graph as first for generation                                                                     |\n| `Ctrl` + `Alt` + `Enter`                | Cancel current generation                                                                                          |\n| `Ctrl` + `Z`/`Ctrl` + `Y`                 | Undo/Redo                                                                                                          |\n| `Ctrl` + `S`                          | Save workflow                                                                                                      |\n| `Ctrl` + `O`                          | Load workflow                                                                                                      |\n| `Ctrl` + `A`                          | Select all nodes                                                                                                   |\n| `Alt `+ `C`                           | Collapse/uncollapse selected nodes                                                                                 |\n| `Ctrl` + `M`                          | Mute/unmute selected nodes                                                                                         |\n| `Ctrl` + `B`                           | Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)            |\n| `Delete`/`Backspace`                   | Delete selected nodes                                                                                              |\n| `Ctrl` + `Backspace`                   | Delete the current graph                                                                                           |\n| `Space`                              | Move the canvas around when held and moving the cursor                                                             |\n| `Ctrl`/`Shift` + `Click`                 | Add clicked node to selection                                                                                      |\n| `Ctrl` + `C`/`Ctrl` + `V`                  | Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)                     |\n| `Ctrl` + `C`/`Ctrl` + `Shift` + `V`          | Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes) |\n| `Shift` + `Drag`                       | Move multiple selected nodes at the same time                                                                      |\n| `Ctrl` + `D`                           | Load default graph                                                                                                 |\n| `Alt` + `+`                          | Canvas Zoom in                                                                                                     |\n| `Alt` + `-`                          | Canvas Zoom out                                                                                                    |\n| `Ctrl` + `Shift` + LMB + Vertical drag | Canvas Zoom in/out                                                                                                 |\n| `P`                                  | Pin/Unpin selected nodes                                                                                           |\n| `Ctrl` + `G`                           | Group selected nodes                                                                                               |\n| `Q`                                 | Toggle visibility of the queue                                                                                     |\n| `H`                                  | Toggle visibility of history                                                                                       |\n| `R`                                  | Refresh graph                                                                                                      |\n| `F`                                  | Show/Hide menu                                                                                                      |\n| `.`                                  | Fit view to selection (Whole graph when nothing is selected)                                                        |\n| Double-Click LMB                   | Open node quick search palette                                                                                     |\n| `Shift` + Drag                       | Move multiple wires at once                                                                                        |\n| `Ctrl` + `Alt` + LMB                   | Disconnect all wires from clicked slot                                                                             |\n\n`Ctrl` can also be replaced with `Cmd` instead for macOS users\n\n# Installing\n\n## Windows\n\nThere is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the [releases page](https://github.com/comfyanonymous/ComfyUI/releases).\n\n### [Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z)\n\nSimply download, extract with [7-Zip](https://7-zip.org) and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\\models\\checkpoints\n\nIf you have trouble extracting it, right click the file -> properties -> unblock\n\n#### How do I share models between another UI and ComfyUI?\n\nSee the [Config file](extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.\n\n## Jupyter Notebook\n\nTo run it on services like paperspace, kaggle or colab you can use my [Jupyter Notebook](notebooks/comfyui_colab.ipynb)\n\n## Manual Install (Windows, Linux)\n\nNote that some dependencies do not yet support python 3.13 so using 3.12 is recommended.\n\nGit clone this repo.\n\nPut your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints\n\nPut your VAE in: models/vae\n\n\n### AMD GPUs (Linux only)\nAMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:\n\n```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2```\n\nThis is the command to install the nightly with ROCm 6.2 which might have some performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.2.4```\n\n### Intel GPUs (Windows and Linux)\n\n(Option 1) Intel Arc GPU users can install native PyTorch with torch.xpu support using pip (currently available in PyTorch nightly builds). More information can be found [here](https://pytorch.org/docs/main/notes/get_start_xpu.html)\n  \n1. To install PyTorch nightly, use the following command:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu```\n\n2. Launch ComfyUI by running `python main.py`\n\n\n(Option 2) Alternatively, Intel GPUs supported by Intel Extension for PyTorch (IPEX) can leverage IPEX for improved performance.\n\n1. For Intel® Arc™ A-Series Graphics utilizing IPEX, create a conda environment and use the commands below:\n\n```\nconda install libuv\npip install torch==2.3.1.post0+cxx11.abi torchvision==0.18.1.post0+cxx11.abi torchaudio==2.3.1.post0+cxx11.abi intel-extension-for-pytorch==2.3.110.post0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/ --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/\n```\n\nFor other supported Intel GPUs with IPEX, visit [Installation](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu) for more information.\n\nAdditional discussion and help can be found [here](https://github.com/comfyanonymous/ComfyUI/discussions/476).\n\n### NVIDIA\n\nNvidia users should install stable pytorch using this command:\n\n```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124```\n\nThis is the command to install pytorch nightly instead which might have performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126```\n\n#### Troubleshooting\n\nIf you get the \"Torch not compiled with CUDA enabled\" error, uninstall torch with:\n\n```pip uninstall torch```\n\nAnd install it again with the command above.\n\n### Dependencies\n\nInstall the dependencies by opening your terminal inside the ComfyUI folder and:\n\n```pip install -r requirements.txt```\n\nAfter this you should have everything installed and can proceed to running ComfyUI.\n\n### Others:\n\n#### Apple Mac silicon\n\nYou can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.\n\n1. Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux.\n1. Install the ComfyUI [dependencies](#dependencies). If you have another Stable Diffusion UI [you might be able to reuse the dependencies](#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies).\n1. Launch ComfyUI by running `python main.py`\n\n> **Note**: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in [ComfyUI manual installation](#manual-install-windows-linux).\n\n#### DirectML (AMD Cards on Windows)\n\n```pip install torch-directml``` Then you can launch ComfyUI with: ```python main.py --directml```\n\n#### Ascend NPUs\n\nFor models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the [installation](https://ascend.github.io/docs/sources/ascend/quick_install.html) page. Here's a step-by-step guide tailored to your platform and installation method:\n\n1. Begin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.\n2. Proceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.\n3. Next, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the [Installation](https://ascend.github.io/docs/sources/pytorch/install.html#pytorch) page.\n4. Finally, adhere to the [ComfyUI manual installation](#manual-install-windows-linux) guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.\n\n\n# Running\n\n```python main.py```\n\n### For AMD cards not officially supported by ROCm\n\nTry running it with this command if you have issues:\n\nFor 6700, 6600 and maybe other RDNA2 or older: ```HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py```\n\nFor AMD 7600 and maybe other RDNA3 cards: ```HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py```\n\n### AMD ROCm Tips\n\nYou can enable experimental memory efficient attention on pytorch 2.5 in ComfyUI on RDNA3 and potentially other AMD GPUs using this command:\n\n```TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1 python main.py --use-pytorch-cross-attention```\n\nYou can also try setting this env variable `PYTORCH_TUNABLEOP_ENABLED=1` which might speed things up at the cost of a very slow initial run.\n\n# Notes\n\nOnly parts of the graph that have an output with all the correct inputs will be executed.\n\nOnly parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.\n\nDragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.\n\nYou can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \\\\( or \\\\).\n\nYou can use {day|night}, for wildcard/dynamic prompts. With this syntax \"{wild|card|test}\" will be randomly replaced by either \"wild\", \"card\" or \"test\" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \\\\{ or \\\\}.\n\nDynamic prompts also support C-style comments, like `// comment` or `/* comment */`.\n\nTo use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):\n\n```embedding:embedding_filename.pt```\n\n\n## How to show high-quality previews?\n\nUse ```--preview-method auto``` to enable previews.\n\nThe default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with [TAESD](https://github.com/madebyollin/taesd), download the [taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth](https://github.com/madebyollin/taesd/) and place them in the `models/vae_approx` folder. Once they're installed, restart ComfyUI and launch it with `--preview-method taesd` to enable high-quality previews.\n\n## How to use TLS/SSL?\nGenerate a self-signed certificate (not appropriate for shared/production use) and key by running the command: `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj \"/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname\"`\n\nUse `--tls-keyfile key.pem --tls-certfile cert.pem` to enable TLS/SSL, the app will now be accessible with `https://...` instead of `http://...`.\n\n> Note: Windows users can use [alexisrolland/docker-openssl](https://github.com/alexisrolland/docker-openssl) or one of the [3rd party binary distributions](https://wiki.openssl.org/index.php/Binaries) to run the command example above. \n<br/><br/>If you use a container, note that the volume mount `-v` can be a relative path so `... -v \".\\:/openssl-certs\" ...` would create the key & cert files in the current directory of your command prompt or powershell terminal.\n\n## Support and dev channel\n\n[Matrix space: #comfyui_space:matrix.org](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) (it's like discord but open source).\n\nSee also: [https://www.comfy.org/](https://www.comfy.org/)\n\n## Frontend Development\n\nAs of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: [ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend). This repository now hosts the compiled JS (from TS/Vue) under the `web/` directory.\n\n### Reporting Issues and Requesting Features\n\nFor any bugs, issues, or feature requests related to the frontend, please use the [ComfyUI Frontend repository](https://github.com/Comfy-Org/ComfyUI_frontend). This will help us manage and address frontend-specific concerns more efficiently.\n\n### Using the Latest Frontend\n\nThe new frontend is now the default for ComfyUI. However, please note:\n\n1. The frontend in the main ComfyUI repository is updated weekly.\n2. Daily releases are available in the separate frontend repository.\n\nTo use the most up-to-date frontend version:\n\n1. For the latest daily release, launch ComfyUI with this command line argument:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@latest\n   ```\n\n2. For a specific version, replace `latest` with the desired version number:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@1.2.2\n   ```\n\nThis approach allows you to easily switch between the stable weekly release and the cutting-edge daily updates, or even specific versions for testing purposes.\n\n### Accessing the Legacy Frontend\n\nIf you need to use the legacy frontend for any reason, you can access it using the following command line argument:\n\n```\n--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest\n```\n\nThis will use a snapshot of the legacy frontend preserved in the [ComfyUI Legacy Frontend repository](https://github.com/Comfy-Org/ComfyUI_legacy_frontend).\n\n# QA\n\n### Which GPU should I buy for this?\n\n[See this page for some recommendations](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)\n"
        },
        {
          "name": "api_server",
          "type": "tree",
          "content": null
        },
        {
          "name": "app",
          "type": "tree",
          "content": null
        },
        {
          "name": "comfy",
          "type": "tree",
          "content": null
        },
        {
          "name": "comfy_execution",
          "type": "tree",
          "content": null
        },
        {
          "name": "comfy_extras",
          "type": "tree",
          "content": null
        },
        {
          "name": "cuda_malloc.py",
          "type": "blob",
          "size": 3.45,
          "content": "import os\nimport importlib.util\nfrom comfy.cli_args import args\nimport subprocess\n\n#Can't use pytorch to get the GPU names because the cuda malloc has to be set before the first import.\ndef get_gpu_names():\n    if os.name == 'nt':\n        import ctypes\n\n        # Define necessary C structures and types\n        class DISPLAY_DEVICEA(ctypes.Structure):\n            _fields_ = [\n                ('cb', ctypes.c_ulong),\n                ('DeviceName', ctypes.c_char * 32),\n                ('DeviceString', ctypes.c_char * 128),\n                ('StateFlags', ctypes.c_ulong),\n                ('DeviceID', ctypes.c_char * 128),\n                ('DeviceKey', ctypes.c_char * 128)\n            ]\n\n        # Load user32.dll\n        user32 = ctypes.windll.user32\n\n        # Call EnumDisplayDevicesA\n        def enum_display_devices():\n            device_info = DISPLAY_DEVICEA()\n            device_info.cb = ctypes.sizeof(device_info)\n            device_index = 0\n            gpu_names = set()\n\n            while user32.EnumDisplayDevicesA(None, device_index, ctypes.byref(device_info), 0):\n                device_index += 1\n                gpu_names.add(device_info.DeviceString.decode('utf-8'))\n            return gpu_names\n        return enum_display_devices()\n    else:\n        gpu_names = set()\n        out = subprocess.check_output(['nvidia-smi', '-L'])\n        for l in out.split(b'\\n'):\n            if len(l) > 0:\n                gpu_names.add(l.decode('utf-8').split(' (UUID')[0])\n        return gpu_names\n\nblacklist = {\"GeForce GTX TITAN X\", \"GeForce GTX 980\", \"GeForce GTX 970\", \"GeForce GTX 960\", \"GeForce GTX 950\", \"GeForce 945M\",\n                \"GeForce 940M\", \"GeForce 930M\", \"GeForce 920M\", \"GeForce 910M\", \"GeForce GTX 750\", \"GeForce GTX 745\", \"Quadro K620\",\n                \"Quadro K1200\", \"Quadro K2200\", \"Quadro M500\", \"Quadro M520\", \"Quadro M600\", \"Quadro M620\", \"Quadro M1000\",\n                \"Quadro M1200\", \"Quadro M2000\", \"Quadro M2200\", \"Quadro M3000\", \"Quadro M4000\", \"Quadro M5000\", \"Quadro M5500\", \"Quadro M6000\",\n                \"GeForce MX110\", \"GeForce MX130\", \"GeForce 830M\", \"GeForce 840M\", \"GeForce GTX 850M\", \"GeForce GTX 860M\",\n                \"GeForce GTX 1650\", \"GeForce GTX 1630\", \"Tesla M4\", \"Tesla M6\", \"Tesla M10\", \"Tesla M40\", \"Tesla M60\"\n                }\n\ndef cuda_malloc_supported():\n    try:\n        names = get_gpu_names()\n    except:\n        names = set()\n    for x in names:\n        if \"NVIDIA\" in x:\n            for b in blacklist:\n                if b in x:\n                    return False\n    return True\n\n\nif not args.cuda_malloc:\n    try:\n        version = \"\"\n        torch_spec = importlib.util.find_spec(\"torch\")\n        for folder in torch_spec.submodule_search_locations:\n            ver_file = os.path.join(folder, \"version.py\")\n            if os.path.isfile(ver_file):\n                spec = importlib.util.spec_from_file_location(\"torch_version_import\", ver_file)\n                module = importlib.util.module_from_spec(spec)\n                spec.loader.exec_module(module)\n                version = module.__version__\n        if int(version[0]) >= 2: #enable by default for torch version 2.0 and up\n            args.cuda_malloc = cuda_malloc_supported()\n    except:\n        pass\n\n\nif args.cuda_malloc and not args.disable_cuda_malloc:\n    env_var = os.environ.get('PYTORCH_CUDA_ALLOC_CONF', None)\n    if env_var is None:\n        env_var = \"backend:cudaMallocAsync\"\n    else:\n        env_var += \",backend:cudaMallocAsync\"\n\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = env_var\n"
        },
        {
          "name": "custom_nodes",
          "type": "tree",
          "content": null
        },
        {
          "name": "execution.py",
          "type": "blob",
          "size": 38.98,
          "content": "import sys\nimport copy\nimport logging\nimport threading\nimport heapq\nimport time\nimport traceback\nfrom enum import Enum\nimport inspect\nfrom typing import List, Literal, NamedTuple, Optional\n\nimport torch\nimport nodes\n\nimport comfy.model_management\nfrom comfy_execution.graph import get_input_info, ExecutionList, DynamicPrompt, ExecutionBlocker\nfrom comfy_execution.graph_utils import is_link, GraphBuilder\nfrom comfy_execution.caching import HierarchicalCache, LRUCache, CacheKeySetInputSignature, CacheKeySetID\nfrom comfy_execution.validation import validate_node_input\n\nclass ExecutionResult(Enum):\n    SUCCESS = 0\n    FAILURE = 1\n    PENDING = 2\n\nclass DuplicateNodeError(Exception):\n    pass\n\nclass IsChangedCache:\n    def __init__(self, dynprompt, outputs_cache):\n        self.dynprompt = dynprompt\n        self.outputs_cache = outputs_cache\n        self.is_changed = {}\n\n    def get(self, node_id):\n        if node_id in self.is_changed:\n            return self.is_changed[node_id]\n\n        node = self.dynprompt.get_node(node_id)\n        class_type = node[\"class_type\"]\n        class_def = nodes.NODE_CLASS_MAPPINGS[class_type]\n        if not hasattr(class_def, \"IS_CHANGED\"):\n            self.is_changed[node_id] = False\n            return self.is_changed[node_id]\n\n        if \"is_changed\" in node:\n            self.is_changed[node_id] = node[\"is_changed\"]\n            return self.is_changed[node_id]\n\n        # Intentionally do not use cached outputs here. We only want constants in IS_CHANGED\n        input_data_all, _ = get_input_data(node[\"inputs\"], class_def, node_id, None)\n        try:\n            is_changed = _map_node_over_list(class_def, input_data_all, \"IS_CHANGED\")\n            node[\"is_changed\"] = [None if isinstance(x, ExecutionBlocker) else x for x in is_changed]\n        except Exception as e:\n            logging.warning(\"WARNING: {}\".format(e))\n            node[\"is_changed\"] = float(\"NaN\")\n        finally:\n            self.is_changed[node_id] = node[\"is_changed\"]\n        return self.is_changed[node_id]\n\nclass CacheSet:\n    def __init__(self, lru_size=None):\n        if lru_size is None or lru_size == 0:\n            self.init_classic_cache()\n        else:\n            self.init_lru_cache(lru_size)\n        self.all = [self.outputs, self.ui, self.objects]\n\n    # Useful for those with ample RAM/VRAM -- allows experimenting without\n    # blowing away the cache every time\n    def init_lru_cache(self, cache_size):\n        self.outputs = LRUCache(CacheKeySetInputSignature, max_size=cache_size)\n        self.ui = LRUCache(CacheKeySetInputSignature, max_size=cache_size)\n        self.objects = HierarchicalCache(CacheKeySetID)\n\n    # Performs like the old cache -- dump data ASAP\n    def init_classic_cache(self):\n        self.outputs = HierarchicalCache(CacheKeySetInputSignature)\n        self.ui = HierarchicalCache(CacheKeySetInputSignature)\n        self.objects = HierarchicalCache(CacheKeySetID)\n\n    def recursive_debug_dump(self):\n        result = {\n            \"outputs\": self.outputs.recursive_debug_dump(),\n            \"ui\": self.ui.recursive_debug_dump(),\n        }\n        return result\n\ndef get_input_data(inputs, class_def, unique_id, outputs=None, dynprompt=None, extra_data={}):\n    valid_inputs = class_def.INPUT_TYPES()\n    input_data_all = {}\n    missing_keys = {}\n    for x in inputs:\n        input_data = inputs[x]\n        input_type, input_category, input_info = get_input_info(class_def, x, valid_inputs)\n        def mark_missing():\n            missing_keys[x] = True\n            input_data_all[x] = (None,)\n        if is_link(input_data) and (not input_info or not input_info.get(\"rawLink\", False)):\n            input_unique_id = input_data[0]\n            output_index = input_data[1]\n            if outputs is None:\n                mark_missing()\n                continue # This might be a lazily-evaluated input\n            cached_output = outputs.get(input_unique_id)\n            if cached_output is None:\n                mark_missing()\n                continue\n            if output_index >= len(cached_output):\n                mark_missing()\n                continue\n            obj = cached_output[output_index]\n            input_data_all[x] = obj\n        elif input_category is not None:\n            input_data_all[x] = [input_data]\n\n    if \"hidden\" in valid_inputs:\n        h = valid_inputs[\"hidden\"]\n        for x in h:\n            if h[x] == \"PROMPT\":\n                input_data_all[x] = [dynprompt.get_original_prompt() if dynprompt is not None else {}]\n            if h[x] == \"DYNPROMPT\":\n                input_data_all[x] = [dynprompt]\n            if h[x] == \"EXTRA_PNGINFO\":\n                input_data_all[x] = [extra_data.get('extra_pnginfo', None)]\n            if h[x] == \"UNIQUE_ID\":\n                input_data_all[x] = [unique_id]\n    return input_data_all, missing_keys\n\nmap_node_over_list = None #Don't hook this please\n\ndef _map_node_over_list(obj, input_data_all, func, allow_interrupt=False, execution_block_cb=None, pre_execute_cb=None):\n    # check if node wants the lists\n    input_is_list = getattr(obj, \"INPUT_IS_LIST\", False)\n\n    if len(input_data_all) == 0:\n        max_len_input = 0\n    else:\n        max_len_input = max(len(x) for x in input_data_all.values())\n\n    # get a slice of inputs, repeat last input when list isn't long enough\n    def slice_dict(d, i):\n        return {k: v[i if len(v) > i else -1] for k, v in d.items()}\n\n    results = []\n    def process_inputs(inputs, index=None, input_is_list=False):\n        if allow_interrupt:\n            nodes.before_node_execution()\n        execution_block = None\n        for k, v in inputs.items():\n            if input_is_list:\n                for e in v:\n                    if isinstance(e, ExecutionBlocker):\n                        v = e\n                        break\n            if isinstance(v, ExecutionBlocker):\n                execution_block = execution_block_cb(v) if execution_block_cb else v\n                break\n        if execution_block is None:\n            if pre_execute_cb is not None and index is not None:\n                pre_execute_cb(index)\n            results.append(getattr(obj, func)(**inputs))\n        else:\n            results.append(execution_block)\n\n    if input_is_list:\n        process_inputs(input_data_all, 0, input_is_list=input_is_list)\n    elif max_len_input == 0:\n        process_inputs({})\n    else:\n        for i in range(max_len_input):\n            input_dict = slice_dict(input_data_all, i)\n            process_inputs(input_dict, i)\n    return results\n\ndef merge_result_data(results, obj):\n    # check which outputs need concatenating\n    output = []\n    output_is_list = [False] * len(results[0])\n    if hasattr(obj, \"OUTPUT_IS_LIST\"):\n        output_is_list = obj.OUTPUT_IS_LIST\n\n    # merge node execution results\n    for i, is_list in zip(range(len(results[0])), output_is_list):\n        if is_list:\n            value = []\n            for o in results:\n                if isinstance(o[i], ExecutionBlocker):\n                    value.append(o[i])\n                else:\n                    value.extend(o[i])\n            output.append(value)\n        else:\n            output.append([o[i] for o in results])\n    return output\n\ndef get_output_data(obj, input_data_all, execution_block_cb=None, pre_execute_cb=None):\n    results = []\n    uis = []\n    subgraph_results = []\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n    has_subgraph = False\n    for i in range(len(return_values)):\n        r = return_values[i]\n        if isinstance(r, dict):\n            if 'ui' in r:\n                uis.append(r['ui'])\n            if 'expand' in r:\n                # Perform an expansion, but do not append results\n                has_subgraph = True\n                new_graph = r['expand']\n                result = r.get(\"result\", None)\n                if isinstance(result, ExecutionBlocker):\n                    result = tuple([result] * len(obj.RETURN_TYPES))\n                subgraph_results.append((new_graph, result))\n            elif 'result' in r:\n                result = r.get(\"result\", None)\n                if isinstance(result, ExecutionBlocker):\n                    result = tuple([result] * len(obj.RETURN_TYPES))\n                results.append(result)\n                subgraph_results.append((None, result))\n        else:\n            if isinstance(r, ExecutionBlocker):\n                r = tuple([r] * len(obj.RETURN_TYPES))\n            results.append(r)\n            subgraph_results.append((None, r))\n\n    if has_subgraph:\n        output = subgraph_results\n    elif len(results) > 0:\n        output = merge_result_data(results, obj)\n    else:\n        output = []\n    ui = dict()\n    if len(uis) > 0:\n        ui = {k: [y for x in uis for y in x[k]] for k in uis[0].keys()}\n    return output, ui, has_subgraph\n\ndef format_value(x):\n    if x is None:\n        return None\n    elif isinstance(x, (int, float, bool, str)):\n        return x\n    else:\n        return str(x)\n\ndef execute(server, dynprompt, caches, current_item, extra_data, executed, prompt_id, execution_list, pending_subgraph_results):\n    unique_id = current_item\n    real_node_id = dynprompt.get_real_node_id(unique_id)\n    display_node_id = dynprompt.get_display_node_id(unique_id)\n    parent_node_id = dynprompt.get_parent_node_id(unique_id)\n    inputs = dynprompt.get_node(unique_id)['inputs']\n    class_type = dynprompt.get_node(unique_id)['class_type']\n    class_def = nodes.NODE_CLASS_MAPPINGS[class_type]\n    if caches.outputs.get(unique_id) is not None:\n        if server.client_id is not None:\n            cached_output = caches.ui.get(unique_id) or {}\n            server.send_sync(\"executed\", { \"node\": unique_id, \"display_node\": display_node_id, \"output\": cached_output.get(\"output\",None), \"prompt_id\": prompt_id }, server.client_id)\n        return (ExecutionResult.SUCCESS, None, None)\n\n    input_data_all = None\n    try:\n        if unique_id in pending_subgraph_results:\n            cached_results = pending_subgraph_results[unique_id]\n            resolved_outputs = []\n            for is_subgraph, result in cached_results:\n                if not is_subgraph:\n                    resolved_outputs.append(result)\n                else:\n                    resolved_output = []\n                    for r in result:\n                        if is_link(r):\n                            source_node, source_output = r[0], r[1]\n                            node_output = caches.outputs.get(source_node)[source_output]\n                            for o in node_output:\n                                resolved_output.append(o)\n\n                        else:\n                            resolved_output.append(r)\n                    resolved_outputs.append(tuple(resolved_output))\n            output_data = merge_result_data(resolved_outputs, class_def)\n            output_ui = []\n            has_subgraph = False\n        else:\n            input_data_all, missing_keys = get_input_data(inputs, class_def, unique_id, caches.outputs, dynprompt, extra_data)\n            if server.client_id is not None:\n                server.last_node_id = display_node_id\n                server.send_sync(\"executing\", { \"node\": unique_id, \"display_node\": display_node_id, \"prompt_id\": prompt_id }, server.client_id)\n\n            obj = caches.objects.get(unique_id)\n            if obj is None:\n                obj = class_def()\n                caches.objects.set(unique_id, obj)\n\n            if hasattr(obj, \"check_lazy_status\"):\n                required_inputs = _map_node_over_list(obj, input_data_all, \"check_lazy_status\", allow_interrupt=True)\n                required_inputs = set(sum([r for r in required_inputs if isinstance(r,list)], []))\n                required_inputs = [x for x in required_inputs if isinstance(x,str) and (\n                    x not in input_data_all or x in missing_keys\n                )]\n                if len(required_inputs) > 0:\n                    for i in required_inputs:\n                        execution_list.make_input_strong_link(unique_id, i)\n                    return (ExecutionResult.PENDING, None, None)\n\n            def execution_block_cb(block):\n                if block.message is not None:\n                    mes = {\n                        \"prompt_id\": prompt_id,\n                        \"node_id\": unique_id,\n                        \"node_type\": class_type,\n                        \"executed\": list(executed),\n\n                        \"exception_message\": f\"Execution Blocked: {block.message}\",\n                        \"exception_type\": \"ExecutionBlocked\",\n                        \"traceback\": [],\n                        \"current_inputs\": [],\n                        \"current_outputs\": [],\n                    }\n                    server.send_sync(\"execution_error\", mes, server.client_id)\n                    return ExecutionBlocker(None)\n                else:\n                    return block\n            def pre_execute_cb(call_index):\n                GraphBuilder.set_default_prefix(unique_id, call_index, 0)\n            output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n        if len(output_ui) > 0:\n            caches.ui.set(unique_id, {\n                \"meta\": {\n                    \"node_id\": unique_id,\n                    \"display_node\": display_node_id,\n                    \"parent_node\": parent_node_id,\n                    \"real_node_id\": real_node_id,\n                },\n                \"output\": output_ui\n            })\n            if server.client_id is not None:\n                server.send_sync(\"executed\", { \"node\": unique_id, \"display_node\": display_node_id, \"output\": output_ui, \"prompt_id\": prompt_id }, server.client_id)\n        if has_subgraph:\n            cached_outputs = []\n            new_node_ids = []\n            new_output_ids = []\n            new_output_links = []\n            for i in range(len(output_data)):\n                new_graph, node_outputs = output_data[i]\n                if new_graph is None:\n                    cached_outputs.append((False, node_outputs))\n                else:\n                    # Check for conflicts\n                    for node_id in new_graph.keys():\n                        if dynprompt.has_node(node_id):\n                            raise DuplicateNodeError(f\"Attempt to add duplicate node {node_id}. Ensure node ids are unique and deterministic or use graph_utils.GraphBuilder.\")\n                    for node_id, node_info in new_graph.items():\n                        new_node_ids.append(node_id)\n                        display_id = node_info.get(\"override_display_id\", unique_id)\n                        dynprompt.add_ephemeral_node(node_id, node_info, unique_id, display_id)\n                        # Figure out if the newly created node is an output node\n                        class_type = node_info[\"class_type\"]\n                        class_def = nodes.NODE_CLASS_MAPPINGS[class_type]\n                        if hasattr(class_def, 'OUTPUT_NODE') and class_def.OUTPUT_NODE == True:\n                            new_output_ids.append(node_id)\n                    for i in range(len(node_outputs)):\n                        if is_link(node_outputs[i]):\n                            from_node_id, from_socket = node_outputs[i][0], node_outputs[i][1]\n                            new_output_links.append((from_node_id, from_socket))\n                    cached_outputs.append((True, node_outputs))\n            new_node_ids = set(new_node_ids)\n            for cache in caches.all:\n                cache.ensure_subcache_for(unique_id, new_node_ids).clean_unused()\n            for node_id in new_output_ids:\n                execution_list.add_node(node_id)\n            for link in new_output_links:\n                execution_list.add_strong_link(link[0], link[1], unique_id)\n            pending_subgraph_results[unique_id] = cached_outputs\n            return (ExecutionResult.PENDING, None, None)\n        caches.outputs.set(unique_id, output_data)\n    except comfy.model_management.InterruptProcessingException as iex:\n        logging.info(\"Processing interrupted\")\n\n        # skip formatting inputs/outputs\n        error_details = {\n            \"node_id\": real_node_id,\n        }\n\n        return (ExecutionResult.FAILURE, error_details, iex)\n    except Exception as ex:\n        typ, _, tb = sys.exc_info()\n        exception_type = full_type_name(typ)\n        input_data_formatted = {}\n        if input_data_all is not None:\n            input_data_formatted = {}\n            for name, inputs in input_data_all.items():\n                input_data_formatted[name] = [format_value(x) for x in inputs]\n\n        logging.error(f\"!!! Exception during processing !!! {ex}\")\n        logging.error(traceback.format_exc())\n\n        error_details = {\n            \"node_id\": real_node_id,\n            \"exception_message\": str(ex),\n            \"exception_type\": exception_type,\n            \"traceback\": traceback.format_tb(tb),\n            \"current_inputs\": input_data_formatted\n        }\n        if isinstance(ex, comfy.model_management.OOM_EXCEPTION):\n            logging.error(\"Got an OOM, unloading all loaded models.\")\n            comfy.model_management.unload_all_models()\n\n        return (ExecutionResult.FAILURE, error_details, ex)\n\n    executed.add(unique_id)\n\n    return (ExecutionResult.SUCCESS, None, None)\n\nclass PromptExecutor:\n    def __init__(self, server, lru_size=None):\n        self.lru_size = lru_size\n        self.server = server\n        self.reset()\n\n    def reset(self):\n        self.caches = CacheSet(self.lru_size)\n        self.status_messages = []\n        self.success = True\n\n    def add_message(self, event, data: dict, broadcast: bool):\n        data = {\n            **data,\n            \"timestamp\": int(time.time() * 1000),\n        }\n        self.status_messages.append((event, data))\n        if self.server.client_id is not None or broadcast:\n            self.server.send_sync(event, data, self.server.client_id)\n\n    def handle_execution_error(self, prompt_id, prompt, current_outputs, executed, error, ex):\n        node_id = error[\"node_id\"]\n        class_type = prompt[node_id][\"class_type\"]\n\n        # First, send back the status to the frontend depending\n        # on the exception type\n        if isinstance(ex, comfy.model_management.InterruptProcessingException):\n            mes = {\n                \"prompt_id\": prompt_id,\n                \"node_id\": node_id,\n                \"node_type\": class_type,\n                \"executed\": list(executed),\n            }\n            self.add_message(\"execution_interrupted\", mes, broadcast=True)\n        else:\n            mes = {\n                \"prompt_id\": prompt_id,\n                \"node_id\": node_id,\n                \"node_type\": class_type,\n                \"executed\": list(executed),\n                \"exception_message\": error[\"exception_message\"],\n                \"exception_type\": error[\"exception_type\"],\n                \"traceback\": error[\"traceback\"],\n                \"current_inputs\": error[\"current_inputs\"],\n                \"current_outputs\": list(current_outputs),\n            }\n            self.add_message(\"execution_error\", mes, broadcast=False)\n\n    def execute(self, prompt, prompt_id, extra_data={}, execute_outputs=[]):\n        nodes.interrupt_processing(False)\n\n        if \"client_id\" in extra_data:\n            self.server.client_id = extra_data[\"client_id\"]\n        else:\n            self.server.client_id = None\n\n        self.status_messages = []\n        self.add_message(\"execution_start\", { \"prompt_id\": prompt_id}, broadcast=False)\n\n        with torch.inference_mode():\n            dynamic_prompt = DynamicPrompt(prompt)\n            is_changed_cache = IsChangedCache(dynamic_prompt, self.caches.outputs)\n            for cache in self.caches.all:\n                cache.set_prompt(dynamic_prompt, prompt.keys(), is_changed_cache)\n                cache.clean_unused()\n\n            cached_nodes = []\n            for node_id in prompt:\n                if self.caches.outputs.get(node_id) is not None:\n                    cached_nodes.append(node_id)\n\n            comfy.model_management.cleanup_models_gc()\n            self.add_message(\"execution_cached\",\n                          { \"nodes\": cached_nodes, \"prompt_id\": prompt_id},\n                          broadcast=False)\n            pending_subgraph_results = {}\n            executed = set()\n            execution_list = ExecutionList(dynamic_prompt, self.caches.outputs)\n            current_outputs = self.caches.outputs.all_node_ids()\n            for node_id in list(execute_outputs):\n                execution_list.add_node(node_id)\n\n            while not execution_list.is_empty():\n                node_id, error, ex = execution_list.stage_node_execution()\n                if error is not None:\n                    self.handle_execution_error(prompt_id, dynamic_prompt.original_prompt, current_outputs, executed, error, ex)\n                    break\n\n                result, error, ex = execute(self.server, dynamic_prompt, self.caches, node_id, extra_data, executed, prompt_id, execution_list, pending_subgraph_results)\n                self.success = result != ExecutionResult.FAILURE\n                if result == ExecutionResult.FAILURE:\n                    self.handle_execution_error(prompt_id, dynamic_prompt.original_prompt, current_outputs, executed, error, ex)\n                    break\n                elif result == ExecutionResult.PENDING:\n                    execution_list.unstage_node_execution()\n                else: # result == ExecutionResult.SUCCESS:\n                    execution_list.complete_node_execution()\n            else:\n                # Only execute when the while-loop ends without break\n                self.add_message(\"execution_success\", { \"prompt_id\": prompt_id }, broadcast=False)\n\n            ui_outputs = {}\n            meta_outputs = {}\n            all_node_ids = self.caches.ui.all_node_ids()\n            for node_id in all_node_ids:\n                ui_info = self.caches.ui.get(node_id)\n                if ui_info is not None:\n                    ui_outputs[node_id] = ui_info[\"output\"]\n                    meta_outputs[node_id] = ui_info[\"meta\"]\n            self.history_result = {\n                \"outputs\": ui_outputs,\n                \"meta\": meta_outputs,\n            }\n            self.server.last_node_id = None\n            if comfy.model_management.DISABLE_SMART_MEMORY:\n                comfy.model_management.unload_all_models()\n\n\ndef validate_inputs(prompt, item, validated):\n    unique_id = item\n    if unique_id in validated:\n        return validated[unique_id]\n\n    inputs = prompt[unique_id]['inputs']\n    class_type = prompt[unique_id]['class_type']\n    obj_class = nodes.NODE_CLASS_MAPPINGS[class_type]\n\n    class_inputs = obj_class.INPUT_TYPES()\n    valid_inputs = set(class_inputs.get('required',{})).union(set(class_inputs.get('optional',{})))\n\n    errors = []\n    valid = True\n\n    validate_function_inputs = []\n    validate_has_kwargs = False\n    if hasattr(obj_class, \"VALIDATE_INPUTS\"):\n        argspec = inspect.getfullargspec(obj_class.VALIDATE_INPUTS)\n        validate_function_inputs = argspec.args\n        validate_has_kwargs = argspec.varkw is not None\n    received_types = {}\n\n    for x in valid_inputs:\n        type_input, input_category, extra_info = get_input_info(obj_class, x, class_inputs)\n        assert extra_info is not None\n        if x not in inputs:\n            if input_category == \"required\":\n                error = {\n                    \"type\": \"required_input_missing\",\n                    \"message\": \"Required input is missing\",\n                    \"details\": f\"{x}\",\n                    \"extra_info\": {\n                        \"input_name\": x\n                    }\n                }\n                errors.append(error)\n            continue\n\n        val = inputs[x]\n        info = (type_input, extra_info)\n        if isinstance(val, list):\n            if len(val) != 2:\n                error = {\n                    \"type\": \"bad_linked_input\",\n                    \"message\": \"Bad linked input, must be a length-2 list of [node_id, slot_index]\",\n                    \"details\": f\"{x}\",\n                    \"extra_info\": {\n                        \"input_name\": x,\n                        \"input_config\": info,\n                        \"received_value\": val\n                    }\n                }\n                errors.append(error)\n                continue\n\n            o_id = val[0]\n            o_class_type = prompt[o_id]['class_type']\n            r = nodes.NODE_CLASS_MAPPINGS[o_class_type].RETURN_TYPES\n            received_type = r[val[1]]\n            received_types[x] = received_type\n            if 'input_types' not in validate_function_inputs and not validate_node_input(received_type, type_input):\n                details = f\"{x}, received_type({received_type}) mismatch input_type({type_input})\"\n                error = {\n                    \"type\": \"return_type_mismatch\",\n                    \"message\": \"Return type mismatch between linked nodes\",\n                    \"details\": details,\n                    \"extra_info\": {\n                        \"input_name\": x,\n                        \"input_config\": info,\n                        \"received_type\": received_type,\n                        \"linked_node\": val\n                    }\n                }\n                errors.append(error)\n                continue\n            try:\n                r = validate_inputs(prompt, o_id, validated)\n                if r[0] is False:\n                    # `r` will be set in `validated[o_id]` already\n                    valid = False\n                    continue\n            except Exception as ex:\n                typ, _, tb = sys.exc_info()\n                valid = False\n                exception_type = full_type_name(typ)\n                reasons = [{\n                    \"type\": \"exception_during_inner_validation\",\n                    \"message\": \"Exception when validating inner node\",\n                    \"details\": str(ex),\n                    \"extra_info\": {\n                        \"input_name\": x,\n                        \"input_config\": info,\n                        \"exception_message\": str(ex),\n                        \"exception_type\": exception_type,\n                        \"traceback\": traceback.format_tb(tb),\n                        \"linked_node\": val\n                    }\n                }]\n                validated[o_id] = (False, reasons, o_id)\n                continue\n        else:\n            try:\n                if type_input == \"INT\":\n                    val = int(val)\n                    inputs[x] = val\n                if type_input == \"FLOAT\":\n                    val = float(val)\n                    inputs[x] = val\n                if type_input == \"STRING\":\n                    val = str(val)\n                    inputs[x] = val\n                if type_input == \"BOOLEAN\":\n                    val = bool(val)\n                    inputs[x] = val\n            except Exception as ex:\n                error = {\n                    \"type\": \"invalid_input_type\",\n                    \"message\": f\"Failed to convert an input value to a {type_input} value\",\n                    \"details\": f\"{x}, {val}, {ex}\",\n                    \"extra_info\": {\n                        \"input_name\": x,\n                        \"input_config\": info,\n                        \"received_value\": val,\n                        \"exception_message\": str(ex)\n                    }\n                }\n                errors.append(error)\n                continue\n\n            if x not in validate_function_inputs and not validate_has_kwargs:\n                if \"min\" in extra_info and val < extra_info[\"min\"]:\n                    error = {\n                        \"type\": \"value_smaller_than_min\",\n                        \"message\": \"Value {} smaller than min of {}\".format(val, extra_info[\"min\"]),\n                        \"details\": f\"{x}\",\n                        \"extra_info\": {\n                            \"input_name\": x,\n                            \"input_config\": info,\n                            \"received_value\": val,\n                        }\n                    }\n                    errors.append(error)\n                    continue\n                if \"max\" in extra_info and val > extra_info[\"max\"]:\n                    error = {\n                        \"type\": \"value_bigger_than_max\",\n                        \"message\": \"Value {} bigger than max of {}\".format(val, extra_info[\"max\"]),\n                        \"details\": f\"{x}\",\n                        \"extra_info\": {\n                            \"input_name\": x,\n                            \"input_config\": info,\n                            \"received_value\": val,\n                        }\n                    }\n                    errors.append(error)\n                    continue\n\n                if isinstance(type_input, list):\n                    if val not in type_input:\n                        input_config = info\n                        list_info = \"\"\n\n                        # Don't send back gigantic lists like if they're lots of\n                        # scanned model filepaths\n                        if len(type_input) > 20:\n                            list_info = f\"(list of length {len(type_input)})\"\n                            input_config = None\n                        else:\n                            list_info = str(type_input)\n\n                        error = {\n                            \"type\": \"value_not_in_list\",\n                            \"message\": \"Value not in list\",\n                            \"details\": f\"{x}: '{val}' not in {list_info}\",\n                            \"extra_info\": {\n                                \"input_name\": x,\n                                \"input_config\": input_config,\n                                \"received_value\": val,\n                            }\n                        }\n                        errors.append(error)\n                        continue\n\n    if len(validate_function_inputs) > 0 or validate_has_kwargs:\n        input_data_all, _ = get_input_data(inputs, obj_class, unique_id)\n        input_filtered = {}\n        for x in input_data_all:\n            if x in validate_function_inputs or validate_has_kwargs:\n                input_filtered[x] = input_data_all[x]\n        if 'input_types' in validate_function_inputs:\n            input_filtered['input_types'] = [received_types]\n\n        #ret = obj_class.VALIDATE_INPUTS(**input_filtered)\n        ret = _map_node_over_list(obj_class, input_filtered, \"VALIDATE_INPUTS\")\n        for x in input_filtered:\n            for i, r in enumerate(ret):\n                if r is not True and not isinstance(r, ExecutionBlocker):\n                    details = f\"{x}\"\n                    if r is not False:\n                        details += f\" - {str(r)}\"\n\n                    error = {\n                        \"type\": \"custom_validation_failed\",\n                        \"message\": \"Custom validation failed for node\",\n                        \"details\": details,\n                        \"extra_info\": {\n                            \"input_name\": x,\n                        }\n                    }\n                    errors.append(error)\n                    continue\n\n    if len(errors) > 0 or valid is not True:\n        ret = (False, errors, unique_id)\n    else:\n        ret = (True, [], unique_id)\n\n    validated[unique_id] = ret\n    return ret\n\ndef full_type_name(klass):\n    module = klass.__module__\n    if module == 'builtins':\n        return klass.__qualname__\n    return module + '.' + klass.__qualname__\n\ndef validate_prompt(prompt):\n    outputs = set()\n    for x in prompt:\n        if 'class_type' not in prompt[x]:\n            error = {\n                \"type\": \"invalid_prompt\",\n                \"message\": \"Cannot execute because a node is missing the class_type property.\",\n                \"details\": f\"Node ID '#{x}'\",\n                \"extra_info\": {}\n            }\n            return (False, error, [], [])\n\n        class_type = prompt[x]['class_type']\n        class_ = nodes.NODE_CLASS_MAPPINGS.get(class_type, None)\n        if class_ is None:\n            error = {\n                \"type\": \"invalid_prompt\",\n                \"message\": f\"Cannot execute because node {class_type} does not exist.\",\n                \"details\": f\"Node ID '#{x}'\",\n                \"extra_info\": {}\n            }\n            return (False, error, [], [])\n\n        if hasattr(class_, 'OUTPUT_NODE') and class_.OUTPUT_NODE is True:\n            outputs.add(x)\n\n    if len(outputs) == 0:\n        error = {\n            \"type\": \"prompt_no_outputs\",\n            \"message\": \"Prompt has no outputs\",\n            \"details\": \"\",\n            \"extra_info\": {}\n        }\n        return (False, error, [], [])\n\n    good_outputs = set()\n    errors = []\n    node_errors = {}\n    validated = {}\n    for o in outputs:\n        valid = False\n        reasons = []\n        try:\n            m = validate_inputs(prompt, o, validated)\n            valid = m[0]\n            reasons = m[1]\n        except Exception as ex:\n            typ, _, tb = sys.exc_info()\n            valid = False\n            exception_type = full_type_name(typ)\n            reasons = [{\n                \"type\": \"exception_during_validation\",\n                \"message\": \"Exception when validating node\",\n                \"details\": str(ex),\n                \"extra_info\": {\n                    \"exception_type\": exception_type,\n                    \"traceback\": traceback.format_tb(tb)\n                }\n            }]\n            validated[o] = (False, reasons, o)\n\n        if valid is True:\n            good_outputs.add(o)\n        else:\n            logging.error(f\"Failed to validate prompt for output {o}:\")\n            if len(reasons) > 0:\n                logging.error(\"* (prompt):\")\n                for reason in reasons:\n                    logging.error(f\"  - {reason['message']}: {reason['details']}\")\n            errors += [(o, reasons)]\n            for node_id, result in validated.items():\n                valid = result[0]\n                reasons = result[1]\n                # If a node upstream has errors, the nodes downstream will also\n                # be reported as invalid, but there will be no errors attached.\n                # So don't return those nodes as having errors in the response.\n                if valid is not True and len(reasons) > 0:\n                    if node_id not in node_errors:\n                        class_type = prompt[node_id]['class_type']\n                        node_errors[node_id] = {\n                            \"errors\": reasons,\n                            \"dependent_outputs\": [],\n                            \"class_type\": class_type\n                        }\n                        logging.error(f\"* {class_type} {node_id}:\")\n                        for reason in reasons:\n                            logging.error(f\"  - {reason['message']}: {reason['details']}\")\n                    node_errors[node_id][\"dependent_outputs\"].append(o)\n            logging.error(\"Output will be ignored\")\n\n    if len(good_outputs) == 0:\n        errors_list = []\n        for o, errors in errors:\n            for error in errors:\n                errors_list.append(f\"{error['message']}: {error['details']}\")\n        errors_list = \"\\n\".join(errors_list)\n\n        error = {\n            \"type\": \"prompt_outputs_failed_validation\",\n            \"message\": \"Prompt outputs failed validation\",\n            \"details\": errors_list,\n            \"extra_info\": {}\n        }\n\n        return (False, error, list(good_outputs), node_errors)\n\n    return (True, None, list(good_outputs), node_errors)\n\nMAXIMUM_HISTORY_SIZE = 10000\n\nclass PromptQueue:\n    def __init__(self, server):\n        self.server = server\n        self.mutex = threading.RLock()\n        self.not_empty = threading.Condition(self.mutex)\n        self.task_counter = 0\n        self.queue = []\n        self.currently_running = {}\n        self.history = {}\n        self.flags = {}\n        server.prompt_queue = self\n\n    def put(self, item):\n        with self.mutex:\n            heapq.heappush(self.queue, item)\n            self.server.queue_updated()\n            self.not_empty.notify()\n\n    def get(self, timeout=None):\n        with self.not_empty:\n            while len(self.queue) == 0:\n                self.not_empty.wait(timeout=timeout)\n                if timeout is not None and len(self.queue) == 0:\n                    return None\n            item = heapq.heappop(self.queue)\n            i = self.task_counter\n            self.currently_running[i] = copy.deepcopy(item)\n            self.task_counter += 1\n            self.server.queue_updated()\n            return (item, i)\n\n    class ExecutionStatus(NamedTuple):\n        status_str: Literal['success', 'error']\n        completed: bool\n        messages: List[str]\n\n    def task_done(self, item_id, history_result,\n                  status: Optional['PromptQueue.ExecutionStatus']):\n        with self.mutex:\n            prompt = self.currently_running.pop(item_id)\n            if len(self.history) > MAXIMUM_HISTORY_SIZE:\n                self.history.pop(next(iter(self.history)))\n\n            status_dict: Optional[dict] = None\n            if status is not None:\n                status_dict = copy.deepcopy(status._asdict())\n\n            self.history[prompt[1]] = {\n                \"prompt\": prompt,\n                \"outputs\": {},\n                'status': status_dict,\n            }\n            self.history[prompt[1]].update(history_result)\n            self.server.queue_updated()\n\n    def get_current_queue(self):\n        with self.mutex:\n            out = []\n            for x in self.currently_running.values():\n                out += [x]\n            return (out, copy.deepcopy(self.queue))\n\n    def get_tasks_remaining(self):\n        with self.mutex:\n            return len(self.queue) + len(self.currently_running)\n\n    def wipe_queue(self):\n        with self.mutex:\n            self.queue = []\n            self.server.queue_updated()\n\n    def delete_queue_item(self, function):\n        with self.mutex:\n            for x in range(len(self.queue)):\n                if function(self.queue[x]):\n                    if len(self.queue) == 1:\n                        self.wipe_queue()\n                    else:\n                        self.queue.pop(x)\n                        heapq.heapify(self.queue)\n                    self.server.queue_updated()\n                    return True\n        return False\n\n    def get_history(self, prompt_id=None, max_items=None, offset=-1):\n        with self.mutex:\n            if prompt_id is None:\n                out = {}\n                i = 0\n                if offset < 0 and max_items is not None:\n                    offset = len(self.history) - max_items\n                for k in self.history:\n                    if i >= offset:\n                        out[k] = self.history[k]\n                        if max_items is not None and len(out) >= max_items:\n                            break\n                    i += 1\n                return out\n            elif prompt_id in self.history:\n                return {prompt_id: copy.deepcopy(self.history[prompt_id])}\n            else:\n                return {}\n\n    def wipe_history(self):\n        with self.mutex:\n            self.history = {}\n\n    def delete_history_item(self, id_to_delete):\n        with self.mutex:\n            self.history.pop(id_to_delete, None)\n\n    def set_flag(self, name, data):\n        with self.mutex:\n            self.flags[name] = data\n            self.not_empty.notify()\n\n    def get_flags(self, reset=True):\n        with self.mutex:\n            if reset:\n                ret = self.flags\n                self.flags = {}\n                return ret\n            else:\n                return self.flags.copy()\n"
        },
        {
          "name": "extra_model_paths.yaml.example",
          "type": "blob",
          "size": 1.45,
          "content": "#Rename this to extra_model_paths.yaml and ComfyUI will load it\n\n\n#config for a1111 ui\n#all you have to do is change the base_path to where yours is installed\na111:\n    base_path: path/to/stable-diffusion-webui/\n\n    checkpoints: models/Stable-diffusion\n    configs: models/Stable-diffusion\n    vae: models/VAE\n    loras: |\n         models/Lora\n         models/LyCORIS\n    upscale_models: |\n                  models/ESRGAN\n                  models/RealESRGAN\n                  models/SwinIR\n    embeddings: embeddings\n    hypernetworks: models/hypernetworks\n    controlnet: models/ControlNet\n\n#config for comfyui\n#your base path should be either an existing comfy install or a central folder where you store all of your models, loras, etc.\n\n#comfyui:\n#     base_path: path/to/comfyui/\n#     # You can use is_default to mark that these folders should be listed first, and used as the default dirs for eg downloads\n#     #is_default: true\n#     checkpoints: models/checkpoints/\n#     clip: models/clip/\n#     clip_vision: models/clip_vision/\n#     configs: models/configs/\n#     controlnet: models/controlnet/\n#     diffusion_models: |\n#                  models/diffusion_models\n#                  models/unet\n#     embeddings: models/embeddings/\n#     loras: models/loras/\n#     upscale_models: models/upscale_models/\n#     vae: models/vae/\n\n#other_ui:\n#    base_path: path/to/ui\n#    checkpoints: models/checkpoints\n#    gligen: models/gligen\n#    custom_nodes: path/custom_nodes\n"
        },
        {
          "name": "fix_torch.py",
          "type": "blob",
          "size": 0.92,
          "content": "import importlib.util\nimport shutil\nimport os\nimport ctypes\nimport logging\n\n\ndef fix_pytorch_libomp():\n    \"\"\"\n    Fix PyTorch libomp DLL issue on Windows by copying the correct DLL file if needed.\n    \"\"\"\n    torch_spec = importlib.util.find_spec(\"torch\")\n    for folder in torch_spec.submodule_search_locations:\n        lib_folder = os.path.join(folder, \"lib\")\n        test_file = os.path.join(lib_folder, \"fbgemm.dll\")\n        dest = os.path.join(lib_folder, \"libomp140.x86_64.dll\")\n        if os.path.exists(dest):\n            break\n\n        with open(test_file, \"rb\") as f:\n            contents = f.read()\n            if b\"libomp140.x86_64.dll\" not in contents:\n                break\n        try:\n            ctypes.cdll.LoadLibrary(test_file)\n        except FileNotFoundError:\n            logging.warning(\"Detected pytorch version with libomp issue, patching.\")\n            shutil.copyfile(os.path.join(lib_folder, \"libiomp5md.dll\"), dest)\n"
        },
        {
          "name": "folder_paths.py",
          "type": "blob",
          "size": 14.42,
          "content": "from __future__ import annotations\n\nimport os\nimport time\nimport mimetypes\nimport logging\nfrom typing import Literal\nfrom collections.abc import Collection\n\nsupported_pt_extensions: set[str] = {'.ckpt', '.pt', '.bin', '.pth', '.safetensors', '.pkl', '.sft'}\n\nfolder_names_and_paths: dict[str, tuple[list[str], set[str]]] = {}\n\nbase_path = os.path.dirname(os.path.realpath(__file__))\nmodels_dir = os.path.join(base_path, \"models\")\nfolder_names_and_paths[\"checkpoints\"] = ([os.path.join(models_dir, \"checkpoints\")], supported_pt_extensions)\nfolder_names_and_paths[\"configs\"] = ([os.path.join(models_dir, \"configs\")], [\".yaml\"])\n\nfolder_names_and_paths[\"loras\"] = ([os.path.join(models_dir, \"loras\")], supported_pt_extensions)\nfolder_names_and_paths[\"vae\"] = ([os.path.join(models_dir, \"vae\")], supported_pt_extensions)\nfolder_names_and_paths[\"text_encoders\"] = ([os.path.join(models_dir, \"text_encoders\"), os.path.join(models_dir, \"clip\")], supported_pt_extensions)\nfolder_names_and_paths[\"diffusion_models\"] = ([os.path.join(models_dir, \"unet\"), os.path.join(models_dir, \"diffusion_models\")], supported_pt_extensions)\nfolder_names_and_paths[\"clip_vision\"] = ([os.path.join(models_dir, \"clip_vision\")], supported_pt_extensions)\nfolder_names_and_paths[\"style_models\"] = ([os.path.join(models_dir, \"style_models\")], supported_pt_extensions)\nfolder_names_and_paths[\"embeddings\"] = ([os.path.join(models_dir, \"embeddings\")], supported_pt_extensions)\nfolder_names_and_paths[\"diffusers\"] = ([os.path.join(models_dir, \"diffusers\")], [\"folder\"])\nfolder_names_and_paths[\"vae_approx\"] = ([os.path.join(models_dir, \"vae_approx\")], supported_pt_extensions)\n\nfolder_names_and_paths[\"controlnet\"] = ([os.path.join(models_dir, \"controlnet\"), os.path.join(models_dir, \"t2i_adapter\")], supported_pt_extensions)\nfolder_names_and_paths[\"gligen\"] = ([os.path.join(models_dir, \"gligen\")], supported_pt_extensions)\n\nfolder_names_and_paths[\"upscale_models\"] = ([os.path.join(models_dir, \"upscale_models\")], supported_pt_extensions)\n\nfolder_names_and_paths[\"custom_nodes\"] = ([os.path.join(base_path, \"custom_nodes\")], set())\n\nfolder_names_and_paths[\"hypernetworks\"] = ([os.path.join(models_dir, \"hypernetworks\")], supported_pt_extensions)\n\nfolder_names_and_paths[\"photomaker\"] = ([os.path.join(models_dir, \"photomaker\")], supported_pt_extensions)\n\nfolder_names_and_paths[\"classifiers\"] = ([os.path.join(models_dir, \"classifiers\")], {\"\"})\n\noutput_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"output\")\ntemp_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"temp\")\ninput_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"input\")\nuser_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"user\")\n\nfilename_list_cache: dict[str, tuple[list[str], dict[str, float], float]] = {}\n\nclass CacheHelper:\n    \"\"\"\n    Helper class for managing file list cache data.\n    \"\"\"\n    def __init__(self):\n        self.cache: dict[str, tuple[list[str], dict[str, float], float]] = {}\n        self.active = False\n\n    def get(self, key: str, default=None) -> tuple[list[str], dict[str, float], float]:\n        if not self.active:\n            return default\n        return self.cache.get(key, default)\n\n    def set(self, key: str, value: tuple[list[str], dict[str, float], float]) -> None:\n        if self.active:\n            self.cache[key] = value\n\n    def clear(self):\n        self.cache.clear()\n\n    def __enter__(self):\n        self.active = True\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.active = False\n        self.clear()\n\ncache_helper = CacheHelper()\n\nextension_mimetypes_cache = {\n    \"webp\" : \"image\",\n}\n\ndef map_legacy(folder_name: str) -> str:\n    legacy = {\"unet\": \"diffusion_models\",\n              \"clip\": \"text_encoders\"}\n    return legacy.get(folder_name, folder_name)\n\nif not os.path.exists(input_directory):\n    try:\n        os.makedirs(input_directory)\n    except:\n        logging.error(\"Failed to create input directory\")\n\ndef set_output_directory(output_dir: str) -> None:\n    global output_directory\n    output_directory = output_dir\n\ndef set_temp_directory(temp_dir: str) -> None:\n    global temp_directory\n    temp_directory = temp_dir\n\ndef set_input_directory(input_dir: str) -> None:\n    global input_directory\n    input_directory = input_dir\n\ndef get_output_directory() -> str:\n    global output_directory\n    return output_directory\n\ndef get_temp_directory() -> str:\n    global temp_directory\n    return temp_directory\n\ndef get_input_directory() -> str:\n    global input_directory\n    return input_directory\n\ndef get_user_directory() -> str:\n    return user_directory\n\ndef set_user_directory(user_dir: str) -> None:\n    global user_directory\n    user_directory = user_dir\n\n\n#NOTE: used in http server so don't put folders that should not be accessed remotely\ndef get_directory_by_type(type_name: str) -> str | None:\n    if type_name == \"output\":\n        return get_output_directory()\n    if type_name == \"temp\":\n        return get_temp_directory()\n    if type_name == \"input\":\n        return get_input_directory()\n    return None\n\ndef filter_files_content_types(files: list[str], content_types: Literal[\"image\", \"video\", \"audio\"]) -> list[str]:\n    \"\"\"\n    Example:\n        files = os.listdir(folder_paths.get_input_directory())\n        filter_files_content_types(files, [\"image\", \"audio\", \"video\"])\n    \"\"\"\n    global extension_mimetypes_cache\n    result = []\n    for file in files:\n        extension = file.split('.')[-1]\n        if extension not in extension_mimetypes_cache:\n            mime_type, _ = mimetypes.guess_type(file, strict=False)\n            if not mime_type:\n                continue\n            content_type = mime_type.split('/')[0]\n            extension_mimetypes_cache[extension] = content_type\n        else:\n            content_type = extension_mimetypes_cache[extension]\n\n        if content_type in content_types:\n            result.append(file)\n    return result\n\n# determine base_dir rely on annotation if name is 'filename.ext [annotation]' format\n# otherwise use default_path as base_dir\ndef annotated_filepath(name: str) -> tuple[str, str | None]:\n    if name.endswith(\"[output]\"):\n        base_dir = get_output_directory()\n        name = name[:-9]\n    elif name.endswith(\"[input]\"):\n        base_dir = get_input_directory()\n        name = name[:-8]\n    elif name.endswith(\"[temp]\"):\n        base_dir = get_temp_directory()\n        name = name[:-7]\n    else:\n        return name, None\n\n    return name, base_dir\n\n\ndef get_annotated_filepath(name: str, default_dir: str | None=None) -> str:\n    name, base_dir = annotated_filepath(name)\n\n    if base_dir is None:\n        if default_dir is not None:\n            base_dir = default_dir\n        else:\n            base_dir = get_input_directory()  # fallback path\n\n    return os.path.join(base_dir, name)\n\n\ndef exists_annotated_filepath(name) -> bool:\n    name, base_dir = annotated_filepath(name)\n\n    if base_dir is None:\n        base_dir = get_input_directory()  # fallback path\n\n    filepath = os.path.join(base_dir, name)\n    return os.path.exists(filepath)\n\n\ndef add_model_folder_path(folder_name: str, full_folder_path: str, is_default: bool = False) -> None:\n    global folder_names_and_paths\n    folder_name = map_legacy(folder_name)\n    if folder_name in folder_names_and_paths:\n        paths, _exts = folder_names_and_paths[folder_name]\n        if full_folder_path in paths:\n            if is_default and paths[0] != full_folder_path:\n                # If the path to the folder is not the first in the list, move it to the beginning.\n                paths.remove(full_folder_path)\n                paths.insert(0, full_folder_path)\n        else:\n            if is_default:\n                paths.insert(0, full_folder_path)\n            else:\n                paths.append(full_folder_path)\n    else:\n        folder_names_and_paths[folder_name] = ([full_folder_path], set())\n\ndef get_folder_paths(folder_name: str) -> list[str]:\n    folder_name = map_legacy(folder_name)\n    return folder_names_and_paths[folder_name][0][:]\n\ndef recursive_search(directory: str, excluded_dir_names: list[str] | None=None) -> tuple[list[str], dict[str, float]]:\n    if not os.path.isdir(directory):\n        return [], {}\n\n    if excluded_dir_names is None:\n        excluded_dir_names = []\n\n    result = []\n    dirs = {}\n\n    # Attempt to add the initial directory to dirs with error handling\n    try:\n        dirs[directory] = os.path.getmtime(directory)\n    except FileNotFoundError:\n        logging.warning(f\"Warning: Unable to access {directory}. Skipping this path.\")\n\n    logging.debug(\"recursive file list on directory {}\".format(directory))\n    dirpath: str\n    subdirs: list[str]\n    filenames: list[str]\n\n    for dirpath, subdirs, filenames in os.walk(directory, followlinks=True, topdown=True):\n        subdirs[:] = [d for d in subdirs if d not in excluded_dir_names]\n        for file_name in filenames:\n            try:\n                relative_path = os.path.relpath(os.path.join(dirpath, file_name), directory)\n                result.append(relative_path)\n            except:\n                logging.warning(f\"Warning: Unable to access {file_name}. Skipping this file.\")\n                continue\n\n        for d in subdirs:\n            path: str = os.path.join(dirpath, d)\n            try:\n                dirs[path] = os.path.getmtime(path)\n            except FileNotFoundError:\n                logging.warning(f\"Warning: Unable to access {path}. Skipping this path.\")\n                continue\n    logging.debug(\"found {} files\".format(len(result)))\n    return result, dirs\n\ndef filter_files_extensions(files: Collection[str], extensions: Collection[str]) -> list[str]:\n    return sorted(list(filter(lambda a: os.path.splitext(a)[-1].lower() in extensions or len(extensions) == 0, files)))\n\n\n\ndef get_full_path(folder_name: str, filename: str) -> str | None:\n    global folder_names_and_paths\n    folder_name = map_legacy(folder_name)\n    if folder_name not in folder_names_and_paths:\n        return None\n    folders = folder_names_and_paths[folder_name]\n    filename = os.path.relpath(os.path.join(\"/\", filename), \"/\")\n    for x in folders[0]:\n        full_path = os.path.join(x, filename)\n        if os.path.isfile(full_path):\n            return full_path\n        elif os.path.islink(full_path):\n            logging.warning(\"WARNING path {} exists but doesn't link anywhere, skipping.\".format(full_path))\n\n    return None\n\n\ndef get_full_path_or_raise(folder_name: str, filename: str) -> str:\n    full_path = get_full_path(folder_name, filename)\n    if full_path is None:\n        raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n    return full_path\n\n\ndef get_filename_list_(folder_name: str) -> tuple[list[str], dict[str, float], float]:\n    folder_name = map_legacy(folder_name)\n    global folder_names_and_paths\n    output_list = set()\n    folders = folder_names_and_paths[folder_name]\n    output_folders = {}\n    for x in folders[0]:\n        files, folders_all = recursive_search(x, excluded_dir_names=[\".git\"])\n        output_list.update(filter_files_extensions(files, folders[1]))\n        output_folders = {**output_folders, **folders_all}\n\n    return sorted(list(output_list)), output_folders, time.perf_counter()\n\ndef cached_filename_list_(folder_name: str) -> tuple[list[str], dict[str, float], float] | None:\n    strong_cache = cache_helper.get(folder_name)\n    if strong_cache is not None:\n        return strong_cache\n\n    global filename_list_cache\n    global folder_names_and_paths\n    folder_name = map_legacy(folder_name)\n    if folder_name not in filename_list_cache:\n        return None\n    out = filename_list_cache[folder_name]\n\n    for x in out[1]:\n        time_modified = out[1][x]\n        folder = x\n        if os.path.getmtime(folder) != time_modified:\n            return None\n\n    folders = folder_names_and_paths[folder_name]\n    for x in folders[0]:\n        if os.path.isdir(x):\n            if x not in out[1]:\n                return None\n\n    return out\n\ndef get_filename_list(folder_name: str) -> list[str]:\n    folder_name = map_legacy(folder_name)\n    out = cached_filename_list_(folder_name)\n    if out is None:\n        out = get_filename_list_(folder_name)\n        global filename_list_cache\n        filename_list_cache[folder_name] = out\n    cache_helper.set(folder_name, out)\n    return list(out[0])\n\ndef get_save_image_path(filename_prefix: str, output_dir: str, image_width=0, image_height=0) -> tuple[str, str, int, str, str]:\n    def map_filename(filename: str) -> tuple[int, str]:\n        prefix_len = len(os.path.basename(filename_prefix))\n        prefix = filename[:prefix_len + 1]\n        try:\n            digits = int(filename[prefix_len + 1:].split('_')[0])\n        except:\n            digits = 0\n        return digits, prefix\n\n    def compute_vars(input: str, image_width: int, image_height: int) -> str:\n        input = input.replace(\"%width%\", str(image_width))\n        input = input.replace(\"%height%\", str(image_height))\n        now = time.localtime()\n        input = input.replace(\"%year%\", str(now.tm_year))\n        input = input.replace(\"%month%\", str(now.tm_mon).zfill(2))\n        input = input.replace(\"%day%\", str(now.tm_mday).zfill(2))\n        input = input.replace(\"%hour%\", str(now.tm_hour).zfill(2))\n        input = input.replace(\"%minute%\", str(now.tm_min).zfill(2))\n        input = input.replace(\"%second%\", str(now.tm_sec).zfill(2))\n        return input\n\n    if \"%\" in filename_prefix:\n        filename_prefix = compute_vars(filename_prefix, image_width, image_height)\n\n    subfolder = os.path.dirname(os.path.normpath(filename_prefix))\n    filename = os.path.basename(os.path.normpath(filename_prefix))\n\n    full_output_folder = os.path.join(output_dir, subfolder)\n\n    if os.path.commonpath((output_dir, os.path.abspath(full_output_folder))) != output_dir:\n        err = \"**** ERROR: Saving image outside the output folder is not allowed.\" + \\\n              \"\\n full_output_folder: \" + os.path.abspath(full_output_folder) + \\\n              \"\\n         output_dir: \" + output_dir + \\\n              \"\\n         commonpath: \" + os.path.commonpath((output_dir, os.path.abspath(full_output_folder)))\n        logging.error(err)\n        raise Exception(err)\n\n    try:\n        counter = max(filter(lambda a: os.path.normcase(a[1][:-1]) == os.path.normcase(filename) and a[1][-1] == \"_\", map(map_filename, os.listdir(full_output_folder))))[0] + 1\n    except ValueError:\n        counter = 1\n    except FileNotFoundError:\n        os.makedirs(full_output_folder, exist_ok=True)\n        counter = 1\n    return full_output_folder, filename, counter, subfolder, filename_prefix\n"
        },
        {
          "name": "input",
          "type": "tree",
          "content": null
        },
        {
          "name": "latent_preview.py",
          "type": "blob",
          "size": 4.09,
          "content": "import torch\nfrom PIL import Image\nfrom comfy.cli_args import args, LatentPreviewMethod\nfrom comfy.taesd.taesd import TAESD\nimport comfy.model_management\nimport folder_paths\nimport comfy.utils\nimport logging\n\nMAX_PREVIEW_RESOLUTION = args.preview_size\n\ndef preview_to_image(latent_image):\n        latents_ubyte = (((latent_image + 1.0) / 2.0).clamp(0, 1)  # change scale from -1..1 to 0..1\n                            .mul(0xFF)  # to 0..255\n                            ).to(device=\"cpu\", dtype=torch.uint8, non_blocking=comfy.model_management.device_supports_non_blocking(latent_image.device))\n\n        return Image.fromarray(latents_ubyte.numpy())\n\nclass LatentPreviewer:\n    def decode_latent_to_preview(self, x0):\n        pass\n\n    def decode_latent_to_preview_image(self, preview_format, x0):\n        preview_image = self.decode_latent_to_preview(x0)\n        return (\"JPEG\", preview_image, MAX_PREVIEW_RESOLUTION)\n\nclass TAESDPreviewerImpl(LatentPreviewer):\n    def __init__(self, taesd):\n        self.taesd = taesd\n\n    def decode_latent_to_preview(self, x0):\n        x_sample = self.taesd.decode(x0[:1])[0].movedim(0, 2)\n        return preview_to_image(x_sample)\n\n\nclass Latent2RGBPreviewer(LatentPreviewer):\n    def __init__(self, latent_rgb_factors, latent_rgb_factors_bias=None):\n        self.latent_rgb_factors = torch.tensor(latent_rgb_factors, device=\"cpu\").transpose(0, 1)\n        self.latent_rgb_factors_bias = None\n        if latent_rgb_factors_bias is not None:\n            self.latent_rgb_factors_bias = torch.tensor(latent_rgb_factors_bias, device=\"cpu\")\n\n    def decode_latent_to_preview(self, x0):\n        self.latent_rgb_factors = self.latent_rgb_factors.to(dtype=x0.dtype, device=x0.device)\n        if self.latent_rgb_factors_bias is not None:\n            self.latent_rgb_factors_bias = self.latent_rgb_factors_bias.to(dtype=x0.dtype, device=x0.device)\n\n        if x0.ndim == 5:\n            x0 = x0[0, :, 0]\n        else:\n            x0 = x0[0]\n\n        latent_image = torch.nn.functional.linear(x0.movedim(0, -1), self.latent_rgb_factors, bias=self.latent_rgb_factors_bias)\n        # latent_image = x0[0].permute(1, 2, 0) @ self.latent_rgb_factors\n\n        return preview_to_image(latent_image)\n\n\ndef get_previewer(device, latent_format):\n    previewer = None\n    method = args.preview_method\n    if method != LatentPreviewMethod.NoPreviews:\n        # TODO previewer methods\n        taesd_decoder_path = None\n        if latent_format.taesd_decoder_name is not None:\n            taesd_decoder_path = next(\n                (fn for fn in folder_paths.get_filename_list(\"vae_approx\")\n                    if fn.startswith(latent_format.taesd_decoder_name)),\n                \"\"\n            )\n            taesd_decoder_path = folder_paths.get_full_path(\"vae_approx\", taesd_decoder_path)\n\n        if method == LatentPreviewMethod.Auto:\n            method = LatentPreviewMethod.Latent2RGB\n\n        if method == LatentPreviewMethod.TAESD:\n            if taesd_decoder_path:\n                taesd = TAESD(None, taesd_decoder_path, latent_channels=latent_format.latent_channels).to(device)\n                previewer = TAESDPreviewerImpl(taesd)\n            else:\n                logging.warning(\"Warning: TAESD previews enabled, but could not find models/vae_approx/{}\".format(latent_format.taesd_decoder_name))\n\n        if previewer is None:\n            if latent_format.latent_rgb_factors is not None:\n                previewer = Latent2RGBPreviewer(latent_format.latent_rgb_factors, latent_format.latent_rgb_factors_bias)\n    return previewer\n\ndef prepare_callback(model, steps, x0_output_dict=None):\n    preview_format = \"JPEG\"\n    if preview_format not in [\"JPEG\", \"PNG\"]:\n        preview_format = \"JPEG\"\n\n    previewer = get_previewer(model.load_device, model.model.latent_format)\n\n    pbar = comfy.utils.ProgressBar(steps)\n    def callback(step, x0, x, total_steps):\n        if x0_output_dict is not None:\n            x0_output_dict[\"x0\"] = x0\n\n        preview_bytes = None\n        if previewer:\n            preview_bytes = previewer.decode_latent_to_preview_image(preview_format, x0)\n        pbar.update_absolute(step + 1, total_steps, preview_bytes)\n    return callback\n\n"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 11.09,
          "content": "import comfy.options\ncomfy.options.enable_args_parsing()\n\nimport os\nimport importlib.util\nimport folder_paths\nimport time\nfrom comfy.cli_args import args\nfrom app.logger import setup_logger\nimport itertools\nimport utils.extra_config\nimport logging\n\nif __name__ == \"__main__\":\n    #NOTE: These do not do anything on core ComfyUI which should already have no communication with the internet, they are for custom nodes.\n    os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n    os.environ['DO_NOT_TRACK'] = '1'\n\n\nsetup_logger(log_level=args.verbose, use_stdout=args.log_stdout)\n\ndef apply_custom_paths():\n    # extra model paths\n    extra_model_paths_config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"extra_model_paths.yaml\")\n    if os.path.isfile(extra_model_paths_config_path):\n        utils.extra_config.load_extra_path_config(extra_model_paths_config_path)\n\n    if args.extra_model_paths_config:\n        for config_path in itertools.chain(*args.extra_model_paths_config):\n            utils.extra_config.load_extra_path_config(config_path)\n\n    # --output-directory, --input-directory, --user-directory\n    if args.output_directory:\n        output_dir = os.path.abspath(args.output_directory)\n        logging.info(f\"Setting output directory to: {output_dir}\")\n        folder_paths.set_output_directory(output_dir)\n\n    # These are the default folders that checkpoints, clip and vae models will be saved to when using CheckpointSave, etc.. nodes\n    folder_paths.add_model_folder_path(\"checkpoints\", os.path.join(folder_paths.get_output_directory(), \"checkpoints\"))\n    folder_paths.add_model_folder_path(\"clip\", os.path.join(folder_paths.get_output_directory(), \"clip\"))\n    folder_paths.add_model_folder_path(\"vae\", os.path.join(folder_paths.get_output_directory(), \"vae\"))\n    folder_paths.add_model_folder_path(\"diffusion_models\",\n                                       os.path.join(folder_paths.get_output_directory(), \"diffusion_models\"))\n    folder_paths.add_model_folder_path(\"loras\", os.path.join(folder_paths.get_output_directory(), \"loras\"))\n\n    if args.input_directory:\n        input_dir = os.path.abspath(args.input_directory)\n        logging.info(f\"Setting input directory to: {input_dir}\")\n        folder_paths.set_input_directory(input_dir)\n\n    if args.user_directory:\n        user_dir = os.path.abspath(args.user_directory)\n        logging.info(f\"Setting user directory to: {user_dir}\")\n        folder_paths.set_user_directory(user_dir)\n\n\ndef execute_prestartup_script():\n    def execute_script(script_path):\n        module_name = os.path.splitext(script_path)[0]\n        try:\n            spec = importlib.util.spec_from_file_location(module_name, script_path)\n            module = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(module)\n            return True\n        except Exception as e:\n            logging.error(f\"Failed to execute startup-script: {script_path} / {e}\")\n        return False\n\n    if args.disable_all_custom_nodes:\n        return\n\n    node_paths = folder_paths.get_folder_paths(\"custom_nodes\")\n    for custom_node_path in node_paths:\n        possible_modules = os.listdir(custom_node_path)\n        node_prestartup_times = []\n\n        for possible_module in possible_modules:\n            module_path = os.path.join(custom_node_path, possible_module)\n            if os.path.isfile(module_path) or module_path.endswith(\".disabled\") or module_path == \"__pycache__\":\n                continue\n\n            script_path = os.path.join(module_path, \"prestartup_script.py\")\n            if os.path.exists(script_path):\n                time_before = time.perf_counter()\n                success = execute_script(script_path)\n                node_prestartup_times.append((time.perf_counter() - time_before, module_path, success))\n    if len(node_prestartup_times) > 0:\n        logging.info(\"\\nPrestartup times for custom nodes:\")\n        for n in sorted(node_prestartup_times):\n            if n[2]:\n                import_message = \"\"\n            else:\n                import_message = \" (PRESTARTUP FAILED)\"\n            logging.info(\"{:6.1f} seconds{}: {}\".format(n[0], import_message, n[1]))\n        logging.info(\"\")\n\napply_custom_paths()\nexecute_prestartup_script()\n\n\n# Main code\nimport asyncio\nimport shutil\nimport threading\nimport gc\n\n\nif os.name == \"nt\":\n    logging.getLogger(\"xformers\").addFilter(lambda record: 'A matching Triton is not available' not in record.getMessage())\n\nif __name__ == \"__main__\":\n    if args.cuda_device is not None:\n        os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda_device)\n        os.environ['HIP_VISIBLE_DEVICES'] = str(args.cuda_device)\n        logging.info(\"Set cuda device to: {}\".format(args.cuda_device))\n\n    if args.oneapi_device_selector is not None:\n        os.environ['ONEAPI_DEVICE_SELECTOR'] = args.oneapi_device_selector\n        logging.info(\"Set oneapi device selector to: {}\".format(args.oneapi_device_selector))\n\n    if args.deterministic:\n        if 'CUBLAS_WORKSPACE_CONFIG' not in os.environ:\n            os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n\n    import cuda_malloc\n\nif args.windows_standalone_build:\n    try:\n        from fix_torch import fix_pytorch_libomp\n        fix_pytorch_libomp()\n    except:\n        pass\n\nimport comfy.utils\n\nimport execution\nimport server\nfrom server import BinaryEventTypes\nimport nodes\nimport comfy.model_management\n\ndef cuda_malloc_warning():\n    device = comfy.model_management.get_torch_device()\n    device_name = comfy.model_management.get_torch_device_name(device)\n    cuda_malloc_warning = False\n    if \"cudaMallocAsync\" in device_name:\n        for b in cuda_malloc.blacklist:\n            if b in device_name:\n                cuda_malloc_warning = True\n        if cuda_malloc_warning:\n            logging.warning(\"\\nWARNING: this card most likely does not support cuda-malloc, if you get \\\"CUDA error\\\" please run ComfyUI with: --disable-cuda-malloc\\n\")\n\n\ndef prompt_worker(q, server_instance):\n    current_time: float = 0.0\n    e = execution.PromptExecutor(server_instance, lru_size=args.cache_lru)\n    last_gc_collect = 0\n    need_gc = False\n    gc_collect_interval = 10.0\n\n    while True:\n        timeout = 1000.0\n        if need_gc:\n            timeout = max(gc_collect_interval - (current_time - last_gc_collect), 0.0)\n\n        queue_item = q.get(timeout=timeout)\n        if queue_item is not None:\n            item, item_id = queue_item\n            execution_start_time = time.perf_counter()\n            prompt_id = item[1]\n            server_instance.last_prompt_id = prompt_id\n\n            e.execute(item[2], prompt_id, item[3], item[4])\n            need_gc = True\n            q.task_done(item_id,\n                        e.history_result,\n                        status=execution.PromptQueue.ExecutionStatus(\n                            status_str='success' if e.success else 'error',\n                            completed=e.success,\n                            messages=e.status_messages))\n            if server_instance.client_id is not None:\n                server_instance.send_sync(\"executing\", {\"node\": None, \"prompt_id\": prompt_id}, server_instance.client_id)\n\n            current_time = time.perf_counter()\n            execution_time = current_time - execution_start_time\n            logging.info(\"Prompt executed in {:.2f} seconds\".format(execution_time))\n\n        flags = q.get_flags()\n        free_memory = flags.get(\"free_memory\", False)\n\n        if flags.get(\"unload_models\", free_memory):\n            comfy.model_management.unload_all_models()\n            need_gc = True\n            last_gc_collect = 0\n\n        if free_memory:\n            e.reset()\n            need_gc = True\n            last_gc_collect = 0\n\n        if need_gc:\n            current_time = time.perf_counter()\n            if (current_time - last_gc_collect) > gc_collect_interval:\n                gc.collect()\n                comfy.model_management.soft_empty_cache()\n                last_gc_collect = current_time\n                need_gc = False\n\n\nasync def run(server_instance, address='', port=8188, verbose=True, call_on_start=None):\n    addresses = []\n    for addr in address.split(\",\"):\n        addresses.append((addr, port))\n    await asyncio.gather(\n        server_instance.start_multi_address(addresses, call_on_start, verbose), server_instance.publish_loop()\n    )\n\n\ndef hijack_progress(server_instance):\n    def hook(value, total, preview_image):\n        comfy.model_management.throw_exception_if_processing_interrupted()\n        progress = {\"value\": value, \"max\": total, \"prompt_id\": server_instance.last_prompt_id, \"node\": server_instance.last_node_id}\n\n        server_instance.send_sync(\"progress\", progress, server_instance.client_id)\n        if preview_image is not None:\n            server_instance.send_sync(BinaryEventTypes.UNENCODED_PREVIEW_IMAGE, preview_image, server_instance.client_id)\n\n    comfy.utils.set_progress_bar_global_hook(hook)\n\n\ndef cleanup_temp():\n    temp_dir = folder_paths.get_temp_directory()\n    if os.path.exists(temp_dir):\n        shutil.rmtree(temp_dir, ignore_errors=True)\n\n\ndef start_comfyui(asyncio_loop=None):\n    \"\"\"\n    Starts the ComfyUI server using the provided asyncio event loop or creates a new one.\n    Returns the event loop, server instance, and a function to start the server asynchronously.\n    \"\"\"\n    if args.temp_directory:\n        temp_dir = os.path.join(os.path.abspath(args.temp_directory), \"temp\")\n        logging.info(f\"Setting temp directory to: {temp_dir}\")\n        folder_paths.set_temp_directory(temp_dir)\n    cleanup_temp()\n\n    if args.windows_standalone_build:\n        try:\n            import new_updater\n            new_updater.update_windows_updater()\n        except:\n            pass\n\n    if not asyncio_loop:\n        asyncio_loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(asyncio_loop)\n    prompt_server = server.PromptServer(asyncio_loop)\n    q = execution.PromptQueue(prompt_server)\n\n    nodes.init_extra_nodes(init_custom_nodes=not args.disable_all_custom_nodes)\n\n    cuda_malloc_warning()\n\n    prompt_server.add_routes()\n    hijack_progress(prompt_server)\n\n    threading.Thread(target=prompt_worker, daemon=True, args=(q, prompt_server,)).start()\n\n    if args.quick_test_for_ci:\n        exit(0)\n\n    os.makedirs(folder_paths.get_temp_directory(), exist_ok=True)\n    call_on_start = None\n    if args.auto_launch:\n        def startup_server(scheme, address, port):\n            import webbrowser\n            if os.name == 'nt' and address == '0.0.0.0':\n                address = '127.0.0.1'\n            if ':' in address:\n                address = \"[{}]\".format(address)\n            webbrowser.open(f\"{scheme}://{address}:{port}\")\n        call_on_start = startup_server\n\n    async def start_all():\n        await prompt_server.setup()\n        await run(prompt_server, address=args.listen, port=args.port, verbose=not args.dont_print_server, call_on_start=call_on_start)\n\n    # Returning these so that other code can integrate with the ComfyUI loop and server\n    return asyncio_loop, prompt_server, start_all\n\n\nif __name__ == \"__main__\":\n    # Running directly, just start ComfyUI.\n    event_loop, _, start_all_func = start_comfyui()\n    try:\n        event_loop.run_until_complete(start_all_func())\n    except KeyboardInterrupt:\n        logging.info(\"\\nStopped server\")\n\n    cleanup_temp()\n"
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "new_updater.py",
          "type": "blob",
          "size": 1.23,
          "content": "import os\nimport shutil\n\nbase_path = os.path.dirname(os.path.realpath(__file__))\n\n\ndef update_windows_updater():\n    top_path = os.path.dirname(base_path)\n    updater_path = os.path.join(base_path, \".ci/update_windows/update.py\")\n    bat_path = os.path.join(base_path, \".ci/update_windows/update_comfyui.bat\")\n\n    dest_updater_path = os.path.join(top_path, \"update/update.py\")\n    dest_bat_path = os.path.join(top_path, \"update/update_comfyui.bat\")\n    dest_bat_deps_path = os.path.join(top_path, \"update/update_comfyui_and_python_dependencies.bat\")\n\n    try:\n        with open(dest_bat_path, 'rb') as f:\n            contents = f.read()\n    except:\n        return\n\n    if not contents.startswith(b\"..\\\\python_embeded\\\\python.exe .\\\\update.py\"):\n        return\n\n    shutil.copy(updater_path, dest_updater_path)\n    try:\n        with open(dest_bat_deps_path, 'rb') as f:\n            contents = f.read()\n            contents = contents.replace(b'..\\\\python_embeded\\\\python.exe .\\\\update.py ..\\\\ComfyUI\\\\', b'call update_comfyui.bat nopause')\n        with open(dest_bat_deps_path, 'wb') as f:\n            f.write(contents)\n    except:\n        pass\n    shutil.copy(bat_path, dest_bat_path)\n    print(\"Updated the windows standalone package updater.\")  # noqa: T201\n"
        },
        {
          "name": "node_helpers.py",
          "type": "blob",
          "size": 0.94,
          "content": "import hashlib\n\nfrom comfy.cli_args import args\n\nfrom PIL import ImageFile, UnidentifiedImageError\n\ndef conditioning_set_values(conditioning, values={}):\n    c = []\n    for t in conditioning:\n        n = [t[0], t[1].copy()]\n        for k in values:\n            n[1][k] = values[k]\n        c.append(n)\n\n    return c\n\ndef pillow(fn, arg):\n    prev_value = None\n    try:\n        x = fn(arg)\n    except (OSError, UnidentifiedImageError, ValueError): #PIL issues #4472 and #2445, also fixes ComfyUI issue #3416\n        prev_value = ImageFile.LOAD_TRUNCATED_IMAGES\n        ImageFile.LOAD_TRUNCATED_IMAGES = True\n        x = fn(arg)\n    finally:\n        if prev_value is not None:\n            ImageFile.LOAD_TRUNCATED_IMAGES = prev_value\n    return x\n\ndef hasher():\n    hashfuncs = {\n        \"md5\": hashlib.md5,\n        \"sha1\": hashlib.sha1,\n        \"sha256\": hashlib.sha256,\n        \"sha512\": hashlib.sha512\n    }\n    return hashfuncs[args.default_hashing_function]\n"
        },
        {
          "name": "nodes.py",
          "type": "blob",
          "size": 88.85,
          "content": "from __future__ import annotations\nimport torch\n\nimport os\nimport sys\nimport json\nimport hashlib\nimport traceback\nimport math\nimport time\nimport random\nimport logging\n\nfrom PIL import Image, ImageOps, ImageSequence\nfrom PIL.PngImagePlugin import PngInfo\n\nimport numpy as np\nimport safetensors.torch\n\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy\"))\n\nimport comfy.diffusers_load\nimport comfy.samplers\nimport comfy.sample\nimport comfy.sd\nimport comfy.utils\nimport comfy.controlnet\nfrom comfy.comfy_types import IO, ComfyNodeABC, InputTypeDict\n\nimport comfy.clip_vision\n\nimport comfy.model_management\nfrom comfy.cli_args import args\n\nimport importlib\n\nimport folder_paths\nimport latent_preview\nimport node_helpers\n\ndef before_node_execution():\n    comfy.model_management.throw_exception_if_processing_interrupted()\n\ndef interrupt_processing(value=True):\n    comfy.model_management.interrupt_current_processing(value)\n\nMAX_RESOLUTION=16384\n\nclass CLIPTextEncode(ComfyNodeABC):\n    @classmethod\n    def INPUT_TYPES(s) -> InputTypeDict:\n        return {\n            \"required\": {\n                \"text\": (IO.STRING, {\"multiline\": True, \"dynamicPrompts\": True, \"tooltip\": \"The text to be encoded.\"}),\n                \"clip\": (IO.CLIP, {\"tooltip\": \"The CLIP model used for encoding the text.\"})\n            }\n        }\n    RETURN_TYPES = (IO.CONDITIONING,)\n    OUTPUT_TOOLTIPS = (\"A conditioning containing the embedded text used to guide the diffusion model.\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning\"\n    DESCRIPTION = \"Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.\"\n\n    def encode(self, clip, text):\n        tokens = clip.tokenize(text)\n        return (clip.encode_from_tokens_scheduled(tokens), )\n\n\nclass ConditioningCombine:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning_1\": (\"CONDITIONING\", ), \"conditioning_2\": (\"CONDITIONING\", )}}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"combine\"\n\n    CATEGORY = \"conditioning\"\n\n    def combine(self, conditioning_1, conditioning_2):\n        return (conditioning_1 + conditioning_2, )\n\nclass ConditioningAverage :\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning_to\": (\"CONDITIONING\", ), \"conditioning_from\": (\"CONDITIONING\", ),\n                              \"conditioning_to_strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"addWeighted\"\n\n    CATEGORY = \"conditioning\"\n\n    def addWeighted(self, conditioning_to, conditioning_from, conditioning_to_strength):\n        out = []\n\n        if len(conditioning_from) > 1:\n            logging.warning(\"Warning: ConditioningAverage conditioning_from contains more than 1 cond, only the first one will actually be applied to conditioning_to.\")\n\n        cond_from = conditioning_from[0][0]\n        pooled_output_from = conditioning_from[0][1].get(\"pooled_output\", None)\n\n        for i in range(len(conditioning_to)):\n            t1 = conditioning_to[i][0]\n            pooled_output_to = conditioning_to[i][1].get(\"pooled_output\", pooled_output_from)\n            t0 = cond_from[:,:t1.shape[1]]\n            if t0.shape[1] < t1.shape[1]:\n                t0 = torch.cat([t0] + [torch.zeros((1, (t1.shape[1] - t0.shape[1]), t1.shape[2]))], dim=1)\n\n            tw = torch.mul(t1, conditioning_to_strength) + torch.mul(t0, (1.0 - conditioning_to_strength))\n            t_to = conditioning_to[i][1].copy()\n            if pooled_output_from is not None and pooled_output_to is not None:\n                t_to[\"pooled_output\"] = torch.mul(pooled_output_to, conditioning_to_strength) + torch.mul(pooled_output_from, (1.0 - conditioning_to_strength))\n            elif pooled_output_from is not None:\n                t_to[\"pooled_output\"] = pooled_output_from\n\n            n = [tw, t_to]\n            out.append(n)\n        return (out, )\n\nclass ConditioningConcat:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\n            \"conditioning_to\": (\"CONDITIONING\",),\n            \"conditioning_from\": (\"CONDITIONING\",),\n            }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"concat\"\n\n    CATEGORY = \"conditioning\"\n\n    def concat(self, conditioning_to, conditioning_from):\n        out = []\n\n        if len(conditioning_from) > 1:\n            logging.warning(\"Warning: ConditioningConcat conditioning_from contains more than 1 cond, only the first one will actually be applied to conditioning_to.\")\n\n        cond_from = conditioning_from[0][0]\n\n        for i in range(len(conditioning_to)):\n            t1 = conditioning_to[i][0]\n            tw = torch.cat((t1, cond_from),1)\n            n = [tw, conditioning_to[i][1].copy()]\n            out.append(n)\n\n        return (out, )\n\nclass ConditioningSetArea:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                              \"width\": (\"INT\", {\"default\": 64, \"min\": 64, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"height\": (\"INT\", {\"default\": 64, \"min\": 64, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"x\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"y\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, width, height, x, y, strength):\n        c = node_helpers.conditioning_set_values(conditioning, {\"area\": (height // 8, width // 8, y // 8, x // 8),\n                                                                \"strength\": strength,\n                                                                \"set_area_to_bounds\": False})\n        return (c, )\n\nclass ConditioningSetAreaPercentage:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                              \"width\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0, \"max\": 1.0, \"step\": 0.01}),\n                              \"height\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0, \"max\": 1.0, \"step\": 0.01}),\n                              \"x\": (\"FLOAT\", {\"default\": 0, \"min\": 0, \"max\": 1.0, \"step\": 0.01}),\n                              \"y\": (\"FLOAT\", {\"default\": 0, \"min\": 0, \"max\": 1.0, \"step\": 0.01}),\n                              \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, width, height, x, y, strength):\n        c = node_helpers.conditioning_set_values(conditioning, {\"area\": (\"percentage\", height, width, y, x),\n                                                                \"strength\": strength,\n                                                                \"set_area_to_bounds\": False})\n        return (c, )\n\nclass ConditioningSetAreaStrength:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                              \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, strength):\n        c = node_helpers.conditioning_set_values(conditioning, {\"strength\": strength})\n        return (c, )\n\n\nclass ConditioningSetMask:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                              \"mask\": (\"MASK\", ),\n                              \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"set_cond_area\": ([\"default\", \"mask bounds\"],),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, mask, set_cond_area, strength):\n        set_area_to_bounds = False\n        if set_cond_area != \"default\":\n            set_area_to_bounds = True\n        if len(mask.shape) < 3:\n            mask = mask.unsqueeze(0)\n\n        c = node_helpers.conditioning_set_values(conditioning, {\"mask\": mask,\n                                                                \"set_area_to_bounds\": set_area_to_bounds,\n                                                                \"mask_strength\": strength})\n        return (c, )\n\nclass ConditioningZeroOut:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", )}}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"zero_out\"\n\n    CATEGORY = \"advanced/conditioning\"\n\n    def zero_out(self, conditioning):\n        c = []\n        for t in conditioning:\n            d = t[1].copy()\n            pooled_output = d.get(\"pooled_output\", None)\n            if pooled_output is not None:\n                d[\"pooled_output\"] = torch.zeros_like(pooled_output)\n            n = [torch.zeros_like(t[0]), d]\n            c.append(n)\n        return (c, )\n\nclass ConditioningSetTimestepRange:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                             \"start\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.001}),\n                             \"end\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.001})\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"set_range\"\n\n    CATEGORY = \"advanced/conditioning\"\n\n    def set_range(self, conditioning, start, end):\n        c = node_helpers.conditioning_set_values(conditioning, {\"start_percent\": start,\n                                                                \"end_percent\": end})\n        return (c, )\n\nclass VAEDecode:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"samples\": (\"LATENT\", {\"tooltip\": \"The latent to be decoded.\"}),\n                \"vae\": (\"VAE\", {\"tooltip\": \"The VAE model used for decoding the latent.\"})\n            }\n        }\n    RETURN_TYPES = (\"IMAGE\",)\n    OUTPUT_TOOLTIPS = (\"The decoded image.\",)\n    FUNCTION = \"decode\"\n\n    CATEGORY = \"latent\"\n    DESCRIPTION = \"Decodes latent images back into pixel space images.\"\n\n    def decode(self, vae, samples):\n        images = vae.decode(samples[\"samples\"])\n        if len(images.shape) == 5: #Combine batches\n            images = images.reshape(-1, images.shape[-3], images.shape[-2], images.shape[-1])\n        return (images, )\n\nclass VAEDecodeTiled:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"samples\": (\"LATENT\", ), \"vae\": (\"VAE\", ),\n                             \"tile_size\": (\"INT\", {\"default\": 512, \"min\": 64, \"max\": 4096, \"step\": 32}),\n                             \"overlap\": (\"INT\", {\"default\": 64, \"min\": 0, \"max\": 4096, \"step\": 32}),\n                             \"temporal_size\": (\"INT\", {\"default\": 64, \"min\": 8, \"max\": 4096, \"step\": 4, \"tooltip\": \"Only used for video VAEs: Amount of frames to decode at a time.\"}),\n                             \"temporal_overlap\": (\"INT\", {\"default\": 8, \"min\": 4, \"max\": 4096, \"step\": 4, \"tooltip\": \"Only used for video VAEs: Amount of frames to overlap.\"}),\n                            }}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"decode\"\n\n    CATEGORY = \"_for_testing\"\n\n    def decode(self, vae, samples, tile_size, overlap=64, temporal_size=64, temporal_overlap=8):\n        if tile_size < overlap * 4:\n            overlap = tile_size // 4\n        if temporal_size < temporal_overlap * 2:\n            temporal_overlap = temporal_overlap // 2\n        temporal_compression = vae.temporal_compression_decode()\n        if temporal_compression is not None:\n            temporal_size = max(2, temporal_size // temporal_compression)\n            temporal_overlap = max(1, min(temporal_size // 2, temporal_overlap // temporal_compression))\n        else:\n            temporal_size = None\n            temporal_overlap = None\n\n        compression = vae.spacial_compression_decode()\n        images = vae.decode_tiled(samples[\"samples\"], tile_x=tile_size // compression, tile_y=tile_size // compression, overlap=overlap // compression, tile_t=temporal_size, overlap_t=temporal_overlap)\n        if len(images.shape) == 5: #Combine batches\n            images = images.reshape(-1, images.shape[-3], images.shape[-2], images.shape[-1])\n        return (images, )\n\nclass VAEEncode:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"pixels\": (\"IMAGE\", ), \"vae\": (\"VAE\", )}}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"latent\"\n\n    def encode(self, vae, pixels):\n        t = vae.encode(pixels[:,:,:,:3])\n        return ({\"samples\":t}, )\n\nclass VAEEncodeTiled:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"pixels\": (\"IMAGE\", ), \"vae\": (\"VAE\", ),\n                             \"tile_size\": (\"INT\", {\"default\": 512, \"min\": 64, \"max\": 4096, \"step\": 64}),\n                             \"overlap\": (\"INT\", {\"default\": 64, \"min\": 0, \"max\": 4096, \"step\": 32}),\n                             \"temporal_size\": (\"INT\", {\"default\": 64, \"min\": 8, \"max\": 4096, \"step\": 4, \"tooltip\": \"Only used for video VAEs: Amount of frames to encode at a time.\"}),\n                             \"temporal_overlap\": (\"INT\", {\"default\": 8, \"min\": 4, \"max\": 4096, \"step\": 4, \"tooltip\": \"Only used for video VAEs: Amount of frames to overlap.\"}),\n                            }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"_for_testing\"\n\n    def encode(self, vae, pixels, tile_size, overlap, temporal_size=64, temporal_overlap=8):\n        t = vae.encode_tiled(pixels[:,:,:,:3], tile_x=tile_size, tile_y=tile_size, overlap=overlap, tile_t=temporal_size, overlap_t=temporal_overlap)\n        return ({\"samples\": t}, )\n\nclass VAEEncodeForInpaint:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"pixels\": (\"IMAGE\", ), \"vae\": (\"VAE\", ), \"mask\": (\"MASK\", ), \"grow_mask_by\": (\"INT\", {\"default\": 6, \"min\": 0, \"max\": 64, \"step\": 1}),}}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"latent/inpaint\"\n\n    def encode(self, vae, pixels, mask, grow_mask_by=6):\n        x = (pixels.shape[1] // vae.downscale_ratio) * vae.downscale_ratio\n        y = (pixels.shape[2] // vae.downscale_ratio) * vae.downscale_ratio\n        mask = torch.nn.functional.interpolate(mask.reshape((-1, 1, mask.shape[-2], mask.shape[-1])), size=(pixels.shape[1], pixels.shape[2]), mode=\"bilinear\")\n\n        pixels = pixels.clone()\n        if pixels.shape[1] != x or pixels.shape[2] != y:\n            x_offset = (pixels.shape[1] % vae.downscale_ratio) // 2\n            y_offset = (pixels.shape[2] % vae.downscale_ratio) // 2\n            pixels = pixels[:,x_offset:x + x_offset, y_offset:y + y_offset,:]\n            mask = mask[:,:,x_offset:x + x_offset, y_offset:y + y_offset]\n\n        #grow mask by a few pixels to keep things seamless in latent space\n        if grow_mask_by == 0:\n            mask_erosion = mask\n        else:\n            kernel_tensor = torch.ones((1, 1, grow_mask_by, grow_mask_by))\n            padding = math.ceil((grow_mask_by - 1) / 2)\n\n            mask_erosion = torch.clamp(torch.nn.functional.conv2d(mask.round(), kernel_tensor, padding=padding), 0, 1)\n\n        m = (1.0 - mask.round()).squeeze(1)\n        for i in range(3):\n            pixels[:,:,:,i] -= 0.5\n            pixels[:,:,:,i] *= m\n            pixels[:,:,:,i] += 0.5\n        t = vae.encode(pixels)\n\n        return ({\"samples\":t, \"noise_mask\": (mask_erosion[:,:,:x,:y].round())}, )\n\n\nclass InpaintModelConditioning:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"pixels\": (\"IMAGE\", ),\n                             \"mask\": (\"MASK\", ),\n                             \"noise_mask\": (\"BOOLEAN\", {\"default\": True, \"tooltip\": \"Add a noise mask to the latent so sampling will only happen within the mask. Might improve results or completely break things depending on the model.\"}),\n                             }}\n\n    RETURN_TYPES = (\"CONDITIONING\",\"CONDITIONING\",\"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/inpaint\"\n\n    def encode(self, positive, negative, pixels, vae, mask, noise_mask=True):\n        x = (pixels.shape[1] // 8) * 8\n        y = (pixels.shape[2] // 8) * 8\n        mask = torch.nn.functional.interpolate(mask.reshape((-1, 1, mask.shape[-2], mask.shape[-1])), size=(pixels.shape[1], pixels.shape[2]), mode=\"bilinear\")\n\n        orig_pixels = pixels\n        pixels = orig_pixels.clone()\n        if pixels.shape[1] != x or pixels.shape[2] != y:\n            x_offset = (pixels.shape[1] % 8) // 2\n            y_offset = (pixels.shape[2] % 8) // 2\n            pixels = pixels[:,x_offset:x + x_offset, y_offset:y + y_offset,:]\n            mask = mask[:,:,x_offset:x + x_offset, y_offset:y + y_offset]\n\n        m = (1.0 - mask.round()).squeeze(1)\n        for i in range(3):\n            pixels[:,:,:,i] -= 0.5\n            pixels[:,:,:,i] *= m\n            pixels[:,:,:,i] += 0.5\n        concat_latent = vae.encode(pixels)\n        orig_latent = vae.encode(orig_pixels)\n\n        out_latent = {}\n\n        out_latent[\"samples\"] = orig_latent\n        if noise_mask:\n            out_latent[\"noise_mask\"] = mask\n\n        out = []\n        for conditioning in [positive, negative]:\n            c = node_helpers.conditioning_set_values(conditioning, {\"concat_latent_image\": concat_latent,\n                                                                    \"concat_mask\": mask})\n            out.append(c)\n        return (out[0], out[1], out_latent)\n\n\nclass SaveLatent:\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\", ),\n                              \"filename_prefix\": (\"STRING\", {\"default\": \"latents/ComfyUI\"})},\n                \"hidden\": {\"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"},\n                }\n    RETURN_TYPES = ()\n    FUNCTION = \"save\"\n\n    OUTPUT_NODE = True\n\n    CATEGORY = \"_for_testing\"\n\n    def save(self, samples, filename_prefix=\"ComfyUI\", prompt=None, extra_pnginfo=None):\n        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(filename_prefix, self.output_dir)\n\n        # support save metadata for latent sharing\n        prompt_info = \"\"\n        if prompt is not None:\n            prompt_info = json.dumps(prompt)\n\n        metadata = None\n        if not args.disable_metadata:\n            metadata = {\"prompt\": prompt_info}\n            if extra_pnginfo is not None:\n                for x in extra_pnginfo:\n                    metadata[x] = json.dumps(extra_pnginfo[x])\n\n        file = f\"{filename}_{counter:05}_.latent\"\n\n        results = list()\n        results.append({\n            \"filename\": file,\n            \"subfolder\": subfolder,\n            \"type\": \"output\"\n        })\n\n        file = os.path.join(full_output_folder, file)\n\n        output = {}\n        output[\"latent_tensor\"] = samples[\"samples\"]\n        output[\"latent_format_version_0\"] = torch.tensor([])\n\n        comfy.utils.save_torch_file(output, file, metadata=metadata)\n        return { \"ui\": { \"latents\": results } }\n\n\nclass LoadLatent:\n    @classmethod\n    def INPUT_TYPES(s):\n        input_dir = folder_paths.get_input_directory()\n        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f)) and f.endswith(\".latent\")]\n        return {\"required\": {\"latent\": [sorted(files), ]}, }\n\n    CATEGORY = \"_for_testing\"\n\n    RETURN_TYPES = (\"LATENT\", )\n    FUNCTION = \"load\"\n\n    def load(self, latent):\n        latent_path = folder_paths.get_annotated_filepath(latent)\n        latent = safetensors.torch.load_file(latent_path, device=\"cpu\")\n        multiplier = 1.0\n        if \"latent_format_version_0\" not in latent:\n            multiplier = 1.0 / 0.18215\n        samples = {\"samples\": latent[\"latent_tensor\"].float() * multiplier}\n        return (samples, )\n\n    @classmethod\n    def IS_CHANGED(s, latent):\n        image_path = folder_paths.get_annotated_filepath(latent)\n        m = hashlib.sha256()\n        with open(image_path, 'rb') as f:\n            m.update(f.read())\n        return m.digest().hex()\n\n    @classmethod\n    def VALIDATE_INPUTS(s, latent):\n        if not folder_paths.exists_annotated_filepath(latent):\n            return \"Invalid latent file: {}\".format(latent)\n        return True\n\n\nclass CheckpointLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"config_name\": (folder_paths.get_filename_list(\"configs\"), ),\n                              \"ckpt_name\": (folder_paths.get_filename_list(\"checkpoints\"), )}}\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"advanced/loaders\"\n    DEPRECATED = True\n\n    def load_checkpoint(self, config_name, ckpt_name):\n        config_path = folder_paths.get_full_path(\"configs\", config_name)\n        ckpt_path = folder_paths.get_full_path_or_raise(\"checkpoints\", ckpt_name)\n        return comfy.sd.load_checkpoint(config_path, ckpt_path, output_vae=True, output_clip=True, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n\nclass CheckpointLoaderSimple:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"ckpt_name\": (folder_paths.get_filename_list(\"checkpoints\"), {\"tooltip\": \"The name of the checkpoint (model) to load.\"}),\n            }\n        }\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\")\n    OUTPUT_TOOLTIPS = (\"The model used for denoising latents.\",\n                       \"The CLIP model used for encoding text prompts.\",\n                       \"The VAE model used for encoding and decoding images to and from latent space.\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"loaders\"\n    DESCRIPTION = \"Loads a diffusion model checkpoint, diffusion models are used to denoise latents.\"\n\n    def load_checkpoint(self, ckpt_name):\n        ckpt_path = folder_paths.get_full_path_or_raise(\"checkpoints\", ckpt_name)\n        out = comfy.sd.load_checkpoint_guess_config(ckpt_path, output_vae=True, output_clip=True, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n        return out[:3]\n\nclass DiffusersLoader:\n    @classmethod\n    def INPUT_TYPES(cls):\n        paths = []\n        for search_path in folder_paths.get_folder_paths(\"diffusers\"):\n            if os.path.exists(search_path):\n                for root, subdir, files in os.walk(search_path, followlinks=True):\n                    if \"model_index.json\" in files:\n                        paths.append(os.path.relpath(root, start=search_path))\n\n        return {\"required\": {\"model_path\": (paths,), }}\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"advanced/loaders/deprecated\"\n\n    def load_checkpoint(self, model_path, output_vae=True, output_clip=True):\n        for search_path in folder_paths.get_folder_paths(\"diffusers\"):\n            if os.path.exists(search_path):\n                path = os.path.join(search_path, model_path)\n                if os.path.exists(path):\n                    model_path = path\n                    break\n\n        return comfy.diffusers_load.load_diffusers(model_path, output_vae=output_vae, output_clip=output_clip, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n\n\nclass unCLIPCheckpointLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"ckpt_name\": (folder_paths.get_filename_list(\"checkpoints\"), ),\n                             }}\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\", \"CLIP_VISION\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"loaders\"\n\n    def load_checkpoint(self, ckpt_name, output_vae=True, output_clip=True):\n        ckpt_path = folder_paths.get_full_path_or_raise(\"checkpoints\", ckpt_name)\n        out = comfy.sd.load_checkpoint_guess_config(ckpt_path, output_vae=True, output_clip=True, output_clipvision=True, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n        return out\n\nclass CLIPSetLastLayer:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"clip\": (\"CLIP\", ),\n                              \"stop_at_clip_layer\": (\"INT\", {\"default\": -1, \"min\": -24, \"max\": -1, \"step\": 1}),\n                              }}\n    RETURN_TYPES = (\"CLIP\",)\n    FUNCTION = \"set_last_layer\"\n\n    CATEGORY = \"conditioning\"\n\n    def set_last_layer(self, clip, stop_at_clip_layer):\n        clip = clip.clone()\n        clip.clip_layer(stop_at_clip_layer)\n        return (clip,)\n\nclass LoraLoader:\n    def __init__(self):\n        self.loaded_lora = None\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"model\": (\"MODEL\", {\"tooltip\": \"The diffusion model the LoRA will be applied to.\"}),\n                \"clip\": (\"CLIP\", {\"tooltip\": \"The CLIP model the LoRA will be applied to.\"}),\n                \"lora_name\": (folder_paths.get_filename_list(\"loras\"), {\"tooltip\": \"The name of the LoRA.\"}),\n                \"strength_model\": (\"FLOAT\", {\"default\": 1.0, \"min\": -100.0, \"max\": 100.0, \"step\": 0.01, \"tooltip\": \"How strongly to modify the diffusion model. This value can be negative.\"}),\n                \"strength_clip\": (\"FLOAT\", {\"default\": 1.0, \"min\": -100.0, \"max\": 100.0, \"step\": 0.01, \"tooltip\": \"How strongly to modify the CLIP model. This value can be negative.\"}),\n            }\n        }\n\n    RETURN_TYPES = (\"MODEL\", \"CLIP\")\n    OUTPUT_TOOLTIPS = (\"The modified diffusion model.\", \"The modified CLIP model.\")\n    FUNCTION = \"load_lora\"\n\n    CATEGORY = \"loaders\"\n    DESCRIPTION = \"LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.\"\n\n    def load_lora(self, model, clip, lora_name, strength_model, strength_clip):\n        if strength_model == 0 and strength_clip == 0:\n            return (model, clip)\n\n        lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n        lora = None\n        if self.loaded_lora is not None:\n            if self.loaded_lora[0] == lora_path:\n                lora = self.loaded_lora[1]\n            else:\n                self.loaded_lora = None\n\n        if lora is None:\n            lora = comfy.utils.load_torch_file(lora_path, safe_load=True)\n            self.loaded_lora = (lora_path, lora)\n\n        model_lora, clip_lora = comfy.sd.load_lora_for_models(model, clip, lora, strength_model, strength_clip)\n        return (model_lora, clip_lora)\n\nclass LoraLoaderModelOnly(LoraLoader):\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"model\": (\"MODEL\",),\n                              \"lora_name\": (folder_paths.get_filename_list(\"loras\"), ),\n                              \"strength_model\": (\"FLOAT\", {\"default\": 1.0, \"min\": -100.0, \"max\": 100.0, \"step\": 0.01}),\n                              }}\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"load_lora_model_only\"\n\n    def load_lora_model_only(self, model, lora_name, strength_model):\n        return (self.load_lora(model, None, lora_name, strength_model, 0)[0],)\n\nclass VAELoader:\n    @staticmethod\n    def vae_list():\n        vaes = folder_paths.get_filename_list(\"vae\")\n        approx_vaes = folder_paths.get_filename_list(\"vae_approx\")\n        sdxl_taesd_enc = False\n        sdxl_taesd_dec = False\n        sd1_taesd_enc = False\n        sd1_taesd_dec = False\n        sd3_taesd_enc = False\n        sd3_taesd_dec = False\n        f1_taesd_enc = False\n        f1_taesd_dec = False\n\n        for v in approx_vaes:\n            if v.startswith(\"taesd_decoder.\"):\n                sd1_taesd_dec = True\n            elif v.startswith(\"taesd_encoder.\"):\n                sd1_taesd_enc = True\n            elif v.startswith(\"taesdxl_decoder.\"):\n                sdxl_taesd_dec = True\n            elif v.startswith(\"taesdxl_encoder.\"):\n                sdxl_taesd_enc = True\n            elif v.startswith(\"taesd3_decoder.\"):\n                sd3_taesd_dec = True\n            elif v.startswith(\"taesd3_encoder.\"):\n                sd3_taesd_enc = True\n            elif v.startswith(\"taef1_encoder.\"):\n                f1_taesd_dec = True\n            elif v.startswith(\"taef1_decoder.\"):\n                f1_taesd_enc = True\n        if sd1_taesd_dec and sd1_taesd_enc:\n            vaes.append(\"taesd\")\n        if sdxl_taesd_dec and sdxl_taesd_enc:\n            vaes.append(\"taesdxl\")\n        if sd3_taesd_dec and sd3_taesd_enc:\n            vaes.append(\"taesd3\")\n        if f1_taesd_dec and f1_taesd_enc:\n            vaes.append(\"taef1\")\n        return vaes\n\n    @staticmethod\n    def load_taesd(name):\n        sd = {}\n        approx_vaes = folder_paths.get_filename_list(\"vae_approx\")\n\n        encoder = next(filter(lambda a: a.startswith(\"{}_encoder.\".format(name)), approx_vaes))\n        decoder = next(filter(lambda a: a.startswith(\"{}_decoder.\".format(name)), approx_vaes))\n\n        enc = comfy.utils.load_torch_file(folder_paths.get_full_path_or_raise(\"vae_approx\", encoder))\n        for k in enc:\n            sd[\"taesd_encoder.{}\".format(k)] = enc[k]\n\n        dec = comfy.utils.load_torch_file(folder_paths.get_full_path_or_raise(\"vae_approx\", decoder))\n        for k in dec:\n            sd[\"taesd_decoder.{}\".format(k)] = dec[k]\n\n        if name == \"taesd\":\n            sd[\"vae_scale\"] = torch.tensor(0.18215)\n            sd[\"vae_shift\"] = torch.tensor(0.0)\n        elif name == \"taesdxl\":\n            sd[\"vae_scale\"] = torch.tensor(0.13025)\n            sd[\"vae_shift\"] = torch.tensor(0.0)\n        elif name == \"taesd3\":\n            sd[\"vae_scale\"] = torch.tensor(1.5305)\n            sd[\"vae_shift\"] = torch.tensor(0.0609)\n        elif name == \"taef1\":\n            sd[\"vae_scale\"] = torch.tensor(0.3611)\n            sd[\"vae_shift\"] = torch.tensor(0.1159)\n        return sd\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"vae_name\": (s.vae_list(), )}}\n    RETURN_TYPES = (\"VAE\",)\n    FUNCTION = \"load_vae\"\n\n    CATEGORY = \"loaders\"\n\n    #TODO: scale factor?\n    def load_vae(self, vae_name):\n        if vae_name in [\"taesd\", \"taesdxl\", \"taesd3\", \"taef1\"]:\n            sd = self.load_taesd(vae_name)\n        else:\n            vae_path = folder_paths.get_full_path_or_raise(\"vae\", vae_name)\n            sd = comfy.utils.load_torch_file(vae_path)\n        vae = comfy.sd.VAE(sd=sd)\n        return (vae,)\n\nclass ControlNetLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"control_net_name\": (folder_paths.get_filename_list(\"controlnet\"), )}}\n\n    RETURN_TYPES = (\"CONTROL_NET\",)\n    FUNCTION = \"load_controlnet\"\n\n    CATEGORY = \"loaders\"\n\n    def load_controlnet(self, control_net_name):\n        controlnet_path = folder_paths.get_full_path_or_raise(\"controlnet\", control_net_name)\n        controlnet = comfy.controlnet.load_controlnet(controlnet_path)\n        return (controlnet,)\n\nclass DiffControlNetLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"model\": (\"MODEL\",),\n                              \"control_net_name\": (folder_paths.get_filename_list(\"controlnet\"), )}}\n\n    RETURN_TYPES = (\"CONTROL_NET\",)\n    FUNCTION = \"load_controlnet\"\n\n    CATEGORY = \"loaders\"\n\n    def load_controlnet(self, model, control_net_name):\n        controlnet_path = folder_paths.get_full_path_or_raise(\"controlnet\", control_net_name)\n        controlnet = comfy.controlnet.load_controlnet(controlnet_path, model)\n        return (controlnet,)\n\n\nclass ControlNetApply:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                             \"control_net\": (\"CONTROL_NET\", ),\n                             \"image\": (\"IMAGE\", ),\n                             \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01})\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"apply_controlnet\"\n\n    DEPRECATED = True\n    CATEGORY = \"conditioning/controlnet\"\n\n    def apply_controlnet(self, conditioning, control_net, image, strength):\n        if strength == 0:\n            return (conditioning, )\n\n        c = []\n        control_hint = image.movedim(-1,1)\n        for t in conditioning:\n            n = [t[0], t[1].copy()]\n            c_net = control_net.copy().set_cond_hint(control_hint, strength)\n            if 'control' in t[1]:\n                c_net.set_previous_controlnet(t[1]['control'])\n            n[1]['control'] = c_net\n            n[1]['control_apply_to_uncond'] = True\n            c.append(n)\n        return (c, )\n\n\nclass ControlNetApplyAdvanced:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"control_net\": (\"CONTROL_NET\", ),\n                             \"image\": (\"IMAGE\", ),\n                             \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             \"start_percent\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.001}),\n                             \"end_percent\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.001})\n                             },\n                \"optional\": {\"vae\": (\"VAE\", ),\n                             }\n    }\n\n    RETURN_TYPES = (\"CONDITIONING\",\"CONDITIONING\")\n    RETURN_NAMES = (\"positive\", \"negative\")\n    FUNCTION = \"apply_controlnet\"\n\n    CATEGORY = \"conditioning/controlnet\"\n\n    def apply_controlnet(self, positive, negative, control_net, image, strength, start_percent, end_percent, vae=None, extra_concat=[]):\n        if strength == 0:\n            return (positive, negative)\n\n        control_hint = image.movedim(-1,1)\n        cnets = {}\n\n        out = []\n        for conditioning in [positive, negative]:\n            c = []\n            for t in conditioning:\n                d = t[1].copy()\n\n                prev_cnet = d.get('control', None)\n                if prev_cnet in cnets:\n                    c_net = cnets[prev_cnet]\n                else:\n                    c_net = control_net.copy().set_cond_hint(control_hint, strength, (start_percent, end_percent), vae=vae, extra_concat=extra_concat)\n                    c_net.set_previous_controlnet(prev_cnet)\n                    cnets[prev_cnet] = c_net\n\n                d['control'] = c_net\n                d['control_apply_to_uncond'] = False\n                n = [t[0], d]\n                c.append(n)\n            out.append(c)\n        return (out[0], out[1])\n\n\nclass UNETLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"unet_name\": (folder_paths.get_filename_list(\"diffusion_models\"), ),\n                              \"weight_dtype\": ([\"default\", \"fp8_e4m3fn\", \"fp8_e4m3fn_fast\", \"fp8_e5m2\"],)\n                             }}\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"load_unet\"\n\n    CATEGORY = \"advanced/loaders\"\n\n    def load_unet(self, unet_name, weight_dtype):\n        model_options = {}\n        if weight_dtype == \"fp8_e4m3fn\":\n            model_options[\"dtype\"] = torch.float8_e4m3fn\n        elif weight_dtype == \"fp8_e4m3fn_fast\":\n            model_options[\"dtype\"] = torch.float8_e4m3fn\n            model_options[\"fp8_optimizations\"] = True\n        elif weight_dtype == \"fp8_e5m2\":\n            model_options[\"dtype\"] = torch.float8_e5m2\n\n        unet_path = folder_paths.get_full_path_or_raise(\"diffusion_models\", unet_name)\n        model = comfy.sd.load_diffusion_model(unet_path, model_options=model_options)\n        return (model,)\n\nclass CLIPLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"clip_name\": (folder_paths.get_filename_list(\"text_encoders\"), ),\n                              \"type\": ([\"stable_diffusion\", \"stable_cascade\", \"sd3\", \"stable_audio\", \"mochi\", \"ltxv\", \"pixart\", \"cosmos\"], ),\n                              },\n                \"optional\": {\n                              \"device\": ([\"default\", \"cpu\"], {\"advanced\": True}),\n                             }}\n    RETURN_TYPES = (\"CLIP\",)\n    FUNCTION = \"load_clip\"\n\n    CATEGORY = \"advanced/loaders\"\n\n    DESCRIPTION = \"[Recipes]\\n\\nstable_diffusion: clip-l\\nstable_cascade: clip-g\\nsd3: t5 / clip-g / clip-l\\nstable_audio: t5\\nmochi: t5\\ncosmos: old t5 xxl\"\n\n    def load_clip(self, clip_name, type=\"stable_diffusion\", device=\"default\"):\n        if type == \"stable_cascade\":\n            clip_type = comfy.sd.CLIPType.STABLE_CASCADE\n        elif type == \"sd3\":\n            clip_type = comfy.sd.CLIPType.SD3\n        elif type == \"stable_audio\":\n            clip_type = comfy.sd.CLIPType.STABLE_AUDIO\n        elif type == \"mochi\":\n            clip_type = comfy.sd.CLIPType.MOCHI\n        elif type == \"ltxv\":\n            clip_type = comfy.sd.CLIPType.LTXV\n        elif type == \"pixart\":\n            clip_type = comfy.sd.CLIPType.PIXART\n        else:\n            clip_type = comfy.sd.CLIPType.STABLE_DIFFUSION\n\n        model_options = {}\n        if device == \"cpu\":\n            model_options[\"load_device\"] = model_options[\"offload_device\"] = torch.device(\"cpu\")\n\n        clip_path = folder_paths.get_full_path_or_raise(\"text_encoders\", clip_name)\n        clip = comfy.sd.load_clip(ckpt_paths=[clip_path], embedding_directory=folder_paths.get_folder_paths(\"embeddings\"), clip_type=clip_type, model_options=model_options)\n        return (clip,)\n\nclass DualCLIPLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"clip_name1\": (folder_paths.get_filename_list(\"text_encoders\"), ),\n                              \"clip_name2\": (folder_paths.get_filename_list(\"text_encoders\"), ),\n                              \"type\": ([\"sdxl\", \"sd3\", \"flux\", \"hunyuan_video\"], ),\n                              },\n                \"optional\": {\n                              \"device\": ([\"default\", \"cpu\"], {\"advanced\": True}),\n                             }}\n    RETURN_TYPES = (\"CLIP\",)\n    FUNCTION = \"load_clip\"\n\n    CATEGORY = \"advanced/loaders\"\n\n    DESCRIPTION = \"[Recipes]\\n\\nsdxl: clip-l, clip-g\\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\\nflux: clip-l, t5\"\n\n    def load_clip(self, clip_name1, clip_name2, type, device=\"default\"):\n        clip_path1 = folder_paths.get_full_path_or_raise(\"text_encoders\", clip_name1)\n        clip_path2 = folder_paths.get_full_path_or_raise(\"text_encoders\", clip_name2)\n        if type == \"sdxl\":\n            clip_type = comfy.sd.CLIPType.STABLE_DIFFUSION\n        elif type == \"sd3\":\n            clip_type = comfy.sd.CLIPType.SD3\n        elif type == \"flux\":\n            clip_type = comfy.sd.CLIPType.FLUX\n        elif type == \"hunyuan_video\":\n            clip_type = comfy.sd.CLIPType.HUNYUAN_VIDEO\n\n        model_options = {}\n        if device == \"cpu\":\n            model_options[\"load_device\"] = model_options[\"offload_device\"] = torch.device(\"cpu\")\n\n        clip = comfy.sd.load_clip(ckpt_paths=[clip_path1, clip_path2], embedding_directory=folder_paths.get_folder_paths(\"embeddings\"), clip_type=clip_type, model_options=model_options)\n        return (clip,)\n\nclass CLIPVisionLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"clip_name\": (folder_paths.get_filename_list(\"clip_vision\"), ),\n                             }}\n    RETURN_TYPES = (\"CLIP_VISION\",)\n    FUNCTION = \"load_clip\"\n\n    CATEGORY = \"loaders\"\n\n    def load_clip(self, clip_name):\n        clip_path = folder_paths.get_full_path_or_raise(\"clip_vision\", clip_name)\n        clip_vision = comfy.clip_vision.load(clip_path)\n        return (clip_vision,)\n\nclass CLIPVisionEncode:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"clip_vision\": (\"CLIP_VISION\",),\n                              \"image\": (\"IMAGE\",),\n                              \"crop\": ([\"center\", \"none\"],)\n                             }}\n    RETURN_TYPES = (\"CLIP_VISION_OUTPUT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning\"\n\n    def encode(self, clip_vision, image, crop):\n        crop_image = True\n        if crop != \"center\":\n            crop_image = False\n        output = clip_vision.encode_image(image, crop=crop_image)\n        return (output,)\n\nclass StyleModelLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"style_model_name\": (folder_paths.get_filename_list(\"style_models\"), )}}\n\n    RETURN_TYPES = (\"STYLE_MODEL\",)\n    FUNCTION = \"load_style_model\"\n\n    CATEGORY = \"loaders\"\n\n    def load_style_model(self, style_model_name):\n        style_model_path = folder_paths.get_full_path_or_raise(\"style_models\", style_model_name)\n        style_model = comfy.sd.load_style_model(style_model_path)\n        return (style_model,)\n\n\nclass StyleModelApply:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                             \"style_model\": (\"STYLE_MODEL\", ),\n                             \"clip_vision_output\": (\"CLIP_VISION_OUTPUT\", ),\n                             \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.001}),\n                             \"strength_type\": ([\"multiply\", \"attn_bias\"], ),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"apply_stylemodel\"\n\n    CATEGORY = \"conditioning/style_model\"\n\n    def apply_stylemodel(self, conditioning, style_model, clip_vision_output, strength, strength_type):\n        cond = style_model.get_cond(clip_vision_output).flatten(start_dim=0, end_dim=1).unsqueeze(dim=0)\n        if strength_type == \"multiply\":\n            cond *= strength\n\n        n = cond.shape[1]\n        c_out = []\n        for t in conditioning:\n            (txt, keys) = t\n            keys = keys.copy()\n            if strength_type == \"attn_bias\" and strength != 1.0:\n                # math.log raises an error if the argument is zero\n                # torch.log returns -inf, which is what we want\n                attn_bias = torch.log(torch.Tensor([strength]))\n                # get the size of the mask image\n                mask_ref_size = keys.get(\"attention_mask_img_shape\", (1, 1))\n                n_ref = mask_ref_size[0] * mask_ref_size[1]\n                n_txt = txt.shape[1]\n                # grab the existing mask\n                mask = keys.get(\"attention_mask\", None)\n                # create a default mask if it doesn't exist\n                if mask is None:\n                    mask = torch.zeros((txt.shape[0], n_txt + n_ref, n_txt + n_ref), dtype=torch.float16)\n                # convert the mask dtype, because it might be boolean\n                # we want it to be interpreted as a bias\n                if mask.dtype == torch.bool:\n                    # log(True) = log(1) = 0\n                    # log(False) = log(0) = -inf\n                    mask = torch.log(mask.to(dtype=torch.float16))\n                # now we make the mask bigger to add space for our new tokens\n                new_mask = torch.zeros((txt.shape[0], n_txt + n + n_ref, n_txt + n + n_ref), dtype=torch.float16)\n                # copy over the old mask, in quandrants\n                new_mask[:, :n_txt, :n_txt] = mask[:, :n_txt, :n_txt]\n                new_mask[:, :n_txt, n_txt+n:] = mask[:, :n_txt, n_txt:]\n                new_mask[:, n_txt+n:, :n_txt] = mask[:, n_txt:, :n_txt]\n                new_mask[:, n_txt+n:, n_txt+n:] = mask[:, n_txt:, n_txt:]\n                # now fill in the attention bias to our redux tokens\n                new_mask[:, :n_txt, n_txt:n_txt+n] = attn_bias\n                new_mask[:, n_txt+n:, n_txt:n_txt+n] = attn_bias\n                keys[\"attention_mask\"] = new_mask.to(txt.device)\n                keys[\"attention_mask_img_shape\"] = mask_ref_size\n\n            c_out.append([torch.cat((txt, cond), dim=1), keys])\n\n        return (c_out,)\n\nclass unCLIPConditioning:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning\": (\"CONDITIONING\", ),\n                             \"clip_vision_output\": (\"CLIP_VISION_OUTPUT\", ),\n                             \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                             \"noise_augmentation\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"apply_adm\"\n\n    CATEGORY = \"conditioning\"\n\n    def apply_adm(self, conditioning, clip_vision_output, strength, noise_augmentation):\n        if strength == 0:\n            return (conditioning, )\n\n        c = []\n        for t in conditioning:\n            o = t[1].copy()\n            x = {\"clip_vision_output\": clip_vision_output, \"strength\": strength, \"noise_augmentation\": noise_augmentation}\n            if \"unclip_conditioning\" in o:\n                o[\"unclip_conditioning\"] = o[\"unclip_conditioning\"][:] + [x]\n            else:\n                o[\"unclip_conditioning\"] = [x]\n            n = [t[0], o]\n            c.append(n)\n        return (c, )\n\nclass GLIGENLoader:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"gligen_name\": (folder_paths.get_filename_list(\"gligen\"), )}}\n\n    RETURN_TYPES = (\"GLIGEN\",)\n    FUNCTION = \"load_gligen\"\n\n    CATEGORY = \"loaders\"\n\n    def load_gligen(self, gligen_name):\n        gligen_path = folder_paths.get_full_path_or_raise(\"gligen\", gligen_name)\n        gligen = comfy.sd.load_gligen(gligen_path)\n        return (gligen,)\n\nclass GLIGENTextBoxApply:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"conditioning_to\": (\"CONDITIONING\", ),\n                              \"clip\": (\"CLIP\", ),\n                              \"gligen_textbox_model\": (\"GLIGEN\", ),\n                              \"text\": (\"STRING\", {\"multiline\": True, \"dynamicPrompts\": True}),\n                              \"width\": (\"INT\", {\"default\": 64, \"min\": 8, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"height\": (\"INT\", {\"default\": 64, \"min\": 8, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"x\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"y\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning/gligen\"\n\n    def append(self, conditioning_to, clip, gligen_textbox_model, text, width, height, x, y):\n        c = []\n        cond, cond_pooled = clip.encode_from_tokens(clip.tokenize(text), return_pooled=\"unprojected\")\n        for t in conditioning_to:\n            n = [t[0], t[1].copy()]\n            position_params = [(cond_pooled, height // 8, width // 8, y // 8, x // 8)]\n            prev = []\n            if \"gligen\" in n[1]:\n                prev = n[1]['gligen'][2]\n\n            n[1]['gligen'] = (\"position\", gligen_textbox_model, prev + position_params)\n            c.append(n)\n        return (c, )\n\nclass EmptyLatentImage:\n    def __init__(self):\n        self.device = comfy.model_management.intermediate_device()\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"width\": (\"INT\", {\"default\": 512, \"min\": 16, \"max\": MAX_RESOLUTION, \"step\": 8, \"tooltip\": \"The width of the latent images in pixels.\"}),\n                \"height\": (\"INT\", {\"default\": 512, \"min\": 16, \"max\": MAX_RESOLUTION, \"step\": 8, \"tooltip\": \"The height of the latent images in pixels.\"}),\n                \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096, \"tooltip\": \"The number of latent images in the batch.\"})\n            }\n        }\n    RETURN_TYPES = (\"LATENT\",)\n    OUTPUT_TOOLTIPS = (\"The empty latent image batch.\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"latent\"\n    DESCRIPTION = \"Create a new batch of empty latent images to be denoised via sampling.\"\n\n    def generate(self, width, height, batch_size=1):\n        latent = torch.zeros([batch_size, 4, height // 8, width // 8], device=self.device)\n        return ({\"samples\":latent}, )\n\n\nclass LatentFromBatch:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",),\n                              \"batch_index\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 63}),\n                              \"length\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 64}),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"frombatch\"\n\n    CATEGORY = \"latent/batch\"\n\n    def frombatch(self, samples, batch_index, length):\n        s = samples.copy()\n        s_in = samples[\"samples\"]\n        batch_index = min(s_in.shape[0] - 1, batch_index)\n        length = min(s_in.shape[0] - batch_index, length)\n        s[\"samples\"] = s_in[batch_index:batch_index + length].clone()\n        if \"noise_mask\" in samples:\n            masks = samples[\"noise_mask\"]\n            if masks.shape[0] == 1:\n                s[\"noise_mask\"] = masks.clone()\n            else:\n                if masks.shape[0] < s_in.shape[0]:\n                    masks = masks.repeat(math.ceil(s_in.shape[0] / masks.shape[0]), 1, 1, 1)[:s_in.shape[0]]\n                s[\"noise_mask\"] = masks[batch_index:batch_index + length].clone()\n        if \"batch_index\" not in s:\n            s[\"batch_index\"] = [x for x in range(batch_index, batch_index+length)]\n        else:\n            s[\"batch_index\"] = samples[\"batch_index\"][batch_index:batch_index + length]\n        return (s,)\n\nclass RepeatLatentBatch:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",),\n                              \"amount\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 64}),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"repeat\"\n\n    CATEGORY = \"latent/batch\"\n\n    def repeat(self, samples, amount):\n        s = samples.copy()\n        s_in = samples[\"samples\"]\n\n        s[\"samples\"] = s_in.repeat((amount, 1,1,1))\n        if \"noise_mask\" in samples and samples[\"noise_mask\"].shape[0] > 1:\n            masks = samples[\"noise_mask\"]\n            if masks.shape[0] < s_in.shape[0]:\n                masks = masks.repeat(math.ceil(s_in.shape[0] / masks.shape[0]), 1, 1, 1)[:s_in.shape[0]]\n            s[\"noise_mask\"] = samples[\"noise_mask\"].repeat((amount, 1,1,1))\n        if \"batch_index\" in s:\n            offset = max(s[\"batch_index\"]) - min(s[\"batch_index\"]) + 1\n            s[\"batch_index\"] = s[\"batch_index\"] + [x + (i * offset) for i in range(1, amount) for x in s[\"batch_index\"]]\n        return (s,)\n\nclass LatentUpscale:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"bislerp\"]\n    crop_methods = [\"disabled\", \"center\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",), \"upscale_method\": (s.upscale_methods,),\n                              \"width\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"crop\": (s.crop_methods,)}}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"latent\"\n\n    def upscale(self, samples, upscale_method, width, height, crop):\n        if width == 0 and height == 0:\n            s = samples\n        else:\n            s = samples.copy()\n\n            if width == 0:\n                height = max(64, height)\n                width = max(64, round(samples[\"samples\"].shape[-1] * height / samples[\"samples\"].shape[-2]))\n            elif height == 0:\n                width = max(64, width)\n                height = max(64, round(samples[\"samples\"].shape[-2] * width / samples[\"samples\"].shape[-1]))\n            else:\n                width = max(64, width)\n                height = max(64, height)\n\n            s[\"samples\"] = comfy.utils.common_upscale(samples[\"samples\"], width // 8, height // 8, upscale_method, crop)\n        return (s,)\n\nclass LatentUpscaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"bislerp\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",), \"upscale_method\": (s.upscale_methods,),\n                              \"scale_by\": (\"FLOAT\", {\"default\": 1.5, \"min\": 0.01, \"max\": 8.0, \"step\": 0.01}),}}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"latent\"\n\n    def upscale(self, samples, upscale_method, scale_by):\n        s = samples.copy()\n        width = round(samples[\"samples\"].shape[-1] * scale_by)\n        height = round(samples[\"samples\"].shape[-2] * scale_by)\n        s[\"samples\"] = comfy.utils.common_upscale(samples[\"samples\"], width, height, upscale_method, \"disabled\")\n        return (s,)\n\nclass LatentRotate:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",),\n                              \"rotation\": ([\"none\", \"90 degrees\", \"180 degrees\", \"270 degrees\"],),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"rotate\"\n\n    CATEGORY = \"latent/transform\"\n\n    def rotate(self, samples, rotation):\n        s = samples.copy()\n        rotate_by = 0\n        if rotation.startswith(\"90\"):\n            rotate_by = 1\n        elif rotation.startswith(\"180\"):\n            rotate_by = 2\n        elif rotation.startswith(\"270\"):\n            rotate_by = 3\n\n        s[\"samples\"] = torch.rot90(samples[\"samples\"], k=rotate_by, dims=[3, 2])\n        return (s,)\n\nclass LatentFlip:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",),\n                              \"flip_method\": ([\"x-axis: vertically\", \"y-axis: horizontally\"],),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"flip\"\n\n    CATEGORY = \"latent/transform\"\n\n    def flip(self, samples, flip_method):\n        s = samples.copy()\n        if flip_method.startswith(\"x\"):\n            s[\"samples\"] = torch.flip(samples[\"samples\"], dims=[2])\n        elif flip_method.startswith(\"y\"):\n            s[\"samples\"] = torch.flip(samples[\"samples\"], dims=[3])\n\n        return (s,)\n\nclass LatentComposite:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples_to\": (\"LATENT\",),\n                              \"samples_from\": (\"LATENT\",),\n                              \"x\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"y\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"feather\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"composite\"\n\n    CATEGORY = \"latent\"\n\n    def composite(self, samples_to, samples_from, x, y, composite_method=\"normal\", feather=0):\n        x =  x // 8\n        y = y // 8\n        feather = feather // 8\n        samples_out = samples_to.copy()\n        s = samples_to[\"samples\"].clone()\n        samples_to = samples_to[\"samples\"]\n        samples_from = samples_from[\"samples\"]\n        if feather == 0:\n            s[:,:,y:y+samples_from.shape[2],x:x+samples_from.shape[3]] = samples_from[:,:,:samples_to.shape[2] - y, :samples_to.shape[3] - x]\n        else:\n            samples_from = samples_from[:,:,:samples_to.shape[2] - y, :samples_to.shape[3] - x]\n            mask = torch.ones_like(samples_from)\n            for t in range(feather):\n                if y != 0:\n                    mask[:,:,t:1+t,:] *= ((1.0/feather) * (t + 1))\n\n                if y + samples_from.shape[2] < samples_to.shape[2]:\n                    mask[:,:,mask.shape[2] -1 -t: mask.shape[2]-t,:] *= ((1.0/feather) * (t + 1))\n                if x != 0:\n                    mask[:,:,:,t:1+t] *= ((1.0/feather) * (t + 1))\n                if x + samples_from.shape[3] < samples_to.shape[3]:\n                    mask[:,:,:,mask.shape[3]- 1 - t: mask.shape[3]- t] *= ((1.0/feather) * (t + 1))\n            rev_mask = torch.ones_like(mask) - mask\n            s[:,:,y:y+samples_from.shape[2],x:x+samples_from.shape[3]] = samples_from[:,:,:samples_to.shape[2] - y, :samples_to.shape[3] - x] * mask + s[:,:,y:y+samples_from.shape[2],x:x+samples_from.shape[3]] * rev_mask\n        samples_out[\"samples\"] = s\n        return (samples_out,)\n\nclass LatentBlend:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\n            \"samples1\": (\"LATENT\",),\n            \"samples2\": (\"LATENT\",),\n            \"blend_factor\": (\"FLOAT\", {\n                \"default\": 0.5,\n                \"min\": 0,\n                \"max\": 1,\n                \"step\": 0.01\n            }),\n        }}\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"blend\"\n\n    CATEGORY = \"_for_testing\"\n\n    def blend(self, samples1, samples2, blend_factor:float, blend_mode: str=\"normal\"):\n\n        samples_out = samples1.copy()\n        samples1 = samples1[\"samples\"]\n        samples2 = samples2[\"samples\"]\n\n        if samples1.shape != samples2.shape:\n            samples2.permute(0, 3, 1, 2)\n            samples2 = comfy.utils.common_upscale(samples2, samples1.shape[3], samples1.shape[2], 'bicubic', crop='center')\n            samples2.permute(0, 2, 3, 1)\n\n        samples_blended = self.blend_mode(samples1, samples2, blend_mode)\n        samples_blended = samples1 * blend_factor + samples_blended * (1 - blend_factor)\n        samples_out[\"samples\"] = samples_blended\n        return (samples_out,)\n\n    def blend_mode(self, img1, img2, mode):\n        if mode == \"normal\":\n            return img2\n        else:\n            raise ValueError(f\"Unsupported blend mode: {mode}\")\n\nclass LatentCrop:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",),\n                              \"width\": (\"INT\", {\"default\": 512, \"min\": 64, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 64, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"x\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              \"y\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"crop\"\n\n    CATEGORY = \"latent/transform\"\n\n    def crop(self, samples, width, height, x, y):\n        s = samples.copy()\n        samples = samples['samples']\n        x =  x // 8\n        y = y // 8\n\n        #enfonce minimum size of 64\n        if x > (samples.shape[3] - 8):\n            x = samples.shape[3] - 8\n        if y > (samples.shape[2] - 8):\n            y = samples.shape[2] - 8\n\n        new_height = height // 8\n        new_width = width // 8\n        to_x = new_width + x\n        to_y = new_height + y\n        s['samples'] = samples[:,:,y:to_y, x:to_x]\n        return (s,)\n\nclass SetLatentNoiseMask:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples\": (\"LATENT\",),\n                              \"mask\": (\"MASK\",),\n                              }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"set_mask\"\n\n    CATEGORY = \"latent/inpaint\"\n\n    def set_mask(self, samples, mask):\n        s = samples.copy()\n        s[\"noise_mask\"] = mask.reshape((-1, 1, mask.shape[-2], mask.shape[-1]))\n        return (s,)\n\ndef common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent, denoise=1.0, disable_noise=False, start_step=None, last_step=None, force_full_denoise=False):\n    latent_image = latent[\"samples\"]\n    latent_image = comfy.sample.fix_empty_latent_channels(model, latent_image)\n\n    if disable_noise:\n        noise = torch.zeros(latent_image.size(), dtype=latent_image.dtype, layout=latent_image.layout, device=\"cpu\")\n    else:\n        batch_inds = latent[\"batch_index\"] if \"batch_index\" in latent else None\n        noise = comfy.sample.prepare_noise(latent_image, seed, batch_inds)\n\n    noise_mask = None\n    if \"noise_mask\" in latent:\n        noise_mask = latent[\"noise_mask\"]\n\n    callback = latent_preview.prepare_callback(model, steps)\n    disable_pbar = not comfy.utils.PROGRESS_BAR_ENABLED\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n                                  denoise=denoise, disable_noise=disable_noise, start_step=start_step, last_step=last_step,\n                                  force_full_denoise=force_full_denoise, noise_mask=noise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n    out = latent.copy()\n    out[\"samples\"] = samples\n    return (out, )\n\nclass KSampler:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"model\": (\"MODEL\", {\"tooltip\": \"The model used for denoising the input latent.\"}),\n                \"seed\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 0xffffffffffffffff, \"tooltip\": \"The random seed used for creating the noise.\"}),\n                \"steps\": (\"INT\", {\"default\": 20, \"min\": 1, \"max\": 10000, \"tooltip\": \"The number of steps used in the denoising process.\"}),\n                \"cfg\": (\"FLOAT\", {\"default\": 8.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.1, \"round\": 0.01, \"tooltip\": \"The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality.\"}),\n                \"sampler_name\": (comfy.samplers.KSampler.SAMPLERS, {\"tooltip\": \"The algorithm used when sampling, this can affect the quality, speed, and style of the generated output.\"}),\n                \"scheduler\": (comfy.samplers.KSampler.SCHEDULERS, {\"tooltip\": \"The scheduler controls how noise is gradually removed to form the image.\"}),\n                \"positive\": (\"CONDITIONING\", {\"tooltip\": \"The conditioning describing the attributes you want to include in the image.\"}),\n                \"negative\": (\"CONDITIONING\", {\"tooltip\": \"The conditioning describing the attributes you want to exclude from the image.\"}),\n                \"latent_image\": (\"LATENT\", {\"tooltip\": \"The latent image to denoise.\"}),\n                \"denoise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01, \"tooltip\": \"The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling.\"}),\n            }\n        }\n\n    RETURN_TYPES = (\"LATENT\",)\n    OUTPUT_TOOLTIPS = (\"The denoised latent.\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n    DESCRIPTION = \"Uses the provided model, positive and negative conditioning to denoise the latent image.\"\n\n    def sample(self, model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0):\n        return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n\nclass KSamplerAdvanced:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"model\": (\"MODEL\",),\n                    \"add_noise\": ([\"enable\", \"disable\"], ),\n                    \"noise_seed\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 0xffffffffffffffff}),\n                    \"steps\": (\"INT\", {\"default\": 20, \"min\": 1, \"max\": 10000}),\n                    \"cfg\": (\"FLOAT\", {\"default\": 8.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.1, \"round\": 0.01}),\n                    \"sampler_name\": (comfy.samplers.KSampler.SAMPLERS, ),\n                    \"scheduler\": (comfy.samplers.KSampler.SCHEDULERS, ),\n                    \"positive\": (\"CONDITIONING\", ),\n                    \"negative\": (\"CONDITIONING\", ),\n                    \"latent_image\": (\"LATENT\", ),\n                    \"start_at_step\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 10000}),\n                    \"end_at_step\": (\"INT\", {\"default\": 10000, \"min\": 0, \"max\": 10000}),\n                    \"return_with_leftover_noise\": ([\"disable\", \"enable\"], ),\n                     }\n                }\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n\n    def sample(self, model, add_noise, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, start_at_step, end_at_step, return_with_leftover_noise, denoise=1.0):\n        force_full_denoise = True\n        if return_with_leftover_noise == \"enable\":\n            force_full_denoise = False\n        disable_noise = False\n        if add_noise == \"disable\":\n            disable_noise = True\n        return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)\n\nclass SaveImage:\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n        self.type = \"output\"\n        self.prefix_append = \"\"\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"images\": (\"IMAGE\", {\"tooltip\": \"The images to save.\"}),\n                \"filename_prefix\": (\"STRING\", {\"default\": \"ComfyUI\", \"tooltip\": \"The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.\"})\n            },\n            \"hidden\": {\n                \"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"\n            },\n        }\n\n    RETURN_TYPES = ()\n    FUNCTION = \"save_images\"\n\n    OUTPUT_NODE = True\n\n    CATEGORY = \"image\"\n    DESCRIPTION = \"Saves the input images to your ComfyUI output directory.\"\n\n    def save_images(self, images, filename_prefix=\"ComfyUI\", prompt=None, extra_pnginfo=None):\n        filename_prefix += self.prefix_append\n        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(filename_prefix, self.output_dir, images[0].shape[1], images[0].shape[0])\n        results = list()\n        for (batch_number, image) in enumerate(images):\n            i = 255. * image.cpu().numpy()\n            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n            metadata = None\n            if not args.disable_metadata:\n                metadata = PngInfo()\n                if prompt is not None:\n                    metadata.add_text(\"prompt\", json.dumps(prompt))\n                if extra_pnginfo is not None:\n                    for x in extra_pnginfo:\n                        metadata.add_text(x, json.dumps(extra_pnginfo[x]))\n\n            filename_with_batch_num = filename.replace(\"%batch_num%\", str(batch_number))\n            file = f\"{filename_with_batch_num}_{counter:05}_.png\"\n            img.save(os.path.join(full_output_folder, file), pnginfo=metadata, compress_level=self.compress_level)\n            results.append({\n                \"filename\": file,\n                \"subfolder\": subfolder,\n                \"type\": self.type\n            })\n            counter += 1\n\n        return { \"ui\": { \"images\": results } }\n\nclass PreviewImage(SaveImage):\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + ''.join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for x in range(5))\n        self.compress_level = 1\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"images\": (\"IMAGE\", ), },\n                \"hidden\": {\"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"},\n                }\n\nclass LoadImage:\n    @classmethod\n    def INPUT_TYPES(s):\n        input_dir = folder_paths.get_input_directory()\n        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n        return {\"required\":\n                    {\"image\": (sorted(files), {\"image_upload\": True})},\n                }\n\n    CATEGORY = \"image\"\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"load_image\"\n    def load_image(self, image):\n        image_path = folder_paths.get_annotated_filepath(image)\n\n        img = node_helpers.pillow(Image.open, image_path)\n\n        output_images = []\n        output_masks = []\n        w, h = None, None\n\n        excluded_formats = ['MPO']\n\n        for i in ImageSequence.Iterator(img):\n            i = node_helpers.pillow(ImageOps.exif_transpose, i)\n\n            if i.mode == 'I':\n                i = i.point(lambda i: i * (1 / 255))\n            image = i.convert(\"RGB\")\n\n            if len(output_images) == 0:\n                w = image.size[0]\n                h = image.size[1]\n\n            if image.size[0] != w or image.size[1] != h:\n                continue\n\n            image = np.array(image).astype(np.float32) / 255.0\n            image = torch.from_numpy(image)[None,]\n            if 'A' in i.getbands():\n                mask = np.array(i.getchannel('A')).astype(np.float32) / 255.0\n                mask = 1. - torch.from_numpy(mask)\n            else:\n                mask = torch.zeros((64,64), dtype=torch.float32, device=\"cpu\")\n            output_images.append(image)\n            output_masks.append(mask.unsqueeze(0))\n\n        if len(output_images) > 1 and img.format not in excluded_formats:\n            output_image = torch.cat(output_images, dim=0)\n            output_mask = torch.cat(output_masks, dim=0)\n        else:\n            output_image = output_images[0]\n            output_mask = output_masks[0]\n\n        return (output_image, output_mask)\n\n    @classmethod\n    def IS_CHANGED(s, image):\n        image_path = folder_paths.get_annotated_filepath(image)\n        m = hashlib.sha256()\n        with open(image_path, 'rb') as f:\n            m.update(f.read())\n        return m.digest().hex()\n\n    @classmethod\n    def VALIDATE_INPUTS(s, image):\n        if not folder_paths.exists_annotated_filepath(image):\n            return \"Invalid image file: {}\".format(image)\n\n        return True\n\nclass LoadImageMask:\n    _color_channels = [\"alpha\", \"red\", \"green\", \"blue\"]\n    @classmethod\n    def INPUT_TYPES(s):\n        input_dir = folder_paths.get_input_directory()\n        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n        return {\"required\":\n                    {\"image\": (sorted(files), {\"image_upload\": True}),\n                     \"channel\": (s._color_channels, ), }\n                }\n\n    CATEGORY = \"mask\"\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"load_image\"\n    def load_image(self, image, channel):\n        image_path = folder_paths.get_annotated_filepath(image)\n        i = node_helpers.pillow(Image.open, image_path)\n        i = node_helpers.pillow(ImageOps.exif_transpose, i)\n        if i.getbands() != (\"R\", \"G\", \"B\", \"A\"):\n            if i.mode == 'I':\n                i = i.point(lambda i: i * (1 / 255))\n            i = i.convert(\"RGBA\")\n        mask = None\n        c = channel[0].upper()\n        if c in i.getbands():\n            mask = np.array(i.getchannel(c)).astype(np.float32) / 255.0\n            mask = torch.from_numpy(mask)\n            if c == 'A':\n                mask = 1. - mask\n        else:\n            mask = torch.zeros((64,64), dtype=torch.float32, device=\"cpu\")\n        return (mask.unsqueeze(0),)\n\n    @classmethod\n    def IS_CHANGED(s, image, channel):\n        image_path = folder_paths.get_annotated_filepath(image)\n        m = hashlib.sha256()\n        with open(image_path, 'rb') as f:\n            m.update(f.read())\n        return m.digest().hex()\n\n    @classmethod\n    def VALIDATE_INPUTS(s, image):\n        if not folder_paths.exists_annotated_filepath(image):\n            return \"Invalid image file: {}\".format(image)\n\n        return True\n\nclass ImageScale:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n    crop_methods = [\"disabled\", \"center\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",), \"upscale_method\": (s.upscale_methods,),\n                              \"width\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"crop\": (s.crop_methods,)}}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, width, height, crop):\n        if width == 0 and height == 0:\n            s = image\n        else:\n            samples = image.movedim(-1,1)\n\n            if width == 0:\n                width = max(1, round(samples.shape[3] * height / samples.shape[2]))\n            elif height == 0:\n                height = max(1, round(samples.shape[2] * width / samples.shape[3]))\n\n            s = comfy.utils.common_upscale(samples, width, height, upscale_method, crop)\n            s = s.movedim(1,-1)\n        return (s,)\n\nclass ImageScaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",), \"upscale_method\": (s.upscale_methods,),\n                              \"scale_by\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.01, \"max\": 8.0, \"step\": 0.01}),}}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, scale_by):\n        samples = image.movedim(-1,1)\n        width = round(samples.shape[3] * scale_by)\n        height = round(samples.shape[2] * scale_by)\n        s = comfy.utils.common_upscale(samples, width, height, upscale_method, \"disabled\")\n        s = s.movedim(1,-1)\n        return (s,)\n\nclass ImageInvert:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"invert\"\n\n    CATEGORY = \"image\"\n\n    def invert(self, image):\n        s = 1.0 - image\n        return (s,)\n\nclass ImageBatch:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image1\": (\"IMAGE\",), \"image2\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"batch\"\n\n    CATEGORY = \"image\"\n\n    def batch(self, image1, image2):\n        if image1.shape[1:] != image2.shape[1:]:\n            image2 = comfy.utils.common_upscale(image2.movedim(-1,1), image1.shape[2], image1.shape[1], \"bilinear\", \"center\").movedim(1,-1)\n        s = torch.cat((image1, image2), dim=0)\n        return (s,)\n\nclass EmptyImage:\n    def __init__(self, device=\"cpu\"):\n        self.device = device\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"width\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                              \"color\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 0xFFFFFF, \"step\": 1, \"display\": \"color\"}),\n                              }}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"image\"\n\n    def generate(self, width, height, batch_size=1, color=0):\n        r = torch.full([batch_size, height, width, 1], ((color >> 16) & 0xFF) / 0xFF)\n        g = torch.full([batch_size, height, width, 1], ((color >> 8) & 0xFF) / 0xFF)\n        b = torch.full([batch_size, height, width, 1], ((color) & 0xFF) / 0xFF)\n        return (torch.cat((r, g, b), dim=-1), )\n\nclass ImagePadForOutpaint:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"left\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"top\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"right\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"bottom\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"feathering\": (\"INT\", {\"default\": 40, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"expand_image\"\n\n    CATEGORY = \"image\"\n\n    def expand_image(self, image, left, top, right, bottom, feathering):\n        d1, d2, d3, d4 = image.size()\n\n        new_image = torch.ones(\n            (d1, d2 + top + bottom, d3 + left + right, d4),\n            dtype=torch.float32,\n        ) * 0.5\n\n        new_image[:, top:top + d2, left:left + d3, :] = image\n\n        mask = torch.ones(\n            (d2 + top + bottom, d3 + left + right),\n            dtype=torch.float32,\n        )\n\n        t = torch.zeros(\n            (d2, d3),\n            dtype=torch.float32\n        )\n\n        if feathering > 0 and feathering * 2 < d2 and feathering * 2 < d3:\n\n            for i in range(d2):\n                for j in range(d3):\n                    dt = i if top != 0 else d2\n                    db = d2 - i if bottom != 0 else d2\n\n                    dl = j if left != 0 else d3\n                    dr = d3 - j if right != 0 else d3\n\n                    d = min(dt, db, dl, dr)\n\n                    if d >= feathering:\n                        continue\n\n                    v = (feathering - d) / feathering\n\n                    t[i, j] = v * v\n\n        mask[top:top + d2, left:left + d3] = t\n\n        return (new_image, mask)\n\n\nNODE_CLASS_MAPPINGS = {\n    \"KSampler\": KSampler,\n    \"CheckpointLoaderSimple\": CheckpointLoaderSimple,\n    \"CLIPTextEncode\": CLIPTextEncode,\n    \"CLIPSetLastLayer\": CLIPSetLastLayer,\n    \"VAEDecode\": VAEDecode,\n    \"VAEEncode\": VAEEncode,\n    \"VAEEncodeForInpaint\": VAEEncodeForInpaint,\n    \"VAELoader\": VAELoader,\n    \"EmptyLatentImage\": EmptyLatentImage,\n    \"LatentUpscale\": LatentUpscale,\n    \"LatentUpscaleBy\": LatentUpscaleBy,\n    \"LatentFromBatch\": LatentFromBatch,\n    \"RepeatLatentBatch\": RepeatLatentBatch,\n    \"SaveImage\": SaveImage,\n    \"PreviewImage\": PreviewImage,\n    \"LoadImage\": LoadImage,\n    \"LoadImageMask\": LoadImageMask,\n    \"ImageScale\": ImageScale,\n    \"ImageScaleBy\": ImageScaleBy,\n    \"ImageInvert\": ImageInvert,\n    \"ImageBatch\": ImageBatch,\n    \"ImagePadForOutpaint\": ImagePadForOutpaint,\n    \"EmptyImage\": EmptyImage,\n    \"ConditioningAverage\": ConditioningAverage ,\n    \"ConditioningCombine\": ConditioningCombine,\n    \"ConditioningConcat\": ConditioningConcat,\n    \"ConditioningSetArea\": ConditioningSetArea,\n    \"ConditioningSetAreaPercentage\": ConditioningSetAreaPercentage,\n    \"ConditioningSetAreaStrength\": ConditioningSetAreaStrength,\n    \"ConditioningSetMask\": ConditioningSetMask,\n    \"KSamplerAdvanced\": KSamplerAdvanced,\n    \"SetLatentNoiseMask\": SetLatentNoiseMask,\n    \"LatentComposite\": LatentComposite,\n    \"LatentBlend\": LatentBlend,\n    \"LatentRotate\": LatentRotate,\n    \"LatentFlip\": LatentFlip,\n    \"LatentCrop\": LatentCrop,\n    \"LoraLoader\": LoraLoader,\n    \"CLIPLoader\": CLIPLoader,\n    \"UNETLoader\": UNETLoader,\n    \"DualCLIPLoader\": DualCLIPLoader,\n    \"CLIPVisionEncode\": CLIPVisionEncode,\n    \"StyleModelApply\": StyleModelApply,\n    \"unCLIPConditioning\": unCLIPConditioning,\n    \"ControlNetApply\": ControlNetApply,\n    \"ControlNetApplyAdvanced\": ControlNetApplyAdvanced,\n    \"ControlNetLoader\": ControlNetLoader,\n    \"DiffControlNetLoader\": DiffControlNetLoader,\n    \"StyleModelLoader\": StyleModelLoader,\n    \"CLIPVisionLoader\": CLIPVisionLoader,\n    \"VAEDecodeTiled\": VAEDecodeTiled,\n    \"VAEEncodeTiled\": VAEEncodeTiled,\n    \"unCLIPCheckpointLoader\": unCLIPCheckpointLoader,\n    \"GLIGENLoader\": GLIGENLoader,\n    \"GLIGENTextBoxApply\": GLIGENTextBoxApply,\n    \"InpaintModelConditioning\": InpaintModelConditioning,\n\n    \"CheckpointLoader\": CheckpointLoader,\n    \"DiffusersLoader\": DiffusersLoader,\n\n    \"LoadLatent\": LoadLatent,\n    \"SaveLatent\": SaveLatent,\n\n    \"ConditioningZeroOut\": ConditioningZeroOut,\n    \"ConditioningSetTimestepRange\": ConditioningSetTimestepRange,\n    \"LoraLoaderModelOnly\": LoraLoaderModelOnly,\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    # Sampling\n    \"KSampler\": \"KSampler\",\n    \"KSamplerAdvanced\": \"KSampler (Advanced)\",\n    # Loaders\n    \"CheckpointLoader\": \"Load Checkpoint With Config (DEPRECATED)\",\n    \"CheckpointLoaderSimple\": \"Load Checkpoint\",\n    \"VAELoader\": \"Load VAE\",\n    \"LoraLoader\": \"Load LoRA\",\n    \"CLIPLoader\": \"Load CLIP\",\n    \"ControlNetLoader\": \"Load ControlNet Model\",\n    \"DiffControlNetLoader\": \"Load ControlNet Model (diff)\",\n    \"StyleModelLoader\": \"Load Style Model\",\n    \"CLIPVisionLoader\": \"Load CLIP Vision\",\n    \"UpscaleModelLoader\": \"Load Upscale Model\",\n    \"UNETLoader\": \"Load Diffusion Model\",\n    # Conditioning\n    \"CLIPVisionEncode\": \"CLIP Vision Encode\",\n    \"StyleModelApply\": \"Apply Style Model\",\n    \"CLIPTextEncode\": \"CLIP Text Encode (Prompt)\",\n    \"CLIPSetLastLayer\": \"CLIP Set Last Layer\",\n    \"ConditioningCombine\": \"Conditioning (Combine)\",\n    \"ConditioningAverage \": \"Conditioning (Average)\",\n    \"ConditioningConcat\": \"Conditioning (Concat)\",\n    \"ConditioningSetArea\": \"Conditioning (Set Area)\",\n    \"ConditioningSetAreaPercentage\": \"Conditioning (Set Area with Percentage)\",\n    \"ConditioningSetMask\": \"Conditioning (Set Mask)\",\n    \"ControlNetApply\": \"Apply ControlNet (OLD)\",\n    \"ControlNetApplyAdvanced\": \"Apply ControlNet\",\n    # Latent\n    \"VAEEncodeForInpaint\": \"VAE Encode (for Inpainting)\",\n    \"SetLatentNoiseMask\": \"Set Latent Noise Mask\",\n    \"VAEDecode\": \"VAE Decode\",\n    \"VAEEncode\": \"VAE Encode\",\n    \"LatentRotate\": \"Rotate Latent\",\n    \"LatentFlip\": \"Flip Latent\",\n    \"LatentCrop\": \"Crop Latent\",\n    \"EmptyLatentImage\": \"Empty Latent Image\",\n    \"LatentUpscale\": \"Upscale Latent\",\n    \"LatentUpscaleBy\": \"Upscale Latent By\",\n    \"LatentComposite\": \"Latent Composite\",\n    \"LatentBlend\": \"Latent Blend\",\n    \"LatentFromBatch\" : \"Latent From Batch\",\n    \"RepeatLatentBatch\": \"Repeat Latent Batch\",\n    # Image\n    \"SaveImage\": \"Save Image\",\n    \"PreviewImage\": \"Preview Image\",\n    \"LoadImage\": \"Load Image\",\n    \"LoadImageMask\": \"Load Image (as Mask)\",\n    \"ImageScale\": \"Upscale Image\",\n    \"ImageScaleBy\": \"Upscale Image By\",\n    \"ImageUpscaleWithModel\": \"Upscale Image (using Model)\",\n    \"ImageInvert\": \"Invert Image\",\n    \"ImagePadForOutpaint\": \"Pad Image for Outpainting\",\n    \"ImageBatch\": \"Batch Images\",\n    \"ImageCrop\": \"Image Crop\",\n    \"ImageBlend\": \"Image Blend\",\n    \"ImageBlur\": \"Image Blur\",\n    \"ImageQuantize\": \"Image Quantize\",\n    \"ImageSharpen\": \"Image Sharpen\",\n    \"ImageScaleToTotalPixels\": \"Scale Image to Total Pixels\",\n    # _for_testing\n    \"VAEDecodeTiled\": \"VAE Decode (Tiled)\",\n    \"VAEEncodeTiled\": \"VAE Encode (Tiled)\",\n}\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\ndef get_module_name(module_path: str) -> str:\n    \"\"\"\n    Returns the module name based on the given module path.\n    Examples:\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.disabled\") -> \"custom_nodes\n    Args:\n        module_path (str): The path of the module.\n    Returns:\n        str: The module name.\n    \"\"\"\n    base_path = os.path.basename(module_path)\n    if os.path.isfile(module_path):\n        base_path = os.path.splitext(base_path)[0]\n    return base_path\n\n\ndef load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    module_name = os.path.basename(module_path)\n    if os.path.isfile(module_path):\n        sp = os.path.splitext(module_path)\n        module_name = sp[0]\n    try:\n        logging.debug(\"Trying to load custom node {}\".format(module_path))\n        if os.path.isfile(module_path):\n            module_spec = importlib.util.spec_from_file_location(module_name, module_path)\n            module_dir = os.path.split(module_path)[0]\n        else:\n            module_spec = importlib.util.spec_from_file_location(module_name, os.path.join(module_path, \"__init__.py\"))\n            module_dir = module_path\n\n        module = importlib.util.module_from_spec(module_spec)\n        sys.modules[module_name] = module\n        module_spec.loader.exec_module(module)\n\n        LOADED_MODULE_DIRS[module_name] = os.path.abspath(module_dir)\n\n        if hasattr(module, \"WEB_DIRECTORY\") and getattr(module, \"WEB_DIRECTORY\") is not None:\n            web_dir = os.path.abspath(os.path.join(module_dir, getattr(module, \"WEB_DIRECTORY\")))\n            if os.path.isdir(web_dir):\n                EXTENSION_WEB_DIRS[module_name] = web_dir\n\n        if hasattr(module, \"NODE_CLASS_MAPPINGS\") and getattr(module, \"NODE_CLASS_MAPPINGS\") is not None:\n            for name, node_cls in module.NODE_CLASS_MAPPINGS.items():\n                if name not in ignore:\n                    NODE_CLASS_MAPPINGS[name] = node_cls\n                    node_cls.RELATIVE_PYTHON_MODULE = \"{}.{}\".format(module_parent, get_module_name(module_path))\n            if hasattr(module, \"NODE_DISPLAY_NAME_MAPPINGS\") and getattr(module, \"NODE_DISPLAY_NAME_MAPPINGS\") is not None:\n                NODE_DISPLAY_NAME_MAPPINGS.update(module.NODE_DISPLAY_NAME_MAPPINGS)\n            return True\n        else:\n            logging.warning(f\"Skip {module_path} module for custom nodes due to the lack of NODE_CLASS_MAPPINGS.\")\n            return False\n    except Exception as e:\n        logging.warning(traceback.format_exc())\n        logging.warning(f\"Cannot import {module_path} module for custom nodes: {e}\")\n        return False\n\ndef init_external_custom_nodes():\n    \"\"\"\n    Initializes the external custom nodes.\n\n    This function loads custom nodes from the specified folder paths and imports them into the application.\n    It measures the import times for each custom node and logs the results.\n\n    Returns:\n        None\n    \"\"\"\n    base_node_names = set(NODE_CLASS_MAPPINGS.keys())\n    node_paths = folder_paths.get_folder_paths(\"custom_nodes\")\n    node_import_times = []\n    for custom_node_path in node_paths:\n        possible_modules = os.listdir(os.path.realpath(custom_node_path))\n        if \"__pycache__\" in possible_modules:\n            possible_modules.remove(\"__pycache__\")\n\n        for possible_module in possible_modules:\n            module_path = os.path.join(custom_node_path, possible_module)\n            if os.path.isfile(module_path) and os.path.splitext(module_path)[1] != \".py\": continue\n            if module_path.endswith(\".disabled\"): continue\n            time_before = time.perf_counter()\n            success = load_custom_node(module_path, base_node_names, module_parent=\"custom_nodes\")\n            node_import_times.append((time.perf_counter() - time_before, module_path, success))\n\n    if len(node_import_times) > 0:\n        logging.info(\"\\nImport times for custom nodes:\")\n        for n in sorted(node_import_times):\n            if n[2]:\n                import_message = \"\"\n            else:\n                import_message = \" (IMPORT FAILED)\"\n            logging.info(\"{:6.1f} seconds{}: {}\".format(n[0], import_message, n[1]))\n        logging.info(\"\")\n\ndef init_builtin_extra_nodes():\n    \"\"\"\n    Initializes the built-in extra nodes in ComfyUI.\n\n    This function loads the extra node files located in the \"comfy_extras\" directory and imports them into ComfyUI.\n    If any of the extra node files fail to import, a warning message is logged.\n\n    Returns:\n        None\n    \"\"\"\n    extras_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_extras\")\n    extras_files = [\n        \"nodes_latent.py\",\n        \"nodes_hypernetwork.py\",\n        \"nodes_upscale_model.py\",\n        \"nodes_post_processing.py\",\n        \"nodes_mask.py\",\n        \"nodes_compositing.py\",\n        \"nodes_rebatch.py\",\n        \"nodes_model_merging.py\",\n        \"nodes_tomesd.py\",\n        \"nodes_clip_sdxl.py\",\n        \"nodes_canny.py\",\n        \"nodes_freelunch.py\",\n        \"nodes_custom_sampler.py\",\n        \"nodes_hypertile.py\",\n        \"nodes_model_advanced.py\",\n        \"nodes_model_downscale.py\",\n        \"nodes_images.py\",\n        \"nodes_video_model.py\",\n        \"nodes_sag.py\",\n        \"nodes_perpneg.py\",\n        \"nodes_stable3d.py\",\n        \"nodes_sdupscale.py\",\n        \"nodes_photomaker.py\",\n        \"nodes_pixart.py\",\n        \"nodes_cond.py\",\n        \"nodes_morphology.py\",\n        \"nodes_stable_cascade.py\",\n        \"nodes_differential_diffusion.py\",\n        \"nodes_ip2p.py\",\n        \"nodes_model_merging_model_specific.py\",\n        \"nodes_pag.py\",\n        \"nodes_align_your_steps.py\",\n        \"nodes_attention_multiply.py\",\n        \"nodes_advanced_samplers.py\",\n        \"nodes_webcam.py\",\n        \"nodes_audio.py\",\n        \"nodes_sd3.py\",\n        \"nodes_gits.py\",\n        \"nodes_controlnet.py\",\n        \"nodes_hunyuan.py\",\n        \"nodes_flux.py\",\n        \"nodes_lora_extract.py\",\n        \"nodes_torch_compile.py\",\n        \"nodes_mochi.py\",\n        \"nodes_slg.py\",\n        \"nodes_mahiro.py\",\n        \"nodes_lt.py\",\n        \"nodes_hooks.py\",\n        \"nodes_load_3d.py\",\n        \"nodes_cosmos.py\",\n    ]\n\n    import_failed = []\n    for node_file in extras_files:\n        if not load_custom_node(os.path.join(extras_dir, node_file), module_parent=\"comfy_extras\"):\n            import_failed.append(node_file)\n\n    return import_failed\n\n\ndef init_extra_nodes(init_custom_nodes=True):\n    import_failed = init_builtin_extra_nodes()\n\n    if init_custom_nodes:\n        init_external_custom_nodes()\n    else:\n        logging.info(\"Skipping loading of custom nodes\")\n\n    if len(import_failed) > 0:\n        logging.warning(\"WARNING: some comfy_extras/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    return import_failed\n"
        },
        {
          "name": "notebooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "output",
          "type": "tree",
          "content": null
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.22,
          "content": "[pytest]\nmarkers = \n  inference: mark as inference test (deselect with '-m \"not inference\"')\n  execution: mark as execution test (deselect with '-m \"not execution\"')\ntestpaths =\n  tests\n  tests-unit\naddopts = -s\npythonpath = .\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.22,
          "content": "torch\ntorchsde\ntorchvision\ntorchaudio\neinops\ntransformers>=4.28.1\ntokenizers>=0.13.3\nsentencepiece\nsafetensors>=0.4.2\naiohttp\npyyaml\nPillow\nscipy\ntqdm\npsutil\n\n#non essential dependencies:\nkornia>=0.7.1\nspandrel\nsoundfile\n"
        },
        {
          "name": "ruff.toml",
          "type": "blob",
          "size": 0.4,
          "content": "# Disable all rules by default\nlint.ignore = [\"ALL\"]\n\n# Enable specific rules\nlint.select = [\n    \"S307\",  # suspicious-eval-usage\n    \"S102\", # exec\n    \"T\",  # print-usage\n    \"W\",\n    # The \"F\" series in Ruff stands for \"Pyflakes\" rules, which catch various Python syntax errors and undefined names.\n    # See all rules here: https://docs.astral.sh/ruff/rules/#pyflakes-f\n    \"F\",\n]\n\nexclude = [\"*.ipynb\"]\n"
        },
        {
          "name": "script_examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "server.py",
          "type": "blob",
          "size": 35.24,
          "content": "import os\nimport sys\nimport asyncio\nimport traceback\n\nimport nodes\nimport folder_paths\nimport execution\nimport uuid\nimport urllib\nimport json\nimport glob\nimport struct\nimport ssl\nimport socket\nimport ipaddress\nfrom PIL import Image, ImageOps\nfrom PIL.PngImagePlugin import PngInfo\nfrom io import BytesIO\n\nimport aiohttp\nfrom aiohttp import web\nimport logging\n\nimport mimetypes\nfrom comfy.cli_args import args\nimport comfy.utils\nimport comfy.model_management\nimport node_helpers\nfrom app.frontend_management import FrontendManager\nfrom app.user_manager import UserManager\nfrom app.model_manager import ModelFileManager\nfrom app.custom_node_manager import CustomNodeManager\nfrom typing import Optional\nfrom api_server.routes.internal.internal_routes import InternalRoutes\n\nclass BinaryEventTypes:\n    PREVIEW_IMAGE = 1\n    UNENCODED_PREVIEW_IMAGE = 2\n\nasync def send_socket_catch_exception(function, message):\n    try:\n        await function(message)\n    except (aiohttp.ClientError, aiohttp.ClientPayloadError, ConnectionResetError, BrokenPipeError, ConnectionError) as err:\n        logging.warning(\"send error: {}\".format(err))\n\ndef get_comfyui_version():\n    comfyui_version = \"unknown\"\n    repo_path = os.path.dirname(os.path.realpath(__file__))\n    try:\n        import pygit2\n        repo = pygit2.Repository(repo_path)\n        comfyui_version = repo.describe(describe_strategy=pygit2.GIT_DESCRIBE_TAGS)\n    except Exception:\n        try:\n            import subprocess\n            comfyui_version = subprocess.check_output([\"git\", \"describe\", \"--tags\"], cwd=repo_path).decode('utf-8')\n        except Exception as e:\n            logging.warning(f\"Failed to get ComfyUI version: {e}\")\n    return comfyui_version.strip()\n\n@web.middleware\nasync def cache_control(request: web.Request, handler):\n    response: web.Response = await handler(request)\n    if request.path.endswith('.js') or request.path.endswith('.css'):\n        response.headers.setdefault('Cache-Control', 'no-cache')\n    return response\n\ndef create_cors_middleware(allowed_origin: str):\n    @web.middleware\n    async def cors_middleware(request: web.Request, handler):\n        if request.method == \"OPTIONS\":\n            # Pre-flight request. Reply successfully:\n            response = web.Response()\n        else:\n            response = await handler(request)\n\n        response.headers['Access-Control-Allow-Origin'] = allowed_origin\n        response.headers['Access-Control-Allow-Methods'] = 'POST, GET, DELETE, PUT, OPTIONS'\n        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'\n        response.headers['Access-Control-Allow-Credentials'] = 'true'\n        return response\n\n    return cors_middleware\n\ndef is_loopback(host):\n    if host is None:\n        return False\n    try:\n        if ipaddress.ip_address(host).is_loopback:\n            return True\n        else:\n            return False\n    except:\n        pass\n\n    loopback = False\n    for family in (socket.AF_INET, socket.AF_INET6):\n        try:\n            r = socket.getaddrinfo(host, None, family, socket.SOCK_STREAM)\n            for family, _, _, _, sockaddr in r:\n                if not ipaddress.ip_address(sockaddr[0]).is_loopback:\n                    return loopback\n                else:\n                    loopback = True\n        except socket.gaierror:\n            pass\n\n    return loopback\n\n\ndef create_origin_only_middleware():\n    @web.middleware\n    async def origin_only_middleware(request: web.Request, handler):\n        #this code is used to prevent the case where a random website can queue comfy workflows by making a POST to 127.0.0.1 which browsers don't prevent for some dumb reason.\n        #in that case the Host and Origin hostnames won't match\n        #I know the proper fix would be to add a cookie but this should take care of the problem in the meantime\n        if 'Host' in request.headers and 'Origin' in request.headers:\n            host = request.headers['Host']\n            origin = request.headers['Origin']\n            host_domain = host.lower()\n            parsed = urllib.parse.urlparse(origin)\n            origin_domain = parsed.netloc.lower()\n            host_domain_parsed = urllib.parse.urlsplit('//' + host_domain)\n\n            #limit the check to when the host domain is localhost, this makes it slightly less safe but should still prevent the exploit\n            loopback = is_loopback(host_domain_parsed.hostname)\n\n            if parsed.port is None: #if origin doesn't have a port strip it from the host to handle weird browsers, same for host\n                host_domain = host_domain_parsed.hostname\n            if host_domain_parsed.port is None:\n                origin_domain = parsed.hostname\n\n            if loopback and host_domain is not None and origin_domain is not None and len(host_domain) > 0 and len(origin_domain) > 0:\n                if host_domain != origin_domain:\n                    logging.warning(\"WARNING: request with non matching host and origin {} != {}, returning 403\".format(host_domain, origin_domain))\n                    return web.Response(status=403)\n\n        if request.method == \"OPTIONS\":\n            response = web.Response()\n        else:\n            response = await handler(request)\n\n        return response\n\n    return origin_only_middleware\n\nclass PromptServer():\n    def __init__(self, loop):\n        PromptServer.instance = self\n\n        mimetypes.init()\n        mimetypes.types_map['.js'] = 'application/javascript; charset=utf-8'\n\n        self.user_manager = UserManager()\n        self.model_file_manager = ModelFileManager()\n        self.custom_node_manager = CustomNodeManager()\n        self.internal_routes = InternalRoutes(self)\n        self.supports = [\"custom_nodes_from_web\"]\n        self.prompt_queue = None\n        self.loop = loop\n        self.messages = asyncio.Queue()\n        self.client_session:Optional[aiohttp.ClientSession] = None\n        self.number = 0\n\n        middlewares = [cache_control]\n        if args.enable_cors_header:\n            middlewares.append(create_cors_middleware(args.enable_cors_header))\n        else:\n            middlewares.append(create_origin_only_middleware())\n\n        max_upload_size = round(args.max_upload_size * 1024 * 1024)\n        self.app = web.Application(client_max_size=max_upload_size, middlewares=middlewares)\n        self.sockets = dict()\n        self.web_root = (\n            FrontendManager.init_frontend(args.front_end_version)\n            if args.front_end_root is None\n            else args.front_end_root\n        )\n        logging.info(f\"[Prompt Server] web root: {self.web_root}\")\n        routes = web.RouteTableDef()\n        self.routes = routes\n        self.last_node_id = None\n        self.client_id = None\n\n        self.on_prompt_handlers = []\n\n        @routes.get('/ws')\n        async def websocket_handler(request):\n            ws = web.WebSocketResponse()\n            await ws.prepare(request)\n            sid = request.rel_url.query.get('clientId', '')\n            if sid:\n                # Reusing existing session, remove old\n                self.sockets.pop(sid, None)\n            else:\n                sid = uuid.uuid4().hex\n\n            self.sockets[sid] = ws\n\n            try:\n                # Send initial state to the new client\n                await self.send(\"status\", { \"status\": self.get_queue_info(), 'sid': sid }, sid)\n                # On reconnect if we are the currently executing client send the current node\n                if self.client_id == sid and self.last_node_id is not None:\n                    await self.send(\"executing\", { \"node\": self.last_node_id }, sid)\n\n                async for msg in ws:\n                    if msg.type == aiohttp.WSMsgType.ERROR:\n                        logging.warning('ws connection closed with exception %s' % ws.exception())\n            finally:\n                self.sockets.pop(sid, None)\n            return ws\n\n        @routes.get(\"/\")\n        async def get_root(request):\n            response = web.FileResponse(os.path.join(self.web_root, \"index.html\"))\n            response.headers['Cache-Control'] = 'no-cache'\n            response.headers[\"Pragma\"] = \"no-cache\"\n            response.headers[\"Expires\"] = \"0\"\n            return response\n\n        @routes.get(\"/embeddings\")\n        def get_embeddings(self):\n            embeddings = folder_paths.get_filename_list(\"embeddings\")\n            return web.json_response(list(map(lambda a: os.path.splitext(a)[0], embeddings)))\n\n        @routes.get(\"/models\")\n        def list_model_types(request):\n            model_types = list(folder_paths.folder_names_and_paths.keys())\n\n            return web.json_response(model_types)\n\n        @routes.get(\"/models/{folder}\")\n        async def get_models(request):\n            folder = request.match_info.get(\"folder\", None)\n            if not folder in folder_paths.folder_names_and_paths:\n                return web.Response(status=404)\n            files = folder_paths.get_filename_list(folder)\n            return web.json_response(files)\n\n        @routes.get(\"/extensions\")\n        async def get_extensions(request):\n            files = glob.glob(os.path.join(\n                glob.escape(self.web_root), 'extensions/**/*.js'), recursive=True)\n\n            extensions = list(map(lambda f: \"/\" + os.path.relpath(f, self.web_root).replace(\"\\\\\", \"/\"), files))\n\n            for name, dir in nodes.EXTENSION_WEB_DIRS.items():\n                files = glob.glob(os.path.join(glob.escape(dir), '**/*.js'), recursive=True)\n                extensions.extend(list(map(lambda f: \"/extensions/\" + urllib.parse.quote(\n                    name) + \"/\" + os.path.relpath(f, dir).replace(\"\\\\\", \"/\"), files)))\n\n            return web.json_response(extensions)\n\n        def get_dir_by_type(dir_type):\n            if dir_type is None:\n                dir_type = \"input\"\n\n            if dir_type == \"input\":\n                type_dir = folder_paths.get_input_directory()\n            elif dir_type == \"temp\":\n                type_dir = folder_paths.get_temp_directory()\n            elif dir_type == \"output\":\n                type_dir = folder_paths.get_output_directory()\n\n            return type_dir, dir_type\n\n        def compare_image_hash(filepath, image):\n            hasher = node_helpers.hasher()\n\n            # function to compare hashes of two images to see if it already exists, fix to #3465\n            if os.path.exists(filepath):\n                a = hasher()\n                b = hasher()\n                with open(filepath, \"rb\") as f:\n                    a.update(f.read())\n                    b.update(image.file.read())\n                    image.file.seek(0)\n                    f.close()\n                return a.hexdigest() == b.hexdigest()\n            return False\n\n        def image_upload(post, image_save_function=None):\n            image = post.get(\"image\")\n            overwrite = post.get(\"overwrite\")\n            image_is_duplicate = False\n\n            image_upload_type = post.get(\"type\")\n            upload_dir, image_upload_type = get_dir_by_type(image_upload_type)\n\n            if image and image.file:\n                filename = image.filename\n                if not filename:\n                    return web.Response(status=400)\n\n                subfolder = post.get(\"subfolder\", \"\")\n                full_output_folder = os.path.join(upload_dir, os.path.normpath(subfolder))\n                filepath = os.path.abspath(os.path.join(full_output_folder, filename))\n\n                if os.path.commonpath((upload_dir, filepath)) != upload_dir:\n                    return web.Response(status=400)\n\n                if not os.path.exists(full_output_folder):\n                    os.makedirs(full_output_folder)\n\n                split = os.path.splitext(filename)\n\n                if overwrite is not None and (overwrite == \"true\" or overwrite == \"1\"):\n                    pass\n                else:\n                    i = 1\n                    while os.path.exists(filepath):\n                        if compare_image_hash(filepath, image): #compare hash to prevent saving of duplicates with same name, fix for #3465\n                            image_is_duplicate = True\n                            break\n                        filename = f\"{split[0]} ({i}){split[1]}\"\n                        filepath = os.path.join(full_output_folder, filename)\n                        i += 1\n\n                if not image_is_duplicate:\n                    if image_save_function is not None:\n                        image_save_function(image, post, filepath)\n                    else:\n                        with open(filepath, \"wb\") as f:\n                            f.write(image.file.read())\n\n                return web.json_response({\"name\" : filename, \"subfolder\": subfolder, \"type\": image_upload_type})\n            else:\n                return web.Response(status=400)\n\n        @routes.post(\"/upload/image\")\n        async def upload_image(request):\n            post = await request.post()\n            return image_upload(post)\n\n\n        @routes.post(\"/upload/mask\")\n        async def upload_mask(request):\n            post = await request.post()\n\n            def image_save_function(image, post, filepath):\n                original_ref = json.loads(post.get(\"original_ref\"))\n                filename, output_dir = folder_paths.annotated_filepath(original_ref['filename'])\n\n                # validation for security: prevent accessing arbitrary path\n                if filename[0] == '/' or '..' in filename:\n                    return web.Response(status=400)\n\n                if output_dir is None:\n                    type = original_ref.get(\"type\", \"output\")\n                    output_dir = folder_paths.get_directory_by_type(type)\n\n                if output_dir is None:\n                    return web.Response(status=400)\n\n                if original_ref.get(\"subfolder\", \"\") != \"\":\n                    full_output_dir = os.path.join(output_dir, original_ref[\"subfolder\"])\n                    if os.path.commonpath((os.path.abspath(full_output_dir), output_dir)) != output_dir:\n                        return web.Response(status=403)\n                    output_dir = full_output_dir\n\n                file = os.path.join(output_dir, filename)\n\n                if os.path.isfile(file):\n                    with Image.open(file) as original_pil:\n                        metadata = PngInfo()\n                        if hasattr(original_pil,'text'):\n                            for key in original_pil.text:\n                                metadata.add_text(key, original_pil.text[key])\n                        original_pil = original_pil.convert('RGBA')\n                        mask_pil = Image.open(image.file).convert('RGBA')\n\n                        # alpha copy\n                        new_alpha = mask_pil.getchannel('A')\n                        original_pil.putalpha(new_alpha)\n                        original_pil.save(filepath, compress_level=4, pnginfo=metadata)\n\n            return image_upload(post, image_save_function)\n\n        @routes.get(\"/view\")\n        async def view_image(request):\n            if \"filename\" in request.rel_url.query:\n                filename = request.rel_url.query[\"filename\"]\n                filename,output_dir = folder_paths.annotated_filepath(filename)\n\n                # validation for security: prevent accessing arbitrary path\n                if filename[0] == '/' or '..' in filename:\n                    return web.Response(status=400)\n\n                if output_dir is None:\n                    type = request.rel_url.query.get(\"type\", \"output\")\n                    output_dir = folder_paths.get_directory_by_type(type)\n\n                if output_dir is None:\n                    return web.Response(status=400)\n\n                if \"subfolder\" in request.rel_url.query:\n                    full_output_dir = os.path.join(output_dir, request.rel_url.query[\"subfolder\"])\n                    if os.path.commonpath((os.path.abspath(full_output_dir), output_dir)) != output_dir:\n                        return web.Response(status=403)\n                    output_dir = full_output_dir\n\n                filename = os.path.basename(filename)\n                file = os.path.join(output_dir, filename)\n\n                if os.path.isfile(file):\n                    if 'preview' in request.rel_url.query:\n                        with Image.open(file) as img:\n                            preview_info = request.rel_url.query['preview'].split(';')\n                            image_format = preview_info[0]\n                            if image_format not in ['webp', 'jpeg'] or 'a' in request.rel_url.query.get('channel', ''):\n                                image_format = 'webp'\n\n                            quality = 90\n                            if preview_info[-1].isdigit():\n                                quality = int(preview_info[-1])\n\n                            buffer = BytesIO()\n                            if image_format in ['jpeg'] or request.rel_url.query.get('channel', '') == 'rgb':\n                                img = img.convert(\"RGB\")\n                            img.save(buffer, format=image_format, quality=quality)\n                            buffer.seek(0)\n\n                            return web.Response(body=buffer.read(), content_type=f'image/{image_format}',\n                                                headers={\"Content-Disposition\": f\"filename=\\\"{filename}\\\"\"})\n\n                    if 'channel' not in request.rel_url.query:\n                        channel = 'rgba'\n                    else:\n                        channel = request.rel_url.query[\"channel\"]\n\n                    if channel == 'rgb':\n                        with Image.open(file) as img:\n                            if img.mode == \"RGBA\":\n                                r, g, b, a = img.split()\n                                new_img = Image.merge('RGB', (r, g, b))\n                            else:\n                                new_img = img.convert(\"RGB\")\n\n                            buffer = BytesIO()\n                            new_img.save(buffer, format='PNG')\n                            buffer.seek(0)\n\n                            return web.Response(body=buffer.read(), content_type='image/png',\n                                                headers={\"Content-Disposition\": f\"filename=\\\"{filename}\\\"\"})\n\n                    elif channel == 'a':\n                        with Image.open(file) as img:\n                            if img.mode == \"RGBA\":\n                                _, _, _, a = img.split()\n                            else:\n                                a = Image.new('L', img.size, 255)\n\n                            # alpha img\n                            alpha_img = Image.new('RGBA', img.size)\n                            alpha_img.putalpha(a)\n                            alpha_buffer = BytesIO()\n                            alpha_img.save(alpha_buffer, format='PNG')\n                            alpha_buffer.seek(0)\n\n                            return web.Response(body=alpha_buffer.read(), content_type='image/png',\n                                                headers={\"Content-Disposition\": f\"filename=\\\"{filename}\\\"\"})\n                    else:\n                        # Get content type from mimetype, defaulting to 'application/octet-stream'\n                        content_type = mimetypes.guess_type(filename)[0] or 'application/octet-stream'\n\n                        # For security, force certain extensions to download instead of display\n                        file_extension = os.path.splitext(filename)[1].lower()\n                        if file_extension in {'.html', '.htm', '.js', '.css'}:\n                            content_type = 'application/octet-stream'  # Forces download\n\n                        return web.FileResponse(\n                            file,\n                            headers={\n                                \"Content-Disposition\": f\"filename=\\\"{filename}\\\"\",\n                                \"Content-Type\": content_type\n                            }\n                        )\n\n            return web.Response(status=404)\n\n        @routes.get(\"/view_metadata/{folder_name}\")\n        async def view_metadata(request):\n            folder_name = request.match_info.get(\"folder_name\", None)\n            if folder_name is None:\n                return web.Response(status=404)\n            if not \"filename\" in request.rel_url.query:\n                return web.Response(status=404)\n\n            filename = request.rel_url.query[\"filename\"]\n            if not filename.endswith(\".safetensors\"):\n                return web.Response(status=404)\n\n            safetensors_path = folder_paths.get_full_path(folder_name, filename)\n            if safetensors_path is None:\n                return web.Response(status=404)\n            out = comfy.utils.safetensors_header(safetensors_path, max_size=1024*1024)\n            if out is None:\n                return web.Response(status=404)\n            dt = json.loads(out)\n            if not \"__metadata__\" in dt:\n                return web.Response(status=404)\n            return web.json_response(dt[\"__metadata__\"])\n\n        @routes.get(\"/system_stats\")\n        async def system_stats(request):\n            device = comfy.model_management.get_torch_device()\n            device_name = comfy.model_management.get_torch_device_name(device)\n            cpu_device = comfy.model_management.torch.device(\"cpu\")\n            ram_total = comfy.model_management.get_total_memory(cpu_device)\n            ram_free = comfy.model_management.get_free_memory(cpu_device)\n            vram_total, torch_vram_total = comfy.model_management.get_total_memory(device, torch_total_too=True)\n            vram_free, torch_vram_free = comfy.model_management.get_free_memory(device, torch_free_too=True)\n\n            system_stats = {\n                \"system\": {\n                    \"os\": os.name,\n                    \"ram_total\": ram_total,\n                    \"ram_free\": ram_free,\n                    \"comfyui_version\": get_comfyui_version(),\n                    \"python_version\": sys.version,\n                    \"pytorch_version\": comfy.model_management.torch_version,\n                    \"embedded_python\": os.path.split(os.path.split(sys.executable)[0])[1] == \"python_embeded\",\n                    \"argv\": sys.argv\n                },\n                \"devices\": [\n                    {\n                        \"name\": device_name,\n                        \"type\": device.type,\n                        \"index\": device.index,\n                        \"vram_total\": vram_total,\n                        \"vram_free\": vram_free,\n                        \"torch_vram_total\": torch_vram_total,\n                        \"torch_vram_free\": torch_vram_free,\n                    }\n                ]\n            }\n            return web.json_response(system_stats)\n\n        @routes.get(\"/prompt\")\n        async def get_prompt(request):\n            return web.json_response(self.get_queue_info())\n\n        def node_info(node_class):\n            obj_class = nodes.NODE_CLASS_MAPPINGS[node_class]\n            info = {}\n            info['input'] = obj_class.INPUT_TYPES()\n            info['input_order'] = {key: list(value.keys()) for (key, value) in obj_class.INPUT_TYPES().items()}\n            info['output'] = obj_class.RETURN_TYPES\n            info['output_is_list'] = obj_class.OUTPUT_IS_LIST if hasattr(obj_class, 'OUTPUT_IS_LIST') else [False] * len(obj_class.RETURN_TYPES)\n            info['output_name'] = obj_class.RETURN_NAMES if hasattr(obj_class, 'RETURN_NAMES') else info['output']\n            info['name'] = node_class\n            info['display_name'] = nodes.NODE_DISPLAY_NAME_MAPPINGS[node_class] if node_class in nodes.NODE_DISPLAY_NAME_MAPPINGS.keys() else node_class\n            info['description'] = obj_class.DESCRIPTION if hasattr(obj_class,'DESCRIPTION') else ''\n            info['python_module'] = getattr(obj_class, \"RELATIVE_PYTHON_MODULE\", \"nodes\")\n            info['category'] = 'sd'\n            if hasattr(obj_class, 'OUTPUT_NODE') and obj_class.OUTPUT_NODE == True:\n                info['output_node'] = True\n            else:\n                info['output_node'] = False\n\n            if hasattr(obj_class, 'CATEGORY'):\n                info['category'] = obj_class.CATEGORY\n\n            if hasattr(obj_class, 'OUTPUT_TOOLTIPS'):\n                info['output_tooltips'] = obj_class.OUTPUT_TOOLTIPS\n\n            if getattr(obj_class, \"DEPRECATED\", False):\n                info['deprecated'] = True\n            if getattr(obj_class, \"EXPERIMENTAL\", False):\n                info['experimental'] = True\n            return info\n\n        @routes.get(\"/object_info\")\n        async def get_object_info(request):\n            with folder_paths.cache_helper:\n                out = {}\n                for x in nodes.NODE_CLASS_MAPPINGS:\n                    try:\n                        out[x] = node_info(x)\n                    except Exception:\n                        logging.error(f\"[ERROR] An error occurred while retrieving information for the '{x}' node.\")\n                        logging.error(traceback.format_exc())\n                return web.json_response(out)\n\n        @routes.get(\"/object_info/{node_class}\")\n        async def get_object_info_node(request):\n            node_class = request.match_info.get(\"node_class\", None)\n            out = {}\n            if (node_class is not None) and (node_class in nodes.NODE_CLASS_MAPPINGS):\n                out[node_class] = node_info(node_class)\n            return web.json_response(out)\n\n        @routes.get(\"/history\")\n        async def get_history(request):\n            max_items = request.rel_url.query.get(\"max_items\", None)\n            if max_items is not None:\n                max_items = int(max_items)\n            return web.json_response(self.prompt_queue.get_history(max_items=max_items))\n\n        @routes.get(\"/history/{prompt_id}\")\n        async def get_history_prompt_id(request):\n            prompt_id = request.match_info.get(\"prompt_id\", None)\n            return web.json_response(self.prompt_queue.get_history(prompt_id=prompt_id))\n\n        @routes.get(\"/queue\")\n        async def get_queue(request):\n            queue_info = {}\n            current_queue = self.prompt_queue.get_current_queue()\n            queue_info['queue_running'] = current_queue[0]\n            queue_info['queue_pending'] = current_queue[1]\n            return web.json_response(queue_info)\n\n        @routes.post(\"/prompt\")\n        async def post_prompt(request):\n            logging.info(\"got prompt\")\n            json_data =  await request.json()\n            json_data = self.trigger_on_prompt(json_data)\n\n            if \"number\" in json_data:\n                number = float(json_data['number'])\n            else:\n                number = self.number\n                if \"front\" in json_data:\n                    if json_data['front']:\n                        number = -number\n\n                self.number += 1\n\n            if \"prompt\" in json_data:\n                prompt = json_data[\"prompt\"]\n                valid = execution.validate_prompt(prompt)\n                extra_data = {}\n                if \"extra_data\" in json_data:\n                    extra_data = json_data[\"extra_data\"]\n\n                if \"client_id\" in json_data:\n                    extra_data[\"client_id\"] = json_data[\"client_id\"]\n                if valid[0]:\n                    prompt_id = str(uuid.uuid4())\n                    outputs_to_execute = valid[2]\n                    self.prompt_queue.put((number, prompt_id, prompt, extra_data, outputs_to_execute))\n                    response = {\"prompt_id\": prompt_id, \"number\": number, \"node_errors\": valid[3]}\n                    return web.json_response(response)\n                else:\n                    logging.warning(\"invalid prompt: {}\".format(valid[1]))\n                    return web.json_response({\"error\": valid[1], \"node_errors\": valid[3]}, status=400)\n            else:\n                return web.json_response({\"error\": \"no prompt\", \"node_errors\": []}, status=400)\n\n        @routes.post(\"/queue\")\n        async def post_queue(request):\n            json_data =  await request.json()\n            if \"clear\" in json_data:\n                if json_data[\"clear\"]:\n                    self.prompt_queue.wipe_queue()\n            if \"delete\" in json_data:\n                to_delete = json_data['delete']\n                for id_to_delete in to_delete:\n                    delete_func = lambda a: a[1] == id_to_delete\n                    self.prompt_queue.delete_queue_item(delete_func)\n\n            return web.Response(status=200)\n\n        @routes.post(\"/interrupt\")\n        async def post_interrupt(request):\n            nodes.interrupt_processing()\n            return web.Response(status=200)\n\n        @routes.post(\"/free\")\n        async def post_free(request):\n            json_data = await request.json()\n            unload_models = json_data.get(\"unload_models\", False)\n            free_memory = json_data.get(\"free_memory\", False)\n            if unload_models:\n                self.prompt_queue.set_flag(\"unload_models\", unload_models)\n            if free_memory:\n                self.prompt_queue.set_flag(\"free_memory\", free_memory)\n            return web.Response(status=200)\n\n        @routes.post(\"/history\")\n        async def post_history(request):\n            json_data =  await request.json()\n            if \"clear\" in json_data:\n                if json_data[\"clear\"]:\n                    self.prompt_queue.wipe_history()\n            if \"delete\" in json_data:\n                to_delete = json_data['delete']\n                for id_to_delete in to_delete:\n                    self.prompt_queue.delete_history_item(id_to_delete)\n\n            return web.Response(status=200)\n\n    async def setup(self):\n        timeout = aiohttp.ClientTimeout(total=None) # no timeout\n        self.client_session = aiohttp.ClientSession(timeout=timeout)\n\n    def add_routes(self):\n        self.user_manager.add_routes(self.routes)\n        self.model_file_manager.add_routes(self.routes)\n        self.custom_node_manager.add_routes(self.routes, self.app, nodes.LOADED_MODULE_DIRS.items())\n        self.app.add_subapp('/internal', self.internal_routes.get_app())\n\n        # Prefix every route with /api for easier matching for delegation.\n        # This is very useful for frontend dev server, which need to forward\n        # everything except serving of static files.\n        # Currently both the old endpoints without prefix and new endpoints with\n        # prefix are supported.\n        api_routes = web.RouteTableDef()\n        for route in self.routes:\n            # Custom nodes might add extra static routes. Only process non-static\n            # routes to add /api prefix.\n            if isinstance(route, web.RouteDef):\n                api_routes.route(route.method, \"/api\" + route.path)(route.handler, **route.kwargs)\n        self.app.add_routes(api_routes)\n        self.app.add_routes(self.routes)\n\n        # Add routes from web extensions.\n        for name, dir in nodes.EXTENSION_WEB_DIRS.items():\n            self.app.add_routes([web.static('/extensions/' + name, dir)])\n\n        self.app.add_routes([\n            web.static('/', self.web_root),\n        ])\n\n    def get_queue_info(self):\n        prompt_info = {}\n        exec_info = {}\n        exec_info['queue_remaining'] = self.prompt_queue.get_tasks_remaining()\n        prompt_info['exec_info'] = exec_info\n        return prompt_info\n\n    async def send(self, event, data, sid=None):\n        if event == BinaryEventTypes.UNENCODED_PREVIEW_IMAGE:\n            await self.send_image(data, sid=sid)\n        elif isinstance(data, (bytes, bytearray)):\n            await self.send_bytes(event, data, sid)\n        else:\n            await self.send_json(event, data, sid)\n\n    def encode_bytes(self, event, data):\n        if not isinstance(event, int):\n            raise RuntimeError(f\"Binary event types must be integers, got {event}\")\n\n        packed = struct.pack(\">I\", event)\n        message = bytearray(packed)\n        message.extend(data)\n        return message\n\n    async def send_image(self, image_data, sid=None):\n        image_type = image_data[0]\n        image = image_data[1]\n        max_size = image_data[2]\n        if max_size is not None:\n            if hasattr(Image, 'Resampling'):\n                resampling = Image.Resampling.BILINEAR\n            else:\n                resampling = Image.ANTIALIAS\n\n            image = ImageOps.contain(image, (max_size, max_size), resampling)\n        type_num = 1\n        if image_type == \"JPEG\":\n            type_num = 1\n        elif image_type == \"PNG\":\n            type_num = 2\n\n        bytesIO = BytesIO()\n        header = struct.pack(\">I\", type_num)\n        bytesIO.write(header)\n        image.save(bytesIO, format=image_type, quality=95, compress_level=1)\n        preview_bytes = bytesIO.getvalue()\n        await self.send_bytes(BinaryEventTypes.PREVIEW_IMAGE, preview_bytes, sid=sid)\n\n    async def send_bytes(self, event, data, sid=None):\n        message = self.encode_bytes(event, data)\n\n        if sid is None:\n            sockets = list(self.sockets.values())\n            for ws in sockets:\n                await send_socket_catch_exception(ws.send_bytes, message)\n        elif sid in self.sockets:\n            await send_socket_catch_exception(self.sockets[sid].send_bytes, message)\n\n    async def send_json(self, event, data, sid=None):\n        message = {\"type\": event, \"data\": data}\n\n        if sid is None:\n            sockets = list(self.sockets.values())\n            for ws in sockets:\n                await send_socket_catch_exception(ws.send_json, message)\n        elif sid in self.sockets:\n            await send_socket_catch_exception(self.sockets[sid].send_json, message)\n\n    def send_sync(self, event, data, sid=None):\n        self.loop.call_soon_threadsafe(\n            self.messages.put_nowait, (event, data, sid))\n\n    def queue_updated(self):\n        self.send_sync(\"status\", { \"status\": self.get_queue_info() })\n\n    async def publish_loop(self):\n        while True:\n            msg = await self.messages.get()\n            await self.send(*msg)\n\n    async def start(self, address, port, verbose=True, call_on_start=None):\n        await self.start_multi_address([(address, port)], call_on_start=call_on_start)\n\n    async def start_multi_address(self, addresses, call_on_start=None, verbose=True):\n        runner = web.AppRunner(self.app, access_log=None)\n        await runner.setup()\n        ssl_ctx = None\n        scheme = \"http\"\n        if args.tls_keyfile and args.tls_certfile:\n                ssl_ctx = ssl.SSLContext(protocol=ssl.PROTOCOL_TLS_SERVER, verify_mode=ssl.CERT_NONE)\n                ssl_ctx.load_cert_chain(certfile=args.tls_certfile,\n                                keyfile=args.tls_keyfile)\n                scheme = \"https\"\n\n        if verbose:\n            logging.info(\"Starting server\\n\")\n        for addr in addresses:\n            address = addr[0]\n            port = addr[1]\n            site = web.TCPSite(runner, address, port, ssl_context=ssl_ctx)\n            await site.start()\n\n            if not hasattr(self, 'address'):\n                self.address = address #TODO: remove this\n                self.port = port\n\n            if ':' in address:\n                address_print = \"[{}]\".format(address)\n            else:\n                address_print = address\n\n            if verbose:\n                logging.info(\"To see the GUI go to: {}://{}:{}\".format(scheme, address_print, port))\n\n        if call_on_start is not None:\n            call_on_start(scheme, self.address, self.port)\n\n    def add_on_prompt_handler(self, handler):\n        self.on_prompt_handlers.append(handler)\n\n    def trigger_on_prompt(self, json_data):\n        for handler in self.on_prompt_handlers:\n            try:\n                json_data = handler(json_data)\n            except Exception:\n                logging.warning(\"[ERROR] An error occurred during the on_prompt_handler processing\")\n                logging.warning(traceback.format_exc())\n\n        return json_data\n"
        },
        {
          "name": "tests-unit",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "web",
          "type": "tree",
          "content": null
        }
      ]
    },
    {
      "nameWithOwner": "xtekky/gpt4free",
      "stars": 63007,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.06,
          "content": "# Auto detect text files and perform LF normalization\n* text=auto"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.8,
          "content": "# Default ignored files\n/shelf/\n/workspace.xml\n# Editor-based HTTP Client requests\n/httpRequests/\n# Datasource local storage ignored files\n/dataSources/\n/dataSources.local.xml\n\n# Ignore local python virtual environment\nvenv/\n\n# Ignore streamlit_chat_app.py conversations pickle\nconversations.pkl\n*.pkl\n\n# Ignore accounts created by api's\naccounts.txt\n\n.idea/\n**/__pycache__/\n__pycache__/\n\ndist/\n*.log\n*.pyc\n*.egg-info/\n*.egg\n*.egg-info\nbuild\n\ntest.py\nupdate.py\ncookie.json\nnotes.txt\nclose_issues.py\nxxx.py\nlab.py\nlab.js\nbing.py\nbing2.py\n.DS_Store\nlab/*\nlab\ntstt.py\nproviderstest.py\nprv.py\n# Emacs crap\n*~\nx.js\nx.py\ninfo.txt\nlocal.py\n*.gguf\nimage.py\n.buildozer\nhardir\nhar_and_cookies\nnode_modules\nmodels\nprojects/windows/g4f\ndoc.txt\ndist.py\nx.txt\nbench.py\nto-reverse.txt\ng4f/Provider/OpenaiChat2.py\ngenerated_images/\n"
        },
        {
          "name": ".gitpod.yml",
          "type": "blob",
          "size": 0.34,
          "content": "# Please adjust to your needs (see https://www.gitpod.io/docs/introduction/learn-gitpod/gitpod-yaml)\n# and commit this file to your remote git repository to share the goodness with others.\n\n# Learn more from ready-to-use templates: https://www.gitpod.io/docs/introduction/getting-started/quickstart\n\ntasks:\n  - init: pip install -r requirements.txt\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.1,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nhttps://t.me/xtekky.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations."
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.5,
          "content": "<img alt=\"gpt4free logo\" src=\"https://user-images.githubusercontent.com/98614666/233799515-1a7cb6a3-b17f-42c4-956d-8d2a0664466f.png\">\n\n### Please, follow these steps to contribute:\n1. Reverse a website from this list: [sites-to-reverse](https://github.com/xtekky/gpt4free/issues/40)\n2. Add it to [./etc/unittest/](https://github.com/xtekky/gpt4free/tree/main/etc/unittest/)\n3. Refactor it and add it to [./g4f](https://github.com/xtekky/gpt4free/tree/main/g4f)\n\n### We will be grateful to see you as a contributor!"
        },
        {
          "name": "LEGAL_NOTICE.md",
          "type": "blob",
          "size": 3.71,
          "content": "## Legal Notice\n\nThis repository is **not associated with or endorsed** by the providers of the APIs contained herein. This project is intended **for educational purposes only**. It is a personal project aimed at learning and exploration. Owners of any included sites or services may contact me to improve their security or request the removal of their content from this repository.\n\n### **Affiliation Disclaimer**\n\nThis repository is not associated with or endorsed by any of the API providers mentioned herein. All trademarks, API services, and other intellectual property referenced are the property of their respective owners. No claim of ownership or affiliation is made by this project.\n\n### **Liability Limitation**\n\nUnder no circumstances shall the author of this repository be liable for any direct, indirect, incidental, special, consequential, or punitive damages—including but not limited to loss of profits, data, or use—arising out of or in connection with the repository. This limitation applies regardless of whether such damages were foreseeable or whether the author was advised of the possibility of such damages.\n\n### **No Warranties**\n\nThis repository is provided on an \"as is\" and \"as available\" basis without any warranties of any kind, express or implied. This includes, but is not limited to, implied warranties of merchantability, fitness for a particular purpose, and non-infringement.\n\n### **User Responsibility**\n\nUsers assume all risks associated with the use of this repository. They are solely responsible for any damage or loss—including financial loss—that results from the use or misuse of the repository and its contents.\n\n### **Legal Compliance**\n\nUsers are responsible for ensuring that their use of the repository and its contents complies with all applicable local, state, national, and international laws and regulations.\n\n### **Indemnification**\n\nUsers agree to indemnify, defend, and hold harmless the author from any claims, liabilities, damages, losses, or expenses—including legal fees—arising out of or in any way connected with their use of this repository, violation of these terms, or infringement of any intellectual property or other rights of any person or entity.\n\n### **No Endorsement**\n\nThe inclusion of third-party content does not imply endorsement or recommendation of such content by the author.\n\n### **Governing Law and Jurisdiction**\n\nAny disputes arising out of or related to the use of this repository shall be governed by the laws of the author's jurisdiction, without regard to conflict of law principles.\n\n### **Severability**\n\nIf any provision of this notice is found to be unlawful, void, or unenforceable, that provision shall be deemed severable from this notice and shall not affect the validity and enforceability of the remaining provisions.\n\n### **Acknowledgment of Understanding**\n\nBy using this repository, users acknowledge that they have read, understood, and agree to be bound by these terms.\n\n### **Updates and Changes**\n\nThe author reserves the right to modify, update, or remove any content, information, or features in this repository at any time without prior notice. Users are responsible for regularly reviewing the content and any changes made to this repository.\n\n### **Unforeseen Consequences**\n\nThe author is not responsible for any consequences, damages, or losses arising from the use or misuse of this repository or the content provided by third-party APIs. Users are solely responsible for their actions and any repercussions that may follow.\n\n### **Educational Purpose**\n\nThis project and its content are provided strictly for educational purposes. Users acknowledge that they are using the APIs and models at their own risk and agree to comply with all applicable laws and regulations.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.32,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<https://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<https://www.gnu.org/licenses/why-not-lgpl.html>."
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.18,
          "content": "recursive-include g4f/gui/server *\nrecursive-include g4f/gui/client *\nrecursive-include g4f/Provider/npm *\nrecursive-include g4f/Provider/gigachat_crt *\nrecursive-include g4f/Provider/you *"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 51.5,
          "content": "\n\n![248433934-7886223b-c1d1-4260-82aa-da5741f303bb](https://github.com/xtekky/gpt4free/assets/98614666/ea012c87-76e0-496a-8ac4-e2de090cc6c9)\n\n<a href=\"https://trendshift.io/repositories/1692\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1692\" alt=\"xtekky%2Fgpt4free | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n---\n\n<p align=\"center\"><strong>Written by <a href=\"https://github.com/xtekky\">@xtekky</a></strong></p>\n\n<div id=\"top\"></div>\n\n> [!IMPORTANT]\n> By using this repository or any code related to it, you agree to the [legal notice](LEGAL_NOTICE.md). The author is **not responsible for the usage of this repository nor endorses it**, nor is the author responsible for any copies, forks, re-uploads made by other users, or anything else related to GPT4Free. This is the author's only account and repository. To prevent impersonation or irresponsible actions, please comply with the GNU GPL license this Repository uses.\n\n> [!WARNING]\n> _\"gpt4free\"_ serves as a **PoC** (proof of concept), demonstrating the development of an API package with multi-provider requests, with features like timeouts, load balance and flow control.\n\n> [!NOTE]\n> <sup><strong>Latest version:</strong></sup> [![PyPI version](https://img.shields.io/pypi/v/g4f?color=blue)](https://pypi.org/project/g4f) [![Docker version](https://img.shields.io/docker/v/hlohaus789/g4f?label=docker&color=blue)](https://hub.docker.com/r/hlohaus789/g4f)  \n> <sup><strong>Stats:</strong></sup> [![Downloads](https://static.pepy.tech/badge/g4f)](https://pepy.tech/project/g4f) [![Downloads](https://static.pepy.tech/badge/g4f/month)](https://pepy.tech/project/g4f)\n\n```sh\npip install -U g4f[all]\n```\n\n```sh\ndocker pull hlohaus789/g4f\n```\n\n## 🆕 What's New\n   - **For comprehensive details on new features and updates, please refer to our** [Releases](https://github.com/xtekky/gpt4free/releases) **page**\n   - **Installation Guide for Windows (.exe):** 💻 [Installation Guide for Windows (.exe)](#installation-guide-for-windows-exe)\n   - **Join our Telegram Channel:** 📨 [telegram.me/g4f_channel](https://telegram.me/g4f_channel)\n   - **Join our Discord Group:** 💬🆕️ [https://discord.gg/5E39JUWUFa](https://discord.gg/5E39JUWUFa)\n\n## 🔻 Site Takedown\n\nIs your site on this repository and you want to take it down? Send an email to takedown@g4f.ai with proof it is yours and it will be removed as fast as possible. To prevent reproduction please secure your API. 😉\n\n## 🚀 GPT4Free on HuggingFace\n\n[![HuggingSpace](https://github.com/user-attachments/assets/1d859e8a-d6fa-416f-a213-ccc26aa11e90)](https://huggingface.co/spaces/roxky/g4f)\n\nExplore our GPT4Free project on HuggingFace Spaces by clicking the link below:\n\n- [Visit GPT4Free on HuggingFace](https://huggingface.co/spaces/roxky/g4f)\n\nIf you would like to create your own copy of this space, you can duplicate it using the following link:\n\n- [Duplicate GPT4Free Space](https://huggingface.co/spaces/roxky/g4f?duplicate=true)\n\n\n## 📚 Table of Contents\n   - [🆕 What's New](#-whats-new)\n   - [📚 Table of Contents](#-table-of-contents)\n   - [🛠️ Getting Started](#-getting-started)\n      - [Docker Container Guide](#docker-container-guide)\n      - [Installation Guide for Windows (.exe)](#installation-guide-for-windows-exe)\n   - [Use python](#use-python)\n      - [Prerequisites](#prerequisites)\n      - [Install using PyPI package](#install-using-pypi-package)\n      - [Install from source](#install-from-source)\n   - [Install using Docker](#install-using-docker)\n   - [💡 Usage](#-usage)\n      - [Text Generation](#text-generation)\n      - [Image Generation](#image-generation)\n      - [Web UI](#web-ui)\n      - [Interference API](#interference-api)\n      - [Local Inference](docs/local.md)\n      - [Configuration](#configuration)\n      -  [Full Documentation for Python API](#full-documentation-for-python-api)\n         - [Requests API from G4F](docs/requests.md)\n         - [Client API from G4F](docs/client.md)\n         - [AsyncClient API from G4F](docs/async_client.md)\n   - [🚀 Providers and Models](docs/providers-and-models.md)\n   - [🔗 Powered by gpt4free](#-powered-by-gpt4free)\n   - [🤝 Contribute](#-contribute)\n      - [How do i create a new Provider?](#guide-how-do-i-create-a-new-provider)\n      - [How can AI help me with writing code?](#guide-how-can-ai-help-me-with-writing-code)\n   - [🙌 Contributors](#-contributors)\n   - [©️ Copyright](#-copyright)\n   - [⭐ Star History](#-star-history)\n   - [📄 License](#-license)\n\n## 🛠️ Getting Started\n\n#### Docker Container Guide\n\n##### Getting Started Quickly:\n\n1. **Install Docker:** Begin by [downloading and installing Docker](https://docs.docker.com/get-docker/).\n\n2. **Check Directories:**\n\nBefore running the container, make sure the necessary data directories exist or can be created. For example, you can create and set ownership on these directories by running:\n\n```bash\nmkdir -p ${PWD}/har_and_cookies ${PWD}/generated_images\nchown -R 1000:1000 ${PWD}/har_and_cookies ${PWD}/generated_images\n```\n\n3. **Set Up the Container:**\n   Use the following commands to pull the latest image and start the container:\n\n```bash\ndocker pull hlohaus789/g4f\ndocker run \\\n  -p 8080:8080 -p 1337:1337 -p 7900:7900 \\\n  --shm-size=\"2g\" \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_images:/app/generated_images \\\n  hlohaus789/g4f:latest\n```\n\n##### Running the Slim Docker Image\n\nUse the following command to run the Slim Docker image. This command also updates the `g4f` package at startup and installs any additional dependencies:\n\n```bash\ndocker run \\\n  -p 1337:1337 \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_images:/app/generated_images \\\n  hlohaus789/g4f:latest-slim \\\n  rm -r -f /app/g4f/ \\\n  && pip install -U g4f[slim] \\\n  && python -m g4f --debug\n```\n\n4. **Access the Client:**\n\n   - To use the included client, navigate to: [http://localhost:8080/chat/](http://localhost:8080/chat/) or [http://localhost:1337/chat/](http://localhost:1337/chat/)\n   - Or set the API base for your client to: [http://localhost:1337/v1](http://localhost:1337/v1)\n\n5. **(Optional) Provider Login:**\n   If required, you can access the container's desktop here: http://localhost:7900/?autoconnect=1&resize=scale&password=secret for provider login purposes.\n\n#### Installation Guide for Windows (.exe)\n\nTo ensure the seamless operation of our application, please follow the instructions below. These steps are designed to guide you through the installation process on Windows operating systems.\n\n### Installation Steps\n\n1. **Download the Application**: Visit our [releases page](https://github.com/xtekky/gpt4free/releases/tag/0.4.0.6) and download the most recent version of the application, named `g4f.exe.zip`.\n2. **File Placement**: After downloading, locate the `.zip` file in your Downloads folder. Unpack it to a directory of your choice on your system, then execute the `g4f.exe` file to run the app.\n3. **Open GUI**: The app starts a web server with the GUI. Open your favorite browser and navigate to `http://localhost:8080/chat/` to access the application interface.\n4. **Firewall Configuration (Hotfix)**: Upon installation, it may be necessary to adjust your Windows Firewall settings to allow the application to operate correctly. To do this, access your Windows Firewall settings and allow the application.\n\nBy following these steps, you should be able to successfully install and run the application on your Windows system. If you encounter any issues during the installation process, please refer to our Issue Tracker or try to get contact over Discord for assistance.\n\n---\n\n### Learn More About the GUI\n\nFor detailed instructions on how to set up, configure, and use the GPT4Free GUI, refer to the **GUI Documentation**:\n\n- [GUI Documentation](docs/gui.md)\n\nThis guide includes step-by-step details on provider selection, managing conversations, using advanced features like speech recognition, and more.\n\n---\n\n### Use Your Smartphone\n\nRun the Web UI on your smartphone for easy access on the go. Check out the dedicated guide to learn how to set up and use the GUI on your mobile device:\n\n- [Run on Smartphone Guide](docs/guides/phone.md)\n\n---\n\n### Use python\n\n##### Prerequisites:\n\n1. [Download and install Python](https://www.python.org/downloads/) (Version 3.10+ is recommended).\n2. [Install Google Chrome](https://www.google.com/chrome/) for providers with webdriver\n\n##### Install using PyPI package:\n\n```\npip install -U g4f[all]\n```\n\nHow do I install only parts or do disable parts?\nUse partial requirements: [/docs/requirements](docs/requirements.md)\n\n##### Install from source:\n\nHow do I load the project using git and installing the project requirements?\nRead this tutorial and follow it step by step: [/docs/git](docs/git.md)\n\n##### Install using Docker:\n\nHow do I build and run composer image from source?\nUse docker-compose: [/docs/docker](docs/docker.md)\n\n## 💡 Usage\n\n#### Text Generation\n\n```python\nfrom g4f.client import Client\n\nclient = Client()\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n    web_search = False\n)\nprint(response.choices[0].message.content)\n```\n\n```\nHello! How can I assist you today?\n```\n\n#### Image Generation\n```python\nfrom g4f.client import Client\n\nclient = Client()\nresponse = client.images.generate(\n    model=\"flux\",\n    prompt=\"a white siamese cat\",\n    response_format=\"url\"\n)\n\nimage_url = response.data[0].url\nprint(f\"Generated image URL: {image_url}\")\n```\n\n[![Image with cat](/docs/images/cat.jpeg)](docs/client.md)\n\n#### **Full Documentation for Python API**\n   - **New:**\n      - **Requests API from G4F:** [/docs/requests](docs/requests.md)\n      - **Client API from G4F:** [/docs/client](docs/client.md)\n      - **AsyncClient API from G4F:** [/docs/async_client](docs/async_client.md)\n      - **File API from G4F:** [/docs/file](docs/file.md)\n\n   - **Legacy:**\n      - **Legacy API with python modules:** [/docs/legacy](docs/legacy.md)\n\n#### Web UI\n\n**To start the web interface, type the following codes in python:**\n\n```python\nfrom g4f.gui import run_gui\n\nrun_gui()\n```\nor execute the following command:\n```bash\npython -m g4f.cli gui -port 8080 -debug\n```\n\n### Interference API\n\nThe **Interference API** enables seamless integration with OpenAI's services through G4F, allowing you to deploy efficient AI solutions.\n\n- **Documentation**: [Interference API Docs](docs/interference-api.md)\n- **Endpoint**: `http://localhost:1337/v1`\n- **Swagger UI**: Explore the OpenAPI documentation via Swagger UI at `http://localhost:1337/docs`\n\nThis API is designed for straightforward implementation and enhanced compatibility with other OpenAI integrations.\n\n### Configuration\n\n#### Authentication\n\nRefer to the [G4F Authentication Setup Guide](docs/authentication.md) for detailed instructions on setting up authentication.\n\n#### Cookies\n\nCookies are essential for using Meta AI and Microsoft Designer to create images.\nAdditionally, cookies are required for the Google Gemini and WhiteRabbitNeo Provider.\nFrom Bing, ensure you have the \"\\_U\" cookie, and from Google, all cookies starting with \"\\_\\_Secure-1PSID\" are needed.\n\nYou can pass these cookies directly to the create function or set them using the `set_cookies` method before running G4F:\n\n```python\nfrom g4f.cookies import set_cookies\n\nset_cookies(\".bing.com\", {\n  \"_U\": \"cookie value\"\n})\n\nset_cookies(\".google.com\", {\n  \"__Secure-1PSID\": \"cookie value\"\n})\n```\n\n#### Using .har and Cookie Files\n\nYou can place `.har` and cookie files `.json` in the default `./har_and_cookies` directory. To export a cookie file, use the [EditThisCookie Extension](https://chromewebstore.google.com/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg) available on the Chrome Web Store.\n\n#### Creating .har Files to Capture Cookies\n\nTo capture cookies, you can also create `.har` files. For more details, refer to the next section.\n\n#### Changing the Cookies Directory and Loading Cookie Files in Python\n\nYou can change the cookies directory and load cookie files in your Python environment. To set the cookies directory relative to your Python file, use the following code:\n\n```python\nimport os.path\nfrom g4f.cookies import set_cookies_dir, read_cookie_files\n\nimport g4f.debug\ng4f.debug.logging = True\n\ncookies_dir = os.path.join(os.path.dirname(__file__), \"har_and_cookies\")\nset_cookies_dir(cookies_dir)\nread_cookie_files(cookies_dir)\n```\n\n### Debug Mode\n\nIf you enable debug mode, you will see logs similar to the following:\n\n```\nRead .har file: ./har_and_cookies/you.com.har\nCookies added: 10 from .you.com\nRead cookie file: ./har_and_cookies/google.json\nCookies added: 16 from .google.com\n```\n\n#### .HAR File for OpenaiChat Provider\n\n##### Generating a .HAR File\n\nTo utilize the OpenaiChat provider, a .har file is required from https://chatgpt.com/. Follow the steps below to create a valid .har file:\n\n1. Navigate to https://chatgpt.com/ using your preferred web browser and log in with your credentials.\n2. Access the Developer Tools in your browser. This can typically be done by right-clicking the page and selecting \"Inspect,\" or by pressing F12 or Ctrl+Shift+I (Cmd+Option+I on a Mac).\n3. With the Developer Tools open, switch to the \"Network\" tab.\n4. Reload the website to capture the loading process within the Network tab.\n5. Initiate an action in the chat which can be captured in the .har file.\n6. Right-click any of the network activities listed and select \"Save all as HAR with content\" to export the .har file.\n\n##### Storing the .HAR File\n\n- Place the exported .har file in the `./har_and_cookies` directory if you are using Docker. Alternatively, if you are using Python from a terminal, you can store it in a `./har_and_cookies` directory within your current working directory.\n\n> **Note:** Ensure that your .har file is stored securely, as it may contain sensitive information.\n\n#### Using Proxy\n\nIf you want to hide or change your IP address for the providers, you can set a proxy globally via an environment variable:\n\n**- On macOS and Linux:**\n```bash\nexport G4F_PROXY=\"http://host:port\"\n```\n\n**- On Windows:**\n```bash\nset G4F_PROXY=http://host:port\n```\n\n## 🔗 Powered by gpt4free\n\n<table>\n  <thead align=\"center\">\n    <tr border: none;>\n      <td>\n        <b>🎁 Projects</b>\n      </td>\n      <td>\n        <b>⭐ Stars</b>\n      </td>\n      <td>\n        <b>📚 Forks</b>\n      </td>\n      <td>\n        <b>🛎 Issues</b>\n      </td>\n      <td>\n        <b>📬 Pull requests</b>\n      </td>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        <a href=\"https://github.com/xtekky/gpt4free\">\n          <b>gpt4free</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/gpt4free/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/xtekky/gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/gpt4free/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/xtekky/gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/gpt4free/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/xtekky/gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/gpt4free/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/xtekky/gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <td>\n      <a href=\"https://github.com/xiangsx/gpt4free-ts\">\n        <b>gpt4free-ts</b>\n      </a>\n    </td>\n    <td>\n      <a href=\"https://github.com/xiangsx/gpt4free-ts/stargazers\">\n        <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/xiangsx/gpt4free-ts?style=flat-square&labelColor=343b41\" />\n      </a>\n    </td>\n    <td>\n      <a href=\"https://github.com/xiangsx/gpt4free-ts/network/members\">\n        <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/xiangsx/gpt4free-ts?style=flat-square&labelColor=343b41\" />\n      </a>\n    </td>\n    <td>\n      <a href=\"https://github.com/xiangsx/gpt4free-ts/issues\">\n        <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/xiangsx/gpt4free-ts?style=flat-square&labelColor=343b41\" />\n      </a>\n    </td>\n    <td>\n      <a href=\"https://github.com/xiangsx/gpt4free-ts/pulls\">\n        <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/xiangsx/gpt4free-ts?style=flat-square&labelColor=343b41\" />\n      </a>\n    </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/zukixa/cool-ai-stuff/\">\n          <b>Free AI API's & Potential Providers List</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zukixa/cool-ai-stuff/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/zukixa/cool-ai-stuff?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zukixa/cool-ai-stuff/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/zukixa/cool-ai-stuff?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zukixa/cool-ai-stuff/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/zukixa/cool-ai-stuff?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zukixa/cool-ai-stuff/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/zukixa/cool-ai-stuff?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/xtekky/chatgpt-clone\">\n          <b>ChatGPT-Clone</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/chatgpt-clone/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/xtekky/chatgpt-clone?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/chatgpt-clone/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/xtekky/chatgpt-clone?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/chatgpt-clone/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/xtekky/chatgpt-clone?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/xtekky/chatgpt-clone/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/xtekky/chatgpt-clone?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free\">\n          <b>Ai agent</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Josh-XT/AGiXT/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Josh-XT/AGiXT/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Josh-XT/AGiXT/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Josh-XT/AGiXT/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free\">\n          <b>ChatGpt Discord Bot</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/mishalhossin/Discord-Chatbot-Gpt4Free/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/mishalhossin/Coding-Chatbot-Gpt4Free/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/mishalhossin/Discord-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    <tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/Zero6992/chatGPT-discord-bot\">\n          <b>chatGPT-discord-bot</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Zero6992/chatGPT-discord-bot/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/Zero6992/chatGPT-discord-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Zero6992/chatGPT-discord-bot/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/Zero6992/chatGPT-discord-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Zero6992/chatGPT-discord-bot/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/Zero6992/chatGPT-discord-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Zero6992/chatGPT-discord-bot/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/Zero6992/chatGPT-discord-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    <tr>\n      <td>\n        <a href=\"https://github.com/SamirXR/Nyx-Bot\">\n          <b>Nyx-Bot (Discord)</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/SamirXR/Nyx-Bot/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/SamirXR/Nyx-Bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/SamirXR/Nyx-Bot/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/SamirXR/Nyx-Bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/SamirXR/Nyx-Bot/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/SamirXR/Nyx-Bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/SamirXR/Nyx-Bot/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/SamirXR/Nyx-Bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/MIDORIBIN/langchain-gpt4free\">\n          <b>LangChain gpt4free</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/MIDORIBIN/langchain-gpt4free/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/MIDORIBIN/langchain-gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/MIDORIBIN/langchain-gpt4free/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/MIDORIBIN/langchain-gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/MIDORIBIN/langchain-gpt4free/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/MIDORIBIN/langchain-gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/MIDORIBIN/langchain-gpt4free/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/MIDORIBIN/langchain-gpt4free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/HexyeDEV/Telegram-Chatbot-Gpt4Free\">\n          <b>ChatGpt Telegram Bot</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/HexyeDEV/Telegram-Chatbot-Gpt4Free/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/HexyeDEV/Telegram-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/HexyeDEV/Telegram-Chatbot-Gpt4Free/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/HexyeDEV/Telegram-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/HexyeDEV/Telegram-Chatbot-Gpt4Free/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/HexyeDEV/Telegram-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/HexyeDEV/Telegram-Chatbot-Gpt4Free/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/HexyeDEV/Telegram-Chatbot-Gpt4Free?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/chatgpt-line-bot\">\n          <b>ChatGpt Line Bot</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/chatgpt-line-bot/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/Lin-jun-xiang/chatgpt-line-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/chatgpt-line-bot/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/Lin-jun-xiang/chatgpt-line-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/chatgpt-line-bot/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/Lin-jun-xiang/chatgpt-line-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/chatgpt-line-bot/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/Lin-jun-xiang/chatgpt-line-bot?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/action-translate-readme\">\n          <b>Action Translate Readme</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/action-translate-readme/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/Lin-jun-xiang/action-translate-readme?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/action-translate-readme/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/Lin-jun-xiang/action-translate-readme?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/action-translate-readme/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/Lin-jun-xiang/action-translate-readme?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/action-translate-readme/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/Lin-jun-xiang/action-translate-readme?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/docGPT-streamlit\">\n          <b>Langchain Document GPT</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/docGPT-streamlit/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/Lin-jun-xiang/docGPT-streamlit?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/docGPT-streamlit/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/Lin-jun-xiang/docGPT-streamlit?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/docGPT-streamlit/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/Lin-jun-xiang/docGPT-streamlit?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Lin-jun-xiang/docGPT-streamlit/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/Lin-jun-xiang/docGPT-streamlit?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/Simatwa/python-tgpt\">\n          <b>python-tgpt</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Simatwa/python-tgpt/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/Simatwa/python-tgpt?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Simatwa/python-tgpt/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/Simatwa/python-tgpt?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Simatwa/python-tgpt/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/Simatwa/python-tgpt?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/Simatwa/python-tgpt/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/Simatwa/python-tgpt?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/zachey01/gpt4free.js\">\n          <b>GPT4js</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zachey01/gpt4free.js/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/zachey01/gpt4free.js?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zachey01/gpt4free.js/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/zachey01/gpt4free.js?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zachey01/gpt4free.js/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/zachey01/gpt4free.js?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/zachey01/gpt4free.js/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/zachey01/gpt4free.js?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/yjg30737/pyqt-openai\">\n          <b>VividNode (pyqt-openai)</b>\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/yjg30737/pyqt-openai/stargazers\">\n          <img alt=\"Stars\" src=\"https://img.shields.io/github/stars/yjg30737/pyqt-openai?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/yjg30737/pyqt-openai/network/members\">\n          <img alt=\"Forks\" src=\"https://img.shields.io/github/forks/yjg30737/pyqt-openai?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/yjg30737/pyqt-openai/issues\">\n          <img alt=\"Issues\" src=\"https://img.shields.io/github/issues/yjg30737/pyqt-openai?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n      <td>\n        <a href=\"https://github.com/yjg30737/pyqt-openai/pulls\">\n          <img alt=\"Pull Requests\" src=\"https://img.shields.io/github/issues-pr/yjg30737/pyqt-openai?style=flat-square&labelColor=343b41\" />\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## 🤝 Contribute\nWe welcome contributions from the community. Whether you're adding new providers or features, or simply fixing typos and making small improvements, your input is valued. Creating a pull request is all it takes – our co-pilot will handle the code review process. Once all changes have been addressed, we'll merge the pull request into the main branch and release the updates at a later time.\n\n###### Guide: How do i create a new Provider?\n   - **Read:** [Create Provider Guide](docs/guides/create_provider.md)\n\n###### Guide: How can AI help me with writing code?\n   - **Read:** [AI Assistance Guide](docs/guides/help_me.md)\n\n## 🙌 Contributors\nA list of all contributors is available [here](https://github.com/xtekky/gpt4free/graphs/contributors)\n\n<a href=\"https://github.com/xtekky\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/98614666?v=4&s=45\" width=\"45\" title=\"xtekky\"></a>\n<a href=\"https://github.com/hlohaus\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/983577?v=4&s=45\" width=\"45\" title=\"hlohaus\"></a>\n<a href=\"https://github.com/kqlio67\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/166700875?v=4&s=45\" width=\"45\" title=\"kqlio67\"></a>\n<a href=\"https://github.com/bagusindrayana\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/36830534?v=4&s=45\" width=\"45\" title=\"bagusindrayana\"></a>\n<a href=\"https://github.com/sudouser777\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/22415463?v=4&s=45\" width=\"45\" title=\"sudouser777\"></a>\n<a href=\"https://github.com/thatlukinhasguy1\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/139662282?v=4&s=45\" width=\"45\" title=\"thatlukinhasguy1\"></a>\n<a href=\"https://github.com/Commenter123321\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/36051603?v=4&s=45\" width=\"45\" title=\"Commenter123321\"></a>\n<a href=\"https://github.com/DanielShemesh\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/20585236?v=4&s=45\" width=\"45\" title=\"DanielShemesh\"></a>\n<a href=\"https://github.com/Luneye\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/73485421?v=4&s=45\" width=\"45\" title=\"Luneye\"></a>\n<a href=\"https://github.com/foxfire52\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/185073927?v=4&s=45\" width=\"45\" title=\"foxfire52\"></a>\n<a href=\"https://github.com/ezerinz\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/100193740?v=4&s=45\" width=\"45\" title=\"ezerinz\"></a>\n<a href=\"https://github.com/enganese\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/69082498?v=4&s=45\" width=\"45\" title=\"enganese\"></a>\n<a href=\"https://github.com/Lin-jun-xiang\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/63782903?v=4&s=45\" width=\"45\" title=\"Lin-jun-xiang\"></a>\n<a href=\"https://github.com/nullstreak\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/139914347?v=4&s=45\" width=\"45\" title=\"nullstreak\"></a>\n<a href=\"https://github.com/valerii-chirkov\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/81074936?v=4&s=45\" width=\"45\" title=\"valerii-chirkov\"></a>\n<a href=\"https://github.com/MIDORIBIN\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/25425217?v=4&s=45\" width=\"45\" title=\"MIDORIBIN\"></a>\n<a href=\"https://github.com/repollo\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/2671466?v=4&s=45\" width=\"45\" title=\"repollo\"></a>\n<a href=\"https://github.com/hpsj\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/54535414?v=4&s=45\" width=\"45\" title=\"hpsj\"></a>\n<a href=\"https://github.com/taiyi747\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/63543716?v=4&s=45\" width=\"45\" title=\"taiyi747\"></a>\n<a href=\"https://github.com/zukixa\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/56563509?v=4&s=45\" width=\"45\" title=\"zukixa\"></a>\n<a href=\"https://github.com/ostix360\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/55257054?v=4&s=45\" width=\"45\" title=\"ostix360\"></a>\n<a href=\"https://github.com/WdR-Tech\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/143020293?v=4&s=45\" width=\"45\" title=\"WdR-Tech\"></a>\n<a href=\"https://github.com/HexyeDEV\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/65314629?v=4&s=45\" width=\"45\" title=\"HexyeDEV\"></a>\n<a href=\"https://github.com/9fo\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/71867245?v=4&s=45\" width=\"45\" title=\"9fo\"></a>\n<a href=\"https://github.com/devAdityaa\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/77636021?v=4&s=45\" width=\"45\" title=\"devAdityaa\"></a>\n<a href=\"https://github.com/24rr\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/109844019?v=4&s=45\" width=\"45\" title=\"24rr\"></a>\n<a href=\"https://github.com/zeng-rr\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/47846202?v=4&s=45\" width=\"45\" title=\"zeng-rr\"></a>\n<a href=\"https://github.com/rkihacker\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/182319878?v=4&s=45\" width=\"45\" title=\"rkihacker\"></a>\n<a href=\"https://github.com/naa7\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/44613678?v=4&s=45\" width=\"45\" title=\"naa7\"></a>\n<a href=\"https://github.com/ramon-victor\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/13617054?v=4&s=45\" width=\"45\" title=\"ramon-victor\"></a>\n<a href=\"https://github.com/eltociear\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4&s=45\" width=\"45\" title=\"eltociear\"></a>\n<a href=\"https://github.com/kggn\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/95663228?v=4&s=45\" width=\"45\" title=\"kggn\"></a>\n<a href=\"https://github.com/xiangsx\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/29322721?v=4&s=45\" width=\"45\" title=\"xiangsx\"></a>\n<a href=\"https://github.com/ggindinson\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/97807772?v=4&s=45\" width=\"45\" title=\"ggindinson\"></a>\n<a href=\"https://github.com/ahobsonsayers\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/32173585?v=4&s=45\" width=\"45\" title=\"ahobsonsayers\"></a>\n<a href=\"https://github.com/mache102\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/91365155?v=4&s=45\" width=\"45\" title=\"mache102\"></a>\n<a href=\"https://github.com/kogakisaki\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/95165750?v=4&s=45\" width=\"45\" title=\"kogakisaki\"></a>\n<a href=\"https://github.com/Andrew-Tsegaye\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/91322467?v=4&s=45\" width=\"45\" title=\"Andrew-Tsegaye\"></a>\n<a href=\"https://github.com/omidima\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/47784584?v=4&s=45\" width=\"45\" title=\"omidima\"></a>\n<a href=\"https://github.com/nonk123\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/43842467?v=4&s=45\" width=\"45\" title=\"nonk123\"></a>\n<a href=\"https://github.com/MaxKUlish1\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/93388714?v=4&s=45\" width=\"45\" title=\"MaxKUlish1\"></a>\n<a href=\"https://github.com/AymaneHrouch\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/36491424?v=4&s=45\" width=\"45\" title=\"AymaneHrouch\"></a>\n<a href=\"https://github.com/Eikosa\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/20538090?v=4&s=45\" width=\"45\" title=\"Eikosa\"></a>\n<a href=\"https://github.com/localagi\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/132956819?v=4&s=45\" width=\"45\" title=\"localagi\"></a>\n<a href=\"https://github.com/thebigbone\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/95130644?v=4&s=45\" width=\"45\" title=\"thebigbone\"></a>\n<a href=\"https://github.com/kailust\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/82623773?v=4&s=45\" width=\"45\" title=\"kailust\"></a>\n<a href=\"https://github.com/ading2210\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/71154407?v=4&s=45\" width=\"45\" title=\"ading2210\"></a>\n<a href=\"https://github.com/Zero6992\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/89479282?v=4&s=45\" width=\"45\" title=\"Zero6992\"></a>\n<a href=\"https://github.com/mishl-dev\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/91066601?v=4&s=45\" width=\"45\" title=\"mishl-dev\"></a>\n<a href=\"https://github.com/ElonGaties\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/59313695?v=4&s=45\" width=\"45\" title=\"ElonGaties\"></a>\n<a href=\"https://github.com/TotoB12\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/91705868?v=4&s=45\" width=\"45\" title=\"TotoB12\"></a>\n<a href=\"https://github.com/malivinayak\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/66154908?v=4&s=45\" width=\"45\" title=\"malivinayak\"></a>\n<a href=\"https://github.com/Zedai00\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/33319711?v=4&s=45\" width=\"45\" title=\"Zedai00\"></a>\n<a href=\"https://github.com/catmeowjiao\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/138079152?v=4&s=45\" width=\"45\" title=\"catmeowjiao\"></a>\n<a href=\"https://github.com/cifer-sudo\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/60644739?v=4&s=45\" width=\"45\" title=\"cifer-sudo\"></a>\n<a href=\"https://github.com/eminemkun\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/49590289?v=4&s=45\" width=\"45\" title=\"eminemkun\"></a>\n<a href=\"https://github.com/kafmws\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/33590879?v=4&s=45\" width=\"45\" title=\"kafmws\"></a>\n<a href=\"https://github.com/najam-tariq\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/103676132?v=4&s=45\" width=\"45\" title=\"najam-tariq\"></a>\n<a href=\"https://github.com/ochen1\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/59662605?v=4&s=45\" width=\"45\" title=\"ochen1\"></a>\n<a href=\"https://github.com/r1di\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/33724815?v=4&s=45\" width=\"45\" title=\"r1di\"></a>\n<a href=\"https://github.com/sagadav\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/42406802?v=4&s=45\" width=\"45\" title=\"sagadav\"></a>\n<a href=\"https://github.com/snyk-bot\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/19733683?v=4&s=45\" width=\"45\" title=\"snyk-bot\"></a>\n<a href=\"https://github.com/vatva691\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/30290559?v=4&s=45\" width=\"45\" title=\"vatva691\"></a>\n<a href=\"https://github.com/Qustelm\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/83110161?v=4&s=45\" width=\"45\" title=\"Qustelm\"></a>\n<a href=\"https://github.com/HyiKi\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/55942998?v=4&s=45\" width=\"45\" title=\"HyiKi\"></a>\n<a href=\"https://github.com/0dminnimda\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/52697657?v=4&s=45\" width=\"45\" title=\"0dminnimda\"></a>\n<a href=\"https://github.com/Akash98Sky\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/37451227?v=4&s=45\" width=\"45\" title=\"Akash98Sky\"></a>\n<a href=\"https://github.com/adeyinkaezra123\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/65364356?v=4&s=45\" width=\"45\" title=\"adeyinkaezra123\"></a>\n<a href=\"https://github.com/Giancarlo-Ma\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/65126107?v=4&s=45\" width=\"45\" title=\"Giancarlo-Ma\"></a>\n<a href=\"https://github.com/gran4\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/80655391?v=4&s=45\" width=\"45\" title=\"gran4\"></a>\n<a href=\"https://github.com/guspan-tanadi\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/36249910?v=4&s=45\" width=\"45\" title=\"guspan-tanadi\"></a>\n<a href=\"https://github.com/oubrax\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/72103863?v=4&s=45\" width=\"45\" title=\"oubrax\"></a>\n<a href=\"https://github.com/hansipie\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/5460714?v=4&s=45\" width=\"45\" title=\"hansipie\"></a>\n<a href=\"https://github.com/GetTuh\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/27581581?v=4&s=45\" width=\"45\" title=\"GetTuh\"></a>\n<a href=\"https://github.com/kushal34712\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/98145879?v=4&s=45\" width=\"45\" title=\"kushal34712\"></a>\n<a href=\"https://github.com/Fubge\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/115476150?v=4&s=45\" width=\"45\" title=\"Fubge\"></a>\n<a href=\"https://github.com/Niapoll\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/64135936?v=4&s=45\" width=\"45\" title=\"Niapoll\"></a>\n<a href=\"https://github.com/OmiiiDev\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/103533638?v=4&s=45\" width=\"45\" title=\"OmiiiDev\"></a>\n<a href=\"https://github.com/RasyiidWho\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/19422415?v=4&s=45\" width=\"45\" title=\"RasyiidWho\"></a>\n<a href=\"https://github.com/RavenOwO\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/118295106?v=4&s=45\" width=\"45\" title=\"RavenOwO\"></a>\n<a href=\"https://github.com/anonymousx97\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/88324835?v=4&s=45\" width=\"45\" title=\"anonymousx97\"></a>\n<a href=\"https://github.com/krjordan\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/10234150?v=4&s=45\" width=\"45\" title=\"krjordan\"></a>\n<a href=\"https://github.com/SilverMarcs\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/77480421?v=4&s=45\" width=\"45\" title=\"SilverMarcs\"></a>\n<a href=\"https://github.com/Yusufibin\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/71589435?v=4&s=45\" width=\"45\" title=\"Yusufibin\"></a>\n<a href=\"https://github.com/yuri-val\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/15129796?v=4&s=45\" width=\"45\" title=\"yuri-val\"></a>\n<a href=\"https://github.com/yousefnegmeldin\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/96620955?v=4&s=45\" width=\"45\" title=\"yousefnegmeldin\"></a>\n<a href=\"https://github.com/perklet\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/1035487?v=4&s=45\" width=\"45\" title=\"perklet\"></a>\n<a href=\"https://github.com/varshney-yash\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/107148830?v=4&s=45\" width=\"45\" title=\"varshney-yash\"></a>\n<a href=\"https://github.com/Yoxmo\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/94254616?v=4&s=45\" width=\"45\" title=\"Yoxmo\"></a>\n<a href=\"https://github.com/yjg30737\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/55078043?v=4&s=45\" width=\"45\" title=\"yjg30737\"></a>\n<a href=\"https://github.com/williamstein\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/1276278?v=4&s=45\" width=\"45\" title=\"williamstein\"></a>\n<a href=\"https://github.com/ZachKLYeh\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/105150034?v=4&s=45\" width=\"45\" title=\"ZachKLYeh\"></a>\n<a href=\"https://github.com/alvarosoaress\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/13721147?v=4&s=45\" width=\"45\" title=\"alvarosoaress\"></a>\n<a href=\"https://github.com/bruvv\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/3063928?v=4&s=45\" width=\"45\" title=\"bruvv\"></a>\n<a href=\"https://github.com/carlinhoshk\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/40872405?v=4&s=45\" width=\"45\" title=\"carlinhoshk\"></a>\n<a href=\"https://github.com/cckuailong\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/10824150?v=4&s=45\" width=\"45\" title=\"cckuailong\"></a>\n<a href=\"https://github.com/chinmay7016\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/75988613?v=4&s=45\" width=\"45\" title=\"chinmay7016\"></a>\n<a href=\"https://github.com/diaodeng\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/108243171?v=4&s=45\" width=\"45\" title=\"diaodeng\"></a>\n<a href=\"https://github.com/monosans\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/76561516?v=4&s=45\" width=\"45\" title=\"monosans\"></a>\n<a href=\"https://github.com/Ayushpanditmoto\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/31253617?v=4&s=45\" width=\"45\" title=\"Ayushpanditmoto\"></a>\n<span></span>\n<img src=\"https://avatars.githubusercontent.com/u/71154407?s=45&v=4\" width=\"45\" title=\"ading2210\">\n<img src=\"https://avatars.githubusercontent.com/u/12299238?s=45&v=4\" width=\"45\" title=\"xqdoo00o\">\n<img src=\"https://avatars.githubusercontent.com/u/97126670?s=45&v=4\" width=\"45\" title=\"nathanrchn\">\n<img src=\"https://avatars.githubusercontent.com/u/81407603?v=4&s=45\" width=\"45\" title=\"dsdanielpark\">\n<img src=\"https://avatars.githubusercontent.com/u/55200481?v=4&s=45\" width=\"45\" title=\"missuo\">\n\n- The [`Vercel.py`](https://github.com/xtekky/gpt4free/blob/main/g4f/Provider/Vercel.py) file contains code from [vercel-llm-api](https://github.com/ading2210/vercel-llm-api) by [@ading2210](https://github.com/ading2210)\n- The [`har_file.py`](https://github.com/xtekky/gpt4free/blob/main/g4f/Provider/openai/har_file.py) has input from [xqdoo00o/ChatGPT-to-API](https://github.com/xqdoo00o/ChatGPT-to-API)\n- The [`PerplexityLabs.py`](https://github.com/xtekky/gpt4free/blob/main/g4f/Provider/PerplexityLabs.py) has input from [nathanrchn/perplexityai](https://github.com/nathanrchn/perplexityai)\n- The [`Gemini.py`](https://github.com/xtekky/gpt4free/blob/main/g4f/Provider/needs_auth/Gemini.py) has input from [dsdanielpark/Gemini-API](https://github.com/dsdanielpark/Gemini-API)\n- The [`MetaAI.py`](https://github.com/xtekky/gpt4free/blob/main/g4f/Provider/MetaAI.py) file contains code from [meta-ai-api](https://github.com/Strvm/meta-ai-api) by [@Strvm](https://github.com/Strvm)\n- The [`proofofwork.py`](https://github.com/xtekky/gpt4free/blob/main/g4f/Provider/openai/proofofwork.py) has input from [missuo/FreeGPT35](https://github.com/missuo/FreeGPT35)\n\n_Having input implies that the AI's code generation utilized it as one of many sources._\n\n## ©️ Copyright\n\nThis program is licensed under the [GNU GPL v3](https://www.gnu.org/licenses/gpl-3.0.txt)\n\n```\nxtekky/gpt4free: Copyright (C) 2023 xtekky\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n```\n\n## ⭐ Star History\n\n<a href=\"https://github.com/xtekky/gpt4free/stargazers\">\n        <img width=\"500\" alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=xtekky/gpt4free&type=Date\">\n</a>\n\n## 📄 License\n\n<table>\n  <tr>\n     <td>\n       <p align=\"center\"> <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/GPLv3_Logo.svg/1200px-GPLv3_Logo.svg.png\" width=\"80%\"></img>\n    </td>\n    <td> \n      <img src=\"https://img.shields.io/badge/License-GNU_GPL_v3.0-red.svg\"/> <br> \nThis project is licensed under <a href=\"https://github.com/xtekky/gpt4free/blob/main/LICENSE\">GNU_GPL_v3.0</a>.\n    </td>\n  </tr>\n</table>\n\n---\n\n<p align=\"right\">(<a href=\"#top\">🔼 Back to top</a>)</p>\n\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.3,
          "content": "## Reporting a Vulnerability\n\nReporting a Vulnerability\nPlease report (suspected) security vulnerabilities to https://t.me/xtekky. You will receive a response within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days."
        },
        {
          "name": "docker-compose-slim.yml",
          "type": "blob",
          "size": 0.5,
          "content": "version: '3'\n\nservices:\n  g4f-gui:\n    container_name: g4f-gui\n    image: hlohaus789/g4f:latest-slim\n    build:\n      context: .\n      dockerfile: docker/Dockerfile-slim\n    command: python -m g4f.cli gui -debug\n    volumes:\n      - .:/app\n    ports:\n      - '8080:8080'\n  g4f-api:\n    container_name: g4f-api\n    image: hlohaus789/g4f:latest-slim\n    build:\n      context: .\n      dockerfile: docker/Dockerfile-slim\n    command: python -m g4f.cli api\n    volumes:\n      - .:/app\n    ports:\n      - '1337:1337'"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.3,
          "content": "version: '3'\n\nservices:\n  gpt4free:\n    image: hlohaus789/g4f:latest\n    shm_size: 2gb\n    build:\n      context: .\n      dockerfile: docker/Dockerfile\n    volumes:\n      - .:/app\n    ports:\n      - '8080:8080'\n      - '1337:1337'\n      - '7900:7900'\n    environment:\n      - OLLAMA_HOST=host.docker.internal\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "etc",
          "type": "tree",
          "content": null
        },
        {
          "name": "g4f",
          "type": "tree",
          "content": null
        },
        {
          "name": "generated_images",
          "type": "tree",
          "content": null
        },
        {
          "name": "har_and_cookies",
          "type": "tree",
          "content": null
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "projects",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements-min.txt",
          "type": "blob",
          "size": 0.05,
          "content": "requests\naiohttp\nbrotli\npycryptodome\nnest_asyncio"
        },
        {
          "name": "requirements-slim.txt",
          "type": "blob",
          "size": 0.19,
          "content": "requests\npycryptodome\ncurl_cffi>=0.6.2\naiohttp\ncertifi\nduckduckgo-search>=6.3.7\nnest_asyncio\nwerkzeug\npillow\nfastapi\nuvicorn\nflask\nbrotli\nbeautifulsoup4\naiohttp_socks\ncryptography\npython-multipart"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.25,
          "content": "requests\npycryptodome\ncurl_cffi>=0.6.2\naiohttp\ncertifi\nbrowser_cookie3\nduckduckgo-search>=5.0\nnest_asyncio\nwerkzeug\npillow\nplatformdirs\nfastapi\nuvicorn\nflask\nbrotli\nbeautifulsoup4\naiohttp_socks\npywebview\ncryptography\nnodriver\npython-multipart\npypdf2\ndocx"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 4.26,
          "content": "import codecs\nimport os\n\nfrom setuptools import find_packages, setup\n\nhere = os.path.abspath(os.path.dirname(__file__))\n\nwith codecs.open(os.path.join(here, 'README.md'), encoding='utf-8') as fh:\n    long_description = '\\n' + fh.read()\n\nlong_description = long_description.replace(\"[!NOTE]\", \"\")\nlong_description = long_description.replace(\"(docs/images/\", \"(https://raw.githubusercontent.com/xtekky/gpt4free/refs/heads/main/docs/images/\")\nlong_description = long_description.replace(\"(docs/\", \"(https://github.com/xtekky/gpt4free/blob/main/docs/\")\n\nINSTALL_REQUIRE = [\n    \"requests\",\n    \"aiohttp\",\n    \"brotli\",\n    \"pycryptodome\",\n    \"nest_asyncio\",\n]\n\nEXTRA_REQUIRE = {\n    'all': [\n        \"curl_cffi>=0.6.2\",\n        \"certifi\",\n        \"browser_cookie3\",         # get_cookies\n        \"duckduckgo-search>=5.0\",  # internet.search\n        \"beautifulsoup4\",          # internet.search and bing.create_images\n        \"platformdirs\",\n        \"aiohttp_socks\",           # proxy\n        \"pillow\",                  # image\n        \"cairosvg\",                # svg image\n        \"werkzeug\", \"flask\",       # gui\n        \"fastapi\",                 # api\n        \"uvicorn\",                 # api\n        \"nodriver\",\n        \"python-multipart\",\n        \"pypdf2\", # files\n        \"docx\",\n        \"odfpy\",\n        \"ebooklib\",\n        \"openpyxl\",\n    ],\n    'slim': [\n        \"curl_cffi>=0.6.2\",\n        \"certifi\",\n        \"duckduckgo-search>=5.0\"  ,# internet.search\n        \"beautifulsoup4\",          # internet.search and bing.create_images\n        \"aiohttp_socks\",           # proxy\n        \"pillow\",                  # image\n        \"cairosvg\",                # svg image\n        \"werkzeug\", \"flask\",       # gui\n        \"fastapi\",                 # api\n        \"uvicorn\",                 # api\n        \"python-multipart\",\n        \"pypdf2\", # files\n        \"docx\",\n    ],\n    \"image\": [\n        \"pillow\",\n        \"cairosvg\",\n        \"beautifulsoup4\"\n    ],\n    \"webview\": [\n        \"pywebview\",\n        \"platformdirs\",\n        \"cryptography\"\n    ],\n    \"api\": [\n        \"loguru\", \"fastapi\",\n        \"uvicorn\",\n        \"python-multipart\",\n    ],\n    \"gui\": [\n        \"werkzeug\", \"flask\",\n        \"beautifulsoup4\", \"pillow\",\n        \"duckduckgo-search>=5.0\",\n        \"browser_cookie3\",\n    ],\n    \"search\": [\n        \"beautifulsoup4\", \"pillow\",\n        \"duckduckgo-search>=5.0\",\n    ],\n    \"local\": [\n        \"gpt4all\"\n    ],\n    \"files\": [\n        \"spacy\",\n        \"beautifulsoup4\",\n        \"pypdf2\",\n        \"docx\",\n        \"odfpy\",\n        \"ebooklib\",\n        \"openpyxl\",\n    ]\n}\n\nDESCRIPTION = (\n    'The official gpt4free repository | various collection of powerful language models'\n)\n\n# Setting up\nsetup(\n    name='g4f',\n    version=os.environ.get(\"G4F_VERSION\"),\n    author='Tekky',\n    author_email='<support@g4f.ai>',\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n    long_description=long_description,\n    packages=find_packages(),\n    package_data={\n        'g4f': ['g4f/interference/*', 'g4f/gui/client/*', 'g4f/gui/server/*', 'g4f/Provider/npm/*', 'g4f/local/models/*']\n    },\n    include_package_data=True,\n    install_requires=INSTALL_REQUIRE,\n    extras_require=EXTRA_REQUIRE,\n    entry_points={\n        'console_scripts': ['g4f=g4f.cli:main'],\n    },\n    url='https://github.com/xtekky/gpt4free',  # Link to your GitHub repository\n    project_urls={\n        'Source Code': 'https://github.com/xtekky/gpt4free',  # GitHub link\n        'Bug Tracker': 'https://github.com/xtekky/gpt4free/issues',  # Link to issue tracker\n    },\n    keywords=[\n        'python',\n        'chatbot',\n        'reverse-engineering',\n        'openai',\n        'chatbots',\n        'gpt',\n        'language-model',\n        'gpt-3',\n        'gpt3',\n        'openai-api',\n        'gpt-4',\n        'gpt4',\n        'chatgpt',\n        'chatgpt-api',\n        'openai-chatgpt',\n        'chatgpt-free',\n        'chatgpt-4',\n        'chatgpt4',\n        'chatgpt4-api',\n        'free',\n        'free-gpt',\n        'gpt4free',\n        'g4f',\n    ],\n    classifiers=[\n        'Development Status :: 2 - Pre-Alpha',\n        'Intended Audience :: Developers',\n        'Programming Language :: Python :: 3',\n        'Operating System :: Unix',\n        'Operating System :: MacOS :: MacOS X',\n        'Operating System :: Microsoft :: Windows',\n    ],\n)\n"
        }
      ]
    },
    {
      "nameWithOwner": "twitter/the-algorithm",
      "stars": 62746,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.01,
          "content": ".DS_Store\n\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 33.71,
          "content": "                    GNU AFFERO GENERAL PUBLIC LICENSE\n                       Version 3, 19 November 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU Affero General Public License is a free, copyleft license for\nsoftware and other kinds of works, specifically designed to ensure\ncooperation with the community in the case of network server software.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nour General Public Licenses are intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  Developers that use our General Public Licenses protect your rights\nwith two steps: (1) assert copyright on the software, and (2) offer\nyou this License which gives you legal permission to copy, distribute\nand/or modify the software.\n\n  A secondary benefit of defending all users' freedom is that\nimprovements made in alternate versions of the program, if they\nreceive widespread use, become available for other developers to\nincorporate.  Many developers of free software are heartened and\nencouraged by the resulting cooperation.  However, in the case of\nsoftware used on network servers, this result may fail to come about.\nThe GNU General Public License permits making a modified version and\nletting the public access it on a server without ever releasing its\nsource code to the public.\n\n  The GNU Affero General Public License is designed specifically to\nensure that, in such cases, the modified source code becomes available\nto the community.  It requires the operator of a network server to\nprovide the source code of the modified version running there to the\nusers of that server.  Therefore, public use of a modified version, on\na publicly accessible server, gives the public access to the source\ncode of the modified version.\n\n  An older license, called the Affero General Public License and\npublished by Affero, was designed to accomplish similar goals.  This is\na different license, not a version of the Affero GPL, but Affero has\nreleased a new version of the Affero GPL which permits relicensing under\nthis license.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU Affero General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Remote Network Interaction; Use with the GNU General Public License.\n\n  Notwithstanding any other provision of this License, if you modify the\nProgram, your modified version must prominently offer all users\ninteracting with it remotely through a computer network (if your version\nsupports such interaction) an opportunity to receive the Corresponding\nSource of your version by providing access to the Corresponding Source\nfrom a network server at no charge, through some standard or customary\nmeans of facilitating copying of software.  This Corresponding Source\nshall include the Corresponding Source for any work covered by version 3\nof the GNU General Public License that is incorporated pursuant to the\nfollowing paragraph.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the work with which it is combined will remain governed by version\n3 of the GNU General Public License.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU Affero General Public License from time to time.  Such new versions\nwill be similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU Affero General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU Affero General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU Affero General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU Affero General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU Affero General Public License for more details.\n\n    You should have received a copy of the GNU Affero General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If your software can interact with users remotely through a computer\nnetwork, you should also make sure that it provides a way for users to\nget its source.  For example, if your program is a web application, its\ninterface could display a \"Source\" link that leads users to an archive\nof the code.  There are many ways you could offer source, and different\nsolutions will be better for different programs; see section 13 for the\nspecific requirements.\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU AGPL, see\n<https://www.gnu.org/licenses/>.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.24,
          "content": "# Twitter's Recommendation Algorithm\n\nTwitter's Recommendation Algorithm is a set of services and jobs that are responsible for serving feeds of Tweets and other content across all Twitter product surfaces (e.g. For You Timeline, Search, Explore, Notifications). For an introduction to how the algorithm works, please refer to our [engineering blog](https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm).\n\n## Architecture\n\nProduct surfaces at Twitter are built on a shared set of data, models, and software frameworks. The shared components included in this repository are listed below:\n\n| Type | Component | Description |\n|------------|------------|------------|\n| Data | [tweetypie](tweetypie/server/README.md) | Core Tweet service that handles the reading and writing of Tweet data. |\n|      | [unified-user-actions](unified_user_actions/README.md) | Real-time stream of user actions on Twitter. |\n|      | [user-signal-service](user-signal-service/README.md) | Centralized platform to retrieve explicit (e.g. likes, replies) and implicit (e.g. profile visits, tweet clicks) user signals. |\n| Model | [SimClusters](src/scala/com/twitter/simclusters_v2/README.md) | Community detection and sparse embeddings into those communities. |\n|       | [TwHIN](https://github.com/twitter/the-algorithm-ml/blob/main/projects/twhin/README.md) | Dense knowledge graph embeddings for Users and Tweets. |\n|       | [trust-and-safety-models](trust_and_safety_models/README.md) | Models for detecting NSFW or abusive content. |\n|       | [real-graph](src/scala/com/twitter/interaction_graph/README.md) | Model to predict the likelihood of a Twitter User interacting with another User. |\n|       | [tweepcred](src/scala/com/twitter/graph/batch/job/tweepcred/README) | Page-Rank algorithm for calculating Twitter User reputation. |\n|       | [recos-injector](recos-injector/README.md) | Streaming event processor for building input streams for [GraphJet](https://github.com/twitter/GraphJet) based services. |\n|       | [graph-feature-service](graph-feature-service/README.md) | Serves graph features for a directed pair of Users (e.g. how many of User A's following liked Tweets from User B). |\n|       | [topic-social-proof](topic-social-proof/README.md) | Identifies topics related to individual Tweets. |\n|       | [representation-scorer](representation-scorer/README.md) | Compute scores between pairs of entities (Users, Tweets, etc.) using embedding similarity. |\n| Software framework | [navi](navi/README.md) | High performance, machine learning model serving written in Rust. |\n|                    | [product-mixer](product-mixer/README.md) | Software framework for building feeds of content. |\n|                    | [timelines-aggregation-framework](timelines/data_processing/ml_util/aggregation_framework/README.md) | Framework for generating aggregate features in batch or real time. |\n|                    | [representation-manager](representation-manager/README.md) | Service to retrieve embeddings (i.e. SimClusers and TwHIN). |\n|                    | [twml](twml/README.md) | Legacy machine learning framework built on TensorFlow v1. |\n\nThe product surfaces currently included in this repository are the For You Timeline and Recommended Notifications.\n\n### For You Timeline\n\nThe diagram below illustrates how major services and jobs interconnect to construct a For You Timeline.\n\n![](docs/system-diagram.png)\n\nThe core components of the For You Timeline included in this repository are listed below:\n\n| Type | Component | Description |\n|------------|------------|------------|\n| Candidate Source | [search-index](src/java/com/twitter/search/README.md) | Find and rank In-Network Tweets. ~50% of Tweets come from this candidate source. |\n|                  | [cr-mixer](cr-mixer/README.md) | Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services. |\n|                  | [user-tweet-entity-graph](src/scala/com/twitter/recos/user_tweet_entity_graph/README.md) (UTEG)| Maintains an in memory User to Tweet interaction graph, and finds candidates based on traversals of this graph. This is built on the [GraphJet](https://github.com/twitter/GraphJet) framework. Several other GraphJet based features and candidate sources are located [here](src/scala/com/twitter/recos). |\n|                  | [follow-recommendation-service](follow-recommendations-service/README.md) (FRS)| Provides Users with recommendations for accounts to follow, and Tweets from those accounts. |\n| Ranking | [light-ranker](src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/README.md) | Light Ranker model used by search index (Earlybird) to rank Tweets. |\n|         | [heavy-ranker](https://github.com/twitter/the-algorithm-ml/blob/main/projects/home/recap/README.md) | Neural network for ranking candidate tweets. One of the main signals used to select timeline Tweets post candidate sourcing. |\n| Tweet mixing & filtering | [home-mixer](home-mixer/README.md) | Main service used to construct and serve the Home Timeline. Built on [product-mixer](product-mixer/README.md). |\n|                          | [visibility-filters](visibilitylib/README.md) | Responsible for filtering Twitter content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking. |\n|                          | [timelineranker](timelineranker/README.md) | Legacy service which provides relevance-scored tweets from the Earlybird Search Index and UTEG service. |\n\n### Recommended Notifications\n\nThe core components of Recommended Notifications included in this repository are listed below:\n\n| Type | Component | Description |\n|------------|------------|------------|\n| Service | [pushservice](pushservice/README.md) | Main recommendation service at Twitter used to surface recommendations to our users via notifications.\n| Ranking | [pushservice-light-ranker](pushservice/src/main/python/models/light_ranking/README.md) | Light Ranker model used by pushservice to rank Tweets. Bridges candidate generation and heavy ranking by pre-selecting highly-relevant candidates from the initial huge candidate pool. |\n|         | [pushservice-heavy-ranker](pushservice/src/main/python/models/heavy_ranking/README.md) | Multi-task learning model to predict the probabilities that the target users will open and engage with the sent notifications. |\n\n## Build and test code\n\nWe include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file. We plan to add a more complete build and test system in the future.\n\n## Contributing\n\nWe invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official [bug bounty program](https://hackerone.com/twitter) through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better Twitter.\n\nRead our blog on the open source initiative [here](https://blog.twitter.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter).\n"
        },
        {
          "name": "RETREIVAL_SIGNALS.md",
          "type": "blob",
          "size": 5.52,
          "content": "# Signals for Candidate Sources\n\n## Overview\n\nThe candidate sourcing stage within the Twitter Recommendation algorithm serves to significantly narrow down the item size from approximately 1 billion to just a few thousand. This process utilizes Twitter user behavior as the primary input for the algorithm. This document comprehensively enumerates all the signals during the candidate sourcing phase.\n\n| Signals               |  Description                                                          |\n| :-------------------- | :-------------------------------------------------------------------- |\n| Author Follow         | The accounts which user explicit follows.                             |\n| Author Unfollow       | The accounts which user recently unfollows.                           |\n| Author Mute           | The accounts which user have muted.                                   |\n| Author Block          | The accounts which user have blocked                                  |\n| Tweet Favorite        | The tweets which user clicked the like botton.                        | \n| Tweet Unfavorite      | The tweets which user clicked the unlike botton.                      |       \n| Retweet               | The tweets which user retweeted                                       |\n| Quote Tweet           | The tweets which user retweeted with comments.                        |\n| Tweet Reply           | The tweets which user replied.                                        |\n| Tweet Share           | The tweets which user clicked the share botton.                       |\n| Tweet Bookmark        | The tweets which user clicked the bookmark botton.                    |\n| Tweet Click           | The tweets which user clicked and viewed the tweet detail page.       |\n| Tweet Video Watch     | The video tweets which user watched certain seconds or percentage.    |\n| Tweet Don't like      | The tweets which user clicked \"Not interested in this tweet\" botton.  |\n| Tweet Report          | The tweets which user clicked \"Report Tweet\" botton.                  |\n| Notification Open     | The push notification tweets which user opened.                       |\n| Ntab click            | The tweets which user click on the Notifications page.                |               \n| User AddressBook      | The author accounts identifiers of the user's addressbook.            | \n\n## Usage Details\n\nTwitter uses these user signals as training labels and/or ML features in the each candidate sourcing algorithms. The following tables shows how they are used in the each components.\n\n| Signals               | USS                | SimClusters        |  TwHin             |   UTEG             | FRS                |  Light Ranking     |\n| :-------------------- | :----------------- | :----------------- | :----------------- | :----------------- | :----------------- | :----------------- | \n| Author Follow         | Features           | Features / Labels  | Features / Labels  | Features           | Features / Labels  | N/A                |\n| Author Unfollow       | Features           | N/A                | N/A                | N/A                | N/A                | N/A                |\n| Author Mute           | Features           | N/A                | N/A                | N/A                | Features           | N/A                |\n| Author Block          | Features           | N/A                | N/A                | N/A                | Features           | N/A                |\n| Tweet Favorite        | Features           | Features           | Features / Labels  | Features           | Features / Labels  | Features / Labels  |\n| Tweet Unfavorite      | Features           | Features           | N/A                | N/A                | N/A                | N/A                |       \n| Retweet               | Features           | N/A                | Features / Labels  | Features           | Features / Labels  | Features / Labels  |\n| Quote Tweet           | Features           | N/A                | Features / Labels  | Features           | Features / Labels  | Features / Labels  |\n| Tweet Reply           | Features           | N/A                | Features           | Features           | Features / Labels  | Features           |\n| Tweet Share           | Features           | N/A                | N/A                | N/A                | Features           | N/A                |\n| Tweet Bookmark        | Features           | N/A                | N/A                | N/A                | N/A                | N/A                |\n| Tweet Click           | Features           | N/A                | N/A                | N/A                | Features           | Labels             |\n| Tweet Video Watch     | Features           | Features           | N/A                | N/A                | N/A                | Labels             |\n| Tweet Don't like      | Features           | N/A                | N/A                | N/A                | N/A                | N/A                |\n| Tweet Report          | Features           | N/A                | N/A                | N/A                | N/A                | N/A                |\n| Notification Open     | Features           | Features           | Features           | N/A                | Features           | N/A                |                       \n| Ntab click            | Features           | Features           | Features           | N/A                | Features           | N/A                |\n| User AddressBook      | N/A                | N/A                | N/A                | N/A                | Features           | N/A                |"
        },
        {
          "name": "ann",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "cr-mixer",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "follow-recommendations-service",
          "type": "tree",
          "content": null
        },
        {
          "name": "graph-feature-service",
          "type": "tree",
          "content": null
        },
        {
          "name": "home-mixer",
          "type": "tree",
          "content": null
        },
        {
          "name": "navi",
          "type": "tree",
          "content": null
        },
        {
          "name": "product-mixer",
          "type": "tree",
          "content": null
        },
        {
          "name": "pushservice",
          "type": "tree",
          "content": null
        },
        {
          "name": "recos-injector",
          "type": "tree",
          "content": null
        },
        {
          "name": "representation-manager",
          "type": "tree",
          "content": null
        },
        {
          "name": "representation-scorer",
          "type": "tree",
          "content": null
        },
        {
          "name": "science",
          "type": "tree",
          "content": null
        },
        {
          "name": "simclusters-ann",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "timelineranker",
          "type": "tree",
          "content": null
        },
        {
          "name": "timelines",
          "type": "tree",
          "content": null
        },
        {
          "name": "topic-social-proof",
          "type": "tree",
          "content": null
        },
        {
          "name": "trust_and_safety_models",
          "type": "tree",
          "content": null
        },
        {
          "name": "tweetypie",
          "type": "tree",
          "content": null
        },
        {
          "name": "twml",
          "type": "tree",
          "content": null
        },
        {
          "name": "unified_user_actions",
          "type": "tree",
          "content": null
        },
        {
          "name": "user-signal-service",
          "type": "tree",
          "content": null
        },
        {
          "name": "visibilitylib",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}